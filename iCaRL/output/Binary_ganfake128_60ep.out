----------------- Options ---------------
               add_binary: False                         
               batch_size: 32                            	[default: 64]
                   binary: True                          	[default: False]
              binary_loss: sum_b_sig                     
            binary_weight: 0.5                           
                blur_prob: 0                             
                 blur_sig: 0.5                           
          checkpoints_dir: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL/checkpoints	[default: ./checkpoints]
                class_bal: False                         
           continue_train: False                         
                 cropSize: 224                           
                 data_aug: False                         
                 dataroot: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/DoGAN_data/new/GanFake	[default: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL]
          earlystop_epoch: 5                             
                    epoch: latest                        
                 fine_tun: False                         
                    gpuid: [1]                           
                init_gain: 0.02                          
                  init_lr: 0.001                         	[default: 0.0005]
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2                           
                 jpg_prob: 0                             
                 jpg_qual: 75                            
          label_smoothing: False                         
                 loadSize: 256                           
                    mixup: False                         
              mixup_alpha: 0.1                           
                     mode: binary                        
               model_name: resnet18                      
               model_type: resnet                        
            model_weights: None                          
               multiclass: [1, 1, 0, 1, 1]               	[default: [1]]
                     name: icarl_ganfake_binary_128_ep60 	[default: experiment_name]
                nb_protos: 128                           
                  no_flip: False                         
              num_classes: 2                             
               num_epochs: 60                            	[default: 12]
              num_threads: 4                             
                  outfile: temp_0.1.csv                  
            pretrain_name:                               
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 20                            
         save_latest_freq: 2000                          
                 schedule: [20, 40, 60]                  	[default: [10]]
           serial_batches: False                         
          smoothing_alpha: 0.1                           
                   suffix:                               
                task_name: cyclegan,progan256,progan1024,glow,stargan	[default: ]
              train_split: train                         
                val_split: val                           
----------------- End -------------------
{'All': 10}
Task order: ['cyclegan', 'progan256', 'progan1024', 'glow', 'stargan']
Classes in this batch: tensor([0, 1])
Data Size: 7196


Before first epoch
  validation loss:		0.800275
  top 1 accuracy:		96.88 %
Batch of classes number 1 arrives ...
0.6776671409606934
0.306299090385437
0.22234831750392914
Batch of classes 1 out of 5 batches
Epoch 1 of 60 took 220.680s
  training loss:		0.375110
  validation loss:		1.099172
  top 1 accuracy:		28.12 %
0.29764658212661743
0.2822042405605316
0.19678299129009247
Batch of classes 1 out of 5 batches
Epoch 2 of 60 took 153.760s
  training loss:		0.274970
  validation loss:		0.943211
  top 1 accuracy:		68.75 %
0.29266124963760376
0.3666750192642212
0.11534735560417175
Batch of classes 1 out of 5 batches
Epoch 3 of 60 took 70.506s
  training loss:		0.227707
  validation loss:		4.740255
  top 1 accuracy:		75.00 %
0.17484837770462036
0.3509312868118286
0.11536131054162979
Batch of classes 1 out of 5 batches
Epoch 4 of 60 took 70.063s
  training loss:		0.220650
  validation loss:		1.278189
  top 1 accuracy:		65.62 %
0.1286739706993103
0.09874620288610458
0.28687363862991333
Batch of classes 1 out of 5 batches
Epoch 5 of 60 took 70.125s
  training loss:		0.188167
  validation loss:		0.391082
  top 1 accuracy:		100.00 %
0.15282300114631653
0.07113002240657806
0.3043642044067383
Batch of classes 1 out of 5 batches
Epoch 6 of 60 took 69.979s
  training loss:		0.137924
  validation loss:		1.448395
  top 1 accuracy:		90.62 %
0.1901272088289261
0.033700741827487946
0.09101280570030212
Batch of classes 1 out of 5 batches
Epoch 7 of 60 took 70.088s
  training loss:		0.130861
  validation loss:		0.830906
  top 1 accuracy:		100.00 %
0.14900878071784973
0.09029775857925415
0.02796122431755066
Batch of classes 1 out of 5 batches
Epoch 8 of 60 took 70.106s
  training loss:		0.117537
  validation loss:		2.043283
  top 1 accuracy:		90.62 %
0.24252045154571533
0.020779121667146683
0.013357318006455898
Batch of classes 1 out of 5 batches
Epoch 9 of 60 took 69.941s
  training loss:		0.083763
  validation loss:		1.180508
  top 1 accuracy:		100.00 %
0.073754221200943
0.13963235914707184
0.01913592964410782
Batch of classes 1 out of 5 batches
Epoch 10 of 60 took 69.986s
  training loss:		0.078029
  validation loss:		1.871986
  top 1 accuracy:		100.00 %
0.10685012489557266
0.010853496380150318
0.04881644994020462
Batch of classes 1 out of 5 batches
Epoch 11 of 60 took 70.036s
  training loss:		0.075038
  validation loss:		3.499384
  top 1 accuracy:		84.38 %
0.1167285218834877
0.028053825721144676
0.12392637133598328
Batch of classes 1 out of 5 batches
Epoch 12 of 60 took 70.029s
  training loss:		0.063578
  validation loss:		1.515464
  top 1 accuracy:		100.00 %
0.022960586473345757
0.04640857130289078
0.003938096109777689
Batch of classes 1 out of 5 batches
Epoch 13 of 60 took 69.935s
  training loss:		0.072104
  validation loss:		1.154622
  top 1 accuracy:		100.00 %
0.05937902629375458
0.020757796242833138
0.08506149053573608
Batch of classes 1 out of 5 batches
Epoch 14 of 60 took 70.191s
  training loss:		0.065984
  validation loss:		1.347635
  top 1 accuracy:		100.00 %
0.07958116382360458
0.016067631542682648
0.05392264947295189
Batch of classes 1 out of 5 batches
Epoch 15 of 60 took 70.076s
  training loss:		0.056570
  validation loss:		1.826954
  top 1 accuracy:		100.00 %
0.025732671841979027
0.013875754550099373
0.01997748576104641
Batch of classes 1 out of 5 batches
Epoch 16 of 60 took 70.080s
  training loss:		0.061185
  validation loss:		1.401099
  top 1 accuracy:		100.00 %
0.07968567311763763
0.2641853094100952
0.014294584281742573
Batch of classes 1 out of 5 batches
Epoch 17 of 60 took 71.227s
  training loss:		0.050296
  validation loss:		1.143275
  top 1 accuracy:		96.88 %
0.013127757236361504
0.0552302822470665
0.1363106369972229
Batch of classes 1 out of 5 batches
Epoch 18 of 60 took 70.146s
  training loss:		0.059113
  validation loss:		0.756157
  top 1 accuracy:		100.00 %
0.004166737198829651
0.11734475940465927
0.006756503134965897
Batch of classes 1 out of 5 batches
Epoch 19 of 60 took 70.700s
  training loss:		0.044123
  validation loss:		1.237729
  top 1 accuracy:		100.00 %
0.07813891023397446
0.009832113981246948
0.08344225585460663
Batch of classes 1 out of 5 batches
Epoch 20 of 60 took 69.446s
  training loss:		0.051205
  validation loss:		2.176025
  top 1 accuracy:		100.00 %
0.029031947255134583
0.05581985414028168
0.008576808497309685
Batch of classes 1 out of 5 batches
Epoch 21 of 60 took 69.783s
  training loss:		0.021403
  validation loss:		1.441160
  top 1 accuracy:		100.00 %
0.0021400421392172575
0.005008150823414326
0.001502562197856605
Batch of classes 1 out of 5 batches
Epoch 22 of 60 took 69.399s
  training loss:		0.016395
  validation loss:		1.467583
  top 1 accuracy:		100.00 %
0.0020043328404426575
0.005916810128837824
0.0008869584416970611
Batch of classes 1 out of 5 batches
Epoch 23 of 60 took 69.872s
  training loss:		0.013421
  validation loss:		1.575929
  top 1 accuracy:		100.00 %
0.014167848974466324
0.0003994812141172588
0.04904773086309433
Batch of classes 1 out of 5 batches
Epoch 24 of 60 took 70.093s
  training loss:		0.016793
  validation loss:		1.479508
  top 1 accuracy:		100.00 %
0.0073721217922866344
0.000415897840866819
0.0430651418864727
Batch of classes 1 out of 5 batches
Epoch 25 of 60 took 70.013s
  training loss:		0.010864
  validation loss:		1.895563
  top 1 accuracy:		100.00 %
0.0011919032549485564
0.0036515695974230766
0.0005850127199664712
Batch of classes 1 out of 5 batches
Epoch 26 of 60 took 70.140s
  training loss:		0.012130
  validation loss:		1.777681
  top 1 accuracy:		100.00 %
0.0003466940252110362
0.004128186032176018
0.0028680970426648855
Batch of classes 1 out of 5 batches
Epoch 27 of 60 took 69.878s
  training loss:		0.011770
  validation loss:		1.853604
  top 1 accuracy:		100.00 %
0.0001796161668607965
0.000451362895546481
0.0002163805766031146
Batch of classes 1 out of 5 batches
Epoch 28 of 60 took 69.979s
  training loss:		0.014657
  validation loss:		2.340514
  top 1 accuracy:		100.00 %
0.004828385543078184
0.12108652293682098
0.0036697580944746733
Batch of classes 1 out of 5 batches
Epoch 29 of 60 took 69.914s
  training loss:		0.011870
  validation loss:		2.027337
  top 1 accuracy:		100.00 %
0.0009525994537398219
0.0033330339938402176
0.02456444688141346
Batch of classes 1 out of 5 batches
Epoch 30 of 60 took 69.638s
  training loss:		0.013421
  validation loss:		1.741866
  top 1 accuracy:		100.00 %
0.025712382048368454
0.04486021399497986
0.00023770096595399082
Batch of classes 1 out of 5 batches
Epoch 31 of 60 took 69.696s
  training loss:		0.013009
  validation loss:		1.906972
  top 1 accuracy:		100.00 %
0.01289835199713707
0.00045848029549233615
0.0018532818648964167
Batch of classes 1 out of 5 batches
Epoch 32 of 60 took 69.911s
  training loss:		0.013198
  validation loss:		2.545884
  top 1 accuracy:		100.00 %
0.12308163940906525
0.0022516802418977022
0.0006208724225871265
Batch of classes 1 out of 5 batches
Epoch 33 of 60 took 70.114s
  training loss:		0.017568
  validation loss:		2.014876
  top 1 accuracy:		100.00 %
0.0028626054991036654
0.009599092416465282
0.011363315396010876
Batch of classes 1 out of 5 batches
Epoch 34 of 60 took 70.075s
  training loss:		0.022830
  validation loss:		1.944884
  top 1 accuracy:		100.00 %
0.001240596640855074
0.06158294901251793
0.0012459243880584836
Batch of classes 1 out of 5 batches
Epoch 35 of 60 took 72.260s
  training loss:		0.013787
  validation loss:		1.761384
  top 1 accuracy:		100.00 %
0.04623505845665932
0.10496526956558228
0.002027178881689906
Batch of classes 1 out of 5 batches
Epoch 36 of 60 took 70.733s
  training loss:		0.012961
  validation loss:		2.289522
  top 1 accuracy:		100.00 %
0.014216641895473003
0.0008409071015194058
0.0009007737971842289
Batch of classes 1 out of 5 batches
Epoch 37 of 60 took 70.302s
  training loss:		0.006625
  validation loss:		1.057271
  top 1 accuracy:		100.00 %
0.049769677221775055
7.167606327129761e-06
0.03279244154691696
Batch of classes 1 out of 5 batches
Epoch 38 of 60 took 70.266s
  training loss:		0.007767
  validation loss:		1.460008
  top 1 accuracy:		100.00 %
0.00019019631145056337
0.0013722153380513191
0.00731388945132494
Batch of classes 1 out of 5 batches
Epoch 39 of 60 took 69.850s
  training loss:		0.008073
  validation loss:		2.407677
  top 1 accuracy:		100.00 %
0.005044049117714167
0.00011057854862883687
0.0051690079271793365
Batch of classes 1 out of 5 batches
Epoch 40 of 60 took 70.567s
  training loss:		0.014089
  validation loss:		2.035576
  top 1 accuracy:		100.00 %
0.00025747911422513425
0.0013094327878206968
0.0009565615910105407
Batch of classes 1 out of 5 batches
Epoch 41 of 60 took 70.956s
  training loss:		0.008647
  validation loss:		2.249061
  top 1 accuracy:		100.00 %
8.552013605367392e-05
0.00033437105594202876
4.322878157836385e-05
Batch of classes 1 out of 5 batches
Epoch 42 of 60 took 69.907s
  training loss:		0.004281
  validation loss:		2.315085
  top 1 accuracy:		100.00 %
0.0005462589324451983
5.4627096687909216e-05
0.0005044860881753266
Batch of classes 1 out of 5 batches
Epoch 43 of 60 took 70.034s
  training loss:		0.005245
  validation loss:		2.157085
  top 1 accuracy:		100.00 %
0.004083668347448111
0.00048324899398721755
0.009407073259353638
Batch of classes 1 out of 5 batches
Epoch 44 of 60 took 69.821s
  training loss:		0.004452
  validation loss:		2.839438
  top 1 accuracy:		100.00 %
0.00033417297527194023
0.00011162692680954933
1.5316825738409534e-05
Batch of classes 1 out of 5 batches
Epoch 45 of 60 took 70.272s
  training loss:		0.005291
  validation loss:		2.235149
  top 1 accuracy:		100.00 %
0.004427596926689148
0.00480696652084589
6.839139678049833e-05
Batch of classes 1 out of 5 batches
Epoch 46 of 60 took 70.504s
  training loss:		0.003535
  validation loss:		2.515776
  top 1 accuracy:		100.00 %
0.0003299871168565005
4.9409904022468254e-05
0.0002885978319682181
Batch of classes 1 out of 5 batches
Epoch 47 of 60 took 70.487s
  training loss:		0.005603
  validation loss:		2.095746
  top 1 accuracy:		100.00 %
2.8440324967959896e-05
0.00024181444314308465
0.0020847490523010492
Batch of classes 1 out of 5 batches
Epoch 48 of 60 took 70.201s
  training loss:		0.004036
  validation loss:		2.087682
  top 1 accuracy:		100.00 %
0.00310885114595294
0.0005229017697274685
0.00012137128942413256
Batch of classes 1 out of 5 batches
Epoch 49 of 60 took 69.951s
  training loss:		0.004182
  validation loss:		2.294160
  top 1 accuracy:		100.00 %
0.006326125934720039
0.016517655923962593
1.2677815902861767e-05
Batch of classes 1 out of 5 batches
Epoch 50 of 60 took 70.519s
  training loss:		0.002211
  validation loss:		2.530950
  top 1 accuracy:		100.00 %
0.00031788955675438046
0.002566880313679576
0.0023879907093942165
Batch of classes 1 out of 5 batches
Epoch 51 of 60 took 70.234s
  training loss:		0.005472
  validation loss:		2.467604
  top 1 accuracy:		100.00 %
4.803646879736334e-05
0.0006229172577150166
3.7327488826122135e-05
Batch of classes 1 out of 5 batches
Epoch 52 of 60 took 69.562s
  training loss:		0.003022
  validation loss:		2.264512
  top 1 accuracy:		100.00 %
2.5953262593247928e-05
0.0001438910694560036
2.282353671034798e-05
Batch of classes 1 out of 5 batches
Epoch 53 of 60 took 69.806s
  training loss:		0.005407
  validation loss:		1.781621
  top 1 accuracy:		100.00 %
0.0004816298605874181
5.3710075007984415e-05
0.0003565173246897757
Batch of classes 1 out of 5 batches
Epoch 54 of 60 took 69.401s
  training loss:		0.003841
  validation loss:		2.204114
  top 1 accuracy:		100.00 %
1.2187729225843213e-05
0.0006757524097338319
1.979788430617191e-05
Batch of classes 1 out of 5 batches
Epoch 55 of 60 took 70.428s
  training loss:		0.002682
  validation loss:		2.210432
  top 1 accuracy:		100.00 %
0.00013644385035149753
6.548245437443256e-05
8.01563001004979e-05
Batch of classes 1 out of 5 batches
Epoch 56 of 60 took 70.478s
  training loss:		0.002220
  validation loss:		2.569259
  top 1 accuracy:		100.00 %
0.000722847820725292
0.0006530190585181117
0.002267030533403158
Batch of classes 1 out of 5 batches
Epoch 57 of 60 took 70.299s
  training loss:		0.004500
  validation loss:		1.504717
  top 1 accuracy:		100.00 %
0.0029119940008968115
4.619441824615933e-06
3.663856659841258e-06
Batch of classes 1 out of 5 batches
Epoch 58 of 60 took 70.293s
  training loss:		0.003675
  validation loss:		1.733017
  top 1 accuracy:		100.00 %
0.010699547827243805
9.26507891563233e-06
0.0004587395815178752
Batch of classes 1 out of 5 batches
Epoch 59 of 60 took 70.155s
  training loss:		0.002900
  validation loss:		2.019709
  top 1 accuracy:		100.00 %
4.761026502819732e-05
0.00022616518253926188
0.004675859119743109
Batch of classes 1 out of 5 batches
Epoch 60 of 60 took 69.751s
  training loss:		0.001339
  validation loss:		1.516530
  top 1 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(500)
tensor(399)
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		75.75 %
  top 1 accuracy Hybrid 1       :		76.73 %
  top 1 accuracy NCM            :		75.79 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		75.75 %
  top 1 accuracy Hybrid 1       :		76.73 %
  top 1 accuracy NCM            :		75.79 %
Classes in this batch: tensor([2, 3])
Data Size: 7200


Before first epoch
  validation loss:		9.278366
  top 1 accuracy:		0.00 %
Batch of classes number 2 arrives ...
2.3807785511016846
0.5533937215805054
0.4936695694923401
Batch of classes 2 out of 5 batches
Epoch 1 of 60 took 143.015s
  training loss:		0.666420
  validation loss:		0.475977
  top 1 accuracy:		87.50 %
0.46794232726097107
0.6309728026390076
0.5991056561470032
Batch of classes 2 out of 5 batches
Epoch 2 of 60 took 83.388s
  training loss:		0.525755
  validation loss:		0.850563
  top 1 accuracy:		37.50 %
0.48992103338241577
0.45970743894577026
0.3455742597579956
Batch of classes 2 out of 5 batches
Epoch 3 of 60 took 82.418s
  training loss:		0.453376
  validation loss:		0.483427
  top 1 accuracy:		59.38 %
0.34307411313056946
0.3121223747730255
0.38466984033584595
Batch of classes 2 out of 5 batches
Epoch 4 of 60 took 82.528s
  training loss:		0.364379
  validation loss:		0.266965
  top 1 accuracy:		100.00 %
0.4170339107513428
0.25391119718551636
0.3192320466041565
Batch of classes 2 out of 5 batches
Epoch 5 of 60 took 83.085s
  training loss:		0.266094
  validation loss:		0.262706
  top 1 accuracy:		81.25 %
0.21932414174079895
0.2642636001110077
0.2533184289932251
Batch of classes 2 out of 5 batches
Epoch 6 of 60 took 82.271s
  training loss:		0.233061
  validation loss:		0.407567
  top 1 accuracy:		100.00 %
0.20682698488235474
0.16532748937606812
0.17412273585796356
Batch of classes 2 out of 5 batches
Epoch 7 of 60 took 82.347s
  training loss:		0.229624
  validation loss:		0.475497
  top 1 accuracy:		90.62 %
0.14852744340896606
0.21512249112129211
0.26299265027046204
Batch of classes 2 out of 5 batches
Epoch 8 of 60 took 82.157s
  training loss:		0.208039
  validation loss:		0.070613
  top 1 accuracy:		96.88 %
0.20020490884780884
0.22657811641693115
0.25915053486824036
Batch of classes 2 out of 5 batches
Epoch 9 of 60 took 82.399s
  training loss:		0.216432
  validation loss:		0.110161
  top 1 accuracy:		100.00 %
0.17030206322669983
0.2937106192111969
0.16901016235351562
Batch of classes 2 out of 5 batches
Epoch 10 of 60 took 82.356s
  training loss:		0.234368
  validation loss:		0.440021
  top 1 accuracy:		40.62 %
0.31645289063453674
0.2025551199913025
0.1617724597454071
Batch of classes 2 out of 5 batches
Epoch 11 of 60 took 82.227s
  training loss:		0.216294
  validation loss:		0.160384
  top 1 accuracy:		96.88 %
0.28042951226234436
0.3390854299068451
0.16780632734298706
Batch of classes 2 out of 5 batches
Epoch 12 of 60 took 82.490s
  training loss:		0.204016
  validation loss:		0.120998
  top 1 accuracy:		100.00 %
0.17903350293636322
0.1778697520494461
0.2084188312292099
Batch of classes 2 out of 5 batches
Epoch 13 of 60 took 82.428s
  training loss:		0.202802
  validation loss:		0.427345
  top 1 accuracy:		96.88 %
0.3478018641471863
0.16549092531204224
0.19075101613998413
Batch of classes 2 out of 5 batches
Epoch 14 of 60 took 82.260s
  training loss:		0.234174
  validation loss:		0.252366
  top 1 accuracy:		87.50 %
0.1573074758052826
0.1494826376438141
0.13390760123729706
Batch of classes 2 out of 5 batches
Epoch 15 of 60 took 82.028s
  training loss:		0.208815
  validation loss:		0.104244
  top 1 accuracy:		100.00 %
0.24733807146549225
0.31283873319625854
0.15258358418941498
Batch of classes 2 out of 5 batches
Epoch 16 of 60 took 82.964s
  training loss:		0.212528
  validation loss:		0.495884
  top 1 accuracy:		65.62 %
0.27143537998199463
0.17302697896957397
0.22809576988220215
Batch of classes 2 out of 5 batches
Epoch 17 of 60 took 82.866s
  training loss:		0.190328
  validation loss:		0.418817
  top 1 accuracy:		56.25 %
0.17841336131095886
0.4109269380569458
0.17769666016101837
Batch of classes 2 out of 5 batches
Epoch 18 of 60 took 82.349s
  training loss:		0.234617
  validation loss:		0.095864
  top 1 accuracy:		93.75 %
0.21208316087722778
0.22722098231315613
0.1579936444759369
Batch of classes 2 out of 5 batches
Epoch 19 of 60 took 82.270s
  training loss:		0.185650
  validation loss:		0.088710
  top 1 accuracy:		100.00 %
0.19300711154937744
0.15910941362380981
0.19345039129257202
Batch of classes 2 out of 5 batches
Epoch 20 of 60 took 82.023s
  training loss:		0.179732
  validation loss:		0.081023
  top 1 accuracy:		100.00 %
0.17518678307533264
0.167442187666893
0.14550656080245972
Batch of classes 2 out of 5 batches
Epoch 21 of 60 took 82.181s
  training loss:		0.167903
  validation loss:		0.054131
  top 1 accuracy:		100.00 %
0.16938476264476776
0.17955470085144043
0.12580440938472748
Batch of classes 2 out of 5 batches
Epoch 22 of 60 took 82.321s
  training loss:		0.165390
  validation loss:		0.069668
  top 1 accuracy:		100.00 %
0.15351681411266327
0.15812431275844574
0.15569105744361877
Batch of classes 2 out of 5 batches
Epoch 23 of 60 took 82.368s
  training loss:		0.158727
  validation loss:		0.061126
  top 1 accuracy:		100.00 %
0.1752367615699768
0.1481405794620514
0.16888779401779175
Batch of classes 2 out of 5 batches
Epoch 24 of 60 took 82.323s
  training loss:		0.158102
  validation loss:		0.036182
  top 1 accuracy:		100.00 %
0.14907048642635345
0.09620115160942078
0.1525966078042984
Batch of classes 2 out of 5 batches
Epoch 25 of 60 took 82.325s
  training loss:		0.159343
  validation loss:		0.072193
  top 1 accuracy:		100.00 %
0.20967233180999756
0.1255573034286499
0.11590541899204254
Batch of classes 2 out of 5 batches
Epoch 26 of 60 took 82.400s
  training loss:		0.155794
  validation loss:		0.097818
  top 1 accuracy:		100.00 %
0.16349640488624573
0.13778841495513916
0.14359548687934875
Batch of classes 2 out of 5 batches
Epoch 27 of 60 took 82.453s
  training loss:		0.154253
  validation loss:		0.046964
  top 1 accuracy:		100.00 %
0.09169849753379822
0.19943642616271973
0.14612959325313568
Batch of classes 2 out of 5 batches
Epoch 28 of 60 took 82.184s
  training loss:		0.159297
  validation loss:		0.058255
  top 1 accuracy:		100.00 %
0.09716060757637024
0.12343725562095642
0.15710285305976868
Batch of classes 2 out of 5 batches
Epoch 29 of 60 took 97.564s
  training loss:		0.157905
  validation loss:		0.054673
  top 1 accuracy:		100.00 %
0.17269937694072723
0.17552971839904785
0.11612926423549652
Batch of classes 2 out of 5 batches
Epoch 30 of 60 took 83.386s
  training loss:		0.154201
  validation loss:		0.059877
  top 1 accuracy:		100.00 %
0.16936254501342773
0.20572063326835632
0.12679630517959595
Batch of classes 2 out of 5 batches
Epoch 31 of 60 took 82.476s
  training loss:		0.159450
  validation loss:		0.078678
  top 1 accuracy:		100.00 %
0.16157393157482147
0.19589467346668243
0.1576153188943863
Batch of classes 2 out of 5 batches
Epoch 32 of 60 took 83.223s
  training loss:		0.158886
  validation loss:		0.054332
  top 1 accuracy:		100.00 %
0.0984993502497673
0.09540463238954544
0.19179405272006989
Batch of classes 2 out of 5 batches
Epoch 33 of 60 took 83.288s
  training loss:		0.159079
  validation loss:		0.047320
  top 1 accuracy:		100.00 %
0.16794289648532867
0.14683416485786438
0.18783894181251526
Batch of classes 2 out of 5 batches
Epoch 34 of 60 took 83.041s
  training loss:		0.161283
  validation loss:		0.060457
  top 1 accuracy:		100.00 %
0.21700310707092285
0.2153494507074356
0.14444318413734436
Batch of classes 2 out of 5 batches
Epoch 35 of 60 took 82.891s
  training loss:		0.168293
  validation loss:		0.052366
  top 1 accuracy:		100.00 %
0.17559996247291565
0.1437845230102539
0.1616107076406479
Batch of classes 2 out of 5 batches
Epoch 36 of 60 took 82.817s
  training loss:		0.152896
  validation loss:		0.047693
  top 1 accuracy:		100.00 %
0.10343386232852936
0.20750652253627777
0.16428926587104797
Batch of classes 2 out of 5 batches
Epoch 37 of 60 took 82.857s
  training loss:		0.151412
  validation loss:		0.064023
  top 1 accuracy:		100.00 %
0.13753697276115417
0.14411894977092743
0.15497367084026337
Batch of classes 2 out of 5 batches
Epoch 38 of 60 took 83.290s
  training loss:		0.154356
  validation loss:		0.064726
  top 1 accuracy:		100.00 %
0.1954118311405182
0.13287100195884705
0.10340958833694458
Batch of classes 2 out of 5 batches
Epoch 39 of 60 took 82.654s
  training loss:		0.152078
  validation loss:		0.061437
  top 1 accuracy:		100.00 %
0.11397910118103027
0.19732631742954254
0.12224827706813812
Batch of classes 2 out of 5 batches
Epoch 40 of 60 took 82.325s
  training loss:		0.153341
  validation loss:		0.080186
  top 1 accuracy:		100.00 %
0.15322773158550262
0.13294143974781036
0.15544123947620392
Batch of classes 2 out of 5 batches
Epoch 41 of 60 took 82.900s
  training loss:		0.150256
  validation loss:		0.049283
  top 1 accuracy:		100.00 %
0.14025664329528809
0.135234072804451
0.15692725777626038
Batch of classes 2 out of 5 batches
Epoch 42 of 60 took 82.456s
  training loss:		0.149781
  validation loss:		0.053378
  top 1 accuracy:		100.00 %
0.1146211177110672
0.1416492611169815
0.15378664433956146
Batch of classes 2 out of 5 batches
Epoch 43 of 60 took 82.335s
  training loss:		0.150310
  validation loss:		0.058643
  top 1 accuracy:		100.00 %
0.12406735867261887
0.12403687834739685
0.1740664541721344
Batch of classes 2 out of 5 batches
Epoch 44 of 60 took 83.017s
  training loss:		0.149604
  validation loss:		0.073212
  top 1 accuracy:		100.00 %
0.0846480056643486
0.0921013355255127
0.154667466878891
Batch of classes 2 out of 5 batches
Epoch 45 of 60 took 82.363s
  training loss:		0.148622
  validation loss:		0.056006
  top 1 accuracy:		100.00 %
0.14425435662269592
0.11320265382528305
0.1230609267950058
Batch of classes 2 out of 5 batches
Epoch 46 of 60 took 82.524s
  training loss:		0.147570
  validation loss:		0.050932
  top 1 accuracy:		100.00 %
0.20398229360580444
0.16257500648498535
0.16340461373329163
Batch of classes 2 out of 5 batches
Epoch 47 of 60 took 82.431s
  training loss:		0.146160
  validation loss:		0.051839
  top 1 accuracy:		100.00 %
0.11557592451572418
0.14319777488708496
0.13373085856437683
Batch of classes 2 out of 5 batches
Epoch 48 of 60 took 82.477s
  training loss:		0.146792
  validation loss:		0.057817
  top 1 accuracy:		100.00 %
0.17301547527313232
0.10188145935535431
0.12220685929059982
Batch of classes 2 out of 5 batches
Epoch 49 of 60 took 82.816s
  training loss:		0.147964
  validation loss:		0.057980
  top 1 accuracy:		100.00 %
0.13225263357162476
0.1148829460144043
0.15284115076065063
Batch of classes 2 out of 5 batches
Epoch 50 of 60 took 82.513s
  training loss:		0.147027
  validation loss:		0.053180
  top 1 accuracy:		100.00 %
0.1543324589729309
0.17339341342449188
0.12552523612976074
Batch of classes 2 out of 5 batches
Epoch 51 of 60 took 82.655s
  training loss:		0.148038
  validation loss:		0.052383
  top 1 accuracy:		100.00 %
0.10201396048069
0.1422962099313736
0.13269445300102234
Batch of classes 2 out of 5 batches
Epoch 52 of 60 took 82.050s
  training loss:		0.147868
  validation loss:		0.055517
  top 1 accuracy:		100.00 %
0.21452546119689941
0.13389132916927338
0.11227431893348694
Batch of classes 2 out of 5 batches
Epoch 53 of 60 took 82.537s
  training loss:		0.146655
  validation loss:		0.050662
  top 1 accuracy:		100.00 %
0.12483016401529312
0.12241402268409729
0.14376521110534668
Batch of classes 2 out of 5 batches
Epoch 54 of 60 took 82.411s
  training loss:		0.148318
  validation loss:		0.055283
  top 1 accuracy:		100.00 %
0.11508014053106308
0.14022701978683472
0.14903473854064941
Batch of classes 2 out of 5 batches
Epoch 55 of 60 took 82.414s
  training loss:		0.152185
  validation loss:		0.057774
  top 1 accuracy:		100.00 %
0.11243090033531189
0.12250049412250519
0.20467022061347961
Batch of classes 2 out of 5 batches
Epoch 56 of 60 took 83.776s
  training loss:		0.148656
  validation loss:		0.052141
  top 1 accuracy:		100.00 %
0.11359171569347382
0.11844968050718307
0.17313766479492188
Batch of classes 2 out of 5 batches
Epoch 57 of 60 took 82.749s
  training loss:		0.147254
  validation loss:		0.052457
  top 1 accuracy:		100.00 %
0.18359673023223877
0.1582118570804596
0.1553017795085907
Batch of classes 2 out of 5 batches
Epoch 58 of 60 took 83.661s
  training loss:		0.148195
  validation loss:		0.052177
  top 1 accuracy:		100.00 %
0.12267851829528809
0.12238471210002899
0.10244356095790863
Batch of classes 2 out of 5 batches
Epoch 59 of 60 took 82.729s
  training loss:		0.146613
  validation loss:		0.051637
  top 1 accuracy:		100.00 %
0.1329476535320282
0.1361728310585022
0.10323586314916611
Batch of classes 2 out of 5 batches
Epoch 60 of 60 took 82.487s
  training loss:		0.146370
  validation loss:		0.058804
  top 1 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(320)
tensor(320)
tensor(320)
tensor(320)
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		75.81 %
  top 1 accuracy Hybrid 1       :		76.90 %
  top 1 accuracy NCM            :		75.73 %
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		99.81 %
  top 1 accuracy Hybrid 1       :		99.85 %
  top 1 accuracy NCM            :		99.79 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		87.81 %
  top 1 accuracy Hybrid 1       :		88.38 %
  top 1 accuracy NCM            :		87.76 %
Classes in this batch: tensor([4, 5])
Data Size: 7201


Before first epoch
  validation loss:		1.846790
  top 1 accuracy:		84.38 %
Batch of classes number 3 arrives ...
0.7434305548667908
0.2989785075187683
0.34769344329833984
Batch of classes 3 out of 5 batches
Epoch 1 of 60 took 1392.055s
  training loss:		0.347095
  validation loss:		0.155824
  top 1 accuracy:		90.62 %
0.19467628002166748
0.16470752656459808
0.28714731335639954
Batch of classes 3 out of 5 batches
Epoch 2 of 60 took 1327.852s
  training loss:		0.255030
  validation loss:		0.888651
  top 1 accuracy:		28.12 %
0.3430037498474121
0.2280808389186859
0.26430201530456543
Batch of classes 3 out of 5 batches
Epoch 3 of 60 took 1310.273s
  training loss:		0.254729
  validation loss:		0.221120
  top 1 accuracy:		87.50 %
0.394277960062027
0.22971299290657043
0.17563489079475403
Batch of classes 3 out of 5 batches
Epoch 4 of 60 took 1375.357s
  training loss:		0.228074
  validation loss:		0.303861
  top 1 accuracy:		81.25 %
0.2552329897880554
0.17889857292175293
0.2081718146800995
Batch of classes 3 out of 5 batches
Epoch 5 of 60 took 1297.525s
  training loss:		0.204427
  validation loss:		0.154440
  top 1 accuracy:		100.00 %
0.23606112599372864
0.2466888129711151
0.2446340024471283
Batch of classes 3 out of 5 batches
Epoch 6 of 60 took 1289.194s
  training loss:		0.202436
  validation loss:		0.111116
  top 1 accuracy:		96.88 %
0.20727798342704773
0.2180214524269104
0.1370561718940735
Batch of classes 3 out of 5 batches
Epoch 7 of 60 took 1302.070s
  training loss:		0.192578
  validation loss:		0.091515
  top 1 accuracy:		96.88 %
0.14918234944343567
0.3258568346500397
0.1648419201374054
Batch of classes 3 out of 5 batches
Epoch 8 of 60 took 1329.802s
  training loss:		0.207019
  validation loss:		0.158536
  top 1 accuracy:		100.00 %
0.22114092111587524
0.2854665219783783
0.16730396449565887
Batch of classes 3 out of 5 batches
Epoch 9 of 60 took 1364.190s
  training loss:		0.191706
  validation loss:		0.526860
  top 1 accuracy:		65.62 %
0.25323575735092163
0.2986874580383301
0.21115177869796753
Batch of classes 3 out of 5 batches
Epoch 10 of 60 took 1406.679s
  training loss:		0.215859
  validation loss:		0.112720
  top 1 accuracy:		100.00 %
0.23727956414222717
0.15442177653312683
0.17212024331092834
Batch of classes 3 out of 5 batches
Epoch 11 of 60 took 1350.692s
  training loss:		0.196496
  validation loss:		0.270224
  top 1 accuracy:		100.00 %
0.14632365107536316
0.1501772552728653
0.18025729060173035
Batch of classes 3 out of 5 batches
Epoch 12 of 60 took 1331.362s
  training loss:		0.188279
  validation loss:		0.296518
  top 1 accuracy:		75.00 %
0.27721643447875977
0.1758977174758911
0.2146872580051422
Batch of classes 3 out of 5 batches
Epoch 13 of 60 took 1392.874s
  training loss:		0.228010
  validation loss:		0.111885
  top 1 accuracy:		100.00 %
0.2112855315208435
0.20493659377098083
0.2073136270046234
Batch of classes 3 out of 5 batches
Epoch 14 of 60 took 1450.713s
  training loss:		0.201842
  validation loss:		0.155562
  top 1 accuracy:		100.00 %
0.3035261631011963
0.15610669553279877
0.18081219494342804
Batch of classes 3 out of 5 batches
Epoch 15 of 60 took 1688.176s
  training loss:		0.193811
  validation loss:		1.080854
  top 1 accuracy:		9.38 %
0.46787363290786743
0.22462964057922363
0.2544576823711395
Batch of classes 3 out of 5 batches
Epoch 16 of 60 took 1660.311s
  training loss:		0.248198
  validation loss:		0.089802
  top 1 accuracy:		100.00 %
0.18400704860687256
0.1903006136417389
0.1423143893480301
Batch of classes 3 out of 5 batches
Epoch 17 of 60 took 1574.386s
  training loss:		0.188700
  validation loss:		0.088617
  top 1 accuracy:		100.00 %
0.18756935000419617
0.182317852973938
0.13903991878032684
Batch of classes 3 out of 5 batches
Epoch 18 of 60 took 1575.366s
  training loss:		0.177943
  validation loss:		0.151221
  top 1 accuracy:		100.00 %
0.2172648310661316
0.1330423355102539
0.16751086711883545
Batch of classes 3 out of 5 batches
Epoch 19 of 60 took 1452.539s
  training loss:		0.206474
  validation loss:		0.197450
  top 1 accuracy:		100.00 %
0.4289856553077698
0.22487273812294006
0.11675482988357544
Batch of classes 3 out of 5 batches
Epoch 20 of 60 took 1378.582s
  training loss:		0.205394
  validation loss:		0.074468
  top 1 accuracy:		100.00 %
0.15428125858306885
0.18399354815483093
0.13430021703243256
Batch of classes 3 out of 5 batches
Epoch 21 of 60 took 1353.706s
  training loss:		0.167584
  validation loss:		0.078078
  top 1 accuracy:		100.00 %
0.1510198563337326
0.14333879947662354
0.1427704095840454
Batch of classes 3 out of 5 batches
Epoch 22 of 60 took 1301.536s
  training loss:		0.166106
  validation loss:		0.086542
  top 1 accuracy:		100.00 %
0.17029574513435364
0.1520307958126068
0.17975085973739624
Batch of classes 3 out of 5 batches
Epoch 23 of 60 took 1320.226s
  training loss:		0.168830
  validation loss:		0.071146
  top 1 accuracy:		100.00 %
0.1742822527885437
0.18289661407470703
0.1647142767906189
Batch of classes 3 out of 5 batches
Epoch 24 of 60 took 1383.666s
  training loss:		0.161256
  validation loss:		0.076132
  top 1 accuracy:		100.00 %
0.11222139000892639
0.12536777555942535
0.19868892431259155
Batch of classes 3 out of 5 batches
Epoch 25 of 60 took 1348.270s
  training loss:		0.158952
  validation loss:		0.078013
  top 1 accuracy:		100.00 %
0.14132556319236755
0.17158375680446625
0.1510297954082489
Batch of classes 3 out of 5 batches
Epoch 26 of 60 took 1348.073s
  training loss:		0.164672
  validation loss:		0.078803
  top 1 accuracy:		100.00 %
0.10776510834693909
0.14211998879909515
0.13984298706054688
Batch of classes 3 out of 5 batches
Epoch 27 of 60 took 1345.305s
  training loss:		0.156627
  validation loss:		0.073525
  top 1 accuracy:		100.00 %
0.17175427079200745
0.12156392633914948
0.19380594789981842
Batch of classes 3 out of 5 batches
Epoch 28 of 60 took 1341.797s
  training loss:		0.156763
  validation loss:		0.085194
  top 1 accuracy:		100.00 %
0.18666809797286987
0.19269675016403198
0.18904462456703186
Batch of classes 3 out of 5 batches
Epoch 29 of 60 took 1326.252s
  training loss:		0.158421
  validation loss:		0.093576
  top 1 accuracy:		100.00 %
0.17864497005939484
0.13255015015602112
0.1257091462612152
Batch of classes 3 out of 5 batches
Epoch 30 of 60 took 1325.490s
  training loss:		0.157436
  validation loss:		0.075679
  top 1 accuracy:		100.00 %
0.14559626579284668
0.17570970952510834
0.17916350066661835
Batch of classes 3 out of 5 batches
Epoch 31 of 60 took 1324.765s
  training loss:		0.157472
  validation loss:		0.064792
  top 1 accuracy:		100.00 %
0.12716491520404816
0.14797109365463257
0.1550971269607544
Batch of classes 3 out of 5 batches
Epoch 32 of 60 took 1330.535s
  training loss:		0.159680
  validation loss:		0.102308
  top 1 accuracy:		100.00 %
0.11871549487113953
0.13080532848834991
0.14655067026615143
Batch of classes 3 out of 5 batches
Epoch 33 of 60 took 1331.330s
  training loss:		0.161908
  validation loss:		0.082240
  top 1 accuracy:		100.00 %
0.14042143523693085
0.1627996563911438
0.15999558568000793
Batch of classes 3 out of 5 batches
Epoch 34 of 60 took 1362.163s
  training loss:		0.154939
  validation loss:		0.115202
  top 1 accuracy:		96.88 %
0.12576881051063538
0.18747955560684204
0.13558578491210938
Batch of classes 3 out of 5 batches
Epoch 35 of 60 took 1338.143s
  training loss:		0.158359
  validation loss:		0.058389
  top 1 accuracy:		100.00 %
0.1436629593372345
0.23046234250068665
0.17596881091594696
Batch of classes 3 out of 5 batches
Epoch 36 of 60 took 1333.756s
  training loss:		0.157701
  validation loss:		0.062775
  top 1 accuracy:		100.00 %
0.15971535444259644
0.14796331524848938
0.13645710051059723
Batch of classes 3 out of 5 batches
Epoch 37 of 60 took 1339.651s
  training loss:		0.154334
  validation loss:		0.150870
  top 1 accuracy:		96.88 %
0.17724673449993134
0.1471949964761734
0.12119118869304657
Batch of classes 3 out of 5 batches
Epoch 38 of 60 took 1346.014s
  training loss:		0.164222
  validation loss:		0.101311
  top 1 accuracy:		100.00 %
0.12557633221149445
0.18966494500637054
0.14987961947917938
Batch of classes 3 out of 5 batches
Epoch 39 of 60 took 1312.010s
  training loss:		0.155555
  validation loss:		0.072855
  top 1 accuracy:		100.00 %
0.17660430073738098
0.1302160620689392
0.17913290858268738
Batch of classes 3 out of 5 batches
Epoch 40 of 60 took 1277.476s
  training loss:		0.154547
  validation loss:		0.076754
  top 1 accuracy:		100.00 %
0.16017219424247742
0.12299618124961853
0.18328650295734406
Batch of classes 3 out of 5 batches
Epoch 41 of 60 took 1292.661s
  training loss:		0.153542
  validation loss:		0.066902
  top 1 accuracy:		100.00 %
0.13623598217964172
0.16811951994895935
0.15973711013793945
Batch of classes 3 out of 5 batches
Epoch 42 of 60 took 1278.465s
  training loss:		0.150299
  validation loss:		0.066012
  top 1 accuracy:		100.00 %
0.09682241082191467
0.18627217411994934
0.11455972492694855
Batch of classes 3 out of 5 batches
Epoch 43 of 60 took 1288.512s
  training loss:		0.149862
  validation loss:		0.061208
  top 1 accuracy:		100.00 %
0.1468072235584259
0.15454865992069244
0.1317669302225113
Batch of classes 3 out of 5 batches
Epoch 44 of 60 took 1272.021s
  training loss:		0.151361
  validation loss:		0.063454
  top 1 accuracy:		100.00 %
0.19096408784389496
0.13314273953437805
0.17164194583892822
Batch of classes 3 out of 5 batches
Epoch 45 of 60 took 1328.015s
  training loss:		0.149497
  validation loss:		0.058427
  top 1 accuracy:		100.00 %
0.1360359936952591
0.11569923907518387
0.16581006348133087
Batch of classes 3 out of 5 batches
Epoch 46 of 60 took 1336.451s
  training loss:		0.150746
  validation loss:		0.062539
  top 1 accuracy:		100.00 %
0.09584592282772064
0.0960373505949974
0.1428089737892151
Batch of classes 3 out of 5 batches
Epoch 47 of 60 took 1383.272s
  training loss:		0.148249
  validation loss:		0.065089
  top 1 accuracy:		100.00 %
0.14126518368721008
0.1354936957359314
0.14177703857421875
Batch of classes 3 out of 5 batches
Epoch 48 of 60 took 1365.318s
  training loss:		0.150655
  validation loss:		0.068301
  top 1 accuracy:		100.00 %
0.13507011532783508
0.12038947641849518
0.13749545812606812
Batch of classes 3 out of 5 batches
Epoch 49 of 60 took 1376.222s
  training loss:		0.152862
  validation loss:		0.057189
  top 1 accuracy:		100.00 %
0.13641655445098877
0.12498248368501663
0.20895688235759735
Batch of classes 3 out of 5 batches
Epoch 50 of 60 took 1412.077s
  training loss:		0.148558
  validation loss:		0.057083
  top 1 accuracy:		100.00 %
0.1031140387058258
0.17694911360740662
0.13254991173744202
slurmstepd: error: *** JOB 535705 ON biwirender13 CANCELLED AT 2022-03-02T12:10:23 ***
