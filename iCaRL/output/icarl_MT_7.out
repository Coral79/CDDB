----------------- Options ---------------
               batch_size: 32                            	[default: 64]
                   binary: False                         
                blur_prob: 0                             
                 blur_sig: 0.5                           
          checkpoints_dir: /scratch_net/kringel/chuqli/CNNDetection/checkpoints	[default: ./checkpoints]
                class_bal: False                         
           continue_train: False                         
                 cropSize: 224                           
                 data_aug: False                         
                 dataroot: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/test	[default: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL]
          earlystop_epoch: 5                             
                    epoch: latest                        
                 fine_tun: False                         
                    gpuid: [1]                           
                init_gain: 0.02                          
                  init_lr: 0.0005                        
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2                           
                 jpg_prob: 0                             
                 jpg_qual: 75                            
                 loadSize: 256                           
                     matr: results/acc_matr.npz          
                     mode: binary                        
               model_name: resnet18                      
               model_type: resnet                        
            model_weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth	[default: None]
               multiclass: [0, 0, 1, 0, 0, 0, 0]         	[default: [1]]
                     name: icarl_df                      	[default: experiment_name]
                  no_flip: False                         
              num_classes: 2                             
               num_epochs: 30                            	[default: 12]
              num_threads: 4                             
                  outfile: temp_0.1.csv                  
            pretrain_name:                               
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 20                            
         save_latest_freq: 2000                          
           serial_batches: False                         
                   suffix:                               
                task_name: gaugan,biggan,cyclegan,imle,deepfake,crn,wild	[default: ]
              train_split: train                         
                val_split: val                           
----------------- End -------------------
{'All': 14}
Task order: ['gaugan', 'biggan', 'cyclegan', 'imle', 'deepfake', 'crn', 'wild']
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Classes in this batch: tensor([0, 1])
Data Size: 6000


Before first epoch
  validation loss:		1.309705
  top 1 accuracy:		17.05 %
  top 2 accuracy:		17.30 %
Batch of classes number 1 arrives ...
1.6209393739700317
0.36133208870887756
Batch of classes 1 out of 7 batches
Epoch 1 of 30 took 39.143s
  training loss:		0.331206
  validation loss:		0.086674
  top 1 accuracy:		71.90 %
  top 2 accuracy:		99.90 %
0.08194687962532043
0.05353878065943718
Batch of classes 1 out of 7 batches
Epoch 2 of 30 took 38.330s
  training loss:		0.081573
  validation loss:		0.072241
  top 1 accuracy:		77.30 %
  top 2 accuracy:		100.00 %
0.05848673731088638
0.05825609713792801
Batch of classes 1 out of 7 batches
Epoch 3 of 30 took 38.438s
  training loss:		0.071299
  validation loss:		0.063723
  top 1 accuracy:		80.50 %
  top 2 accuracy:		100.00 %
0.04006531462073326
0.06018522381782532
Batch of classes 1 out of 7 batches
Epoch 4 of 30 took 38.391s
  training loss:		0.063378
  validation loss:		0.061992
  top 1 accuracy:		79.85 %
  top 2 accuracy:		100.00 %
0.04464320093393326
0.05406305938959122
Batch of classes 1 out of 7 batches
Epoch 5 of 30 took 38.737s
  training loss:		0.057507
  validation loss:		0.052787
  top 1 accuracy:		84.45 %
  top 2 accuracy:		100.00 %
0.05852331593632698
0.06844993680715561
Batch of classes 1 out of 7 batches
Epoch 6 of 30 took 38.054s
  training loss:		0.050007
  validation loss:		0.047780
  top 1 accuracy:		85.65 %
  top 2 accuracy:		100.00 %
0.08856035768985748
0.038921158760786057
Batch of classes 1 out of 7 batches
Epoch 7 of 30 took 38.771s
  training loss:		0.045514
  validation loss:		0.052735
  top 1 accuracy:		84.30 %
  top 2 accuracy:		100.00 %
0.07633616030216217
0.05689410865306854
Batch of classes 1 out of 7 batches
Epoch 8 of 30 took 38.338s
  training loss:		0.042452
  validation loss:		0.038848
  top 1 accuracy:		88.55 %
  top 2 accuracy:		100.00 %
0.037200503051280975
0.026756195351481438
Batch of classes 1 out of 7 batches
Epoch 9 of 30 took 37.888s
  training loss:		0.037526
  validation loss:		0.038450
  top 1 accuracy:		89.20 %
  top 2 accuracy:		100.00 %
0.04709146171808243
0.03634301573038101
Batch of classes 1 out of 7 batches
Epoch 10 of 30 took 38.107s
  training loss:		0.036245
  validation loss:		0.046606
  top 1 accuracy:		86.80 %
  top 2 accuracy:		100.00 %
0.03137354552745819
0.0238703154027462
Batch of classes 1 out of 7 batches
Epoch 11 of 30 took 38.079s
  training loss:		0.031990
  validation loss:		0.034606
  top 1 accuracy:		89.35 %
  top 2 accuracy:		100.00 %
0.015245127491652966
0.025011343881487846
Batch of classes 1 out of 7 batches
Epoch 12 of 30 took 38.445s
  training loss:		0.030454
  validation loss:		0.028894
  top 1 accuracy:		92.25 %
  top 2 accuracy:		100.00 %
0.032847993075847626
0.03151543810963631
Batch of classes 1 out of 7 batches
Epoch 13 of 30 took 38.415s
  training loss:		0.027451
  validation loss:		0.060313
  top 1 accuracy:		84.35 %
  top 2 accuracy:		100.00 %
0.01782849058508873
0.07001086324453354
Batch of classes 1 out of 7 batches
Epoch 14 of 30 took 38.777s
  training loss:		0.024232
  validation loss:		0.034243
  top 1 accuracy:		90.70 %
  top 2 accuracy:		100.00 %
0.03267746418714523
0.030335212126374245
Batch of classes 1 out of 7 batches
Epoch 15 of 30 took 38.371s
  training loss:		0.023673
  validation loss:		0.045971
  top 1 accuracy:		87.30 %
  top 2 accuracy:		100.00 %
0.01582968980073929
0.003952988423407078
Batch of classes 1 out of 7 batches
Epoch 16 of 30 took 38.145s
  training loss:		0.023197
  validation loss:		0.023944
  top 1 accuracy:		92.80 %
  top 2 accuracy:		100.00 %
0.01933530531823635
0.007664602715522051
Batch of classes 1 out of 7 batches
Epoch 17 of 30 took 38.537s
  training loss:		0.020615
  validation loss:		0.033118
  top 1 accuracy:		90.80 %
  top 2 accuracy:		100.00 %
0.031181171536445618
0.03519563004374504
Batch of classes 1 out of 7 batches
Epoch 18 of 30 took 37.399s
  training loss:		0.017810
  validation loss:		0.023049
  top 1 accuracy:		93.60 %
  top 2 accuracy:		100.00 %
0.013986730016767979
0.020434780046343803
Batch of classes 1 out of 7 batches
Epoch 19 of 30 took 38.374s
  training loss:		0.017079
  validation loss:		0.018098
  top 1 accuracy:		95.85 %
  top 2 accuracy:		100.00 %
0.004821551498025656
0.0048965271562337875
Batch of classes 1 out of 7 batches
Epoch 20 of 30 took 37.851s
  training loss:		0.015082
  validation loss:		0.017863
  top 1 accuracy:		94.80 %
  top 2 accuracy:		100.00 %
0.014112545177340508
0.01877901516854763
Batch of classes 1 out of 7 batches
Epoch 21 of 30 took 38.323s
  training loss:		0.012334
  validation loss:		0.012713
  top 1 accuracy:		96.85 %
  top 2 accuracy:		100.00 %
0.01473904401063919
0.004036925733089447
Batch of classes 1 out of 7 batches
Epoch 22 of 30 took 38.572s
  training loss:		0.010926
  validation loss:		0.012467
  top 1 accuracy:		96.50 %
  top 2 accuracy:		100.00 %
0.02808990329504013
0.01170976273715496
Batch of classes 1 out of 7 batches
Epoch 23 of 30 took 38.625s
  training loss:		0.011524
  validation loss:		0.011958
  top 1 accuracy:		96.95 %
  top 2 accuracy:		100.00 %
0.005923332646489143
0.015320058912038803
Batch of classes 1 out of 7 batches
Epoch 24 of 30 took 38.997s
  training loss:		0.010174
  validation loss:		0.011988
  top 1 accuracy:		96.85 %
  top 2 accuracy:		100.00 %
0.0035736230202019215
0.006309210322797298
Batch of classes 1 out of 7 batches
Epoch 25 of 30 took 38.719s
  training loss:		0.010453
  validation loss:		0.016125
  top 1 accuracy:		95.70 %
  top 2 accuracy:		100.00 %
0.016646170988678932
0.017230864614248276
Batch of classes 1 out of 7 batches
Epoch 26 of 30 took 37.972s
  training loss:		0.009452
  validation loss:		0.011837
  top 1 accuracy:		96.70 %
  top 2 accuracy:		100.00 %
0.006581519730389118
0.017809981480240822
Batch of classes 1 out of 7 batches
Epoch 27 of 30 took 38.732s
  training loss:		0.009050
  validation loss:		0.012040
  top 1 accuracy:		97.10 %
  top 2 accuracy:		100.00 %
0.014704587869346142
0.009727606549859047
Batch of classes 1 out of 7 batches
Epoch 28 of 30 took 38.528s
  training loss:		0.009034
  validation loss:		0.011205
  top 1 accuracy:		97.30 %
  top 2 accuracy:		100.00 %
0.01843312196433544
0.014340437948703766
Batch of classes 1 out of 7 batches
Epoch 29 of 30 took 38.658s
  training loss:		0.009128
  validation loss:		0.010675
  top 1 accuracy:		97.30 %
  top 2 accuracy:		100.00 %
0.035121720284223557
0.007041033357381821
Batch of classes 1 out of 7 batches
Epoch 30 of 30 took 38.229s
  training loss:		0.008189
  validation loss:		0.009698
  top 1 accuracy:		97.50 %
  top 2 accuracy:		100.00 %
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		97.20 %
  top 1 accuracy Hybrid 1       :		97.50 %
  top 1 accuracy NCM            :		97.25 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		97.25 %
  top 1 accuracy Hybrid 1       :		97.50 %
  top 1 accuracy NCM            :		97.30 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		97.20 %
  top 1 accuracy Hybrid 1       :		97.50 %
  top 1 accuracy NCM            :		97.25 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		97.25 %
  top 1 accuracy Hybrid 1       :		97.50 %
  top 1 accuracy NCM            :		97.30 %
Classes in this batch: tensor([2, 3])
Data Size: 2400


Before first epoch
  validation loss:		1.014845
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 2 arrives ...
0.474528431892395
0.12127669155597687
Batch of classes 2 out of 7 batches
Epoch 1 of 30 took 27.324s
  training loss:		0.191379
  validation loss:		0.550291
  top 1 accuracy:		0.00 %
  top 2 accuracy:		59.38 %
0.11069229245185852
0.11296138167381287
Batch of classes 2 out of 7 batches
Epoch 2 of 30 took 26.547s
  training loss:		0.121288
  validation loss:		0.414960
  top 1 accuracy:		1.25 %
  top 2 accuracy:		66.12 %
0.12280932813882828
0.11195147782564163
Batch of classes 2 out of 7 batches
Epoch 3 of 30 took 26.918s
  training loss:		0.117301
  validation loss:		0.455442
  top 1 accuracy:		2.00 %
  top 2 accuracy:		64.38 %
0.11146910488605499
0.09721247851848602
Batch of classes 2 out of 7 batches
Epoch 4 of 30 took 26.597s
  training loss:		0.116756
  validation loss:		0.422555
  top 1 accuracy:		1.13 %
  top 2 accuracy:		62.00 %
0.11704397946596146
0.10871011763811111
Batch of classes 2 out of 7 batches
Epoch 5 of 30 took 26.794s
  training loss:		0.116508
  validation loss:		0.471250
  top 1 accuracy:		2.13 %
  top 2 accuracy:		62.75 %
0.12737727165222168
0.10035011917352676
Batch of classes 2 out of 7 batches
Epoch 6 of 30 took 26.864s
  training loss:		0.114448
  validation loss:		0.408611
  top 1 accuracy:		3.75 %
  top 2 accuracy:		67.50 %
0.12122350931167603
0.09334976971149445
Batch of classes 2 out of 7 batches
Epoch 7 of 30 took 26.731s
  training loss:		0.113391
  validation loss:		0.437431
  top 1 accuracy:		2.75 %
  top 2 accuracy:		64.75 %
0.12220922112464905
0.10275257378816605
Batch of classes 2 out of 7 batches
Epoch 8 of 30 took 26.729s
  training loss:		0.113515
  validation loss:		0.374487
  top 1 accuracy:		5.75 %
  top 2 accuracy:		65.75 %
0.11450502276420593
0.12050523608922958
Batch of classes 2 out of 7 batches
Epoch 9 of 30 took 26.684s
  training loss:		0.112965
  validation loss:		0.342112
  top 1 accuracy:		10.37 %
  top 2 accuracy:		67.75 %
0.10650023818016052
0.1136256754398346
Batch of classes 2 out of 7 batches
Epoch 10 of 30 took 26.679s
  training loss:		0.111633
  validation loss:		0.352207
  top 1 accuracy:		11.00 %
  top 2 accuracy:		69.88 %
0.10801050812005997
0.14505742490291595
Batch of classes 2 out of 7 batches
Epoch 11 of 30 took 26.885s
  training loss:		0.113067
  validation loss:		0.400723
  top 1 accuracy:		6.50 %
  top 2 accuracy:		67.37 %
0.10739768296480179
0.09404424577951431
Batch of classes 2 out of 7 batches
Epoch 12 of 30 took 26.511s
  training loss:		0.111685
  validation loss:		0.352548
  top 1 accuracy:		8.25 %
  top 2 accuracy:		73.00 %
0.10941971093416214
0.09730277955532074
Batch of classes 2 out of 7 batches
Epoch 13 of 30 took 26.639s
  training loss:		0.109758
  validation loss:		0.336813
  top 1 accuracy:		6.75 %
  top 2 accuracy:		68.62 %
0.10980711877346039
0.10300496965646744
Batch of classes 2 out of 7 batches
Epoch 14 of 30 took 26.895s
  training loss:		0.109425
  validation loss:		0.330534
  top 1 accuracy:		9.75 %
  top 2 accuracy:		73.62 %
0.0955028384923935
0.12860806286334991
Batch of classes 2 out of 7 batches
Epoch 15 of 30 took 26.533s
  training loss:		0.109795
  validation loss:		0.323298
  top 1 accuracy:		10.13 %
  top 2 accuracy:		70.75 %
0.07667555660009384
0.11781392991542816
Batch of classes 2 out of 7 batches
Epoch 16 of 30 took 26.624s
  training loss:		0.107975
  validation loss:		0.313094
  top 1 accuracy:		11.12 %
  top 2 accuracy:		71.50 %
0.10422831028699875
0.10393404215574265
Batch of classes 2 out of 7 batches
Epoch 17 of 30 took 26.758s
  training loss:		0.107219
  validation loss:		0.325710
  top 1 accuracy:		10.00 %
  top 2 accuracy:		71.00 %
0.1270991861820221
0.08239515125751495
Batch of classes 2 out of 7 batches
Epoch 18 of 30 took 26.879s
  training loss:		0.108214
  validation loss:		0.328107
  top 1 accuracy:		10.63 %
  top 2 accuracy:		73.50 %
0.10813063383102417
0.08530524373054504
Batch of classes 2 out of 7 batches
Epoch 19 of 30 took 26.960s
  training loss:		0.108023
  validation loss:		0.376036
  top 1 accuracy:		7.12 %
  top 2 accuracy:		70.88 %
0.10552234947681427
0.10076039284467697
Batch of classes 2 out of 7 batches
Epoch 20 of 30 took 26.715s
  training loss:		0.106733
  validation loss:		0.301882
  top 1 accuracy:		16.25 %
  top 2 accuracy:		73.50 %
0.11230552941560745
0.12571905553340912
Batch of classes 2 out of 7 batches
Epoch 21 of 30 took 26.816s
  training loss:		0.100369
  validation loss:		0.318361
  top 1 accuracy:		12.62 %
  top 2 accuracy:		75.88 %
0.09881521016359329
0.11967431008815765
Batch of classes 2 out of 7 batches
Epoch 22 of 30 took 26.678s
  training loss:		0.101521
  validation loss:		0.316538
  top 1 accuracy:		14.37 %
  top 2 accuracy:		76.75 %
0.10897744446992874
0.10145319998264313
Batch of classes 2 out of 7 batches
Epoch 23 of 30 took 26.937s
  training loss:		0.101108
  validation loss:		0.310447
  top 1 accuracy:		15.50 %
  top 2 accuracy:		74.87 %
0.0819530040025711
0.09992022812366486
Batch of classes 2 out of 7 batches
Epoch 24 of 30 took 26.696s
  training loss:		0.101896
  validation loss:		0.304544
  top 1 accuracy:		15.75 %
  top 2 accuracy:		76.63 %
0.08791986852884293
0.14013522863388062
Batch of classes 2 out of 7 batches
Epoch 25 of 30 took 27.097s
  training loss:		0.101148
  validation loss:		0.317070
  top 1 accuracy:		15.50 %
  top 2 accuracy:		76.38 %
0.09359114617109299
0.09161566197872162
Batch of classes 2 out of 7 batches
Epoch 26 of 30 took 26.574s
  training loss:		0.100616
  validation loss:		0.318451
  top 1 accuracy:		11.87 %
  top 2 accuracy:		76.38 %
0.1254306435585022
0.09070374816656113
Batch of classes 2 out of 7 batches
Epoch 27 of 30 took 26.727s
  training loss:		0.099768
  validation loss:		0.312693
  top 1 accuracy:		14.12 %
  top 2 accuracy:		77.75 %
0.07656482607126236
0.09528546035289764
Batch of classes 2 out of 7 batches
Epoch 28 of 30 took 26.426s
  training loss:		0.100718
  validation loss:		0.327423
  top 1 accuracy:		12.50 %
  top 2 accuracy:		78.75 %
0.10541156679391861
0.12617214024066925
Batch of classes 2 out of 7 batches
Epoch 29 of 30 took 26.780s
  training loss:		0.098655
  validation loss:		0.316589
  top 1 accuracy:		13.75 %
  top 2 accuracy:		77.50 %
0.11231137067079544
0.10361360013484955
Batch of classes 2 out of 7 batches
Epoch 30 of 30 took 26.857s
  training loss:		0.100499
  validation loss:		0.315787
  top 1 accuracy:		15.13 %
  top 2 accuracy:		76.38 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		81.90 %
  top 1 accuracy Hybrid 1       :		93.50 %
  top 1 accuracy NCM            :		81.30 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		93.85 %
  top 1 accuracy Hybrid 1       :		97.15 %
  top 1 accuracy NCM            :		93.35 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		34.38 %
  top 1 accuracy Hybrid 1       :		15.12 %
  top 1 accuracy NCM            :		35.38 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		77.38 %
  top 1 accuracy Hybrid 1       :		64.25 %
  top 1 accuracy NCM            :		77.12 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		68.32 %
  top 1 accuracy Hybrid 1       :		71.11 %
  top 1 accuracy NCM            :		68.18 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		89.14 %
  top 1 accuracy Hybrid 1       :		87.75 %
  top 1 accuracy NCM            :		88.71 %
Classes in this batch: tensor([4, 5])
Data Size: 1572


Before first epoch
  validation loss:		1.022002
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 3 arrives ...
0.3088333308696747
0.22620655596256256
Batch of classes 3 out of 7 batches
Epoch 1 of 30 took 26.199s
  training loss:		0.241740
  validation loss:		0.455891
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
0.2017497718334198
0.18192154169082642
Batch of classes 3 out of 7 batches
Epoch 2 of 30 took 25.087s
  training loss:		0.185674
  validation loss:		0.443215
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
0.15442340075969696
0.18064942955970764
Batch of classes 3 out of 7 batches
Epoch 3 of 30 took 24.989s
  training loss:		0.183053
  validation loss:		0.448988
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.57 %
0.17047461867332458
0.18336565792560577
Batch of classes 3 out of 7 batches
Epoch 4 of 30 took 25.124s
  training loss:		0.183328
  validation loss:		0.433364
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.95 %
0.16606970131397247
0.19746817648410797
Batch of classes 3 out of 7 batches
Epoch 5 of 30 took 25.043s
  training loss:		0.183416
  validation loss:		0.432793
  top 1 accuracy:		0.00 %
  top 2 accuracy:		4.01 %
0.17126184701919556
0.18328455090522766
Batch of classes 3 out of 7 batches
Epoch 6 of 30 took 25.141s
  training loss:		0.181705
  validation loss:		0.432001
  top 1 accuracy:		0.00 %
  top 2 accuracy:		3.82 %
0.18286046385765076
0.1874195784330368
Batch of classes 3 out of 7 batches
Epoch 7 of 30 took 25.040s
  training loss:		0.181052
  validation loss:		0.440568
  top 1 accuracy:		0.00 %
  top 2 accuracy:		3.44 %
0.180487260222435
0.19512327015399933
Batch of classes 3 out of 7 batches
Epoch 8 of 30 took 25.204s
  training loss:		0.181317
  validation loss:		0.430513
  top 1 accuracy:		0.00 %
  top 2 accuracy:		6.87 %
0.18344633281230927
0.19722606241703033
Batch of classes 3 out of 7 batches
Epoch 9 of 30 took 25.207s
  training loss:		0.180552
  validation loss:		0.430495
  top 1 accuracy:		0.00 %
  top 2 accuracy:		4.20 %
0.1985047310590744
0.19129744172096252
Batch of classes 3 out of 7 batches
Epoch 10 of 30 took 25.282s
  training loss:		0.179886
  validation loss:		0.405632
  top 1 accuracy:		0.00 %
  top 2 accuracy:		4.96 %
0.17016126215457916
0.16375750303268433
Batch of classes 3 out of 7 batches
Epoch 11 of 30 took 24.932s
  training loss:		0.178773
  validation loss:		0.416940
  top 1 accuracy:		0.00 %
  top 2 accuracy:		9.54 %
0.1774335354566574
0.1742398887872696
Batch of classes 3 out of 7 batches
Epoch 12 of 30 took 25.027s
  training loss:		0.177729
  validation loss:		0.420962
  top 1 accuracy:		0.00 %
  top 2 accuracy:		6.49 %
0.19593439996242523
0.1526803821325302
Batch of classes 3 out of 7 batches
Epoch 13 of 30 took 25.171s
  training loss:		0.177129
  validation loss:		0.422709
  top 1 accuracy:		0.00 %
  top 2 accuracy:		7.06 %
0.190727099776268
0.182607039809227
Batch of classes 3 out of 7 batches
Epoch 14 of 30 took 25.079s
  training loss:		0.176774
  validation loss:		0.403931
  top 1 accuracy:		0.00 %
  top 2 accuracy:		11.07 %
0.17503134906291962
0.15217386186122894
Batch of classes 3 out of 7 batches
Epoch 15 of 30 took 25.015s
  training loss:		0.176030
  validation loss:		0.397842
  top 1 accuracy:		0.00 %
  top 2 accuracy:		9.54 %
0.18164382874965668
0.17582683265209198
Batch of classes 3 out of 7 batches
Epoch 16 of 30 took 25.264s
  training loss:		0.174893
  validation loss:		0.410102
  top 1 accuracy:		0.19 %
  top 2 accuracy:		16.41 %
0.16010145843029022
0.17034736275672913
Batch of classes 3 out of 7 batches
Epoch 17 of 30 took 25.003s
  training loss:		0.174596
  validation loss:		0.391857
  top 1 accuracy:		0.00 %
  top 2 accuracy:		9.92 %
0.1689489781856537
0.16490912437438965
Batch of classes 3 out of 7 batches
Epoch 18 of 30 took 25.353s
  training loss:		0.173307
  validation loss:		0.410472
  top 1 accuracy:		0.00 %
  top 2 accuracy:		16.03 %
0.18375615775585175
0.1727963089942932
Batch of classes 3 out of 7 batches
Epoch 19 of 30 took 25.184s
  training loss:		0.174168
  validation loss:		0.410143
  top 1 accuracy:		0.19 %
  top 2 accuracy:		18.70 %
0.1539531648159027
0.18799176812171936
Batch of classes 3 out of 7 batches
Epoch 20 of 30 took 25.154s
  training loss:		0.172641
  validation loss:		0.393664
  top 1 accuracy:		0.19 %
  top 2 accuracy:		16.98 %
0.18712158501148224
0.16578979790210724
Batch of classes 3 out of 7 batches
Epoch 21 of 30 took 25.159s
  training loss:		0.172249
  validation loss:		0.399299
  top 1 accuracy:		0.19 %
  top 2 accuracy:		19.85 %
0.16753798723220825
0.20210137963294983
Batch of classes 3 out of 7 batches
Epoch 22 of 30 took 25.205s
  training loss:		0.171143
  validation loss:		0.405630
  top 1 accuracy:		0.19 %
  top 2 accuracy:		19.47 %
0.171868234872818
0.16866901516914368
Batch of classes 3 out of 7 batches
Epoch 23 of 30 took 25.123s
  training loss:		0.170225
  validation loss:		0.401602
  top 1 accuracy:		0.19 %
  top 2 accuracy:		18.89 %
0.17735332250595093
0.15642184019088745
Batch of classes 3 out of 7 batches
Epoch 24 of 30 took 25.127s
  training loss:		0.170853
  validation loss:		0.394974
  top 1 accuracy:		0.19 %
  top 2 accuracy:		19.27 %
0.16728034615516663
0.18004287779331207
Batch of classes 3 out of 7 batches
Epoch 25 of 30 took 25.390s
  training loss:		0.170341
  validation loss:		0.387005
  top 1 accuracy:		0.19 %
  top 2 accuracy:		21.18 %
0.1731281727552414
0.1637534350156784
Batch of classes 3 out of 7 batches
Epoch 26 of 30 took 25.135s
  training loss:		0.170387
  validation loss:		0.406376
  top 1 accuracy:		0.19 %
  top 2 accuracy:		18.70 %
0.15284648537635803
0.1617843359708786
Batch of classes 3 out of 7 batches
Epoch 27 of 30 took 25.107s
  training loss:		0.169899
  validation loss:		0.393568
  top 1 accuracy:		0.38 %
  top 2 accuracy:		25.95 %
0.17938081920146942
0.17774567008018494
Batch of classes 3 out of 7 batches
Epoch 28 of 30 took 24.973s
  training loss:		0.169293
  validation loss:		0.396626
  top 1 accuracy:		0.19 %
  top 2 accuracy:		24.43 %
0.17270351946353912
0.15935936570167542
Batch of classes 3 out of 7 batches
Epoch 29 of 30 took 25.152s
  training loss:		0.169018
  validation loss:		0.385452
  top 1 accuracy:		0.19 %
  top 2 accuracy:		22.52 %
0.15926498174667358
0.14403943717479706
Batch of classes 3 out of 7 batches
Epoch 30 of 30 took 25.173s
  training loss:		0.167200
  validation loss:		0.400642
  top 1 accuracy:		0.57 %
  top 2 accuracy:		24.24 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		81.20 %
  top 1 accuracy Hybrid 1       :		91.40 %
  top 1 accuracy NCM            :		78.80 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		93.35 %
  top 1 accuracy Hybrid 1       :		95.30 %
  top 1 accuracy NCM            :		92.70 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		21.88 %
  top 1 accuracy Hybrid 1       :		9.25 %
  top 1 accuracy NCM            :		22.38 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		74.12 %
  top 1 accuracy Hybrid 1       :		57.88 %
  top 1 accuracy NCM            :		74.88 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		25.38 %
  top 1 accuracy Hybrid 1       :		0.57 %
  top 1 accuracy NCM            :		34.35 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		72.71 %
  top 1 accuracy Hybrid 1       :		54.01 %
  top 1 accuracy NCM            :		73.28 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		58.12 %
  top 1 accuracy Hybrid 1       :		57.31 %
  top 1 accuracy NCM            :		58.21 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		85.47 %
  top 1 accuracy Hybrid 1       :		79.78 %
  top 1 accuracy NCM            :		85.35 %
Classes in this batch: tensor([6, 7])
Data Size: 7656


Before first epoch
  validation loss:		1.077100
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 4 arrives ...
0.8955709338188171
0.250374436378479
0.2590181827545166
Batch of classes 4 out of 7 batches
Epoch 1 of 30 took 73.893s
  training loss:		0.295260
  validation loss:		0.304128
  top 1 accuracy:		53.41 %
  top 2 accuracy:		97.26 %
0.25145840644836426
0.23128429055213928
0.2517565190792084
Batch of classes 4 out of 7 batches
Epoch 2 of 30 took 74.136s
  training loss:		0.237619
  validation loss:		0.297953
  top 1 accuracy:		66.50 %
  top 2 accuracy:		98.28 %
0.24258239567279816
0.23350055515766144
0.24916772544384003
Batch of classes 4 out of 7 batches
Epoch 3 of 30 took 73.601s
  training loss:		0.230429
  validation loss:		0.305661
  top 1 accuracy:		76.84 %
  top 2 accuracy:		99.22 %
0.24655413627624512
0.22113092243671417
0.24518899619579315
Batch of classes 4 out of 7 batches
Epoch 4 of 30 took 73.711s
  training loss:		0.226239
  validation loss:		0.289896
  top 1 accuracy:		81.03 %
  top 2 accuracy:		98.55 %
0.21551012992858887
0.2239130735397339
0.2625056207180023
Batch of classes 4 out of 7 batches
Epoch 5 of 30 took 73.623s
  training loss:		0.222069
  validation loss:		0.280649
  top 1 accuracy:		79.47 %
  top 2 accuracy:		97.69 %
0.2217976599931717
0.2139844447374344
0.21331313252449036
Batch of classes 4 out of 7 batches
Epoch 6 of 30 took 74.038s
  training loss:		0.219854
  validation loss:		0.287405
  top 1 accuracy:		92.63 %
  top 2 accuracy:		99.65 %
0.19896617531776428
0.2187042534351349
0.20806120336055756
Batch of classes 4 out of 7 batches
Epoch 7 of 30 took 74.054s
  training loss:		0.216919
  validation loss:		0.298635
  top 1 accuracy:		89.89 %
  top 2 accuracy:		99.37 %
0.22019244730472565
0.21239826083183289
0.22329282760620117
Batch of classes 4 out of 7 batches
Epoch 8 of 30 took 73.696s
  training loss:		0.215704
  validation loss:		0.287812
  top 1 accuracy:		93.26 %
  top 2 accuracy:		99.45 %
0.22915494441986084
0.21295493841171265
0.20639964938163757
Batch of classes 4 out of 7 batches
Epoch 9 of 30 took 73.611s
  training loss:		0.215422
  validation loss:		0.286261
  top 1 accuracy:		94.98 %
  top 2 accuracy:		99.65 %
0.2228793501853943
0.2001028209924698
0.20957429707050323
Batch of classes 4 out of 7 batches
Epoch 10 of 30 took 74.027s
  training loss:		0.213781
  validation loss:		0.304378
  top 1 accuracy:		93.26 %
  top 2 accuracy:		99.84 %
0.1977914273738861
0.21057406067848206
0.21964216232299805
Batch of classes 4 out of 7 batches
Epoch 11 of 30 took 74.320s
  training loss:		0.212645
  validation loss:		0.283667
  top 1 accuracy:		95.57 %
  top 2 accuracy:		99.84 %
0.2073546200990677
0.2284790426492691
0.2165018618106842
Batch of classes 4 out of 7 batches
Epoch 12 of 30 took 74.262s
  training loss:		0.212144
  validation loss:		0.299726
  top 1 accuracy:		96.08 %
  top 2 accuracy:		99.84 %
0.22237297892570496
0.20619241893291473
0.22061049938201904
Batch of classes 4 out of 7 batches
Epoch 13 of 30 took 73.932s
  training loss:		0.212318
  validation loss:		0.280734
  top 1 accuracy:		95.85 %
  top 2 accuracy:		99.73 %
0.20976322889328003
0.19905152916908264
0.2089085876941681
Batch of classes 4 out of 7 batches
Epoch 14 of 30 took 73.783s
  training loss:		0.211050
  validation loss:		0.287016
  top 1 accuracy:		95.73 %
  top 2 accuracy:		99.73 %
0.20687490701675415
0.21506908535957336
0.2070452719926834
Batch of classes 4 out of 7 batches
Epoch 15 of 30 took 73.948s
  training loss:		0.211412
  validation loss:		0.269870
  top 1 accuracy:		95.73 %
  top 2 accuracy:		99.45 %
0.196400985121727
0.2137262523174286
0.22689935564994812
Batch of classes 4 out of 7 batches
Epoch 16 of 30 took 74.242s
  training loss:		0.209915
  validation loss:		0.293189
  top 1 accuracy:		97.10 %
  top 2 accuracy:		99.84 %
0.20227760076522827
0.20896489918231964
0.228401318192482
Batch of classes 4 out of 7 batches
Epoch 17 of 30 took 74.492s
  training loss:		0.209937
  validation loss:		0.278534
  top 1 accuracy:		98.08 %
  top 2 accuracy:		99.73 %
0.21178562939167023
0.20558558404445648
0.220182865858078
Batch of classes 4 out of 7 batches
Epoch 18 of 30 took 73.858s
  training loss:		0.209407
  validation loss:		0.284924
  top 1 accuracy:		98.43 %
  top 2 accuracy:		99.92 %
0.20777736604213715
0.20610323548316956
0.20719392597675323
Batch of classes 4 out of 7 batches
Epoch 19 of 30 took 73.899s
  training loss:		0.208318
  validation loss:		0.284360
  top 1 accuracy:		96.71 %
  top 2 accuracy:		99.69 %
0.19985796511173248
0.20630840957164764
0.22415663301944733
Batch of classes 4 out of 7 batches
Epoch 20 of 30 took 74.213s
  training loss:		0.208776
  validation loss:		0.271224
  top 1 accuracy:		96.12 %
  top 2 accuracy:		99.45 %
0.21515245735645294
0.19933530688285828
0.2111065834760666
Batch of classes 4 out of 7 batches
Epoch 21 of 30 took 73.700s
  training loss:		0.207220
  validation loss:		0.287718
  top 1 accuracy:		98.24 %
  top 2 accuracy:		99.96 %
0.21276335418224335
0.21007119119167328
0.23048576712608337
Batch of classes 4 out of 7 batches
Epoch 22 of 30 took 73.923s
  training loss:		0.206451
  validation loss:		0.284436
  top 1 accuracy:		98.32 %
  top 2 accuracy:		99.96 %
0.21603167057037354
0.2169831246137619
0.21350762248039246
Batch of classes 4 out of 7 batches
Epoch 23 of 30 took 74.195s
  training loss:		0.206849
  validation loss:		0.283000
  top 1 accuracy:		98.20 %
  top 2 accuracy:		99.96 %
0.18690212070941925
0.20038561522960663
0.22153612971305847
Batch of classes 4 out of 7 batches
Epoch 24 of 30 took 74.070s
  training loss:		0.207279
  validation loss:		0.285490
  top 1 accuracy:		98.51 %
  top 2 accuracy:		99.92 %
0.19521591067314148
0.20775826275348663
0.20090539753437042
Batch of classes 4 out of 7 batches
Epoch 25 of 30 took 74.174s
  training loss:		0.206277
  validation loss:		0.284355
  top 1 accuracy:		98.24 %
  top 2 accuracy:		99.92 %
0.21238161623477936
0.20002873241901398
0.20699720084667206
Batch of classes 4 out of 7 batches
Epoch 26 of 30 took 74.242s
  training loss:		0.206106
  validation loss:		0.290859
  top 1 accuracy:		98.12 %
  top 2 accuracy:		99.96 %
0.20169395208358765
0.2131415158510208
0.21023888885974884
Batch of classes 4 out of 7 batches
Epoch 27 of 30 took 73.943s
  training loss:		0.206838
  validation loss:		0.283981
  top 1 accuracy:		98.55 %
  top 2 accuracy:		99.96 %
0.2072494924068451
0.19846640527248383
0.22109949588775635
Batch of classes 4 out of 7 batches
Epoch 28 of 30 took 74.165s
  training loss:		0.207173
  validation loss:		0.286249
  top 1 accuracy:		98.08 %
  top 2 accuracy:		99.92 %
0.20316053926944733
0.21446511149406433
0.21598589420318604
Batch of classes 4 out of 7 batches
Epoch 29 of 30 took 74.176s
  training loss:		0.206016
  validation loss:		0.290170
  top 1 accuracy:		98.39 %
  top 2 accuracy:		99.96 %
0.20838920772075653
0.20969416201114655
0.20566555857658386
Batch of classes 4 out of 7 batches
Epoch 30 of 30 took 73.844s
  training loss:		0.205740
  validation loss:		0.281800
  top 1 accuracy:		98.39 %
  top 2 accuracy:		99.84 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		59.75 %
  top 1 accuracy Hybrid 1       :		87.40 %
  top 1 accuracy NCM            :		61.45 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		82.70 %
  top 1 accuracy Hybrid 1       :		89.75 %
  top 1 accuracy NCM            :		82.35 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		23.75 %
  top 1 accuracy Hybrid 1       :		2.50 %
  top 1 accuracy NCM            :		20.38 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		72.38 %
  top 1 accuracy Hybrid 1       :		55.12 %
  top 1 accuracy NCM            :		72.12 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		36.64 %
  top 1 accuracy Hybrid 1       :		0.57 %
  top 1 accuracy NCM            :		38.17 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		68.13 %
  top 1 accuracy Hybrid 1       :		51.91 %
  top 1 accuracy NCM            :		68.32 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		98.90 %
  top 1 accuracy Hybrid 1       :		98.39 %
  top 1 accuracy NCM            :		98.90 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.18 %
  top 1 accuracy Hybrid 1       :		99.49 %
  top 1 accuracy NCM            :		99.18 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		69.79 %
  top 1 accuracy Hybrid 1       :		72.87 %
  top 1 accuracy NCM            :		70.05 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		87.15 %
  top 1 accuracy Hybrid 1       :		85.89 %
  top 1 accuracy NCM            :		87.01 %
Classes in this batch: tensor([8, 9])
Data Size: 3248


Before first epoch
  validation loss:		1.022659
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 5 arrives ...
1.4170506000518799
0.3312623202800751
Batch of classes 5 out of 7 batches
Epoch 1 of 30 took 38.788s
  training loss:		0.386572
  validation loss:		0.588432
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.74 %
0.30228328704833984
0.3213462829589844
Batch of classes 5 out of 7 batches
Epoch 2 of 30 took 38.246s
  training loss:		0.307985
  validation loss:		0.553486
  top 1 accuracy:		0.00 %
  top 2 accuracy:		3.70 %
0.321334570646286
0.27699798345565796
Batch of classes 5 out of 7 batches
Epoch 3 of 30 took 38.575s
  training loss:		0.292655
  validation loss:		0.540811
  top 1 accuracy:		0.00 %
  top 2 accuracy:		30.68 %
0.29510265588760376
0.26856616139411926
Batch of classes 5 out of 7 batches
Epoch 4 of 30 took 38.680s
  training loss:		0.278582
  validation loss:		0.498661
  top 1 accuracy:		0.09 %
  top 2 accuracy:		64.42 %
0.24537308514118195
0.2887638807296753
Batch of classes 5 out of 7 batches
Epoch 5 of 30 took 38.792s
  training loss:		0.268032
  validation loss:		0.502984
  top 1 accuracy:		5.82 %
  top 2 accuracy:		64.60 %
0.2571384012699127
0.25065821409225464
Batch of classes 5 out of 7 batches
Epoch 6 of 30 took 38.341s
  training loss:		0.261958
  validation loss:		0.506446
  top 1 accuracy:		24.21 %
  top 2 accuracy:		75.88 %
0.24769343435764313
0.2581055164337158
Batch of classes 5 out of 7 batches
Epoch 7 of 30 took 38.732s
  training loss:		0.257217
  validation loss:		0.495879
  top 1 accuracy:		31.79 %
  top 2 accuracy:		84.29 %
0.25037822127342224
0.23640358448028564
Batch of classes 5 out of 7 batches
Epoch 8 of 30 took 38.628s
  training loss:		0.252986
  validation loss:		0.486001
  top 1 accuracy:		19.50 %
  top 2 accuracy:		82.07 %
0.23339654505252838
0.25340503454208374
Batch of classes 5 out of 7 batches
Epoch 9 of 30 took 38.675s
  training loss:		0.251352
  validation loss:		0.508052
  top 1 accuracy:		38.17 %
  top 2 accuracy:		86.32 %
0.25894781947135925
0.24584147334098816
Batch of classes 5 out of 7 batches
Epoch 10 of 30 took 38.551s
  training loss:		0.248927
  validation loss:		0.496988
  top 1 accuracy:		47.97 %
  top 2 accuracy:		89.19 %
0.23159334063529968
0.2594086527824402
Batch of classes 5 out of 7 batches
Epoch 11 of 30 took 38.674s
  training loss:		0.248616
  validation loss:		0.467970
  top 1 accuracy:		48.52 %
  top 2 accuracy:		90.11 %
0.24262258410453796
0.273230642080307
Batch of classes 5 out of 7 batches
Epoch 12 of 30 took 38.430s
  training loss:		0.245642
  validation loss:		0.504670
  top 1 accuracy:		57.58 %
  top 2 accuracy:		88.45 %
0.23745636641979218
0.24297918379306793
Batch of classes 5 out of 7 batches
Epoch 13 of 30 took 38.855s
  training loss:		0.244982
  validation loss:		0.485456
  top 1 accuracy:		59.98 %
  top 2 accuracy:		89.83 %
0.24960172176361084
0.23736822605133057
Batch of classes 5 out of 7 batches
Epoch 14 of 30 took 38.248s
  training loss:		0.243381
  validation loss:		0.509991
  top 1 accuracy:		60.07 %
  top 2 accuracy:		89.28 %
0.2324112206697464
0.24331584572792053
Batch of classes 5 out of 7 batches
Epoch 15 of 30 took 38.490s
  training loss:		0.243853
  validation loss:		0.512906
  top 1 accuracy:		69.87 %
  top 2 accuracy:		91.96 %
0.2597251832485199
0.26933956146240234
Batch of classes 5 out of 7 batches
Epoch 16 of 30 took 37.980s
  training loss:		0.242581
  validation loss:		0.515293
  top 1 accuracy:		65.16 %
  top 2 accuracy:		91.68 %
0.2530450224876404
0.24914181232452393
Batch of classes 5 out of 7 batches
Epoch 17 of 30 took 38.677s
  training loss:		0.239351
  validation loss:		0.511048
  top 1 accuracy:		73.66 %
  top 2 accuracy:		90.85 %
0.24923941493034363
0.22675319015979767
Batch of classes 5 out of 7 batches
Epoch 18 of 30 took 38.490s
  training loss:		0.241889
  validation loss:		0.500324
  top 1 accuracy:		77.82 %
  top 2 accuracy:		91.68 %
0.2440112978219986
0.23116368055343628
Batch of classes 5 out of 7 batches
Epoch 19 of 30 took 38.498s
  training loss:		0.239532
  validation loss:		0.493531
  top 1 accuracy:		76.52 %
  top 2 accuracy:		92.42 %
0.24130232632160187
0.23646217584609985
Batch of classes 5 out of 7 batches
Epoch 20 of 30 took 38.787s
  training loss:		0.237141
  validation loss:		0.511124
  top 1 accuracy:		79.11 %
  top 2 accuracy:		91.77 %
0.23382695019245148
0.22497215867042542
Batch of classes 5 out of 7 batches
Epoch 21 of 30 took 38.385s
  training loss:		0.236925
  validation loss:		0.505295
  top 1 accuracy:		78.37 %
  top 2 accuracy:		92.51 %
0.221071258187294
0.23372511565685272
Batch of classes 5 out of 7 batches
Epoch 22 of 30 took 38.467s
  training loss:		0.237305
  validation loss:		0.511520
  top 1 accuracy:		79.21 %
  top 2 accuracy:		92.70 %
0.25473645329475403
0.2221987247467041
Batch of classes 5 out of 7 batches
Epoch 23 of 30 took 38.620s
  training loss:		0.235947
  validation loss:		0.514842
  top 1 accuracy:		77.36 %
  top 2 accuracy:		91.77 %
0.24256129562854767
0.23929181694984436
Batch of classes 5 out of 7 batches
Epoch 24 of 30 took 38.629s
  training loss:		0.236366
  validation loss:		0.507837
  top 1 accuracy:		76.62 %
  top 2 accuracy:		92.14 %
0.232140451669693
0.2515565752983093
Batch of classes 5 out of 7 batches
Epoch 25 of 30 took 39.033s
  training loss:		0.236055
  validation loss:		0.511772
  top 1 accuracy:		76.89 %
  top 2 accuracy:		92.14 %
0.2552386522293091
0.24109847843647003
Batch of classes 5 out of 7 batches
Epoch 26 of 30 took 38.384s
  training loss:		0.235404
  validation loss:		0.505247
  top 1 accuracy:		76.16 %
  top 2 accuracy:		91.96 %
0.22074700891971588
0.23843038082122803
Batch of classes 5 out of 7 batches
Epoch 27 of 30 took 38.406s
  training loss:		0.234748
  validation loss:		0.510440
  top 1 accuracy:		77.54 %
  top 2 accuracy:		92.05 %
0.228047177195549
0.23042885959148407
Batch of classes 5 out of 7 batches
Epoch 28 of 30 took 38.642s
  training loss:		0.235676
  validation loss:		0.510021
  top 1 accuracy:		76.99 %
  top 2 accuracy:		91.77 %
0.23766359686851501
0.2460702806711197
Batch of classes 5 out of 7 batches
Epoch 29 of 30 took 38.608s
  training loss:		0.234652
  validation loss:		0.508803
  top 1 accuracy:		78.19 %
  top 2 accuracy:		92.24 %
0.23325158655643463
0.2398623824119568
Batch of classes 5 out of 7 batches
Epoch 30 of 30 took 38.504s
  training loss:		0.234798
  validation loss:		0.518750
  top 1 accuracy:		80.31 %
  top 2 accuracy:		92.33 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		51.25 %
  top 1 accuracy Hybrid 1       :		85.35 %
  top 1 accuracy NCM            :		58.80 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		79.00 %
  top 1 accuracy Hybrid 1       :		86.35 %
  top 1 accuracy NCM            :		79.65 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		26.37 %
  top 1 accuracy Hybrid 1       :		0.62 %
  top 1 accuracy NCM            :		17.38 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		68.88 %
  top 1 accuracy Hybrid 1       :		53.62 %
  top 1 accuracy NCM            :		69.00 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		19.66 %
  top 1 accuracy Hybrid 1       :		0.76 %
  top 1 accuracy NCM            :		19.27 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		56.30 %
  top 1 accuracy Hybrid 1       :		51.91 %
  top 1 accuracy NCM            :		55.73 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		92.55 %
  top 1 accuracy Hybrid 1       :		79.78 %
  top 1 accuracy NCM            :		92.87 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		96.16 %
  top 1 accuracy Hybrid 1       :		96.43 %
  top 1 accuracy NCM            :		95.81 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		94.82 %
  top 1 accuracy Hybrid 1       :		80.31 %
  top 1 accuracy NCM            :		95.29 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		96.30 %
  top 1 accuracy Hybrid 1       :		91.96 %
  top 1 accuracy NCM            :		96.03 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		67.94 %
  top 1 accuracy Hybrid 1       :		66.41 %
  top 1 accuracy NCM            :		69.23 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		85.11 %
  top 1 accuracy Hybrid 1       :		84.56 %
  top 1 accuracy NCM            :		85.10 %
Classes in this batch: tensor([10, 11])
Data Size: 7658


Before first epoch
  validation loss:		2.151160
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 6 arrives ...
1.083132266998291
0.2919706702232361
0.2800217866897583
Batch of classes 6 out of 7 batches
Epoch 1 of 30 took 75.855s
  training loss:		0.341252
  validation loss:		0.534023
  top 1 accuracy:		21.63 %
  top 2 accuracy:		78.06 %
0.2726424038410187
0.25882184505462646
0.30941087007522583
Batch of classes 6 out of 7 batches
Epoch 2 of 30 took 74.391s
  training loss:		0.276226
  validation loss:		0.518590
  top 1 accuracy:		41.42 %
  top 2 accuracy:		80.29 %
0.309961199760437
0.24024242162704468
0.29948821663856506
Batch of classes 6 out of 7 batches
Epoch 3 of 30 took 75.137s
  training loss:		0.271923
  validation loss:		0.530538
  top 1 accuracy:		63.56 %
  top 2 accuracy:		93.03 %
0.25145235657691956
0.2614130973815918
0.2532622218132019
Batch of classes 6 out of 7 batches
Epoch 4 of 30 took 74.602s
  training loss:		0.268371
  validation loss:		0.525088
  top 1 accuracy:		63.71 %
  top 2 accuracy:		92.08 %
0.2638748586177826
0.2701603174209595
0.284095823764801
Batch of classes 6 out of 7 batches
Epoch 5 of 30 took 75.086s
  training loss:		0.266575
  validation loss:		0.512189
  top 1 accuracy:		65.28 %
  top 2 accuracy:		92.63 %
0.29939761757850647
0.29746928811073303
0.2637217044830322
Batch of classes 6 out of 7 batches
Epoch 6 of 30 took 74.398s
  training loss:		0.265124
  validation loss:		0.521913
  top 1 accuracy:		65.52 %
  top 2 accuracy:		93.42 %
0.2738860845565796
0.2752400040626526
0.2574704587459564
Batch of classes 6 out of 7 batches
Epoch 7 of 30 took 75.363s
  training loss:		0.263551
  validation loss:		0.527767
  top 1 accuracy:		73.47 %
  top 2 accuracy:		96.08 %
0.25297898054122925
0.2779019773006439
0.28662556409835815
Batch of classes 6 out of 7 batches
Epoch 8 of 30 took 75.041s
  training loss:		0.262651
  validation loss:		0.527803
  top 1 accuracy:		78.06 %
  top 2 accuracy:		96.79 %
0.28629255294799805
0.2540019750595093
0.24536654353141785
Batch of classes 6 out of 7 batches
Epoch 9 of 30 took 75.041s
  training loss:		0.261313
  validation loss:		0.531166
  top 1 accuracy:		71.04 %
  top 2 accuracy:		93.46 %
0.2774689793586731
0.2646577060222626
0.2462679147720337
Batch of classes 6 out of 7 batches
Epoch 10 of 30 took 74.557s
  training loss:		0.260980
  validation loss:		0.527622
  top 1 accuracy:		65.95 %
  top 2 accuracy:		89.58 %
0.25572624802589417
0.2561805546283722
0.24377766251564026
Batch of classes 6 out of 7 batches
Epoch 11 of 30 took 74.864s
  training loss:		0.259894
  validation loss:		0.539276
  top 1 accuracy:		81.00 %
  top 2 accuracy:		97.06 %
0.2950250804424286
0.25961989164352417
0.2499990612268448
Batch of classes 6 out of 7 batches
Epoch 12 of 30 took 74.917s
  training loss:		0.259328
  validation loss:		0.520595
  top 1 accuracy:		78.41 %
  top 2 accuracy:		96.12 %
0.25181782245635986
0.26474377512931824
0.25231778621673584
Batch of classes 6 out of 7 batches
Epoch 13 of 30 took 75.196s
  training loss:		0.259187
  validation loss:		0.543130
  top 1 accuracy:		71.67 %
  top 2 accuracy:		95.02 %
0.24531236290931702
0.25011157989501953
0.2333136349916458
Batch of classes 6 out of 7 batches
Epoch 14 of 30 took 74.940s
  training loss:		0.259567
  validation loss:		0.534799
  top 1 accuracy:		81.27 %
  top 2 accuracy:		96.75 %
0.24638013541698456
0.25830164551734924
0.27077385783195496
Batch of classes 6 out of 7 batches
Epoch 15 of 30 took 74.869s
  training loss:		0.257853
  validation loss:		0.526243
  top 1 accuracy:		77.12 %
  top 2 accuracy:		96.71 %
0.25606030225753784
0.26660391688346863
0.23778630793094635
Batch of classes 6 out of 7 batches
Epoch 16 of 30 took 75.239s
  training loss:		0.257812
  validation loss:		0.515244
  top 1 accuracy:		73.16 %
  top 2 accuracy:		94.79 %
0.26473867893218994
0.2557797431945801
0.2773658335208893
Batch of classes 6 out of 7 batches
Epoch 17 of 30 took 74.930s
  training loss:		0.257241
  validation loss:		0.518804
  top 1 accuracy:		82.13 %
  top 2 accuracy:		98.12 %
0.2475018948316574
0.2661709189414978
0.2588691711425781
Batch of classes 6 out of 7 batches
Epoch 18 of 30 took 74.752s
  training loss:		0.256929
  validation loss:		0.529333
  top 1 accuracy:		78.41 %
  top 2 accuracy:		95.53 %
0.2584061026573181
0.25803419947624207
0.23887869715690613
Batch of classes 6 out of 7 batches
Epoch 19 of 30 took 74.807s
  training loss:		0.256851
  validation loss:		0.510806
  top 1 accuracy:		85.38 %
  top 2 accuracy:		97.06 %
0.24272334575653076
0.25116321444511414
0.23752523958683014
Batch of classes 6 out of 7 batches
Epoch 20 of 30 took 74.806s
  training loss:		0.256711
  validation loss:		0.502782
  top 1 accuracy:		84.95 %
  top 2 accuracy:		98.04 %
0.2534532845020294
0.2532840967178345
0.25822144746780396
Batch of classes 6 out of 7 batches
Epoch 21 of 30 took 74.666s
  training loss:		0.255145
  validation loss:		0.526557
  top 1 accuracy:		83.42 %
  top 2 accuracy:		97.81 %
0.2400619089603424
0.2569621801376343
0.2601500153541565
Batch of classes 6 out of 7 batches
Epoch 22 of 30 took 74.515s
  training loss:		0.255287
  validation loss:		0.517173
  top 1 accuracy:		80.05 %
  top 2 accuracy:		95.81 %
0.2636207938194275
0.2577066421508789
0.2580338418483734
Batch of classes 6 out of 7 batches
Epoch 23 of 30 took 74.846s
  training loss:		0.254973
  validation loss:		0.522257
  top 1 accuracy:		78.17 %
  top 2 accuracy:		95.77 %
0.2743555009365082
0.273478627204895
0.2613018751144409
Batch of classes 6 out of 7 batches
Epoch 24 of 30 took 74.937s
  training loss:		0.255842
  validation loss:		0.529380
  top 1 accuracy:		85.23 %
  top 2 accuracy:		97.73 %
0.2443004846572876
0.24621620774269104
0.24651624262332916
Batch of classes 6 out of 7 batches
Epoch 25 of 30 took 74.211s
  training loss:		0.255530
  validation loss:		0.520903
  top 1 accuracy:		78.92 %
  top 2 accuracy:		95.96 %
0.2367124855518341
0.2549325227737427
0.2713887691497803
Batch of classes 6 out of 7 batches
Epoch 26 of 30 took 74.513s
  training loss:		0.255486
  validation loss:		0.523886
  top 1 accuracy:		79.98 %
  top 2 accuracy:		96.59 %
0.25491610169410706
0.2586386501789093
0.2538980543613434
Batch of classes 6 out of 7 batches
Epoch 27 of 30 took 75.142s
  training loss:		0.255836
  validation loss:		0.519131
  top 1 accuracy:		78.76 %
  top 2 accuracy:		96.39 %
0.26496821641921997
0.24943608045578003
0.25001516938209534
Batch of classes 6 out of 7 batches
Epoch 28 of 30 took 74.748s
  training loss:		0.255249
  validation loss:		0.524272
  top 1 accuracy:		80.45 %
  top 2 accuracy:		96.79 %
0.25143587589263916
0.25372952222824097
0.2620394825935364
Batch of classes 6 out of 7 batches
Epoch 29 of 30 took 74.633s
  training loss:		0.254983
  validation loss:		0.530331
  top 1 accuracy:		89.97 %
  top 2 accuracy:		98.82 %
0.2796003818511963
0.26386094093322754
0.24862627685070038
Batch of classes 6 out of 7 batches
Epoch 30 of 30 took 74.116s
  training loss:		0.254984
  validation loss:		0.518684
  top 1 accuracy:		79.78 %
  top 2 accuracy:		96.28 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		49.30 %
  top 1 accuracy Hybrid 1       :		80.35 %
  top 1 accuracy NCM            :		49.10 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		77.30 %
  top 1 accuracy Hybrid 1       :		80.80 %
  top 1 accuracy NCM            :		76.70 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		29.25 %
  top 1 accuracy Hybrid 1       :		0.50 %
  top 1 accuracy NCM            :		28.88 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		66.62 %
  top 1 accuracy Hybrid 1       :		53.88 %
  top 1 accuracy NCM            :		67.38 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		23.85 %
  top 1 accuracy Hybrid 1       :		1.15 %
  top 1 accuracy NCM            :		25.19 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		61.26 %
  top 1 accuracy Hybrid 1       :		54.20 %
  top 1 accuracy NCM            :		60.50 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		57.84 %
  top 1 accuracy Hybrid 1       :		41.85 %
  top 1 accuracy NCM            :		67.63 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.18 %
  top 1 accuracy Hybrid 1       :		87.54 %
  top 1 accuracy NCM            :		99.18 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		93.90 %
  top 1 accuracy Hybrid 1       :		41.50 %
  top 1 accuracy NCM            :		94.36 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		95.01 %
  top 1 accuracy Hybrid 1       :		72.74 %
  top 1 accuracy NCM            :		95.47 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		79.55 %
  top 1 accuracy Hybrid 1       :		79.78 %
  top 1 accuracy NCM            :		72.92 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.41 %
  top 1 accuracy Hybrid 1       :		98.98 %
  top 1 accuracy NCM            :		99.37 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		61.69 %
  top 1 accuracy Hybrid 1       :		54.36 %
  top 1 accuracy NCM            :		62.60 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		89.34 %
  top 1 accuracy Hybrid 1       :		82.84 %
  top 1 accuracy NCM            :		89.27 %
Classes in this batch: tensor([12, 13])
Data Size: 6208


Before first epoch
  validation loss:		1.097454
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 7 arrives ...
1.084855556488037
0.4743932783603668
0.4547656774520874
Batch of classes 7 out of 7 batches
Epoch 1 of 30 took 61.446s
  training loss:		0.516435
  validation loss:		0.623064
  top 1 accuracy:		0.00 %
  top 2 accuracy:		1.16 %
0.44840705394744873
0.4568284749984741
0.5642368197441101
Batch of classes 7 out of 7 batches
Epoch 2 of 30 took 61.166s
  training loss:		0.462627
  validation loss:		0.633796
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.29 %
0.481132447719574
0.5072793364524841
0.4390140473842621
Batch of classes 7 out of 7 batches
Epoch 3 of 30 took 60.953s
  training loss:		0.452221
  validation loss:		0.666183
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.10 %
0.4918792247772217
0.45002639293670654
0.43249064683914185
Batch of classes 7 out of 7 batches
Epoch 4 of 30 took 60.879s
  training loss:		0.442506
  validation loss:		0.673479
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.29 %
0.44072213768959045
0.4036140739917755
0.4151298701763153
Batch of classes 7 out of 7 batches
Epoch 5 of 30 took 60.615s
  training loss:		0.434081
  validation loss:		0.676773
  top 1 accuracy:		0.00 %
  top 2 accuracy:		1.21 %
0.42444556951522827
0.45822206139564514
0.4507582187652588
Batch of classes 7 out of 7 batches
Epoch 6 of 30 took 61.213s
  training loss:		0.430845
  validation loss:		0.656203
  top 1 accuracy:		0.00 %
  top 2 accuracy:		2.18 %
0.41920486092567444
0.40853607654571533
0.4221194386482239
Batch of classes 7 out of 7 batches
Epoch 7 of 30 took 61.284s
  training loss:		0.430316
  validation loss:		0.665881
  top 1 accuracy:		0.00 %
  top 2 accuracy:		4.46 %
0.39983588457107544
0.49575984477996826
0.43307504057884216
Batch of classes 7 out of 7 batches
Epoch 8 of 30 took 61.018s
  training loss:		0.426793
  validation loss:		0.669558
  top 1 accuracy:		0.00 %
  top 2 accuracy:		4.99 %
0.4278113543987274
0.4578394293785095
0.44076043367385864
Batch of classes 7 out of 7 batches
Epoch 9 of 30 took 61.075s
  training loss:		0.425738
  validation loss:		0.659277
  top 1 accuracy:		0.00 %
  top 2 accuracy:		6.59 %
0.4086977541446686
0.39393556118011475
0.40398499369621277
Batch of classes 7 out of 7 batches
Epoch 10 of 30 took 61.581s
  training loss:		0.422783
  validation loss:		0.668442
  top 1 accuracy:		0.00 %
  top 2 accuracy:		7.76 %
0.42415279150009155
0.46105289459228516
0.43241173028945923
Batch of classes 7 out of 7 batches
Epoch 11 of 30 took 61.502s
  training loss:		0.423143
  validation loss:		0.667554
  top 1 accuracy:		0.00 %
  top 2 accuracy:		5.96 %
0.4278363287448883
0.4098162353038788
0.40381672978401184
Batch of classes 7 out of 7 batches
Epoch 12 of 30 took 61.244s
  training loss:		0.421784
  validation loss:		0.656313
  top 1 accuracy:		0.00 %
  top 2 accuracy:		11.49 %
0.4022551476955414
0.41747066378593445
0.42758065462112427
Batch of classes 7 out of 7 batches
Epoch 13 of 30 took 61.287s
  training loss:		0.419096
  validation loss:		0.655310
  top 1 accuracy:		0.00 %
  top 2 accuracy:		13.18 %
0.4198342263698578
0.3900684118270874
0.41193702816963196
Batch of classes 7 out of 7 batches
Epoch 14 of 30 took 61.550s
  training loss:		0.418581
  validation loss:		0.661560
  top 1 accuracy:		0.00 %
  top 2 accuracy:		11.00 %
0.44458234310150146
0.42283371090888977
0.4160880446434021
Batch of classes 7 out of 7 batches
Epoch 15 of 30 took 60.399s
  training loss:		0.416947
  validation loss:		0.652462
  top 1 accuracy:		0.00 %
  top 2 accuracy:		14.15 %
0.38863933086395264
0.40841013193130493
0.3886975646018982
Batch of classes 7 out of 7 batches
Epoch 16 of 30 took 61.160s
  training loss:		0.416413
  validation loss:		0.664880
  top 1 accuracy:		0.00 %
  top 2 accuracy:		14.20 %
0.4457743763923645
0.3969901502132416
0.38091742992401123
Batch of classes 7 out of 7 batches
Epoch 17 of 30 took 61.119s
  training loss:		0.414698
  validation loss:		0.675649
  top 1 accuracy:		0.00 %
  top 2 accuracy:		17.16 %
0.36766332387924194
0.39820340275764465
0.4344426691532135
Batch of classes 7 out of 7 batches
Epoch 18 of 30 took 61.110s
  training loss:		0.415166
  validation loss:		0.663199
  top 1 accuracy:		0.00 %
  top 2 accuracy:		18.66 %
0.4371732473373413
0.43558764457702637
0.4118967354297638
Batch of classes 7 out of 7 batches
Epoch 19 of 30 took 61.442s
  training loss:		0.413605
  validation loss:		0.647528
  top 1 accuracy:		0.00 %
  top 2 accuracy:		20.94 %
0.4099407494068146
0.45566192269325256
0.4261395037174225
Batch of classes 7 out of 7 batches
Epoch 20 of 30 took 60.965s
  training loss:		0.412459
  validation loss:		0.648198
  top 1 accuracy:		0.00 %
  top 2 accuracy:		21.67 %
0.4187682867050171
0.4464847445487976
0.4222696125507355
Batch of classes 7 out of 7 batches
Epoch 21 of 30 took 61.063s
  training loss:		0.410397
  validation loss:		0.657312
  top 1 accuracy:		0.00 %
  top 2 accuracy:		23.36 %
0.4234166443347931
0.4012472331523895
0.40437567234039307
Batch of classes 7 out of 7 batches
Epoch 22 of 30 took 61.415s
  training loss:		0.409542
  validation loss:		0.665639
  top 1 accuracy:		0.00 %
  top 2 accuracy:		22.93 %
0.41942018270492554
0.40678662061691284
0.3980537950992584
Batch of classes 7 out of 7 batches
Epoch 23 of 30 took 60.437s
  training loss:		0.408621
  validation loss:		0.664223
  top 1 accuracy:		0.00 %
  top 2 accuracy:		25.35 %
0.4226752817630768
0.42547833919525146
0.3868946135044098
Batch of classes 7 out of 7 batches
Epoch 24 of 30 took 61.464s
  training loss:		0.408102
  validation loss:		0.645162
  top 1 accuracy:		0.00 %
  top 2 accuracy:		25.69 %
0.4036060869693756
0.37807515263557434
0.42263856530189514
Batch of classes 7 out of 7 batches
Epoch 25 of 30 took 60.854s
  training loss:		0.408194
  validation loss:		0.646279
  top 1 accuracy:		0.00 %
  top 2 accuracy:		25.16 %
0.4270614981651306
0.4027949571609497
0.4195267856121063
Batch of classes 7 out of 7 batches
Epoch 26 of 30 took 60.692s
  training loss:		0.407836
  validation loss:		0.661686
  top 1 accuracy:		0.00 %
  top 2 accuracy:		25.21 %
0.43209829926490784
0.3937031030654907
0.40027907490730286
Batch of classes 7 out of 7 batches
Epoch 27 of 30 took 61.268s
  training loss:		0.407289
  validation loss:		0.640533
  top 1 accuracy:		0.00 %
  top 2 accuracy:		27.63 %
0.4039249122142792
0.3955305814743042
0.4069194197654724
Batch of classes 7 out of 7 batches
Epoch 28 of 30 took 61.307s
  training loss:		0.408196
  validation loss:		0.642405
  top 1 accuracy:		0.00 %
  top 2 accuracy:		28.79 %
0.38559839129447937
0.37339097261428833
0.3811260163784027
Batch of classes 7 out of 7 batches
Epoch 29 of 30 took 61.523s
  training loss:		0.407143
  validation loss:		0.664123
  top 1 accuracy:		0.00 %
  top 2 accuracy:		28.70 %
0.4036571681499481
0.42653051018714905
0.3933485448360443
Batch of classes 7 out of 7 batches
Epoch 30 of 30 took 61.083s
  training loss:		0.407885
  validation loss:		0.640678
  top 1 accuracy:		0.00 %
  top 2 accuracy:		31.46 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		30.70 %
  top 1 accuracy Hybrid 1       :		75.55 %
  top 1 accuracy NCM            :		28.30 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		75.45 %
  top 1 accuracy Hybrid 1       :		76.35 %
  top 1 accuracy NCM            :		75.30 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		12.75 %
  top 1 accuracy Hybrid 1       :		0.00 %
  top 1 accuracy NCM            :		12.88 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		63.75 %
  top 1 accuracy Hybrid 1       :		55.75 %
  top 1 accuracy NCM            :		62.75 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		3.82 %
  top 1 accuracy Hybrid 1       :		1.72 %
  top 1 accuracy NCM            :		5.73 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		55.15 %
  top 1 accuracy Hybrid 1       :		53.82 %
  top 1 accuracy NCM            :		54.20 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		57.37 %
  top 1 accuracy Hybrid 1       :		46.55 %
  top 1 accuracy NCM            :		73.35 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.14 %
  top 1 accuracy Hybrid 1       :		89.46 %
  top 1 accuracy NCM            :		98.86 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		87.06 %
  top 1 accuracy Hybrid 1       :		6.10 %
  top 1 accuracy NCM            :		87.25 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		90.11 %
  top 1 accuracy Hybrid 1       :		54.53 %
  top 1 accuracy NCM            :		90.20 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		78.88 %
  top 1 accuracy Hybrid 1       :		61.09 %
  top 1 accuracy NCM            :		62.42 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		96.43 %
  top 1 accuracy Hybrid 1       :		97.45 %
  top 1 accuracy NCM            :		96.20 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		47.60 %
  top 1 accuracy Hybrid 1       :		0.00 %
  top 1 accuracy NCM            :		47.50 %
Binary accuracy:
Final results on wild classes:
  top 1 accuracy iCaRL          :		66.41 %
  top 1 accuracy Hybrid 1       :		49.25 %
  top 1 accuracy NCM            :		66.60 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		53.03 %
  top 1 accuracy Hybrid 1       :		37.44 %
  top 1 accuracy NCM            :		52.61 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		83.33 %
  top 1 accuracy Hybrid 1       :		74.58 %
  top 1 accuracy NCM            :		83.12 %
