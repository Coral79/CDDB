----------------- Options ---------------
               add_binary: False                         
               batch_size: 32                            	[default: 64]
                   binary: False                         
                blur_prob: 0                             
                 blur_sig: 0.5                           
          checkpoints_dir: /scratch_net/kringel/chuqli/CNNDetection/checkpoints	[default: ./checkpoints]
                class_bal: False                         
           continue_train: False                         
                 cropSize: 224                           
                 data_aug: False                         
                 dataroot: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/test	[default: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL]
          earlystop_epoch: 5                             
                    epoch: latest                        
                 fine_tun: False                         
                    gpuid: [1]                           
                init_gain: 0.02                          
                  init_lr: 0.0005                        
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2                           
                 jpg_prob: 0                             
                 jpg_qual: 75                            
                 loadSize: 256                           
                     mode: binary                        
               model_name: resnet18                      
               model_type: resnet                        
            model_weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth	[default: None]
               multiclass: [0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0]	[default: [1]]
                     name: icarl_df                      	[default: experiment_name]
                  no_flip: False                         
              num_classes: 2                             
               num_epochs: 25                            	[default: 12]
              num_threads: 4                             
                  outfile: temp_0.1.csv                  
            pretrain_name:                               
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 20                            
         save_latest_freq: 2000                          
                 schedule: [10, 25, 20]                  	[default: [10]]
           serial_batches: False                         
                   suffix:                               
                task_name: gaugan,biggan,cyclegan,imle,deepfake,crn,wild,glow,stargan_gf,stylegan,whichfaceisreal,san	[default: ]
              train_split: train                         
                val_split: val                           
----------------- End -------------------
{'All': 24}
Task order: ['gaugan', 'biggan', 'cyclegan', 'imle', 'deepfake', 'crn', 'wild', 'glow', 'stargan_gf', 'stylegan', 'whichfaceisreal', 'san']
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Classes in this batch: tensor([0, 1])
Data Size: 6000


Before first epoch
  validation loss:		1.040402
  top 1 accuracy:		16.90 %
  top 2 accuracy:		17.25 %
Batch of classes number 1 arrives ...
0.7993030548095703
0.042195480316877365
Batch of classes 1 out of 12 batches
Epoch 1 of 25 took 41.365s
  training loss:		0.085426
  validation loss:		0.027662
  top 1 accuracy:		85.90 %
  top 2 accuracy:		100.00 %
0.016337554901838303
0.034353096038103104
Batch of classes 1 out of 12 batches
Epoch 2 of 25 took 39.270s
  training loss:		0.025426
  validation loss:		0.019382
  top 1 accuracy:		90.10 %
  top 2 accuracy:		100.00 %
0.04114694893360138
0.027628730982542038
Batch of classes 1 out of 12 batches
Epoch 3 of 25 took 39.298s
  training loss:		0.019040
  validation loss:		0.038070
  top 1 accuracy:		80.05 %
  top 2 accuracy:		100.00 %
0.015202682465314865
0.018047964200377464
Batch of classes 1 out of 12 batches
Epoch 4 of 25 took 39.576s
  training loss:		0.014983
  validation loss:		0.042145
  top 1 accuracy:		82.85 %
  top 2 accuracy:		100.00 %
0.008326960727572441
0.01897728256881237
Batch of classes 1 out of 12 batches
Epoch 5 of 25 took 39.481s
  training loss:		0.013343
  validation loss:		0.011898
  top 1 accuracy:		94.05 %
  top 2 accuracy:		100.00 %
0.005471080541610718
0.0046273404732346535
Batch of classes 1 out of 12 batches
Epoch 6 of 25 took 39.511s
  training loss:		0.013113
  validation loss:		0.018315
  top 1 accuracy:		91.30 %
  top 2 accuracy:		100.00 %
0.011623757891356945
0.011345716193318367
Batch of classes 1 out of 12 batches
Epoch 7 of 25 took 39.370s
  training loss:		0.010917
  validation loss:		0.032321
  top 1 accuracy:		84.65 %
  top 2 accuracy:		100.00 %
0.0056322491727769375
0.0019866933580487967
Batch of classes 1 out of 12 batches
Epoch 8 of 25 took 39.437s
  training loss:		0.010779
  validation loss:		0.020632
  top 1 accuracy:		89.15 %
  top 2 accuracy:		100.00 %
0.002068812493234873
0.026148870587348938
Batch of classes 1 out of 12 batches
Epoch 9 of 25 took 38.535s
  training loss:		0.009556
  validation loss:		0.030247
  top 1 accuracy:		85.40 %
  top 2 accuracy:		99.95 %
0.0037325702141970396
0.0075098564848303795
Batch of classes 1 out of 12 batches
Epoch 10 of 25 took 39.394s
  training loss:		0.008094
  validation loss:		0.025827
  top 1 accuracy:		87.75 %
  top 2 accuracy:		100.00 %
0.02450982853770256
0.0021345075219869614
Batch of classes 1 out of 12 batches
Epoch 11 of 25 took 39.905s
  training loss:		0.005213
  validation loss:		0.005931
  top 1 accuracy:		97.50 %
  top 2 accuracy:		100.00 %
0.0019202654948458076
0.004626511596143246
Batch of classes 1 out of 12 batches
Epoch 12 of 25 took 39.450s
  training loss:		0.003767
  validation loss:		0.003077
  top 1 accuracy:		98.70 %
  top 2 accuracy:		100.00 %
0.0007195486105047166
0.0003345875011291355
Batch of classes 1 out of 12 batches
Epoch 13 of 25 took 39.520s
  training loss:		0.003580
  validation loss:		0.004504
  top 1 accuracy:		98.10 %
  top 2 accuracy:		100.00 %
0.0034941858612000942
0.003754387143999338
Batch of classes 1 out of 12 batches
Epoch 14 of 25 took 39.684s
  training loss:		0.003411
  validation loss:		0.003308
  top 1 accuracy:		98.80 %
  top 2 accuracy:		100.00 %
0.027449335902929306
0.0014701224863529205
Batch of classes 1 out of 12 batches
Epoch 15 of 25 took 39.222s
  training loss:		0.004135
  validation loss:		0.004590
  top 1 accuracy:		97.90 %
  top 2 accuracy:		100.00 %
0.0031737503595650196
0.01550428755581379
Batch of classes 1 out of 12 batches
Epoch 16 of 25 took 39.147s
  training loss:		0.003047
  validation loss:		0.005729
  top 1 accuracy:		97.55 %
  top 2 accuracy:		100.00 %
0.00013580964878201485
0.0028065815567970276
Batch of classes 1 out of 12 batches
Epoch 17 of 25 took 38.982s
  training loss:		0.003919
  validation loss:		0.003416
  top 1 accuracy:		98.45 %
  top 2 accuracy:		100.00 %
0.008237384259700775
0.002811963204294443
Batch of classes 1 out of 12 batches
Epoch 18 of 25 took 39.415s
  training loss:		0.003286
  validation loss:		0.004047
  top 1 accuracy:		98.25 %
  top 2 accuracy:		100.00 %
0.0005649116355925798
0.002242309506982565
Batch of classes 1 out of 12 batches
Epoch 19 of 25 took 39.609s
  training loss:		0.003958
  validation loss:		0.005978
  top 1 accuracy:		97.35 %
  top 2 accuracy:		100.00 %
0.0013924918603152037
0.000564174959436059
Batch of classes 1 out of 12 batches
Epoch 20 of 25 took 39.449s
  training loss:		0.002855
  validation loss:		0.005740
  top 1 accuracy:		97.45 %
  top 2 accuracy:		100.00 %
0.005113439634442329
0.0006083607440814376
Batch of classes 1 out of 12 batches
Epoch 21 of 25 took 39.198s
  training loss:		0.001621
  validation loss:		0.001407
  top 1 accuracy:		99.60 %
  top 2 accuracy:		100.00 %
0.0005061471601948142
0.00020512714399956167
Batch of classes 1 out of 12 batches
Epoch 22 of 25 took 39.409s
  training loss:		0.001097
  validation loss:		0.002303
  top 1 accuracy:		99.25 %
  top 2 accuracy:		100.00 %
0.00028638076037168503
0.0003738696686923504
Batch of classes 1 out of 12 batches
Epoch 23 of 25 took 39.272s
  training loss:		0.001226
  validation loss:		0.002105
  top 1 accuracy:		98.95 %
  top 2 accuracy:		100.00 %
4.822520349989645e-05
0.0008077886886894703
Batch of classes 1 out of 12 batches
Epoch 24 of 25 took 39.659s
  training loss:		0.001098
  validation loss:		0.001259
  top 1 accuracy:		99.60 %
  top 2 accuracy:		100.00 %
0.0017109591281041503
0.0031492970883846283
Batch of classes 1 out of 12 batches
Epoch 25 of 25 took 39.619s
  training loss:		0.001417
  validation loss:		0.003290
  top 1 accuracy:		98.60 %
  top 2 accuracy:		100.00 %
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		98.85 %
  top 1 accuracy Hybrid 1       :		98.60 %
  top 1 accuracy NCM            :		98.85 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		98.85 %
  top 1 accuracy Hybrid 1       :		98.60 %
  top 1 accuracy NCM            :		98.85 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		98.85 %
  top 1 accuracy Hybrid 1       :		98.60 %
  top 1 accuracy NCM            :		98.85 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		98.85 %
  top 1 accuracy Hybrid 1       :		98.60 %
  top 1 accuracy NCM            :		98.85 %
Classes in this batch: tensor([2, 3])
Data Size: 2400


Before first epoch
  validation loss:		1.214123
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 2 arrives ...
0.27006199955940247
0.05059880018234253
Batch of classes 2 out of 12 batches
Epoch 1 of 25 took 28.238s
  training loss:		0.093227
  validation loss:		0.198877
  top 1 accuracy:		9.75 %
  top 2 accuracy:		76.25 %
0.06426006555557251
0.04760384559631348
Batch of classes 2 out of 12 batches
Epoch 2 of 25 took 26.977s
  training loss:		0.061170
  validation loss:		0.200414
  top 1 accuracy:		19.37 %
  top 2 accuracy:		84.75 %
0.06434699892997742
0.034202225506305695
Batch of classes 2 out of 12 batches
Epoch 3 of 25 took 26.769s
  training loss:		0.052863
  validation loss:		0.192521
  top 1 accuracy:		43.13 %
  top 2 accuracy:		92.50 %
0.05547415465116501
0.04621913284063339
Batch of classes 2 out of 12 batches
Epoch 4 of 25 took 26.937s
  training loss:		0.046715
  validation loss:		0.203890
  top 1 accuracy:		33.13 %
  top 2 accuracy:		86.87 %
0.03509879857301712
0.038292042911052704
Batch of classes 2 out of 12 batches
Epoch 5 of 25 took 26.638s
  training loss:		0.043238
  validation loss:		0.313435
  top 1 accuracy:		43.50 %
  top 2 accuracy:		94.25 %
0.03141140565276146
0.032374970614910126
Batch of classes 2 out of 12 batches
Epoch 6 of 25 took 26.938s
  training loss:		0.039890
  validation loss:		0.175413
  top 1 accuracy:		34.38 %
  top 2 accuracy:		88.00 %
0.03761812299489975
0.0318293422460556
Batch of classes 2 out of 12 batches
Epoch 7 of 25 took 26.898s
  training loss:		0.038937
  validation loss:		0.199509
  top 1 accuracy:		53.87 %
  top 2 accuracy:		91.87 %
0.030706752091646194
0.03478669375181198
Batch of classes 2 out of 12 batches
Epoch 8 of 25 took 26.782s
  training loss:		0.036772
  validation loss:		0.209666
  top 1 accuracy:		55.75 %
  top 2 accuracy:		90.62 %
0.026023712009191513
0.027233362197875977
Batch of classes 2 out of 12 batches
Epoch 9 of 25 took 27.080s
  training loss:		0.038332
  validation loss:		0.223222
  top 1 accuracy:		46.88 %
  top 2 accuracy:		97.37 %
0.05185741186141968
0.03794441372156143
Batch of classes 2 out of 12 batches
Epoch 10 of 25 took 26.786s
  training loss:		0.036226
  validation loss:		0.168503
  top 1 accuracy:		45.38 %
  top 2 accuracy:		91.62 %
0.04717903584241867
0.03187188506126404
Batch of classes 2 out of 12 batches
Epoch 11 of 25 took 27.114s
  training loss:		0.030948
  validation loss:		0.165423
  top 1 accuracy:		60.62 %
  top 2 accuracy:		97.37 %
0.02495366893708706
0.029590120539069176
Batch of classes 2 out of 12 batches
Epoch 12 of 25 took 27.191s
  training loss:		0.026843
  validation loss:		0.171553
  top 1 accuracy:		62.63 %
  top 2 accuracy:		98.50 %
0.020999711006879807
0.019839894026517868
Batch of classes 2 out of 12 batches
Epoch 13 of 25 took 27.069s
  training loss:		0.026690
  validation loss:		0.179384
  top 1 accuracy:		62.37 %
  top 2 accuracy:		97.62 %
0.028076063841581345
0.02610642835497856
Batch of classes 2 out of 12 batches
Epoch 14 of 25 took 26.733s
  training loss:		0.029271
  validation loss:		0.163064
  top 1 accuracy:		67.62 %
  top 2 accuracy:		97.75 %
0.03260783106088638
0.039880529046058655
Batch of classes 2 out of 12 batches
Epoch 15 of 25 took 27.027s
  training loss:		0.025835
  validation loss:		0.165928
  top 1 accuracy:		73.37 %
  top 2 accuracy:		98.00 %
0.024188941344618797
0.023824915289878845
Batch of classes 2 out of 12 batches
Epoch 16 of 25 took 26.971s
  training loss:		0.025107
  validation loss:		0.145312
  top 1 accuracy:		69.88 %
  top 2 accuracy:		94.63 %
0.012704441323876381
0.014625510200858116
Batch of classes 2 out of 12 batches
Epoch 17 of 25 took 26.703s
  training loss:		0.024473
  validation loss:		0.178364
  top 1 accuracy:		71.50 %
  top 2 accuracy:		98.00 %
0.029443267732858658
0.02798963338136673
Batch of classes 2 out of 12 batches
Epoch 18 of 25 took 26.902s
  training loss:		0.023432
  validation loss:		0.223387
  top 1 accuracy:		66.75 %
  top 2 accuracy:		97.50 %
0.02867136523127556
0.025239085778594017
Batch of classes 2 out of 12 batches
Epoch 19 of 25 took 26.795s
  training loss:		0.024092
  validation loss:		0.180026
  top 1 accuracy:		67.50 %
  top 2 accuracy:		97.75 %
0.02494002692401409
0.02558968961238861
Batch of classes 2 out of 12 batches
Epoch 20 of 25 took 26.959s
  training loss:		0.026577
  validation loss:		0.172661
  top 1 accuracy:		76.13 %
  top 2 accuracy:		98.62 %
0.019308386370539665
0.017406878992915154
Batch of classes 2 out of 12 batches
Epoch 21 of 25 took 26.854s
  training loss:		0.021144
  validation loss:		0.170970
  top 1 accuracy:		74.12 %
  top 2 accuracy:		97.37 %
0.019882695749402046
0.017968472093343735
Batch of classes 2 out of 12 batches
Epoch 22 of 25 took 27.043s
  training loss:		0.020420
  validation loss:		0.173894
  top 1 accuracy:		74.25 %
  top 2 accuracy:		97.87 %
0.022667309269309044
0.013654700480401516
Batch of classes 2 out of 12 batches
Epoch 23 of 25 took 26.729s
  training loss:		0.020052
  validation loss:		0.193909
  top 1 accuracy:		74.37 %
  top 2 accuracy:		98.12 %
0.017308859154582024
0.026059141382575035
Batch of classes 2 out of 12 batches
Epoch 24 of 25 took 27.188s
  training loss:		0.021112
  validation loss:		0.220502
  top 1 accuracy:		73.87 %
  top 2 accuracy:		98.37 %
0.023326968774199486
0.03080405853688717
Batch of classes 2 out of 12 batches
Epoch 25 of 25 took 27.054s
  training loss:		0.020051
  validation loss:		0.182982
  top 1 accuracy:		72.75 %
  top 2 accuracy:		96.88 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		77.10 %
  top 1 accuracy Hybrid 1       :		84.75 %
  top 1 accuracy NCM            :		79.20 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		96.30 %
  top 1 accuracy Hybrid 1       :		97.60 %
  top 1 accuracy NCM            :		96.20 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		83.62 %
  top 1 accuracy Hybrid 1       :		72.62 %
  top 1 accuracy NCM            :		81.62 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		98.25 %
  top 1 accuracy Hybrid 1       :		98.00 %
  top 1 accuracy NCM            :		98.25 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		78.96 %
  top 1 accuracy Hybrid 1       :		81.29 %
  top 1 accuracy NCM            :		79.89 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		96.86 %
  top 1 accuracy Hybrid 1       :		97.71 %
  top 1 accuracy NCM            :		96.79 %
Classes in this batch: tensor([4, 5])
Data Size: 1572


Before first epoch
  validation loss:		0.701979
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 3 arrives ...
0.23395085334777832
0.07421879470348358
Batch of classes 3 out of 12 batches
Epoch 1 of 25 took 28.603s
  training loss:		0.107322
  validation loss:		0.279495
  top 1 accuracy:		1.91 %
  top 2 accuracy:		21.18 %
0.0851428359746933
0.05788522586226463
Batch of classes 3 out of 12 batches
Epoch 2 of 25 took 27.150s
  training loss:		0.071712
  validation loss:		0.211087
  top 1 accuracy:		46.95 %
  top 2 accuracy:		70.99 %
0.0819462463259697
0.051924578845500946
Batch of classes 3 out of 12 batches
Epoch 3 of 25 took 26.996s
  training loss:		0.064879
  validation loss:		0.226136
  top 1 accuracy:		45.04 %
  top 2 accuracy:		73.28 %
0.0837416797876358
0.054965995252132416
Batch of classes 3 out of 12 batches
Epoch 4 of 25 took 26.828s
  training loss:		0.062048
  validation loss:		0.205488
  top 1 accuracy:		50.95 %
  top 2 accuracy:		76.15 %
0.04848382994532585
0.04679262638092041
Batch of classes 3 out of 12 batches
Epoch 5 of 25 took 26.857s
  training loss:		0.061455
  validation loss:		0.214642
  top 1 accuracy:		54.01 %
  top 2 accuracy:		79.58 %
0.06665566563606262
0.05732855200767517
Batch of classes 3 out of 12 batches
Epoch 6 of 25 took 27.048s
  training loss:		0.057533
  validation loss:		0.220217
  top 1 accuracy:		58.40 %
  top 2 accuracy:		79.39 %
0.05889039486646652
0.0737103745341301
Batch of classes 3 out of 12 batches
Epoch 7 of 25 took 26.930s
  training loss:		0.057565
  validation loss:		0.199364
  top 1 accuracy:		68.32 %
  top 2 accuracy:		87.02 %
0.05697392672300339
0.05471755191683769
Batch of classes 3 out of 12 batches
Epoch 8 of 25 took 27.038s
  training loss:		0.055566
  validation loss:		0.210688
  top 1 accuracy:		63.36 %
  top 2 accuracy:		83.21 %
0.050236836075782776
0.04792068526148796
Batch of classes 3 out of 12 batches
Epoch 9 of 25 took 26.825s
  training loss:		0.055079
  validation loss:		0.249388
  top 1 accuracy:		57.63 %
  top 2 accuracy:		79.20 %
0.06395591795444489
0.054983969777822495
Batch of classes 3 out of 12 batches
Epoch 10 of 25 took 27.264s
  training loss:		0.055069
  validation loss:		0.221288
  top 1 accuracy:		72.14 %
  top 2 accuracy:		86.64 %
0.04709569737315178
0.04277994856238365
Batch of classes 3 out of 12 batches
Epoch 11 of 25 took 26.957s
  training loss:		0.049133
  validation loss:		0.205772
  top 1 accuracy:		75.38 %
  top 2 accuracy:		87.40 %
0.04247492179274559
0.048766251653432846
Batch of classes 3 out of 12 batches
Epoch 12 of 25 took 27.249s
  training loss:		0.046617
  validation loss:		0.202515
  top 1 accuracy:		80.73 %
  top 2 accuracy:		92.75 %
0.04286116361618042
0.04729636758565903
Batch of classes 3 out of 12 batches
Epoch 13 of 25 took 26.969s
  training loss:		0.046496
  validation loss:		0.220264
  top 1 accuracy:		81.30 %
  top 2 accuracy:		92.75 %
0.04614785313606262
0.04106657952070236
Batch of classes 3 out of 12 batches
Epoch 14 of 25 took 27.103s
  training loss:		0.045190
  validation loss:		0.201068
  top 1 accuracy:		87.40 %
  top 2 accuracy:		94.47 %
0.04521072655916214
0.06036116182804108
Batch of classes 3 out of 12 batches
Epoch 15 of 25 took 27.454s
  training loss:		0.046741
  validation loss:		0.201469
  top 1 accuracy:		81.49 %
  top 2 accuracy:		92.94 %
0.0437496118247509
0.06063179671764374
Batch of classes 3 out of 12 batches
Epoch 16 of 25 took 27.096s
  training loss:		0.046527
  validation loss:		0.216918
  top 1 accuracy:		82.44 %
  top 2 accuracy:		89.31 %
0.046352487057447433
0.03960774093866348
Batch of classes 3 out of 12 batches
Epoch 17 of 25 took 26.945s
  training loss:		0.045658
  validation loss:		0.203047
  top 1 accuracy:		87.60 %
  top 2 accuracy:		94.66 %
0.03466172143816948
0.04269952327013016
Batch of classes 3 out of 12 batches
Epoch 18 of 25 took 27.043s
  training loss:		0.045653
  validation loss:		0.207292
  top 1 accuracy:		84.35 %
  top 2 accuracy:		92.56 %
0.042210616171360016
0.05427016317844391
Batch of classes 3 out of 12 batches
Epoch 19 of 25 took 26.750s
  training loss:		0.045719
  validation loss:		0.206356
  top 1 accuracy:		85.11 %
  top 2 accuracy:		93.70 %
0.040351495146751404
0.04733534902334213
Batch of classes 3 out of 12 batches
Epoch 20 of 25 took 26.971s
  training loss:		0.045668
  validation loss:		0.209831
  top 1 accuracy:		83.59 %
  top 2 accuracy:		93.13 %
0.04746919870376587
0.050863027572631836
Batch of classes 3 out of 12 batches
Epoch 21 of 25 took 27.290s
  training loss:		0.044320
  validation loss:		0.216705
  top 1 accuracy:		88.74 %
  top 2 accuracy:		94.85 %
0.035208284854888916
0.04481372982263565
Batch of classes 3 out of 12 batches
Epoch 22 of 25 took 26.939s
  training loss:		0.042504
  validation loss:		0.207120
  top 1 accuracy:		89.31 %
  top 2 accuracy:		94.66 %
0.0360640287399292
0.03972986713051796
Batch of classes 3 out of 12 batches
Epoch 23 of 25 took 27.067s
  training loss:		0.042734
  validation loss:		0.210523
  top 1 accuracy:		89.89 %
  top 2 accuracy:		95.61 %
0.04726994037628174
0.059918396174907684
Batch of classes 3 out of 12 batches
Epoch 24 of 25 took 27.010s
  training loss:		0.042611
  validation loss:		0.230013
  top 1 accuracy:		87.02 %
  top 2 accuracy:		95.04 %
0.04250454157590866
0.034702301025390625
Batch of classes 3 out of 12 batches
Epoch 25 of 25 took 26.910s
  training loss:		0.042915
  validation loss:		0.213356
  top 1 accuracy:		88.93 %
  top 2 accuracy:		95.42 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		79.55 %
  top 1 accuracy Hybrid 1       :		89.60 %
  top 1 accuracy NCM            :		80.90 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		95.95 %
  top 1 accuracy Hybrid 1       :		96.85 %
  top 1 accuracy NCM            :		95.90 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		70.38 %
  top 1 accuracy Hybrid 1       :		63.13 %
  top 1 accuracy NCM            :		69.75 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		96.62 %
  top 1 accuracy Hybrid 1       :		95.25 %
  top 1 accuracy NCM            :		96.50 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		96.56 %
  top 1 accuracy Hybrid 1       :		88.93 %
  top 1 accuracy NCM            :		96.37 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		98.47 %
  top 1 accuracy Hybrid 1       :		97.33 %
  top 1 accuracy NCM            :		98.47 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		80.02 %
  top 1 accuracy Hybrid 1       :		83.12 %
  top 1 accuracy NCM            :		80.66 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		96.51 %
  top 1 accuracy Hybrid 1       :		96.54 %
  top 1 accuracy NCM            :		96.45 %
Classes in this batch: tensor([6, 7])
Data Size: 7656


Before first epoch
  validation loss:		0.644077
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 4 arrives ...
0.4047182500362396
0.08663515746593475
0.09083348512649536
0.07418078184127808
Batch of classes 4 out of 12 batches
Epoch 1 of 25 took 84.644s
  training loss:		0.098086
  validation loss:		0.144078
  top 1 accuracy:		97.65 %
  top 2 accuracy:		98.90 %
0.06019312143325806
0.08124434947967529
0.06746139377355576
0.06594496965408325
Batch of classes 4 out of 12 batches
Epoch 2 of 25 took 82.777s
  training loss:		0.070009
  validation loss:		0.193845
  top 1 accuracy:		85.74 %
  top 2 accuracy:		92.28 %
0.05822669714689255
0.06236892193555832
0.06948356330394745
0.054783254861831665
Batch of classes 4 out of 12 batches
Epoch 3 of 25 took 82.673s
  training loss:		0.070223
  validation loss:		0.215920
  top 1 accuracy:		94.44 %
  top 2 accuracy:		97.10 %
0.05749306082725525
0.09199582040309906
0.06541398167610168
0.06675366312265396
Batch of classes 4 out of 12 batches
Epoch 4 of 25 took 82.991s
  training loss:		0.068297
  validation loss:		0.175256
  top 1 accuracy:		99.80 %
  top 2 accuracy:		99.96 %
0.06831046938896179
0.08677151799201965
0.07923659682273865
0.08756516873836517
Batch of classes 4 out of 12 batches
Epoch 5 of 25 took 82.772s
  training loss:		0.067497
  validation loss:		0.171725
  top 1 accuracy:		99.41 %
  top 2 accuracy:		99.76 %
0.06798126548528671
0.06575930863618851
0.07128360867500305
0.07042782008647919
Batch of classes 4 out of 12 batches
Epoch 6 of 25 took 82.504s
  training loss:		0.068840
  validation loss:		0.160265
  top 1 accuracy:		90.16 %
  top 2 accuracy:		96.08 %
0.06775009632110596
0.062170010060071945
0.05968453735113144
0.06636569648981094
Batch of classes 4 out of 12 batches
Epoch 7 of 25 took 82.286s
  training loss:		0.067469
  validation loss:		0.257881
  top 1 accuracy:		83.78 %
  top 2 accuracy:		91.11 %
0.07017682492733002
0.05892223119735718
0.0656118094921112
0.06327809393405914
Batch of classes 4 out of 12 batches
Epoch 8 of 25 took 83.302s
  training loss:		0.067360
  validation loss:		0.152361
  top 1 accuracy:		92.08 %
  top 2 accuracy:		94.44 %
0.08800798654556274
0.06354106217622757
0.0645885095000267
0.06256332248449326
Batch of classes 4 out of 12 batches
Epoch 9 of 25 took 82.738s
  training loss:		0.066746
  validation loss:		0.204099
  top 1 accuracy:		93.26 %
  top 2 accuracy:		94.75 %
0.05961146578192711
0.05024140328168869
0.059182681143283844
0.05732584744691849
Batch of classes 4 out of 12 batches
Epoch 10 of 25 took 89.122s
  training loss:		0.066776
  validation loss:		0.184985
  top 1 accuracy:		92.52 %
  top 2 accuracy:		94.63 %
0.07270770519971848
0.07172460854053497
0.05972946435213089
0.0666595995426178
Batch of classes 4 out of 12 batches
Epoch 11 of 25 took 88.793s
  training loss:		0.064245
  validation loss:		0.172720
  top 1 accuracy:		99.73 %
  top 2 accuracy:		99.92 %
0.06701979041099548
0.0606328621506691
0.058150872588157654
0.05086283013224602
Batch of classes 4 out of 12 batches
Epoch 12 of 25 took 90.453s
  training loss:		0.062781
  validation loss:		0.181457
  top 1 accuracy:		99.76 %
  top 2 accuracy:		99.96 %
0.0559253916144371
0.05768487975001335
0.06982707232236862
0.06797676533460617
Batch of classes 4 out of 12 batches
Epoch 13 of 25 took 86.510s
  training loss:		0.063019
  validation loss:		0.179705
  top 1 accuracy:		97.92 %
  top 2 accuracy:		98.82 %
0.06698249280452728
0.06269773095846176
0.06483699381351471
0.06095246598124504
Batch of classes 4 out of 12 batches
Epoch 14 of 25 took 89.398s
  training loss:		0.062352
  validation loss:		0.148982
  top 1 accuracy:		99.49 %
  top 2 accuracy:		99.88 %
0.06382207572460175
0.06141260266304016
0.06072930246591568
0.06011989340186119
Batch of classes 4 out of 12 batches
Epoch 15 of 25 took 87.591s
  training loss:		0.063150
  validation loss:		0.193397
  top 1 accuracy:		98.82 %
  top 2 accuracy:		99.53 %
0.06155472248792648
0.06300431489944458
0.05415784940123558
0.05212424322962761
Batch of classes 4 out of 12 batches
Epoch 16 of 25 took 87.476s
  training loss:		0.062137
  validation loss:		0.207048
  top 1 accuracy:		97.96 %
  top 2 accuracy:		98.71 %
0.06524671614170074
0.05790683627128601
0.058650340884923935
0.06007829308509827
Batch of classes 4 out of 12 batches
Epoch 17 of 25 took 89.956s
  training loss:		0.062324
  validation loss:		0.159473
  top 1 accuracy:		99.49 %
  top 2 accuracy:		99.84 %
0.06788890063762665
0.05684511363506317
0.06631097197532654
0.06320185959339142
Batch of classes 4 out of 12 batches
Epoch 18 of 25 took 87.390s
  training loss:		0.062294
  validation loss:		0.180744
  top 1 accuracy:		99.65 %
  top 2 accuracy:		99.80 %
0.05472543090581894
0.06132351979613304
0.07275362312793732
0.05934664607048035
Batch of classes 4 out of 12 batches
Epoch 19 of 25 took 88.850s
  training loss:		0.063141
  validation loss:		0.187969
  top 1 accuracy:		98.94 %
  top 2 accuracy:		99.49 %
0.07869584858417511
0.05724368616938591
0.05910906195640564
0.06650316715240479
Batch of classes 4 out of 12 batches
Epoch 20 of 25 took 88.617s
  training loss:		0.062963
  validation loss:		0.182056
  top 1 accuracy:		93.93 %
  top 2 accuracy:		96.16 %
0.06736151874065399
0.05380323529243469
0.06440714001655579
0.0653281956911087
Batch of classes 4 out of 12 batches
Epoch 21 of 25 took 90.435s
  training loss:		0.061669
  validation loss:		0.191394
  top 1 accuracy:		99.92 %
  top 2 accuracy:		99.96 %
0.06504876911640167
0.061329733580350876
0.07506980001926422
0.06312787532806396
Batch of classes 4 out of 12 batches
Epoch 22 of 25 took 87.707s
  training loss:		0.060943
  validation loss:		0.170420
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
0.059936948120594025
0.055111221969127655
0.06142253801226616
0.06507238000631332
Batch of classes 4 out of 12 batches
Epoch 23 of 25 took 88.194s
  training loss:		0.060781
  validation loss:		0.166789
  top 1 accuracy:		99.80 %
  top 2 accuracy:		99.96 %
0.06627369672060013
0.053418032824993134
0.05823894590139389
0.05977064371109009
Batch of classes 4 out of 12 batches
Epoch 24 of 25 took 89.062s
  training loss:		0.060342
  validation loss:		0.196459
  top 1 accuracy:		99.88 %
  top 2 accuracy:		99.96 %
0.058066513389348984
0.055785439908504486
0.06186218187212944
0.06926517188549042
Batch of classes 4 out of 12 batches
Epoch 25 of 25 took 85.856s
  training loss:		0.060805
  validation loss:		0.188014
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		78.85 %
  top 1 accuracy Hybrid 1       :		88.85 %
  top 1 accuracy NCM            :		79.95 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		96.00 %
  top 1 accuracy Hybrid 1       :		94.40 %
  top 1 accuracy NCM            :		96.20 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		69.88 %
  top 1 accuracy Hybrid 1       :		58.25 %
  top 1 accuracy NCM            :		69.50 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		95.38 %
  top 1 accuracy Hybrid 1       :		94.12 %
  top 1 accuracy NCM            :		95.12 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		93.13 %
  top 1 accuracy Hybrid 1       :		81.87 %
  top 1 accuracy NCM            :		92.75 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		97.14 %
  top 1 accuracy Hybrid 1       :		96.95 %
  top 1 accuracy NCM            :		97.14 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		99.92 %
  top 1 accuracy NCM            :		100.00 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		100.00 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		88.09 %
  top 1 accuracy Hybrid 1       :		88.87 %
  top 1 accuracy NCM            :		88.38 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		97.75 %
  top 1 accuracy Hybrid 1       :		97.02 %
  top 1 accuracy NCM            :		97.79 %
Classes in this batch: tensor([8, 9])
Data Size: 3248


Before first epoch
  validation loss:		0.515440
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 5 arrives ...
0.30652934312820435
0.12247288227081299
Batch of classes 5 out of 12 batches
Epoch 1 of 25 took 48.132s
  training loss:		0.141271
  validation loss:		0.242886
  top 1 accuracy:		84.20 %
  top 2 accuracy:		89.00 %
0.09839987754821777
0.09769344329833984
Batch of classes 5 out of 12 batches
Epoch 2 of 25 took 47.188s
  training loss:		0.105746
  validation loss:		0.258814
  top 1 accuracy:		83.46 %
  top 2 accuracy:		87.99 %
0.1128319650888443
0.11160016059875488
Batch of classes 5 out of 12 batches
Epoch 3 of 25 took 47.384s
  training loss:		0.102279
  validation loss:		0.223880
  top 1 accuracy:		93.53 %
  top 2 accuracy:		94.82 %
0.09975895285606384
0.10057549178600311
Batch of classes 5 out of 12 batches
Epoch 4 of 25 took 47.216s
  training loss:		0.102522
  validation loss:		0.244933
  top 1 accuracy:		94.27 %
  top 2 accuracy:		95.47 %
0.10820214450359344
0.08647081255912781
Batch of classes 5 out of 12 batches
Epoch 5 of 25 took 47.130s
  training loss:		0.099958
  validation loss:		0.268900
  top 1 accuracy:		75.23 %
  top 2 accuracy:		79.02 %
0.10728368163108826
0.09892535209655762
Batch of classes 5 out of 12 batches
Epoch 6 of 25 took 47.473s
  training loss:		0.100797
  validation loss:		0.226167
  top 1 accuracy:		92.88 %
  top 2 accuracy:		94.36 %
0.11615309119224548
0.10217571258544922
Batch of classes 5 out of 12 batches
Epoch 7 of 25 took 47.367s
  training loss:		0.102061
  validation loss:		0.261579
  top 1 accuracy:		85.77 %
  top 2 accuracy:		89.46 %
0.09038015455007553
0.09157554805278778
Batch of classes 5 out of 12 batches
Epoch 8 of 25 took 46.986s
  training loss:		0.099843
  validation loss:		0.225669
  top 1 accuracy:		91.77 %
  top 2 accuracy:		93.25 %
0.1013454794883728
0.11237020790576935
Batch of classes 5 out of 12 batches
Epoch 9 of 25 took 47.337s
  training loss:		0.097790
  validation loss:		0.220349
  top 1 accuracy:		92.33 %
  top 2 accuracy:		94.09 %
0.09580959379673004
0.08293718099594116
Batch of classes 5 out of 12 batches
Epoch 10 of 25 took 47.626s
  training loss:		0.098541
  validation loss:		0.228170
  top 1 accuracy:		95.10 %
  top 2 accuracy:		95.84 %
0.10427449643611908
0.10025878250598907
Batch of classes 5 out of 12 batches
Epoch 11 of 25 took 47.376s
  training loss:		0.095946
  validation loss:		0.239310
  top 1 accuracy:		95.19 %
  top 2 accuracy:		95.66 %
0.1044774055480957
0.11050307750701904
Batch of classes 5 out of 12 batches
Epoch 12 of 25 took 47.391s
  training loss:		0.095312
  validation loss:		0.226655
  top 1 accuracy:		93.72 %
  top 2 accuracy:		94.64 %
0.08867627382278442
0.09896477311849594
Batch of classes 5 out of 12 batches
Epoch 13 of 25 took 46.922s
  training loss:		0.095392
  validation loss:		0.239060
  top 1 accuracy:		93.62 %
  top 2 accuracy:		94.92 %
0.08657430112361908
0.08680206537246704
Batch of classes 5 out of 12 batches
Epoch 14 of 25 took 47.310s
  training loss:		0.095484
  validation loss:		0.245086
  top 1 accuracy:		94.45 %
  top 2 accuracy:		95.38 %
0.08282983303070068
0.1066383346915245
Batch of classes 5 out of 12 batches
Epoch 15 of 25 took 47.164s
  training loss:		0.094980
  validation loss:		0.239782
  top 1 accuracy:		95.01 %
  top 2 accuracy:		95.56 %
0.08978839963674545
0.10300806164741516
Batch of classes 5 out of 12 batches
Epoch 16 of 25 took 46.836s
  training loss:		0.094716
  validation loss:		0.245742
  top 1 accuracy:		94.55 %
  top 2 accuracy:		95.10 %
0.09671662747859955
0.08659940958023071
Batch of classes 5 out of 12 batches
Epoch 17 of 25 took 47.407s
  training loss:		0.095037
  validation loss:		0.231498
  top 1 accuracy:		95.56 %
  top 2 accuracy:		95.93 %
0.09236469119787216
0.08359762281179428
Batch of classes 5 out of 12 batches
Epoch 18 of 25 took 46.982s
  training loss:		0.094803
  validation loss:		0.240442
  top 1 accuracy:		94.82 %
  top 2 accuracy:		95.75 %
0.10456934571266174
0.0943150520324707
Batch of classes 5 out of 12 batches
Epoch 19 of 25 took 47.114s
  training loss:		0.095255
  validation loss:		0.241087
  top 1 accuracy:		93.25 %
  top 2 accuracy:		95.01 %
0.09353673458099365
0.10206343978643417
Batch of classes 5 out of 12 batches
Epoch 20 of 25 took 46.937s
  training loss:		0.094969
  validation loss:		0.224169
  top 1 accuracy:		95.29 %
  top 2 accuracy:		95.93 %
0.09159296751022339
0.0929630920290947
Batch of classes 5 out of 12 batches
Epoch 21 of 25 took 47.525s
  training loss:		0.094015
  validation loss:		0.238176
  top 1 accuracy:		95.56 %
  top 2 accuracy:		95.93 %
0.10921603441238403
0.0975964367389679
Batch of classes 5 out of 12 batches
Epoch 22 of 25 took 47.301s
  training loss:		0.093553
  validation loss:		0.242351
  top 1 accuracy:		94.92 %
  top 2 accuracy:		95.75 %
0.08884371817111969
0.09952688217163086
Batch of classes 5 out of 12 batches
Epoch 23 of 25 took 46.962s
  training loss:		0.093578
  validation loss:		0.234678
  top 1 accuracy:		93.44 %
  top 2 accuracy:		95.01 %
0.11844774335622787
0.08601111173629761
Batch of classes 5 out of 12 batches
Epoch 24 of 25 took 47.068s
  training loss:		0.094000
  validation loss:		0.243113
  top 1 accuracy:		93.16 %
  top 2 accuracy:		94.45 %
0.09283444285392761
0.09465610980987549
Batch of classes 5 out of 12 batches
Epoch 25 of 25 took 47.172s
  training loss:		0.093510
  validation loss:		0.237118
  top 1 accuracy:		95.56 %
  top 2 accuracy:		95.75 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		78.40 %
  top 1 accuracy Hybrid 1       :		84.10 %
  top 1 accuracy NCM            :		78.95 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		93.95 %
  top 1 accuracy Hybrid 1       :		89.95 %
  top 1 accuracy NCM            :		93.85 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		66.12 %
  top 1 accuracy Hybrid 1       :		55.87 %
  top 1 accuracy NCM            :		66.50 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		94.50 %
  top 1 accuracy Hybrid 1       :		88.75 %
  top 1 accuracy NCM            :		95.12 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		92.75 %
  top 1 accuracy Hybrid 1       :		71.95 %
  top 1 accuracy NCM            :		92.75 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		97.33 %
  top 1 accuracy Hybrid 1       :		93.89 %
  top 1 accuracy NCM            :		97.33 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		97.84 %
  top 1 accuracy NCM            :		100.00 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		99.96 %
  top 1 accuracy NCM            :		100.00 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		96.12 %
  top 1 accuracy Hybrid 1       :		95.56 %
  top 1 accuracy NCM            :		96.12 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		96.21 %
  top 1 accuracy Hybrid 1       :		95.84 %
  top 1 accuracy NCM            :		96.21 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		88.75 %
  top 1 accuracy Hybrid 1       :		86.76 %
  top 1 accuracy NCM            :		88.95 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		96.84 %
  top 1 accuracy Hybrid 1       :		94.70 %
  top 1 accuracy NCM            :		96.88 %
Classes in this batch: tensor([10, 11])
Data Size: 7658


Before first epoch
  validation loss:		0.896481
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 6 arrives ...
0.34074482321739197
0.09476505219936371
0.08611824363470078
0.10371029376983643
Batch of classes 6 out of 12 batches
Epoch 1 of 25 took 85.453s
  training loss:		0.113377
  validation loss:		0.340546
  top 1 accuracy:		26.72 %
  top 2 accuracy:		60.15 %
0.08700945228338242
0.09252408146858215
0.08967654407024384
0.08345126360654831
Batch of classes 6 out of 12 batches
Epoch 2 of 25 took 84.156s
  training loss:		0.089192
  validation loss:		0.387915
  top 1 accuracy:		48.71 %
  top 2 accuracy:		64.77 %
0.09337256848812103
0.08451776951551437
0.07800120115280151
0.09505166113376617
Batch of classes 6 out of 12 batches
Epoch 3 of 25 took 84.414s
  training loss:		0.088915
  validation loss:		0.409989
  top 1 accuracy:		49.80 %
  top 2 accuracy:		55.33 %
0.08754884451627731
0.09261848032474518
0.08502000570297241
0.08993782848119736
Batch of classes 6 out of 12 batches
Epoch 4 of 25 took 84.865s
  training loss:		0.087399
  validation loss:		0.414957
  top 1 accuracy:		46.32 %
  top 2 accuracy:		71.00 %
0.0982995256781578
0.08755012601613998
0.07628430426120758
0.08854162693023682
Batch of classes 6 out of 12 batches
Epoch 5 of 25 took 84.018s
  training loss:		0.086912
  validation loss:		0.421567
  top 1 accuracy:		49.53 %
  top 2 accuracy:		65.52 %
0.07596553862094879
0.08682717382907867
0.08443856239318848
0.09218363463878632
Batch of classes 6 out of 12 batches
Epoch 6 of 25 took 84.195s
  training loss:		0.087390
  validation loss:		0.418105
  top 1 accuracy:		49.57 %
  top 2 accuracy:		53.57 %
0.08445388078689575
0.0840851292014122
0.08902929723262787
0.07834511995315552
Batch of classes 6 out of 12 batches
Epoch 7 of 25 took 84.054s
  training loss:		0.086875
  validation loss:		0.379728
  top 1 accuracy:		49.69 %
  top 2 accuracy:		51.92 %
0.07464225590229034
0.08788149058818817
0.08698520064353943
0.08279617130756378
Batch of classes 6 out of 12 batches
Epoch 8 of 25 took 83.867s
  training loss:		0.085930
  validation loss:		0.410738
  top 1 accuracy:		49.41 %
  top 2 accuracy:		61.79 %
0.08214651048183441
0.0889301523566246
0.0981934517621994
0.08699830621480942
Batch of classes 6 out of 12 batches
Epoch 9 of 25 took 84.044s
  training loss:		0.086647
  validation loss:		0.407743
  top 1 accuracy:		40.60 %
  top 2 accuracy:		62.62 %
0.08282504975795746
0.07718103379011154
0.08906474709510803
0.07913017272949219
Batch of classes 6 out of 12 batches
Epoch 10 of 25 took 84.145s
  training loss:		0.086404
  validation loss:		0.387976
  top 1 accuracy:		51.49 %
  top 2 accuracy:		64.11 %
0.09100522100925446
0.06711496412754059
0.07021783292293549
0.0650026798248291
Batch of classes 6 out of 12 batches
Epoch 11 of 25 took 83.802s
  training loss:		0.081531
  validation loss:		0.438045
  top 1 accuracy:		65.48 %
  top 2 accuracy:		97.14 %
0.07990951091051102
0.09025666117668152
0.0760631188750267
0.07507315278053284
Batch of classes 6 out of 12 batches
Epoch 12 of 25 took 83.912s
  training loss:		0.080761
  validation loss:		0.383745
  top 1 accuracy:		74.92 %
  top 2 accuracy:		95.26 %
0.07357557117938995
0.07673929631710052
0.07059451937675476
0.08116324245929718
Batch of classes 6 out of 12 batches
Epoch 13 of 25 took 84.247s
  training loss:		0.080692
  validation loss:		0.438844
  top 1 accuracy:		90.40 %
  top 2 accuracy:		99.45 %
0.07652094960212708
0.09785979241132736
0.06290403008460999
0.07115813344717026
Batch of classes 6 out of 12 batches
Epoch 14 of 25 took 84.240s
  training loss:		0.080251
  validation loss:		0.399120
  top 1 accuracy:		86.13 %
  top 2 accuracy:		97.77 %
0.0853167399764061
0.08167381584644318
0.07970503717660904
0.08506884425878525
Batch of classes 6 out of 12 batches
Epoch 15 of 25 took 84.579s
  training loss:		0.081023
  validation loss:		0.411911
  top 1 accuracy:		79.00 %
  top 2 accuracy:		98.35 %
0.08032065629959106
0.08325718343257904
0.08717160671949387
0.08265252411365509
Batch of classes 6 out of 12 batches
Epoch 16 of 25 took 84.070s
  training loss:		0.080812
  validation loss:		0.383195
  top 1 accuracy:		88.32 %
  top 2 accuracy:		98.12 %
0.06679921597242355
0.08272458612918854
0.07683993875980377
0.08817090839147568
Batch of classes 6 out of 12 batches
Epoch 17 of 25 took 84.149s
  training loss:		0.080455
  validation loss:		0.407411
  top 1 accuracy:		86.79 %
  top 2 accuracy:		98.90 %
0.08639853447675705
0.07136359810829163
0.08351421356201172
0.06733590364456177
Batch of classes 6 out of 12 batches
Epoch 18 of 25 took 83.966s
  training loss:		0.080794
  validation loss:		0.417982
  top 1 accuracy:		61.87 %
  top 2 accuracy:		89.69 %
0.08130413293838501
0.07392105460166931
0.06940189003944397
0.07776843011379242
Batch of classes 6 out of 12 batches
Epoch 19 of 25 took 83.562s
  training loss:		0.080765
  validation loss:		0.515288
  top 1 accuracy:		86.76 %
  top 2 accuracy:		99.80 %
0.09307276457548141
0.0822874903678894
0.08082884550094604
0.0896492600440979
Batch of classes 6 out of 12 batches
Epoch 20 of 25 took 84.354s
  training loss:		0.080156
  validation loss:		0.436157
  top 1 accuracy:		76.65 %
  top 2 accuracy:		96.04 %
0.07969974726438522
0.0762789323925972
0.08859221637248993
0.0715966448187828
Batch of classes 6 out of 12 batches
Epoch 21 of 25 took 84.313s
  training loss:		0.079681
  validation loss:		0.417996
  top 1 accuracy:		90.95 %
  top 2 accuracy:		99.57 %
0.07506300508975983
0.06741219013929367
0.07530228048563004
0.066110759973526
Batch of classes 6 out of 12 batches
Epoch 22 of 25 took 84.085s
  training loss:		0.079331
  validation loss:		0.448573
  top 1 accuracy:		89.66 %
  top 2 accuracy:		99.76 %
0.0812084749341011
0.07259275764226913
0.06780962646007538
0.07580497115850449
Batch of classes 6 out of 12 batches
Epoch 23 of 25 took 84.457s
  training loss:		0.079178
  validation loss:		0.383086
  top 1 accuracy:		94.00 %
  top 2 accuracy:		99.02 %
0.09159525483846664
0.08515476435422897
0.07837536185979843
0.07538601011037827
Batch of classes 6 out of 12 batches
Epoch 24 of 25 took 83.932s
  training loss:		0.078890
  validation loss:		0.440843
  top 1 accuracy:		89.11 %
  top 2 accuracy:		99.37 %
0.0796954482793808
0.0805545225739479
0.08273099362850189
0.07171327620744705
Batch of classes 6 out of 12 batches
Epoch 25 of 25 took 83.910s
  training loss:		0.078770
  validation loss:		0.419520
  top 1 accuracy:		92.63 %
  top 2 accuracy:		99.18 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		74.35 %
  top 1 accuracy Hybrid 1       :		79.20 %
  top 1 accuracy NCM            :		75.50 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		91.95 %
  top 1 accuracy Hybrid 1       :		87.10 %
  top 1 accuracy NCM            :		92.25 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		66.12 %
  top 1 accuracy Hybrid 1       :		53.50 %
  top 1 accuracy NCM            :		65.38 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		93.62 %
  top 1 accuracy Hybrid 1       :		85.25 %
  top 1 accuracy NCM            :		94.00 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		92.56 %
  top 1 accuracy Hybrid 1       :		71.95 %
  top 1 accuracy NCM            :		92.37 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		96.95 %
  top 1 accuracy Hybrid 1       :		94.08 %
  top 1 accuracy NCM            :		96.76 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		70.92 %
  top 1 accuracy Hybrid 1       :		56.74 %
  top 1 accuracy NCM            :		75.04 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		99.76 %
  top 1 accuracy NCM            :		100.00 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		96.03 %
  top 1 accuracy Hybrid 1       :		93.99 %
  top 1 accuracy NCM            :		96.03 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		96.12 %
  top 1 accuracy Hybrid 1       :		96.03 %
  top 1 accuracy NCM            :		96.12 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		79.08 %
  top 1 accuracy Hybrid 1       :		92.63 %
  top 1 accuracy NCM            :		75.00 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		99.88 %
  top 1 accuracy NCM            :		100.00 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		77.48 %
  top 1 accuracy Hybrid 1       :		75.90 %
  top 1 accuracy NCM            :		77.66 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		97.16 %
  top 1 accuracy Hybrid 1       :		95.17 %
  top 1 accuracy NCM            :		97.25 %
Classes in this batch: tensor([12, 13])
Data Size: 6208


Before first epoch
  validation loss:		0.693616
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 7 arrives ...
0.4626844823360443
0.17012381553649902
0.17219875752925873
Batch of classes 7 out of 12 batches
Epoch 1 of 25 took 70.449s
  training loss:		0.195654
  validation loss:		0.342231
  top 1 accuracy:		0.10 %
  top 2 accuracy:		3.20 %
0.18358676135540009
0.1739278882741928
0.22237662971019745
Batch of classes 7 out of 12 batches
Epoch 2 of 25 took 71.314s
  training loss:		0.177917
  validation loss:		0.341254
  top 1 accuracy:		1.70 %
  top 2 accuracy:		14.69 %
0.17396852374076843
0.1558324545621872
0.15906795859336853
Batch of classes 7 out of 12 batches
Epoch 3 of 25 took 69.366s
  training loss:		0.174608
  validation loss:		0.334695
  top 1 accuracy:		7.56 %
  top 2 accuracy:		27.34 %
0.18618559837341309
0.18382340669631958
0.16664840281009674
Batch of classes 7 out of 12 batches
Epoch 4 of 25 took 70.380s
  training loss:		0.171392
  validation loss:		0.327166
  top 1 accuracy:		23.80 %
  top 2 accuracy:		40.86 %
0.1582808494567871
0.1373281329870224
0.16952818632125854
Batch of classes 7 out of 12 batches
Epoch 5 of 25 took 69.650s
  training loss:		0.169280
  validation loss:		0.319487
  top 1 accuracy:		33.40 %
  top 2 accuracy:		51.14 %
0.1569138616323471
0.17359772324562073
0.18225614726543427
Batch of classes 7 out of 12 batches
Epoch 6 of 25 took 69.436s
  training loss:		0.168245
  validation loss:		0.331557
  top 1 accuracy:		25.40 %
  top 2 accuracy:		42.32 %
0.15416406095027924
0.14041487872600555
0.18414950370788574
Batch of classes 7 out of 12 batches
Epoch 7 of 25 took 69.926s
  training loss:		0.167124
  validation loss:		0.326997
  top 1 accuracy:		28.41 %
  top 2 accuracy:		45.08 %
0.16832947731018066
0.16137999296188354
0.1832459419965744
Batch of classes 7 out of 12 batches
Epoch 8 of 25 took 69.130s
  training loss:		0.166280
  validation loss:		0.332430
  top 1 accuracy:		42.95 %
  top 2 accuracy:		56.42 %
0.15749965608119965
0.19388413429260254
0.1509373039007187
Batch of classes 7 out of 12 batches
Epoch 9 of 25 took 69.599s
  training loss:		0.164753
  validation loss:		0.365722
  top 1 accuracy:		33.01 %
  top 2 accuracy:		50.70 %
0.212749645113945
0.14931799471378326
0.17067250609397888
Batch of classes 7 out of 12 batches
Epoch 10 of 25 took 69.954s
  training loss:		0.164058
  validation loss:		0.357113
  top 1 accuracy:		27.82 %
  top 2 accuracy:		46.15 %
0.14496003091335297
0.14029628038406372
0.15960510075092316
Batch of classes 7 out of 12 batches
Epoch 11 of 25 took 69.428s
  training loss:		0.158211
  validation loss:		0.341944
  top 1 accuracy:		37.03 %
  top 2 accuracy:		55.45 %
0.1526351273059845
0.16909301280975342
0.14981389045715332
Batch of classes 7 out of 12 batches
Epoch 12 of 25 took 69.912s
  training loss:		0.156306
  validation loss:		0.353489
  top 1 accuracy:		41.40 %
  top 2 accuracy:		58.07 %
0.15515516698360443
0.17414049804210663
0.18129685521125793
Batch of classes 7 out of 12 batches
Epoch 13 of 25 took 69.437s
  training loss:		0.155698
  validation loss:		0.344935
  top 1 accuracy:		39.41 %
  top 2 accuracy:		57.73 %
0.14270542562007904
0.13104461133480072
0.162858784198761
Batch of classes 7 out of 12 batches
Epoch 14 of 25 took 70.317s
  training loss:		0.155374
  validation loss:		0.346106
  top 1 accuracy:		41.44 %
  top 2 accuracy:		59.09 %
0.16204698383808136
0.14297401905059814
0.16783612966537476
Batch of classes 7 out of 12 batches
Epoch 15 of 25 took 69.842s
  training loss:		0.155037
  validation loss:		0.359296
  top 1 accuracy:		46.29 %
  top 2 accuracy:		63.79 %
0.15195666253566742
0.1671343892812729
0.15308980643749237
Batch of classes 7 out of 12 batches
Epoch 16 of 25 took 69.211s
  training loss:		0.154155
  validation loss:		0.347631
  top 1 accuracy:		48.18 %
  top 2 accuracy:		62.09 %
0.1490004062652588
0.14574959874153137
0.14532306790351868
Batch of classes 7 out of 12 batches
Epoch 17 of 25 took 69.345s
  training loss:		0.153663
  validation loss:		0.344014
  top 1 accuracy:		41.35 %
  top 2 accuracy:		58.02 %
0.13182352483272552
0.14926473796367645
0.19014251232147217
Batch of classes 7 out of 12 batches
Epoch 18 of 25 took 69.998s
  training loss:		0.153226
  validation loss:		0.352508
  top 1 accuracy:		49.15 %
  top 2 accuracy:		63.16 %
0.1513492465019226
0.15839749574661255
0.18494705855846405
Batch of classes 7 out of 12 batches
Epoch 19 of 25 took 69.287s
  training loss:		0.152346
  validation loss:		0.353174
  top 1 accuracy:		46.92 %
  top 2 accuracy:		61.46 %
0.1433817744255066
0.14251279830932617
0.14400023221969604
Batch of classes 7 out of 12 batches
Epoch 20 of 25 took 70.034s
  training loss:		0.151743
  validation loss:		0.346599
  top 1 accuracy:		50.02 %
  top 2 accuracy:		64.57 %
0.15168265998363495
0.1333995759487152
0.1411222219467163
Batch of classes 7 out of 12 batches
Epoch 21 of 25 took 69.420s
  training loss:		0.148489
  validation loss:		0.354930
  top 1 accuracy:		52.64 %
  top 2 accuracy:		68.15 %
0.1227794736623764
0.14863617718219757
0.14658136665821075
Batch of classes 7 out of 12 batches
Epoch 22 of 25 took 70.149s
  training loss:		0.147060
  validation loss:		0.352856
  top 1 accuracy:		55.36 %
  top 2 accuracy:		69.37 %
0.15663796663284302
0.15288326144218445
0.13744370639324188
Batch of classes 7 out of 12 batches
Epoch 23 of 25 took 69.915s
  training loss:		0.146165
  validation loss:		0.361767
  top 1 accuracy:		52.50 %
  top 2 accuracy:		65.97 %
0.13941065967082977
0.13264694809913635
0.13677488267421722
Batch of classes 7 out of 12 batches
Epoch 24 of 25 took 69.912s
  training loss:		0.146054
  validation loss:		0.357635
  top 1 accuracy:		53.13 %
  top 2 accuracy:		67.96 %
0.13080154359340668
0.13900040090084076
0.14183075726032257
Batch of classes 7 out of 12 batches
Epoch 25 of 25 took 69.100s
  training loss:		0.145677
  validation loss:		0.348698
  top 1 accuracy:		58.26 %
  top 2 accuracy:		68.88 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		71.00 %
  top 1 accuracy Hybrid 1       :		71.70 %
  top 1 accuracy NCM            :		71.85 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		88.15 %
  top 1 accuracy Hybrid 1       :		79.50 %
  top 1 accuracy NCM            :		88.15 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		62.50 %
  top 1 accuracy Hybrid 1       :		48.75 %
  top 1 accuracy NCM            :		61.50 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		89.88 %
  top 1 accuracy Hybrid 1       :		79.75 %
  top 1 accuracy NCM            :		89.50 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		87.21 %
  top 1 accuracy Hybrid 1       :		63.55 %
  top 1 accuracy NCM            :		87.79 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		95.42 %
  top 1 accuracy Hybrid 1       :		91.98 %
  top 1 accuracy NCM            :		95.23 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		76.53 %
  top 1 accuracy Hybrid 1       :		49.80 %
  top 1 accuracy NCM            :		72.61 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		99.80 %
  top 1 accuracy NCM            :		100.00 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		89.56 %
  top 1 accuracy Hybrid 1       :		91.68 %
  top 1 accuracy NCM            :		89.37 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		95.84 %
  top 1 accuracy Hybrid 1       :		96.21 %
  top 1 accuracy NCM            :		95.84 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		73.47 %
  top 1 accuracy Hybrid 1       :		99.18 %
  top 1 accuracy NCM            :		77.39 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		99.96 %
  top 1 accuracy NCM            :		100.00 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		77.46 %
  top 1 accuracy Hybrid 1       :		58.26 %
  top 1 accuracy NCM            :		77.56 %
Binary accuracy:
Final results on wild classes:
  top 1 accuracy iCaRL          :		79.25 %
  top 1 accuracy Hybrid 1       :		76.73 %
  top 1 accuracy NCM            :		79.30 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		75.80 %
  top 1 accuracy Hybrid 1       :		70.45 %
  top 1 accuracy NCM            :		75.90 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		92.96 %
  top 1 accuracy Hybrid 1       :		90.14 %
  top 1 accuracy NCM            :		92.93 %
Classes in this batch: tensor([14, 15])
Data Size: 7200


Before first epoch
  validation loss:		0.693552
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 8 arrives ...
0.42136773467063904
0.1635572463274002
0.12375527620315552
0.11742396652698517
Batch of classes 8 out of 12 batches
Epoch 1 of 25 took 85.952s
  training loss:		0.153267
  validation loss:		0.194379
  top 1 accuracy:		87.98 %
  top 2 accuracy:		93.04 %
0.11164192855358124
0.11056356877088547
0.11564841121435165
0.12665504217147827
Batch of classes 8 out of 12 batches
Epoch 2 of 25 took 86.709s
  training loss:		0.117249
  validation loss:		0.204298
  top 1 accuracy:		88.27 %
  top 2 accuracy:		92.23 %
0.10224723070859909
0.1125062108039856
0.11161790788173676
0.1241772398352623
Batch of classes 8 out of 12 batches
Epoch 3 of 25 took 84.216s
  training loss:		0.115902
  validation loss:		0.205322
  top 1 accuracy:		88.27 %
  top 2 accuracy:		92.44 %
0.11744615435600281
0.11609189957380295
0.10641874372959137
0.11379073560237885
Batch of classes 8 out of 12 batches
Epoch 4 of 25 took 87.000s
  training loss:		0.115000
  validation loss:		0.182788
  top 1 accuracy:		84.35 %
  top 2 accuracy:		91.23 %
0.12362469732761383
0.10287880897521973
0.12404623627662659
0.09941290318965912
Batch of classes 8 out of 12 batches
Epoch 5 of 25 took 83.778s
  training loss:		0.112691
  validation loss:		0.222382
  top 1 accuracy:		76.33 %
  top 2 accuracy:		82.90 %
0.1001734659075737
0.10416118800640106
0.10880296677350998
0.10215874761343002
Batch of classes 8 out of 12 batches
Epoch 6 of 25 took 84.247s
  training loss:		0.113375
  validation loss:		0.188790
  top 1 accuracy:		97.02 %
  top 2 accuracy:		98.37 %
0.10371391475200653
0.1187729686498642
0.10372685641050339
0.11221986263990402
Batch of classes 8 out of 12 batches
Epoch 7 of 25 took 84.239s
  training loss:		0.112720
  validation loss:		0.187233
  top 1 accuracy:		86.69 %
  top 2 accuracy:		92.92 %
0.13226044178009033
0.10413839668035507
0.11155204474925995
0.10860699415206909
Batch of classes 8 out of 12 batches
Epoch 8 of 25 took 82.741s
  training loss:		0.113844
  validation loss:		0.203881
  top 1 accuracy:		93.44 %
  top 2 accuracy:		96.31 %
0.12155353277921677
0.10711207240819931
0.11177973449230194
0.11273407936096191
Batch of classes 8 out of 12 batches
Epoch 9 of 25 took 85.487s
  training loss:		0.112901
  validation loss:		0.186307
  top 1 accuracy:		95.25 %
  top 2 accuracy:		97.65 %
0.11632226407527924
0.11172625422477722
0.107494056224823
0.10484804213047028
Batch of classes 8 out of 12 batches
Epoch 10 of 25 took 87.080s
  training loss:		0.111040
  validation loss:		0.198716
  top 1 accuracy:		98.35 %
  top 2 accuracy:		99.02 %
0.10737907141447067
0.11016213893890381
0.11734398454427719
0.11378657817840576
Batch of classes 8 out of 12 batches
Epoch 11 of 25 took 83.849s
  training loss:		0.109441
  validation loss:		0.201163
  top 1 accuracy:		97.10 %
  top 2 accuracy:		98.52 %
0.10247385501861572
0.09517189115285873
0.09415318816900253
0.10766774415969849
Batch of classes 8 out of 12 batches
Epoch 12 of 25 took 86.228s
  training loss:		0.108967
  validation loss:		0.189580
  top 1 accuracy:		98.17 %
  top 2 accuracy:		98.92 %
0.1033509224653244
0.10342931747436523
0.09790708124637604
0.10808821022510529
Batch of classes 8 out of 12 batches
Epoch 13 of 25 took 85.378s
  training loss:		0.108729
  validation loss:		0.196452
  top 1 accuracy:		90.90 %
  top 2 accuracy:		93.73 %
0.11526928842067719
0.1250966191291809
0.10187124460935593
0.11139380931854248
Batch of classes 8 out of 12 batches
Epoch 14 of 25 took 85.890s
  training loss:		0.108848
  validation loss:		0.197600
  top 1 accuracy:		97.90 %
  top 2 accuracy:		98.90 %
0.10622485727071762
0.10154715180397034
0.11225971579551697
0.11630710959434509
Batch of classes 8 out of 12 batches
Epoch 15 of 25 took 84.928s
  training loss:		0.109261
  validation loss:		0.194006
  top 1 accuracy:		96.83 %
  top 2 accuracy:		98.15 %
0.10703595727682114
0.10768191516399384
0.12024538218975067
0.10657370090484619
Batch of classes 8 out of 12 batches
Epoch 16 of 25 took 85.092s
  training loss:		0.108627
  validation loss:		0.185136
  top 1 accuracy:		98.33 %
  top 2 accuracy:		99.04 %
0.10535194724798203
0.10383474081754684
0.11478547751903534
0.11833202093839645
Batch of classes 8 out of 12 batches
Epoch 17 of 25 took 84.109s
  training loss:		0.108386
  validation loss:		0.196778
  top 1 accuracy:		98.12 %
  top 2 accuracy:		98.90 %
0.10512831062078476
0.10861461609601974
0.10965004563331604
0.11256353557109833
Batch of classes 8 out of 12 batches
Epoch 18 of 25 took 84.780s
  training loss:		0.108359
  validation loss:		0.179450
  top 1 accuracy:		99.21 %
  top 2 accuracy:		99.46 %
0.11063487827777863
0.10941537469625473
0.11464717239141464
0.10595135390758514
Batch of classes 8 out of 12 batches
Epoch 19 of 25 took 84.812s
  training loss:		0.108824
  validation loss:		0.210170
  top 1 accuracy:		90.50 %
  top 2 accuracy:		93.23 %
0.11830110847949982
0.10060372203588486
0.11261175572872162
0.10187387466430664
Batch of classes 8 out of 12 batches
Epoch 20 of 25 took 84.530s
  training loss:		0.109421
  validation loss:		0.179991
  top 1 accuracy:		97.54 %
  top 2 accuracy:		98.60 %
0.0979233831167221
0.10415905714035034
0.10664854943752289
0.10073316097259521
Batch of classes 8 out of 12 batches
Epoch 21 of 25 took 85.227s
  training loss:		0.107606
  validation loss:		0.193580
  top 1 accuracy:		99.02 %
  top 2 accuracy:		99.56 %
0.1195104718208313
0.10941442102193832
0.10154306888580322
0.09583050012588501
Batch of classes 8 out of 12 batches
Epoch 22 of 25 took 84.144s
  training loss:		0.107750
  validation loss:		0.194287
  top 1 accuracy:		98.79 %
  top 2 accuracy:		99.42 %
0.12029387056827545
0.10989783704280853
0.10832595825195312
0.11614172160625458
Batch of classes 8 out of 12 batches
Epoch 23 of 25 took 85.643s
  training loss:		0.107570
  validation loss:		0.197857
  top 1 accuracy:		98.94 %
  top 2 accuracy:		99.40 %
0.10183968394994736
0.11039212346076965
0.11203108727931976
0.10954344272613525
Batch of classes 8 out of 12 batches
Epoch 24 of 25 took 86.466s
  training loss:		0.107341
  validation loss:		0.197001
  top 1 accuracy:		96.38 %
  top 2 accuracy:		98.00 %
0.10342146456241608
0.10222004354000092
0.10167735815048218
0.09759537875652313
Batch of classes 8 out of 12 batches
Epoch 25 of 25 took 85.051s
  training loss:		0.107456
  validation loss:		0.185324
  top 1 accuracy:		98.96 %
  top 2 accuracy:		99.46 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		68.60 %
  top 1 accuracy Hybrid 1       :		64.40 %
  top 1 accuracy NCM            :		69.50 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		86.00 %
  top 1 accuracy Hybrid 1       :		73.10 %
  top 1 accuracy NCM            :		86.65 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		60.38 %
  top 1 accuracy Hybrid 1       :		45.38 %
  top 1 accuracy NCM            :		61.38 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		89.12 %
  top 1 accuracy Hybrid 1       :		75.50 %
  top 1 accuracy NCM            :		89.12 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		87.79 %
  top 1 accuracy Hybrid 1       :		59.54 %
  top 1 accuracy NCM            :		87.98 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		94.47 %
  top 1 accuracy Hybrid 1       :		89.31 %
  top 1 accuracy NCM            :		94.47 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		77.78 %
  top 1 accuracy Hybrid 1       :		49.76 %
  top 1 accuracy NCM            :		73.79 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.96 %
  top 1 accuracy Hybrid 1       :		99.73 %
  top 1 accuracy NCM            :		99.96 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		90.30 %
  top 1 accuracy Hybrid 1       :		90.48 %
  top 1 accuracy NCM            :		89.83 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		96.21 %
  top 1 accuracy Hybrid 1       :		95.01 %
  top 1 accuracy NCM            :		96.40 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		72.14 %
  top 1 accuracy Hybrid 1       :		98.47 %
  top 1 accuracy NCM            :		76.06 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		100.00 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		73.19 %
  top 1 accuracy Hybrid 1       :		44.89 %
  top 1 accuracy NCM            :		74.02 %
Binary accuracy:
Final results on wild classes:
  top 1 accuracy iCaRL          :		76.10 %
  top 1 accuracy Hybrid 1       :		71.30 %
  top 1 accuracy NCM            :		76.05 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		99.58 %
  top 1 accuracy Hybrid 1       :		98.96 %
  top 1 accuracy NCM            :		99.58 %
Binary accuracy:
Final results on glow classes:
  top 1 accuracy iCaRL          :		99.65 %
  top 1 accuracy Hybrid 1       :		99.52 %
  top 1 accuracy NCM            :		99.65 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		81.89 %
  top 1 accuracy Hybrid 1       :		75.74 %
  top 1 accuracy NCM            :		82.12 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		94.21 %
  top 1 accuracy Hybrid 1       :		91.05 %
  top 1 accuracy NCM            :		94.30 %
Classes in this batch: tensor([16, 17])
Data Size: 7200


Before first epoch
  validation loss:		0.874073
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 9 arrives ...
0.37898609042167664
0.17598609626293182
0.14960834383964539
0.1392907202243805
Batch of classes 9 out of 12 batches
Epoch 1 of 25 took 85.400s
  training loss:		0.179439
  validation loss:		0.389407
  top 1 accuracy:		49.56 %
  top 2 accuracy:		96.06 %
0.16061650216579437
0.15382367372512817
0.15301130712032318
0.13000190258026123
Batch of classes 9 out of 12 batches
Epoch 2 of 25 took 84.530s
  training loss:		0.151222
  validation loss:		0.383151
  top 1 accuracy:		49.48 %
  top 2 accuracy:		95.69 %
0.14877872169017792
0.15368953347206116
0.13997749984264374
0.14650849997997284
Batch of classes 9 out of 12 batches
Epoch 3 of 25 took 87.055s
  training loss:		0.150121
  validation loss:		0.335908
  top 1 accuracy:		49.96 %
  top 2 accuracy:		85.33 %
0.14667415618896484
0.15337511897087097
0.13320234417915344
0.16723474860191345
Batch of classes 9 out of 12 batches
Epoch 4 of 25 took 87.159s
  training loss:		0.149850
  validation loss:		0.355009
  top 1 accuracy:		49.88 %
  top 2 accuracy:		95.04 %
0.15802322328090668
0.15584304928779602
0.1754014939069748
0.151046484708786
Batch of classes 9 out of 12 batches
Epoch 5 of 25 took 85.086s
  training loss:		0.150147
  validation loss:		0.368987
  top 1 accuracy:		49.75 %
  top 2 accuracy:		96.71 %
0.14420735836029053
0.15315577387809753
0.14558005332946777
0.1407962590456009
Batch of classes 9 out of 12 batches
Epoch 6 of 25 took 84.969s
  training loss:		0.149723
  validation loss:		0.377555
  top 1 accuracy:		49.08 %
  top 2 accuracy:		91.10 %
0.12864936888217926
0.15796713531017303
0.14639613032341003
0.14952239394187927
Batch of classes 9 out of 12 batches
Epoch 7 of 25 took 85.241s
  training loss:		0.150680
  validation loss:		0.387097
  top 1 accuracy:		50.13 %
  top 2 accuracy:		96.79 %
0.15046894550323486
0.16035711765289307
0.14085052907466888
0.15359726548194885
Batch of classes 9 out of 12 batches
Epoch 8 of 25 took 86.379s
  training loss:		0.149288
  validation loss:		0.392451
  top 1 accuracy:		49.56 %
  top 2 accuracy:		90.13 %
0.149789497256279
0.13331402838230133
0.16121023893356323
0.14563700556755066
Batch of classes 9 out of 12 batches
Epoch 9 of 25 took 86.523s
  training loss:		0.149398
  validation loss:		0.358675
  top 1 accuracy:		50.04 %
  top 2 accuracy:		95.65 %
0.1532021164894104
0.15358638763427734
0.1584220826625824
0.15340863168239594
Batch of classes 9 out of 12 batches
Epoch 10 of 25 took 86.813s
  training loss:		0.148825
  validation loss:		0.324803
  top 1 accuracy:		48.85 %
  top 2 accuracy:		81.35 %
0.15788888931274414
0.1469866931438446
0.13490737974643707
0.1361105740070343
Batch of classes 9 out of 12 batches
Epoch 11 of 25 took 85.150s
  training loss:		0.146184
  validation loss:		0.428478
  top 1 accuracy:		50.65 %
  top 2 accuracy:		98.35 %
0.14401373267173767
0.12193268537521362
0.1453583836555481
0.14108824729919434
Batch of classes 9 out of 12 batches
Epoch 12 of 25 took 86.041s
  training loss:		0.144784
  validation loss:		0.440822
  top 1 accuracy:		51.02 %
  top 2 accuracy:		96.00 %
0.14411908388137817
0.14067292213439941
0.14715273678302765
0.14076006412506104
Batch of classes 9 out of 12 batches
Epoch 13 of 25 took 85.240s
  training loss:		0.144878
  validation loss:		0.401313
  top 1 accuracy:		55.33 %
  top 2 accuracy:		97.92 %
0.14018742740154266
0.13038863241672516
0.15326711535453796
0.1385936439037323
Batch of classes 9 out of 12 batches
Epoch 14 of 25 took 85.694s
  training loss:		0.144599
  validation loss:		0.419663
  top 1 accuracy:		62.25 %
  top 2 accuracy:		99.27 %
0.16111019253730774
0.14433734118938446
0.14790579676628113
0.13314592838287354
Batch of classes 9 out of 12 batches
Epoch 15 of 25 took 85.096s
  training loss:		0.144331
  validation loss:		0.387426
  top 1 accuracy:		66.21 %
  top 2 accuracy:		99.06 %
0.14558348059654236
0.13166199624538422
0.13645675778388977
0.14858108758926392
Batch of classes 9 out of 12 batches
Epoch 16 of 25 took 86.373s
  training loss:		0.143833
  validation loss:		0.397184
  top 1 accuracy:		57.75 %
  top 2 accuracy:		95.35 %
0.1452299803495407
0.15186551213264465
0.1455659568309784
0.14667652547359467
Batch of classes 9 out of 12 batches
Epoch 17 of 25 took 83.601s
  training loss:		0.144805
  validation loss:		0.407153
  top 1 accuracy:		61.33 %
  top 2 accuracy:		98.62 %
0.15320876240730286
0.139171302318573
0.15007564425468445
0.14518342912197113
Batch of classes 9 out of 12 batches
Epoch 18 of 25 took 84.859s
  training loss:		0.143822
  validation loss:		0.446492
  top 1 accuracy:		76.65 %
  top 2 accuracy:		99.77 %
0.15384671092033386
0.13077974319458008
0.14652815461158752
0.16991882026195526
Batch of classes 9 out of 12 batches
Epoch 19 of 25 took 84.581s
  training loss:		0.143599
  validation loss:		0.402890
  top 1 accuracy:		77.35 %
  top 2 accuracy:		98.94 %
0.1301601082086563
0.14395296573638916
0.14636757969856262
0.14732655882835388
Batch of classes 9 out of 12 batches
Epoch 20 of 25 took 87.413s
  training loss:		0.144028
  validation loss:		0.390234
  top 1 accuracy:		77.79 %
  top 2 accuracy:		99.21 %
0.15102311968803406
0.14033542573451996
0.12040074914693832
0.13362406194210052
Batch of classes 9 out of 12 batches
Epoch 21 of 25 took 86.340s
  training loss:		0.143129
  validation loss:		0.412179
  top 1 accuracy:		77.69 %
  top 2 accuracy:		99.67 %
0.15721842646598816
0.14438238739967346
0.14211952686309814
0.1272222101688385
Batch of classes 9 out of 12 batches
Epoch 22 of 25 took 84.399s
  training loss:		0.142635
  validation loss:		0.415251
  top 1 accuracy:		78.19 %
  top 2 accuracy:		99.73 %
0.1378641575574875
0.14168843626976013
0.1305077224969864
0.15209519863128662
Batch of classes 9 out of 12 batches
Epoch 23 of 25 took 85.626s
  training loss:		0.142589
  validation loss:		0.410056
  top 1 accuracy:		84.08 %
  top 2 accuracy:		99.60 %
0.15820586681365967
0.13399991393089294
0.14636225998401642
0.1443120241165161
Batch of classes 9 out of 12 batches
Epoch 24 of 25 took 85.652s
  training loss:		0.142506
  validation loss:		0.414332
  top 1 accuracy:		82.38 %
  top 2 accuracy:		99.77 %
0.1622406542301178
0.14442823827266693
0.1478150337934494
0.13381004333496094
Batch of classes 9 out of 12 batches
Epoch 25 of 25 took 87.956s
  training loss:		0.142378
  validation loss:		0.406716
  top 1 accuracy:		70.58 %
  top 2 accuracy:		98.58 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		68.50 %
  top 1 accuracy Hybrid 1       :		66.00 %
  top 1 accuracy NCM            :		68.55 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		86.20 %
  top 1 accuracy Hybrid 1       :		74.70 %
  top 1 accuracy NCM            :		85.95 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		59.00 %
  top 1 accuracy Hybrid 1       :		40.88 %
  top 1 accuracy NCM            :		60.00 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		87.88 %
  top 1 accuracy Hybrid 1       :		72.88 %
  top 1 accuracy NCM            :		87.75 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		85.88 %
  top 1 accuracy Hybrid 1       :		59.54 %
  top 1 accuracy NCM            :		86.26 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		93.70 %
  top 1 accuracy Hybrid 1       :		89.31 %
  top 1 accuracy NCM            :		93.70 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		72.88 %
  top 1 accuracy Hybrid 1       :		49.88 %
  top 1 accuracy NCM            :		75.00 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.92 %
  top 1 accuracy Hybrid 1       :		99.80 %
  top 1 accuracy NCM            :		99.92 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		90.67 %
  top 1 accuracy Hybrid 1       :		89.65 %
  top 1 accuracy NCM            :		90.02 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		96.03 %
  top 1 accuracy Hybrid 1       :		94.92 %
  top 1 accuracy NCM            :		96.03 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		76.92 %
  top 1 accuracy Hybrid 1       :		97.96 %
  top 1 accuracy NCM            :		74.76 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.96 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		99.96 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		71.69 %
  top 1 accuracy Hybrid 1       :		40.67 %
  top 1 accuracy NCM            :		72.61 %
Binary accuracy:
Final results on wild classes:
  top 1 accuracy iCaRL          :		75.96 %
  top 1 accuracy Hybrid 1       :		69.27 %
  top 1 accuracy NCM            :		75.71 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		68.56 %
  top 1 accuracy Hybrid 1       :		76.54 %
  top 1 accuracy NCM            :		71.06 %
Binary accuracy:
Final results on glow classes:
  top 1 accuracy iCaRL          :		99.54 %
  top 1 accuracy Hybrid 1       :		97.85 %
  top 1 accuracy NCM            :		99.52 %
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		80.08 %
  top 1 accuracy Hybrid 1       :		70.60 %
  top 1 accuracy NCM            :		76.85 %
Binary accuracy:
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		99.71 %
  top 1 accuracy Hybrid 1       :		99.88 %
  top 1 accuracy NCM            :		99.69 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		74.20 %
  top 1 accuracy Hybrid 1       :		68.97 %
  top 1 accuracy NCM            :		74.13 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		95.35 %
  top 1 accuracy Hybrid 1       :		92.53 %
  top 1 accuracy NCM            :		95.29 %
Classes in this batch: tensor([18, 19])
Data Size: 7188


Before first epoch
  validation loss:		0.689119
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 10 arrives ...
0.4873226583003998
0.1620294749736786
0.17728351056575775
0.17425191402435303
Batch of classes 10 out of 12 batches
Epoch 1 of 25 took 81.726s
  training loss:		0.182452
  validation loss:		0.277619
  top 1 accuracy:		29.20 %
  top 2 accuracy:		43.40 %
0.14301589131355286
0.13186562061309814
0.1303451657295227
0.13897734880447388
Batch of classes 10 out of 12 batches
Epoch 2 of 25 took 80.533s
  training loss:		0.141067
  validation loss:		0.229419
  top 1 accuracy:		73.02 %
  top 2 accuracy:		81.79 %
0.13704898953437805
0.1351361870765686
0.13252303004264832
0.14098942279815674
Batch of classes 10 out of 12 batches
Epoch 3 of 25 took 80.207s
  training loss:		0.135701
  validation loss:		0.234510
  top 1 accuracy:		69.63 %
  top 2 accuracy:		77.11 %
0.14254765212535858
0.1341402530670166
0.12598659098148346
0.145753875374794
Batch of classes 10 out of 12 batches
Epoch 4 of 25 took 80.388s
  training loss:		0.132428
  validation loss:		0.223941
  top 1 accuracy:		80.37 %
  top 2 accuracy:		86.38 %
0.14407366514205933
0.13749442994594574
0.1332479566335678
0.1415913701057434
Batch of classes 10 out of 12 batches
Epoch 5 of 25 took 80.261s
  training loss:		0.132133
  validation loss:		0.216917
  top 1 accuracy:		89.64 %
  top 2 accuracy:		94.32 %
0.12792406976222992
0.13415741920471191
0.13180869817733765
0.13404801487922668
Batch of classes 10 out of 12 batches
Epoch 6 of 25 took 80.883s
  training loss:		0.130695
  validation loss:		0.211379
  top 1 accuracy:		85.80 %
  top 2 accuracy:		90.73 %
0.13119806349277496
0.1348026692867279
0.12390150874853134
0.13931629061698914
Batch of classes 10 out of 12 batches
Epoch 7 of 25 took 80.405s
  training loss:		0.129761
  validation loss:		0.213096
  top 1 accuracy:		79.11 %
  top 2 accuracy:		85.88 %
0.1270979642868042
0.133403941988945
0.12133942544460297
0.11529622972011566
Batch of classes 10 out of 12 batches
Epoch 8 of 25 took 80.339s
  training loss:		0.129135
  validation loss:		0.206962
  top 1 accuracy:		79.20 %
  top 2 accuracy:		85.80 %
0.12062098830938339
0.1296948492527008
0.13923558592796326
0.14341789484024048
Batch of classes 10 out of 12 batches
Epoch 9 of 25 took 80.321s
  training loss:		0.128205
  validation loss:		0.226737
  top 1 accuracy:		84.13 %
  top 2 accuracy:		89.52 %
0.14225396513938904
0.1319209486246109
0.12511013448238373
0.13872605562210083
Batch of classes 10 out of 12 batches
Epoch 10 of 25 took 80.125s
  training loss:		0.128947
  validation loss:		0.199687
  top 1 accuracy:		87.43 %
  top 2 accuracy:		91.77 %
0.12999093532562256
0.12710919976234436
0.1288928985595703
0.1239422857761383
Batch of classes 10 out of 12 batches
Epoch 11 of 25 took 80.398s
  training loss:		0.124620
  validation loss:		0.214786
  top 1 accuracy:		89.26 %
  top 2 accuracy:		93.65 %
0.12232305854558945
0.12714943289756775
0.11969213932752609
0.13183051347732544
Batch of classes 10 out of 12 batches
Epoch 12 of 25 took 79.736s
  training loss:		0.123319
  validation loss:		0.212626
  top 1 accuracy:		94.11 %
  top 2 accuracy:		95.99 %
0.12793049216270447
0.137373149394989
0.12863385677337646
0.10906878113746643
Batch of classes 10 out of 12 batches
Epoch 13 of 25 took 79.692s
  training loss:		0.123397
  validation loss:		0.218122
  top 1 accuracy:		94.82 %
  top 2 accuracy:		96.87 %
0.10628078877925873
0.1187158077955246
0.12721198797225952
0.13227280974388123
Batch of classes 10 out of 12 batches
Epoch 14 of 25 took 80.219s
  training loss:		0.123139
  validation loss:		0.218162
  top 1 accuracy:		94.03 %
  top 2 accuracy:		96.28 %
0.11057339608669281
0.1271752119064331
0.10748132318258286
0.11035878956317902
Batch of classes 10 out of 12 batches
Epoch 15 of 25 took 80.569s
  training loss:		0.123162
  validation loss:		0.204259
  top 1 accuracy:		87.84 %
  top 2 accuracy:		91.23 %
0.1253274530172348
0.11170358955860138
0.11264897882938385
0.12633714079856873
Batch of classes 10 out of 12 batches
Epoch 16 of 25 took 80.316s
  training loss:		0.123189
  validation loss:		0.202858
  top 1 accuracy:		93.78 %
  top 2 accuracy:		96.28 %
0.12098662555217743
0.13288119435310364
0.12534523010253906
0.12583741545677185
Batch of classes 10 out of 12 batches
Epoch 17 of 25 took 80.318s
  training loss:		0.123361
  validation loss:		0.209548
  top 1 accuracy:		93.86 %
  top 2 accuracy:		96.57 %
0.12553954124450684
0.12814605236053467
0.11580389738082886
0.12323689460754395
Batch of classes 10 out of 12 batches
Epoch 18 of 25 took 80.361s
  training loss:		0.123287
  validation loss:		0.210828
  top 1 accuracy:		93.94 %
  top 2 accuracy:		95.95 %
0.1343468725681305
0.1289806067943573
0.13486549258232117
0.14297838509082794
Batch of classes 10 out of 12 batches
Epoch 19 of 25 took 80.308s
  training loss:		0.122995
  validation loss:		0.227352
  top 1 accuracy:		85.13 %
  top 2 accuracy:		89.43 %
0.12145324796438217
0.11897125095129013
0.12544916570186615
0.10913997888565063
Batch of classes 10 out of 12 batches
Epoch 20 of 25 took 80.162s
  training loss:		0.122612
  validation loss:		0.212891
  top 1 accuracy:		95.53 %
  top 2 accuracy:		97.58 %
0.12528064846992493
0.11133453249931335
0.1130208820104599
0.12569434940814972
Batch of classes 10 out of 12 batches
Epoch 21 of 25 took 79.747s
  training loss:		0.121366
  validation loss:		0.217273
  top 1 accuracy:		96.87 %
  top 2 accuracy:		98.41 %
0.11301937699317932
0.12160243093967438
0.11874323338270187
0.1255825161933899
Batch of classes 10 out of 12 batches
Epoch 22 of 25 took 79.954s
  training loss:		0.120874
  validation loss:		0.203811
  top 1 accuracy:		97.45 %
  top 2 accuracy:		98.50 %
0.11390474438667297
0.12091007828712463
0.10923658311367035
0.12173426151275635
Batch of classes 10 out of 12 batches
Epoch 23 of 25 took 80.158s
  training loss:		0.120858
  validation loss:		0.209986
  top 1 accuracy:		97.49 %
  top 2 accuracy:		98.50 %
0.12311267107725143
0.11348866671323776
0.11928296089172363
0.1281786859035492
Batch of classes 10 out of 12 batches
Epoch 24 of 25 took 80.269s
  training loss:		0.120922
  validation loss:		0.206950
  top 1 accuracy:		97.16 %
  top 2 accuracy:		98.37 %
0.10872354358434677
0.13171285390853882
0.12194254249334335
0.11376456916332245
Batch of classes 10 out of 12 batches
Epoch 25 of 25 took 80.263s
  training loss:		0.120124
  validation loss:		0.221624
  top 1 accuracy:		98.04 %
  top 2 accuracy:		98.50 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		59.40 %
  top 1 accuracy Hybrid 1       :		60.65 %
  top 1 accuracy NCM            :		59.80 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		79.35 %
  top 1 accuracy Hybrid 1       :		71.95 %
  top 1 accuracy NCM            :		79.60 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		49.50 %
  top 1 accuracy Hybrid 1       :		30.75 %
  top 1 accuracy NCM            :		48.38 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		83.88 %
  top 1 accuracy Hybrid 1       :		69.75 %
  top 1 accuracy NCM            :		83.38 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		83.59 %
  top 1 accuracy Hybrid 1       :		55.92 %
  top 1 accuracy NCM            :		83.78 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		95.04 %
  top 1 accuracy Hybrid 1       :		87.79 %
  top 1 accuracy NCM            :		95.23 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		72.73 %
  top 1 accuracy Hybrid 1       :		49.84 %
  top 1 accuracy NCM            :		67.63 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.92 %
  top 1 accuracy Hybrid 1       :		99.80 %
  top 1 accuracy NCM            :		99.96 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		90.48 %
  top 1 accuracy Hybrid 1       :		88.91 %
  top 1 accuracy NCM            :		90.11 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		95.19 %
  top 1 accuracy Hybrid 1       :		94.92 %
  top 1 accuracy NCM            :		94.82 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		77.08 %
  top 1 accuracy Hybrid 1       :		97.88 %
  top 1 accuracy NCM            :		82.17 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.92 %
  top 1 accuracy Hybrid 1       :		99.84 %
  top 1 accuracy NCM            :		99.96 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		69.27 %
  top 1 accuracy Hybrid 1       :		33.35 %
  top 1 accuracy NCM            :		69.75 %
Binary accuracy:
Final results on wild classes:
  top 1 accuracy iCaRL          :		74.36 %
  top 1 accuracy Hybrid 1       :		65.00 %
  top 1 accuracy NCM            :		74.50 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		72.98 %
  top 1 accuracy Hybrid 1       :		94.23 %
  top 1 accuracy NCM            :		75.27 %
Binary accuracy:
Final results on glow classes:
  top 1 accuracy iCaRL          :		98.48 %
  top 1 accuracy Hybrid 1       :		98.77 %
  top 1 accuracy NCM            :		98.48 %
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		74.69 %
  top 1 accuracy Hybrid 1       :		51.02 %
  top 1 accuracy NCM            :		72.02 %
Binary accuracy:
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		98.56 %
  top 1 accuracy Hybrid 1       :		98.69 %
  top 1 accuracy NCM            :		98.52 %
Final results on stylegan classes:
  top 1 accuracy iCaRL          :		98.62 %
  top 1 accuracy Hybrid 1       :		98.04 %
  top 1 accuracy NCM            :		98.29 %
Binary accuracy:
Final results on stylegan classes:
  top 1 accuracy iCaRL          :		99.16 %
  top 1 accuracy Hybrid 1       :		98.91 %
  top 1 accuracy NCM            :		99.00 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		75.11 %
  top 1 accuracy Hybrid 1       :		69.97 %
  top 1 accuracy NCM            :		75.03 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		94.42 %
  top 1 accuracy Hybrid 1       :		92.36 %
  top 1 accuracy NCM            :		94.41 %
Classes in this batch: tensor([20, 21])
Data Size: 1200


Before first epoch
  validation loss:		0.706995
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 11 arrives ...
0.34185275435447693
0.16014021635055542
Batch of classes 11 out of 12 batches
Epoch 1 of 25 took 38.514s
  training loss:		0.177550
  validation loss:		0.385053
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.25 %
0.15385447442531586
0.14539095759391785
Batch of classes 11 out of 12 batches
Epoch 2 of 25 took 37.989s
  training loss:		0.157389
  validation loss:		0.289523
  top 1 accuracy:		0.00 %
  top 2 accuracy:		11.25 %
0.1582915037870407
0.1340198516845703
Batch of classes 11 out of 12 batches
Epoch 3 of 25 took 37.735s
  training loss:		0.153470
  validation loss:		0.312156
  top 1 accuracy:		17.00 %
  top 2 accuracy:		39.25 %
0.17190194129943848
0.13994097709655762
Batch of classes 11 out of 12 batches
Epoch 4 of 25 took 37.794s
  training loss:		0.150980
  validation loss:		0.306276
  top 1 accuracy:		44.50 %
  top 2 accuracy:		62.50 %
0.14479494094848633
0.12784570455551147
Batch of classes 11 out of 12 batches
Epoch 5 of 25 took 37.895s
  training loss:		0.150754
  validation loss:		0.342289
  top 1 accuracy:		35.25 %
  top 2 accuracy:		48.75 %
0.16282081604003906
0.14490126073360443
Batch of classes 11 out of 12 batches
Epoch 6 of 25 took 37.952s
  training loss:		0.149891
  validation loss:		0.275820
  top 1 accuracy:		48.00 %
  top 2 accuracy:		57.75 %
0.15761327743530273
0.16278961300849915
Batch of classes 11 out of 12 batches
Epoch 7 of 25 took 37.955s
  training loss:		0.148043
  validation loss:		0.344952
  top 1 accuracy:		53.50 %
  top 2 accuracy:		68.25 %
0.142719104886055
0.13302651047706604
Batch of classes 11 out of 12 batches
Epoch 8 of 25 took 38.069s
  training loss:		0.146745
  validation loss:		0.319615
  top 1 accuracy:		60.50 %
  top 2 accuracy:		70.25 %
0.13996052742004395
0.15658946335315704
Batch of classes 11 out of 12 batches
Epoch 9 of 25 took 37.571s
  training loss:		0.148522
  validation loss:		0.323873
  top 1 accuracy:		57.50 %
  top 2 accuracy:		69.25 %
0.14512087404727936
0.15013901889324188
Batch of classes 11 out of 12 batches
Epoch 10 of 25 took 37.985s
  training loss:		0.146024
  validation loss:		0.307649
  top 1 accuracy:		61.25 %
  top 2 accuracy:		71.75 %
0.13312208652496338
0.14229035377502441
Batch of classes 11 out of 12 batches
Epoch 11 of 25 took 37.933s
  training loss:		0.143153
  validation loss:		0.320703
  top 1 accuracy:		57.25 %
  top 2 accuracy:		68.00 %
0.14317071437835693
0.13956771790981293
Batch of classes 11 out of 12 batches
Epoch 12 of 25 took 37.634s
  training loss:		0.141508
  validation loss:		0.308409
  top 1 accuracy:		65.25 %
  top 2 accuracy:		78.00 %
0.14107513427734375
0.14229124784469604
Batch of classes 11 out of 12 batches
Epoch 13 of 25 took 37.531s
  training loss:		0.140958
  validation loss:		0.309645
  top 1 accuracy:		72.75 %
  top 2 accuracy:		80.00 %
0.1243562400341034
0.12755471467971802
Batch of classes 11 out of 12 batches
Epoch 14 of 25 took 37.887s
  training loss:		0.140795
  validation loss:		0.308877
  top 1 accuracy:		76.00 %
  top 2 accuracy:		81.00 %
0.1458749920129776
0.1527004837989807
Batch of classes 11 out of 12 batches
Epoch 15 of 25 took 37.462s
  training loss:		0.140585
  validation loss:		0.327949
  top 1 accuracy:		70.00 %
  top 2 accuracy:		78.75 %
0.12218695133924484
0.13454002141952515
Batch of classes 11 out of 12 batches
Epoch 16 of 25 took 37.710s
  training loss:		0.140418
  validation loss:		0.308670
  top 1 accuracy:		72.00 %
  top 2 accuracy:		77.75 %
0.13746163249015808
0.14225870370864868
Batch of classes 11 out of 12 batches
Epoch 17 of 25 took 38.173s
  training loss:		0.139933
  validation loss:		0.278000
  top 1 accuracy:		78.25 %
  top 2 accuracy:		83.75 %
0.13090050220489502
0.1583082228899002
Batch of classes 11 out of 12 batches
Epoch 18 of 25 took 38.242s
  training loss:		0.139812
  validation loss:		0.319460
  top 1 accuracy:		73.50 %
  top 2 accuracy:		83.75 %
0.14193205535411835
0.1508401334285736
Batch of classes 11 out of 12 batches
Epoch 19 of 25 took 37.692s
  training loss:		0.139520
  validation loss:		0.320795
  top 1 accuracy:		75.75 %
  top 2 accuracy:		80.75 %
0.13771754503250122
0.14180994033813477
Batch of classes 11 out of 12 batches
Epoch 20 of 25 took 37.772s
  training loss:		0.140052
  validation loss:		0.312019
  top 1 accuracy:		79.00 %
  top 2 accuracy:		83.75 %
0.14695200324058533
0.1319064199924469
Batch of classes 11 out of 12 batches
Epoch 21 of 25 took 37.502s
  training loss:		0.137920
  validation loss:		0.321946
  top 1 accuracy:		82.75 %
  top 2 accuracy:		86.75 %
0.12636373937129974
0.13955865800380707
Batch of classes 11 out of 12 batches
Epoch 22 of 25 took 38.021s
  training loss:		0.137839
  validation loss:		0.305314
  top 1 accuracy:		81.75 %
  top 2 accuracy:		86.00 %
0.13699692487716675
0.12170997262001038
Batch of classes 11 out of 12 batches
Epoch 23 of 25 took 38.191s
  training loss:		0.137813
  validation loss:		0.331052
  top 1 accuracy:		74.00 %
  top 2 accuracy:		79.50 %
0.14480584859848022
0.1375245898962021
Batch of classes 11 out of 12 batches
Epoch 24 of 25 took 37.916s
  training loss:		0.137565
  validation loss:		0.325572
  top 1 accuracy:		75.50 %
  top 2 accuracy:		79.25 %
0.13790738582611084
0.15006838738918304
Batch of classes 11 out of 12 batches
Epoch 25 of 25 took 37.963s
  training loss:		0.137426
  validation loss:		0.300489
  top 1 accuracy:		82.75 %
  top 2 accuracy:		86.50 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		62.30 %
  top 1 accuracy Hybrid 1       :		62.75 %
  top 1 accuracy NCM            :		61.75 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		81.95 %
  top 1 accuracy Hybrid 1       :		70.35 %
  top 1 accuracy NCM            :		81.45 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		48.25 %
  top 1 accuracy Hybrid 1       :		33.50 %
  top 1 accuracy NCM            :		48.00 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		85.12 %
  top 1 accuracy Hybrid 1       :		71.12 %
  top 1 accuracy NCM            :		84.25 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		83.59 %
  top 1 accuracy Hybrid 1       :		52.67 %
  top 1 accuracy NCM            :		83.97 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		96.18 %
  top 1 accuracy Hybrid 1       :		85.11 %
  top 1 accuracy NCM            :		96.18 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		73.16 %
  top 1 accuracy Hybrid 1       :		50.12 %
  top 1 accuracy NCM            :		71.87 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.76 %
  top 1 accuracy Hybrid 1       :		99.80 %
  top 1 accuracy NCM            :		99.80 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		89.56 %
  top 1 accuracy Hybrid 1       :		88.82 %
  top 1 accuracy NCM            :		89.19 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		95.29 %
  top 1 accuracy Hybrid 1       :		94.73 %
  top 1 accuracy NCM            :		95.38 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		76.33 %
  top 1 accuracy Hybrid 1       :		96.83 %
  top 1 accuracy NCM            :		77.63 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.76 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		99.80 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		69.41 %
  top 1 accuracy Hybrid 1       :		28.07 %
  top 1 accuracy NCM            :		69.90 %
Binary accuracy:
Final results on wild classes:
  top 1 accuracy iCaRL          :		74.07 %
  top 1 accuracy Hybrid 1       :		60.49 %
  top 1 accuracy NCM            :		73.73 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		75.85 %
  top 1 accuracy Hybrid 1       :		94.15 %
  top 1 accuracy NCM            :		68.60 %
Binary accuracy:
Final results on glow classes:
  top 1 accuracy iCaRL          :		98.79 %
  top 1 accuracy Hybrid 1       :		98.85 %
  top 1 accuracy NCM            :		98.77 %
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		72.29 %
  top 1 accuracy Hybrid 1       :		49.83 %
  top 1 accuracy NCM            :		78.44 %
Binary accuracy:
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		98.92 %
  top 1 accuracy Hybrid 1       :		98.23 %
  top 1 accuracy NCM            :		98.88 %
Final results on stylegan classes:
  top 1 accuracy iCaRL          :		96.91 %
  top 1 accuracy Hybrid 1       :		85.88 %
  top 1 accuracy NCM            :		96.78 %
Binary accuracy:
Final results on stylegan classes:
  top 1 accuracy iCaRL          :		97.87 %
  top 1 accuracy Hybrid 1       :		94.74 %
  top 1 accuracy NCM            :		97.83 %
Final results on whichfaceisreal classes:
  top 1 accuracy iCaRL          :		95.25 %
  top 1 accuracy Hybrid 1       :		82.75 %
  top 1 accuracy NCM            :		95.25 %
Binary accuracy:
Final results on whichfaceisreal classes:
  top 1 accuracy iCaRL          :		95.25 %
  top 1 accuracy Hybrid 1       :		95.00 %
  top 1 accuracy NCM            :		95.25 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		75.51 %
  top 1 accuracy Hybrid 1       :		68.37 %
  top 1 accuracy NCM            :		75.26 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		94.67 %
  top 1 accuracy Hybrid 1       :		91.38 %
  top 1 accuracy NCM            :		94.56 %
Classes in this batch: tensor([22, 23])
Data Size: 260


Before first epoch
  validation loss:		0.758073
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 12 arrives ...
0.1648714691400528
0.14048662781715393
Batch of classes 12 out of 12 batches
Epoch 1 of 25 took 26.164s
  training loss:		0.154840
  validation loss:		0.426448
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
0.14275717735290527
0.14501133561134338
Batch of classes 12 out of 12 batches
Epoch 2 of 25 took 25.563s
  training loss:		0.147601
  validation loss:		0.373781
  top 1 accuracy:		0.00 %
  top 2 accuracy:		2.22 %
0.1380387544631958
0.148549884557724
Batch of classes 12 out of 12 batches
Epoch 3 of 25 took 25.654s
  training loss:		0.146011
  validation loss:		0.414605
  top 1 accuracy:		0.00 %
  top 2 accuracy:		1.11 %
0.14942608773708344
0.1257551610469818
Batch of classes 12 out of 12 batches
Epoch 4 of 25 took 25.519s
  training loss:		0.144524
  validation loss:		0.383637
  top 1 accuracy:		5.56 %
  top 2 accuracy:		18.89 %
0.14433996379375458
0.13258859515190125
Batch of classes 12 out of 12 batches
Epoch 5 of 25 took 25.761s
  training loss:		0.144897
  validation loss:		0.388226
  top 1 accuracy:		4.44 %
  top 2 accuracy:		14.44 %
0.13382019102573395
0.14003333449363708
Batch of classes 12 out of 12 batches
Epoch 6 of 25 took 25.634s
  training loss:		0.143042
  validation loss:		0.383751
  top 1 accuracy:		4.44 %
  top 2 accuracy:		13.33 %
0.14387275278568268
0.14107421040534973
Batch of classes 12 out of 12 batches
Epoch 7 of 25 took 25.634s
  training loss:		0.143807
  validation loss:		0.391120
  top 1 accuracy:		1.11 %
  top 2 accuracy:		5.56 %
0.13132953643798828
0.1297779530286789
Batch of classes 12 out of 12 batches
Epoch 8 of 25 took 25.571s
  training loss:		0.142447
  validation loss:		0.378019
  top 1 accuracy:		3.33 %
  top 2 accuracy:		13.33 %
0.15010838210582733
0.14265871047973633
Batch of classes 12 out of 12 batches
Epoch 9 of 25 took 25.398s
  training loss:		0.142988
  validation loss:		0.335603
  top 1 accuracy:		4.44 %
  top 2 accuracy:		23.33 %
0.14410540461540222
0.16274598240852356
Batch of classes 12 out of 12 batches
Epoch 10 of 25 took 25.643s
  training loss:		0.142621
  validation loss:		0.375087
  top 1 accuracy:		7.78 %
  top 2 accuracy:		16.67 %
0.157804474234581
0.14879487454891205
Batch of classes 12 out of 12 batches
Epoch 11 of 25 took 25.549s
  training loss:		0.139564
  validation loss:		0.381008
  top 1 accuracy:		4.44 %
  top 2 accuracy:		17.78 %
0.1444404572248459
0.1409381926059723
Batch of classes 12 out of 12 batches
Epoch 12 of 25 took 25.461s
  training loss:		0.138876
  validation loss:		0.392253
  top 1 accuracy:		3.33 %
  top 2 accuracy:		10.00 %
0.14693193137645721
0.1353037804365158
Batch of classes 12 out of 12 batches
Epoch 13 of 25 took 25.570s
  training loss:		0.138583
  validation loss:		0.397339
  top 1 accuracy:		11.11 %
  top 2 accuracy:		22.22 %
0.1323692798614502
0.14213943481445312
Batch of classes 12 out of 12 batches
Epoch 14 of 25 took 25.490s
  training loss:		0.138677
  validation loss:		0.400970
  top 1 accuracy:		7.78 %
  top 2 accuracy:		18.89 %
0.14704066514968872
0.14691630005836487
Batch of classes 12 out of 12 batches
Epoch 15 of 25 took 25.560s
  training loss:		0.138607
  validation loss:		0.402868
  top 1 accuracy:		8.89 %
  top 2 accuracy:		22.22 %
0.13041943311691284
0.14887282252311707
Batch of classes 12 out of 12 batches
Epoch 16 of 25 took 25.604s
  training loss:		0.138527
  validation loss:		0.411473
  top 1 accuracy:		7.78 %
  top 2 accuracy:		17.78 %
0.13127103447914124
0.1315012276172638
Batch of classes 12 out of 12 batches
Epoch 17 of 25 took 25.591s
  training loss:		0.138369
  validation loss:		0.392385
  top 1 accuracy:		3.33 %
  top 2 accuracy:		16.67 %
0.14030501246452332
0.1370069533586502
Batch of classes 12 out of 12 batches
Epoch 18 of 25 took 25.587s
  training loss:		0.138214
  validation loss:		0.385878
  top 1 accuracy:		5.56 %
  top 2 accuracy:		16.67 %
0.13608291745185852
0.13697700202465057
Batch of classes 12 out of 12 batches
Epoch 19 of 25 took 25.562s
  training loss:		0.138150
  validation loss:		0.401695
  top 1 accuracy:		6.67 %
  top 2 accuracy:		20.00 %
0.1377565711736679
0.13399356603622437
Batch of classes 12 out of 12 batches
Epoch 20 of 25 took 25.716s
  training loss:		0.138118
  validation loss:		0.385217
  top 1 accuracy:		8.89 %
  top 2 accuracy:		24.44 %
0.13079231977462769
0.17177677154541016
Batch of classes 12 out of 12 batches
Epoch 21 of 25 took 25.524s
  training loss:		0.137346
  validation loss:		0.380739
  top 1 accuracy:		6.67 %
  top 2 accuracy:		17.78 %
0.14696073532104492
0.12838780879974365
Batch of classes 12 out of 12 batches
Epoch 22 of 25 took 25.597s
  training loss:		0.137457
  validation loss:		0.372372
  top 1 accuracy:		7.78 %
  top 2 accuracy:		20.00 %
0.13537020981311798
0.1247067004442215
Batch of classes 12 out of 12 batches
Epoch 23 of 25 took 25.312s
  training loss:		0.137403
  validation loss:		0.388034
  top 1 accuracy:		4.44 %
  top 2 accuracy:		15.56 %
0.14702385663986206
0.1253419816493988
Batch of classes 12 out of 12 batches
Epoch 24 of 25 took 25.692s
  training loss:		0.136743
  validation loss:		0.395052
  top 1 accuracy:		12.22 %
  top 2 accuracy:		24.44 %
0.13016155362129211
0.14100269973278046
Batch of classes 12 out of 12 batches
Epoch 25 of 25 took 25.849s
  training loss:		0.136823
  validation loss:		0.360979
  top 1 accuracy:		7.78 %
  top 2 accuracy:		23.33 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		58.50 %
  top 1 accuracy Hybrid 1       :		63.60 %
  top 1 accuracy NCM            :		57.40 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		79.90 %
  top 1 accuracy Hybrid 1       :		71.60 %
  top 1 accuracy NCM            :		78.95 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		47.50 %
  top 1 accuracy Hybrid 1       :		34.88 %
  top 1 accuracy NCM            :		48.88 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		83.75 %
  top 1 accuracy Hybrid 1       :		72.25 %
  top 1 accuracy NCM            :		82.75 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		81.30 %
  top 1 accuracy Hybrid 1       :		54.01 %
  top 1 accuracy NCM            :		82.06 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		94.85 %
  top 1 accuracy Hybrid 1       :		87.60 %
  top 1 accuracy NCM            :		94.85 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		73.82 %
  top 1 accuracy Hybrid 1       :		50.00 %
  top 1 accuracy NCM            :		71.12 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.84 %
  top 1 accuracy Hybrid 1       :		99.73 %
  top 1 accuracy NCM            :		99.84 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		88.91 %
  top 1 accuracy Hybrid 1       :		87.80 %
  top 1 accuracy NCM            :		88.63 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		94.55 %
  top 1 accuracy Hybrid 1       :		94.73 %
  top 1 accuracy NCM            :		94.55 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		75.74 %
  top 1 accuracy Hybrid 1       :		97.10 %
  top 1 accuracy NCM            :		78.37 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.80 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		99.80 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		69.03 %
  top 1 accuracy Hybrid 1       :		28.99 %
  top 1 accuracy NCM            :		69.61 %
Binary accuracy:
Final results on wild classes:
  top 1 accuracy iCaRL          :		72.76 %
  top 1 accuracy Hybrid 1       :		61.12 %
  top 1 accuracy NCM            :		72.90 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		70.98 %
  top 1 accuracy Hybrid 1       :		94.21 %
  top 1 accuracy NCM            :		73.40 %
Binary accuracy:
Final results on glow classes:
  top 1 accuracy iCaRL          :		98.83 %
  top 1 accuracy Hybrid 1       :		98.88 %
  top 1 accuracy NCM            :		98.81 %
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		77.25 %
  top 1 accuracy Hybrid 1       :		50.33 %
  top 1 accuracy NCM            :		75.12 %
Binary accuracy:
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		99.10 %
  top 1 accuracy Hybrid 1       :		99.08 %
  top 1 accuracy NCM            :		99.10 %
Final results on stylegan classes:
  top 1 accuracy iCaRL          :		89.22 %
  top 1 accuracy Hybrid 1       :		75.06 %
  top 1 accuracy NCM            :		89.47 %
Binary accuracy:
Final results on stylegan classes:
  top 1 accuracy iCaRL          :		93.82 %
  top 1 accuracy Hybrid 1       :		89.85 %
  top 1 accuracy NCM            :		94.28 %
Final results on whichfaceisreal classes:
  top 1 accuracy iCaRL          :		91.25 %
  top 1 accuracy Hybrid 1       :		63.50 %
  top 1 accuracy NCM            :		91.00 %
Binary accuracy:
Final results on whichfaceisreal classes:
  top 1 accuracy iCaRL          :		91.50 %
  top 1 accuracy Hybrid 1       :		87.50 %
  top 1 accuracy NCM            :		91.25 %
Final results on san classes:
  top 1 accuracy iCaRL          :		53.33 %
  top 1 accuracy Hybrid 1       :		7.78 %
  top 1 accuracy NCM            :		50.00 %
Binary accuracy:
Final results on san classes:
  top 1 accuracy iCaRL          :		72.22 %
  top 1 accuracy Hybrid 1       :		54.44 %
  top 1 accuracy NCM            :		70.00 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		74.17 %
  top 1 accuracy Hybrid 1       :		67.06 %
  top 1 accuracy NCM            :		74.23 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		93.79 %
  top 1 accuracy Hybrid 1       :		91.05 %
  top 1 accuracy NCM            :		93.71 %
----------------- Options ---------------
               add_binary: False                         
               batch_size: 32                            	[default: 64]
                   binary: False                         
                blur_prob: 0                             
                 blur_sig: 0.5                           
          checkpoints_dir: /scratch_net/kringel/chuqli/CNNDetection/checkpoints	[default: ./checkpoints]
                class_bal: False                         
           continue_train: False                         
                 cropSize: 224                           
                 data_aug: False                         
                 dataroot: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/test	[default: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL]
          earlystop_epoch: 5                             
                    epoch: latest                        
                 fine_tun: False                         
                    gpuid: [1]                           
                init_gain: 0.02                          
                  init_lr: 0.0005                        
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2                           
                 jpg_prob: 0                             
                 jpg_qual: 75                            
                 loadSize: 256                           
                     mode: binary                        
               model_name: resnet18                      
               model_type: resnet                        
            model_weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth	[default: None]
               multiclass: [0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0]	[default: [1]]
                     name: icarl_df                      	[default: experiment_name]
                  no_flip: False                         
              num_classes: 2                             
               num_epochs: 20                            	[default: 12]
              num_threads: 4                             
                  outfile: temp_0.1.csv                  
            pretrain_name:                               
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 20                            
         save_latest_freq: 2000                          
                 schedule: [15, 20, 25]                  	[default: [10]]
           serial_batches: False                         
                   suffix:                               
                task_name: gaugan,biggan,cyclegan,imle,deepfake,crn,wild,glow,stargan_gf,stylegan,whichfaceisreal,san	[default: ]
              train_split: train                         
                val_split: val                           
----------------- End -------------------
{'All': 24}
Task order: ['gaugan', 'biggan', 'cyclegan', 'imle', 'deepfake', 'crn', 'wild', 'glow', 'stargan_gf', 'stylegan', 'whichfaceisreal', 'san']
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Classes in this batch: tensor([0, 1])
Data Size: 6000


Before first epoch
  validation loss:		1.040402
  top 1 accuracy:		16.90 %
  top 2 accuracy:		17.25 %
Batch of classes number 1 arrives ...
0.7993027567863464
0.045448243618011475
Batch of classes 1 out of 12 batches
Epoch 1 of 20 took 41.436s
  training loss:		0.087376
  validation loss:		0.042283
  top 1 accuracy:		78.85 %
  top 2 accuracy:		100.00 %
0.018203144893050194
0.019391324371099472
Batch of classes 1 out of 12 batches
Epoch 2 of 20 took 39.582s
  training loss:		0.025059
  validation loss:		0.041269
  top 1 accuracy:		77.50 %
  top 2 accuracy:		100.00 %
0.026404595002532005
0.03671468421816826
Batch of classes 1 out of 12 batches
Epoch 3 of 20 took 39.211s
  training loss:		0.018356
  validation loss:		0.019694
  top 1 accuracy:		90.75 %
  top 2 accuracy:		100.00 %
0.005807504989206791
0.01757357269525528
Batch of classes 1 out of 12 batches
Epoch 4 of 20 took 39.240s
  training loss:		0.014613
  validation loss:		0.017850
  top 1 accuracy:		91.15 %
  top 2 accuracy:		100.00 %
0.010022677481174469
0.016785582527518272
Batch of classes 1 out of 12 batches
Epoch 5 of 20 took 38.776s
  training loss:		0.013236
  validation loss:		0.016839
  top 1 accuracy:		91.40 %
  top 2 accuracy:		100.00 %
0.006249530240893364
0.004873925354331732
Batch of classes 1 out of 12 batches
Epoch 6 of 20 took 39.134s
  training loss:		0.012797
  validation loss:		0.023348
  top 1 accuracy:		89.20 %
  top 2 accuracy:		100.00 %
0.03388092666864395
0.00609872629866004
Batch of classes 1 out of 12 batches
Epoch 7 of 20 took 39.434s
  training loss:		0.010683
  validation loss:		0.033914
  top 1 accuracy:		82.80 %
  top 2 accuracy:		100.00 %
0.005607870407402515
0.0035898080095648766
Batch of classes 1 out of 12 batches
Epoch 8 of 20 took 39.347s
  training loss:		0.010590
  validation loss:		0.008940
  top 1 accuracy:		96.00 %
  top 2 accuracy:		100.00 %
0.0012588270474225283
0.0364263579249382
Batch of classes 1 out of 12 batches
Epoch 9 of 20 took 39.398s
  training loss:		0.009174
  validation loss:		0.012998
  top 1 accuracy:		93.95 %
  top 2 accuracy:		100.00 %
0.015433190390467644
0.0028556189499795437
Batch of classes 1 out of 12 batches
Epoch 10 of 20 took 39.306s
  training loss:		0.007529
  validation loss:		0.037128
  top 1 accuracy:		82.75 %
  top 2 accuracy:		100.00 %
0.02882368117570877
0.0010345997288823128
Batch of classes 1 out of 12 batches
Epoch 11 of 20 took 39.266s
  training loss:		0.008672
  validation loss:		0.009316
  top 1 accuracy:		95.80 %
  top 2 accuracy:		99.95 %
0.004030745476484299
0.0027367305010557175
Batch of classes 1 out of 12 batches
Epoch 12 of 20 took 38.848s
  training loss:		0.008693
  validation loss:		0.018057
  top 1 accuracy:		91.25 %
  top 2 accuracy:		100.00 %
0.0011248444207012653
0.006010419689118862
Batch of classes 1 out of 12 batches
Epoch 13 of 20 took 39.587s
  training loss:		0.007605
  validation loss:		0.022218
  top 1 accuracy:		91.50 %
  top 2 accuracy:		99.95 %
0.016405504196882248
0.002117031253874302
Batch of classes 1 out of 12 batches
Epoch 14 of 20 took 38.844s
  training loss:		0.007318
  validation loss:		0.010325
  top 1 accuracy:		95.50 %
  top 2 accuracy:		100.00 %
0.02199428342282772
0.005615150090306997
Batch of classes 1 out of 12 batches
Epoch 15 of 20 took 39.015s
  training loss:		0.006749
  validation loss:		0.007081
  top 1 accuracy:		97.00 %
  top 2 accuracy:		100.00 %
0.005140875931829214
0.0051506441086530685
Batch of classes 1 out of 12 batches
Epoch 16 of 20 took 39.537s
  training loss:		0.003909
  validation loss:		0.003799
  top 1 accuracy:		98.30 %
  top 2 accuracy:		100.00 %
0.0016162738902494311
0.0024742968380451202
Batch of classes 1 out of 12 batches
Epoch 17 of 20 took 39.260s
  training loss:		0.002888
  validation loss:		0.006384
  top 1 accuracy:		97.15 %
  top 2 accuracy:		100.00 %
0.0012852286454290152
0.011754721403121948
Batch of classes 1 out of 12 batches
Epoch 18 of 20 took 39.208s
  training loss:		0.002594
  validation loss:		0.003964
  top 1 accuracy:		98.35 %
  top 2 accuracy:		100.00 %
0.0002351631410419941
0.0009444011375308037
Batch of classes 1 out of 12 batches
Epoch 19 of 20 took 39.444s
  training loss:		0.002788
  validation loss:		0.008520
  top 1 accuracy:		96.50 %
  top 2 accuracy:		100.00 %
0.006114198826253414
0.004213336855173111
Batch of classes 1 out of 12 batches
Epoch 20 of 20 took 39.195s
  training loss:		0.003042
  validation loss:		0.003016
  top 1 accuracy:		98.65 %
  top 2 accuracy:		100.00 %
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		98.60 %
  top 1 accuracy Hybrid 1       :		98.65 %
  top 1 accuracy NCM            :		98.60 %
Binary accuracy:
Traceback (most recent call last):
  File "main_icarl_CNND.py", line 539, in <module>
    main()
  File "main_icarl_CNND.py", line 508, in main
    top1_acc_list_ori = icarl_accuracy_measure_to_binary(task_info.get_task_test_set(i), class_means, val_fn,
  File "/home/chuqli/icarl-pytorch/cl_strategies/icarl.py", line 112, in icarl_accuracy_measure_to_binary
    _, pred, pred_inter = val_fn(patterns, targets)
  File "/home/chuqli/icarl-pytorch/utils/theano_utils.py", line 140, in make_theano_validation_function
    loss = criterion(output, y)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 530, in forward
    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2518, in binary_cross_entropy
    raise ValueError("Using a target size ({}) that is different to the input size ({}) is deprecated. "
ValueError: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 24])) is deprecated. Please ensure they have the same size.
----------------- Options ---------------
               add_binary: False                         
               batch_size: 32                            	[default: 64]
                   binary: False                         
                blur_prob: 0                             
                 blur_sig: 0.5                           
          checkpoints_dir: /scratch_net/kringel/chuqli/CNNDetection/checkpoints	[default: ./checkpoints]
                class_bal: False                         
           continue_train: False                         
                 cropSize: 224                           
                 data_aug: False                         
                 dataroot: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/test	[default: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL]
          earlystop_epoch: 5                             
                    epoch: latest                        
                 fine_tun: False                         
                    gpuid: [1]                           
                init_gain: 0.02                          
                  init_lr: 0.0005                        
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2                           
                 jpg_prob: 0                             
                 jpg_qual: 75                            
                 loadSize: 256                           
                     mode: binary                        
               model_name: resnet18                      
               model_type: resnet                        
            model_weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth	[default: None]
               multiclass: [0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0]	[default: [1]]
                     name: icarl_df                      	[default: experiment_name]
                  no_flip: False                         
              num_classes: 2                             
               num_epochs: 20                            	[default: 12]
              num_threads: 4                             
                  outfile: temp_0.1.csv                  
            pretrain_name:                               
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 20                            
         save_latest_freq: 2000                          
                 schedule: [20, 25, 30]                  	[default: [10]]
           serial_batches: False                         
                   suffix:                               
                task_name: gaugan,biggan,cyclegan,imle,deepfake,crn,wild,glow,stargan_gf,stylegan,whichfaceisreal,san	[default: ]
              train_split: train                         
                val_split: val                           
----------------- End -------------------
{'All': 24}
Task order: ['gaugan', 'biggan', 'cyclegan', 'imle', 'deepfake', 'crn', 'wild', 'glow', 'stargan_gf', 'stylegan', 'whichfaceisreal', 'san']
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Classes in this batch: tensor([0, 1])
Data Size: 6000


Before first epoch
  validation loss:		1.040402
  top 1 accuracy:		16.90 %
  top 2 accuracy:		17.25 %
Batch of classes number 1 arrives ...
0.7992855906486511
0.04171917960047722
Batch of classes 1 out of 12 batches
Epoch 1 of 20 took 40.502s
  training loss:		0.084692
  validation loss:		0.044405
  top 1 accuracy:		79.30 %
  top 2 accuracy:		100.00 %
0.014641384594142437
0.03150194138288498
Batch of classes 1 out of 12 batches
Epoch 2 of 20 took 39.008s
  training loss:		0.026063
  validation loss:		0.022459
  top 1 accuracy:		88.30 %
  top 2 accuracy:		100.00 %
0.03448423743247986
0.023243948817253113
Batch of classes 1 out of 12 batches
Epoch 3 of 20 took 39.193s
  training loss:		0.018008
  validation loss:		0.019531
  top 1 accuracy:		91.50 %
  top 2 accuracy:		100.00 %
0.017656100913882256
0.01107045542448759
Batch of classes 1 out of 12 batches
Epoch 4 of 20 took 39.030s
  training loss:		0.015106
  validation loss:		0.064484
  top 1 accuracy:		74.50 %
  top 2 accuracy:		100.00 %
0.014492087066173553
0.029066577553749084
Batch of classes 1 out of 12 batches
Epoch 5 of 20 took 39.583s
  training loss:		0.013921
  validation loss:		0.012632
  top 1 accuracy:		94.05 %
  top 2 accuracy:		100.00 %
0.004857270047068596
0.002491493010893464
Batch of classes 1 out of 12 batches
Epoch 6 of 20 took 39.165s
  training loss:		0.012210
  validation loss:		0.027355
  top 1 accuracy:		88.85 %
  top 2 accuracy:		100.00 %
0.016460765153169632
0.010418623685836792
Batch of classes 1 out of 12 batches
Epoch 7 of 20 took 39.138s
  training loss:		0.011573
  validation loss:		0.013881
  top 1 accuracy:		93.00 %
  top 2 accuracy:		100.00 %
0.0034609846770763397
0.007087169215083122
Batch of classes 1 out of 12 batches
Epoch 8 of 20 took 39.043s
  training loss:		0.010373
  validation loss:		0.028678
  top 1 accuracy:		88.20 %
  top 2 accuracy:		100.00 %
0.003053238382562995
0.03340834006667137
Batch of classes 1 out of 12 batches
Epoch 9 of 20 took 39.037s
  training loss:		0.009577
  validation loss:		0.017156
  top 1 accuracy:		91.75 %
  top 2 accuracy:		100.00 %
0.00962117500603199
0.012807488441467285
Batch of classes 1 out of 12 batches
Epoch 10 of 20 took 38.900s
  training loss:		0.007620
  validation loss:		0.028785
  top 1 accuracy:		90.25 %
  top 2 accuracy:		99.85 %
0.01828364096581936
0.0063928887248039246
Batch of classes 1 out of 12 batches
Epoch 11 of 20 took 39.222s
  training loss:		0.007853
  validation loss:		0.007460
  top 1 accuracy:		96.70 %
  top 2 accuracy:		100.00 %
0.011532570235431194
0.0019377719145268202
Batch of classes 1 out of 12 batches
Epoch 12 of 20 took 38.881s
  training loss:		0.009013
  validation loss:		0.019915
  top 1 accuracy:		89.90 %
  top 2 accuracy:		100.00 %
0.003995122388005257
0.0036105893086642027
Batch of classes 1 out of 12 batches
Epoch 13 of 20 took 38.788s
  training loss:		0.007257
  validation loss:		0.015850
  top 1 accuracy:		92.90 %
  top 2 accuracy:		100.00 %
0.009173374623060226
0.0027034785598516464
Batch of classes 1 out of 12 batches
Epoch 14 of 20 took 39.171s
  training loss:		0.006577
  validation loss:		0.007801
  top 1 accuracy:		96.55 %
  top 2 accuracy:		100.00 %
0.024828407913446426
0.0022097909823060036
Batch of classes 1 out of 12 batches
Epoch 15 of 20 took 40.405s
  training loss:		0.006630
  validation loss:		0.015229
  top 1 accuracy:		93.95 %
  top 2 accuracy:		100.00 %
0.012117968872189522
0.02077353373169899
Batch of classes 1 out of 12 batches
Epoch 16 of 20 took 38.690s
  training loss:		0.007871
  validation loss:		0.013975
  top 1 accuracy:		93.60 %
  top 2 accuracy:		100.00 %
0.0024978709407150745
0.012517116963863373
Batch of classes 1 out of 12 batches
Epoch 17 of 20 took 38.709s
  training loss:		0.006227
  validation loss:		0.009199
  top 1 accuracy:		95.80 %
  top 2 accuracy:		100.00 %
0.02576693519949913
0.00969730131328106
Batch of classes 1 out of 12 batches
Epoch 18 of 20 took 38.654s
  training loss:		0.005861
  validation loss:		0.009425
  top 1 accuracy:		95.75 %
  top 2 accuracy:		100.00 %
0.0013665386941283941
0.006462067365646362
Batch of classes 1 out of 12 batches
Epoch 19 of 20 took 38.832s
  training loss:		0.006456
  validation loss:		0.005036
  top 1 accuracy:		97.70 %
  top 2 accuracy:		100.00 %
0.0009450713987462223
0.008227592334151268
Batch of classes 1 out of 12 batches
Epoch 20 of 20 took 38.580s
  training loss:		0.006716
  validation loss:		0.015289
  top 1 accuracy:		92.80 %
  top 2 accuracy:		100.00 %
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		95.05 %
  top 1 accuracy Hybrid 1       :		92.80 %
  top 1 accuracy NCM            :		95.25 %
Binary accuracy:
Traceback (most recent call last):
  File "main_icarl_CNND.py", line 539, in <module>
    main()
  File "main_icarl_CNND.py", line 508, in main
    top1_acc_list_ori = icarl_accuracy_measure_to_binary(task_info.get_task_test_set(i), class_means, val_fn,
  File "/home/chuqli/icarl-pytorch/cl_strategies/icarl.py", line 112, in icarl_accuracy_measure_to_binary
    _, pred, pred_inter = val_fn(patterns, targets)
  File "/home/chuqli/icarl-pytorch/utils/theano_utils.py", line 140, in make_theano_validation_function
    loss = criterion(output, y)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 530, in forward
    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2518, in binary_cross_entropy
    raise ValueError("Using a target size ({}) that is different to the input size ({}) is deprecated. "
ValueError: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 24])) is deprecated. Please ensure they have the same size.
