----------------- Options ---------------
               add_binary: True                          	[default: False]
               batch_size: 32                            	[default: 64]
                   binary: False                         
              binary_loss: sum_b_log                     	[default: sum_b_sig]
            binary_weight: 0.4                           	[default: 0.5]
                blur_prob: 0                             
                 blur_sig: 0.5                           
          checkpoints_dir: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL/checkpoints	[default: ./checkpoints]
                class_bal: False                         
           continue_train: False                         
                 cropSize: 224                           
                 data_aug: False                         
                 dataroot: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/test	[default: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL]
          earlystop_epoch: 5                             
                    epoch: latest                        
                 fine_tun: False                         
                    gpuid: [1]                           
                init_gain: 0.02                          
                  init_lr: 0.0005                        
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2                           
                 jpg_prob: 0                             
                 jpg_qual: 75                            
          label_smoothing: False                         
                 loadSize: 256                           
                    mixup: False                         
              mixup_alpha: 0.1                           
                     mode: binary                        
               model_name: resnet18                      
               model_type: resnet                        
            model_weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth	[default: None]
               multiclass: [0, 0, 1, 0, 0, 0, 0]         	[default: [1]]
                     name: MT_7_bm_sum_b_log04_15        	[default: experiment_name]
                  no_flip: False                         
              num_classes: 2                             
               num_epochs: 30                            	[default: 12]
              num_threads: 4                             
                  outfile: temp_0.1.csv                  
            pretrain_name:                               
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 20                            
         save_latest_freq: 2000                          
                 schedule: [10, 20, 30]                  	[default: [10]]
           serial_batches: False                         
          smoothing_alpha: 0.1                           
                   suffix:                               
                task_name: gaugan,biggan,cyclegan,imle,deepfake,crn,wild	[default: ]
              train_split: train                         
                val_split: val                           
----------------- End -------------------
{'All': 14}
Task order: ['gaugan', 'biggan', 'cyclegan', 'imle', 'deepfake', 'crn', 'wild']
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Classes in this batch: tensor([0, 1])
Data Size: 6000


Before first epoch
  validation loss:		1.309705
  top 1 accuracy:		17.05 %
  top 2 accuracy:		17.30 %
Batch of classes number 1 arrives ...
0.9424769878387451
0.2538875341415405
Batch of classes 1 out of 7 batches
Epoch 1 of 30 took 138.623s
  training loss:		0.273153
  validation loss:		0.043956
  top 1 accuracy:		86.20 %
  top 2 accuracy:		100.00 %
0.2436131238937378
0.21567778289318085
Batch of classes 1 out of 7 batches
Epoch 2 of 30 took 115.487s
  training loss:		0.223364
  validation loss:		0.047704
  top 1 accuracy:		84.40 %
  top 2 accuracy:		100.00 %
0.21368665993213654
0.2083558291196823
Batch of classes 1 out of 7 batches
Epoch 3 of 30 took 94.759s
  training loss:		0.215753
  validation loss:		0.027991
  top 1 accuracy:		92.35 %
  top 2 accuracy:		100.00 %
0.20968317985534668
0.20631642639636993
Batch of classes 1 out of 7 batches
Epoch 4 of 30 took 77.183s
  training loss:		0.211876
  validation loss:		0.019338
  top 1 accuracy:		95.00 %
  top 2 accuracy:		100.00 %
0.21284037828445435
0.21813586354255676
Batch of classes 1 out of 7 batches
Epoch 5 of 30 took 58.047s
  training loss:		0.210126
  validation loss:		0.018961
  top 1 accuracy:		94.75 %
  top 2 accuracy:		100.00 %
0.2100861519575119
0.21935467422008514
Batch of classes 1 out of 7 batches
Epoch 6 of 30 took 59.733s
  training loss:		0.209178
  validation loss:		0.029411
  top 1 accuracy:		91.20 %
  top 2 accuracy:		100.00 %
0.23753346502780914
0.20100906491279602
Batch of classes 1 out of 7 batches
Epoch 7 of 30 took 71.994s
  training loss:		0.207672
  validation loss:		0.022610
  top 1 accuracy:		93.20 %
  top 2 accuracy:		100.00 %
0.22252289950847626
0.21751566231250763
Batch of classes 1 out of 7 batches
Epoch 8 of 30 took 106.460s
  training loss:		0.207659
  validation loss:		0.016807
  top 1 accuracy:		95.90 %
  top 2 accuracy:		100.00 %
0.21114128828048706
0.2024427354335785
Batch of classes 1 out of 7 batches
Epoch 9 of 30 took 117.812s
  training loss:		0.203836
  validation loss:		0.015460
  top 1 accuracy:		96.20 %
  top 2 accuracy:		100.00 %
0.20215916633605957
0.21523550152778625
Batch of classes 1 out of 7 batches
Epoch 10 of 30 took 93.369s
  training loss:		0.202974
  validation loss:		0.016853
  top 1 accuracy:		96.25 %
  top 2 accuracy:		100.00 %
0.19997984170913696
0.19501841068267822
Batch of classes 1 out of 7 batches
Epoch 11 of 30 took 50.930s
  training loss:		0.198109
  validation loss:		0.006602
  top 1 accuracy:		98.25 %
  top 2 accuracy:		100.00 %
0.1923961490392685
0.20067423582077026
Batch of classes 1 out of 7 batches
Epoch 12 of 30 took 52.112s
  training loss:		0.194260
  validation loss:		0.005394
  top 1 accuracy:		98.85 %
  top 2 accuracy:		100.00 %
0.19362270832061768
0.190907821059227
Batch of classes 1 out of 7 batches
Epoch 13 of 30 took 52.507s
  training loss:		0.193410
  validation loss:		0.005993
  top 1 accuracy:		98.65 %
  top 2 accuracy:		100.00 %
0.19105927646160126
0.19364261627197266
Batch of classes 1 out of 7 batches
Epoch 14 of 30 took 73.240s
  training loss:		0.192002
  validation loss:		0.006222
  top 1 accuracy:		98.45 %
  top 2 accuracy:		100.00 %
0.19204674661159515
0.19463634490966797
Batch of classes 1 out of 7 batches
Epoch 15 of 30 took 109.158s
  training loss:		0.192611
  validation loss:		0.006297
  top 1 accuracy:		98.25 %
  top 2 accuracy:		100.00 %
0.19774439930915833
0.1889244168996811
Batch of classes 1 out of 7 batches
Epoch 16 of 30 took 117.821s
  training loss:		0.191521
  validation loss:		0.005597
  top 1 accuracy:		98.35 %
  top 2 accuracy:		100.00 %
0.1886737197637558
0.18709540367126465
Batch of classes 1 out of 7 batches
Epoch 17 of 30 took 99.667s
  training loss:		0.190494
  validation loss:		0.011719
  top 1 accuracy:		97.15 %
  top 2 accuracy:		100.00 %
0.18889479339122772
0.18748579919338226
Batch of classes 1 out of 7 batches
Epoch 18 of 30 took 61.106s
  training loss:		0.190748
  validation loss:		0.007191
  top 1 accuracy:		98.35 %
  top 2 accuracy:		100.00 %
0.1898117959499359
0.18819624185562134
Batch of classes 1 out of 7 batches
Epoch 19 of 30 took 54.510s
  training loss:		0.190787
  validation loss:		0.005357
  top 1 accuracy:		98.55 %
  top 2 accuracy:		100.00 %
0.18797476589679718
0.20287029445171356
Batch of classes 1 out of 7 batches
Epoch 20 of 30 took 58.496s
  training loss:		0.190528
  validation loss:		0.004945
  top 1 accuracy:		98.55 %
  top 2 accuracy:		100.00 %
0.1869312822818756
0.18779979646205902
Batch of classes 1 out of 7 batches
Epoch 21 of 30 took 92.971s
  training loss:		0.188904
  validation loss:		0.003232
  top 1 accuracy:		99.35 %
  top 2 accuracy:		100.00 %
0.1917712539434433
0.18778717517852783
Batch of classes 1 out of 7 batches
Epoch 22 of 30 took 118.504s
  training loss:		0.187998
  validation loss:		0.002548
  top 1 accuracy:		99.50 %
  top 2 accuracy:		100.00 %
0.1958758383989334
0.18723569810390472
Batch of classes 1 out of 7 batches
Epoch 23 of 30 took 79.363s
  training loss:		0.187559
  validation loss:		0.004410
  top 1 accuracy:		99.10 %
  top 2 accuracy:		100.00 %
0.18705634772777557
0.18853384256362915
Batch of classes 1 out of 7 batches
Epoch 24 of 30 took 50.591s
  training loss:		0.186970
  validation loss:		0.004229
  top 1 accuracy:		99.00 %
  top 2 accuracy:		100.00 %
0.18702010810375214
0.18941321969032288
Batch of classes 1 out of 7 batches
Epoch 25 of 30 took 52.408s
  training loss:		0.186927
  validation loss:		0.004164
  top 1 accuracy:		99.15 %
  top 2 accuracy:		100.00 %
0.1858159750699997
0.1859719157218933
Batch of classes 1 out of 7 batches
Epoch 26 of 30 took 51.062s
  training loss:		0.186558
  validation loss:		0.002736
  top 1 accuracy:		99.45 %
  top 2 accuracy:		100.00 %
0.1878643035888672
0.18555103242397308
Batch of classes 1 out of 7 batches
Epoch 27 of 30 took 51.353s
  training loss:		0.185916
  validation loss:		0.003860
  top 1 accuracy:		99.15 %
  top 2 accuracy:		100.00 %
0.18534372746944427
0.18512818217277527
Batch of classes 1 out of 7 batches
Epoch 28 of 30 took 50.468s
  training loss:		0.186295
  validation loss:		0.005728
  top 1 accuracy:		98.90 %
  top 2 accuracy:		100.00 %
0.1855282187461853
0.1850835084915161
Batch of classes 1 out of 7 batches
Epoch 29 of 30 took 55.731s
  training loss:		0.185639
  validation loss:		0.002827
  top 1 accuracy:		99.35 %
  top 2 accuracy:		100.00 %
0.18564565479755402
0.18471497297286987
Batch of classes 1 out of 7 batches
Epoch 30 of 30 took 79.514s
  training loss:		0.185371
  validation loss:		0.003207
  top 1 accuracy:		99.25 %
  top 2 accuracy:		100.00 %
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(500)
tensor(500)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		99.35 %
  top 1 accuracy Hybrid 1       :		99.25 %
  top 1 accuracy NCM            :		99.35 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		99.40 %
  top 1 accuracy Hybrid 1       :		99.25 %
  top 1 accuracy NCM            :		99.40 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		99.35 %
  top 1 accuracy Hybrid 1       :		99.25 %
  top 1 accuracy NCM            :		99.35 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		99.40 %
  top 1 accuracy Hybrid 1       :		99.25 %
  top 1 accuracy NCM            :		99.40 %
Classes in this batch: tensor([2, 3])
Data Size: 2400


Before first epoch
  validation loss:		1.627672
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.12 %
Batch of classes number 2 arrives ...
0.9438706636428833
0.25706911087036133
Batch of classes 2 out of 7 batches
Epoch 1 of 30 took 45.732s
  training loss:		0.310945
  validation loss:		0.109347
  top 1 accuracy:		66.87 %
  top 2 accuracy:		96.88 %
0.254866361618042
0.2422623634338379
Batch of classes 2 out of 7 batches
Epoch 2 of 30 took 31.486s
  training loss:		0.252790
  validation loss:		0.067689
  top 1 accuracy:		83.63 %
  top 2 accuracy:		99.00 %
0.2548438012599945
0.22021369636058807
Batch of classes 2 out of 7 batches
Epoch 3 of 30 took 31.452s
  training loss:		0.239990
  validation loss:		0.071131
  top 1 accuracy:		82.88 %
  top 2 accuracy:		97.50 %
0.23688650131225586
0.2319968044757843
Batch of classes 2 out of 7 batches
Epoch 4 of 30 took 31.405s
  training loss:		0.234584
  validation loss:		0.087984
  top 1 accuracy:		76.25 %
  top 2 accuracy:		93.75 %
0.24121686816215515
0.22279849648475647
Batch of classes 2 out of 7 batches
Epoch 5 of 30 took 31.418s
  training loss:		0.228750
  validation loss:		0.062994
  top 1 accuracy:		85.25 %
  top 2 accuracy:		97.25 %
0.22763580083847046
0.2149648368358612
Batch of classes 2 out of 7 batches
Epoch 6 of 30 took 31.250s
  training loss:		0.225164
  validation loss:		0.037158
  top 1 accuracy:		91.12 %
  top 2 accuracy:		99.25 %
0.2171991467475891
0.22344473004341125
Batch of classes 2 out of 7 batches
Epoch 7 of 30 took 31.926s
  training loss:		0.221056
  validation loss:		0.064074
  top 1 accuracy:		80.00 %
  top 2 accuracy:		96.50 %
0.22356528043746948
0.21454429626464844
Batch of classes 2 out of 7 batches
Epoch 8 of 30 took 31.474s
  training loss:		0.218277
  validation loss:		0.121293
  top 1 accuracy:		68.00 %
  top 2 accuracy:		92.87 %
0.2084185779094696
0.210979163646698
Batch of classes 2 out of 7 batches
Epoch 9 of 30 took 31.105s
  training loss:		0.215417
  validation loss:		0.048458
  top 1 accuracy:		87.25 %
  top 2 accuracy:		98.12 %
0.20685748755931854
0.2084125131368637
Batch of classes 2 out of 7 batches
Epoch 10 of 30 took 31.607s
  training loss:		0.215411
  validation loss:		0.042356
  top 1 accuracy:		88.13 %
  top 2 accuracy:		97.62 %
0.20657268166542053
0.2087753713130951
Batch of classes 2 out of 7 batches
Epoch 11 of 30 took 31.290s
  training loss:		0.206108
  validation loss:		0.018798
  top 1 accuracy:		96.00 %
  top 2 accuracy:		99.75 %
0.21352986991405487
0.19479650259017944
Batch of classes 2 out of 7 batches
Epoch 12 of 30 took 35.378s
  training loss:		0.199741
  validation loss:		0.029575
  top 1 accuracy:		91.75 %
  top 2 accuracy:		98.25 %
0.19516602158546448
0.19329777359962463
Batch of classes 2 out of 7 batches
Epoch 13 of 30 took 31.497s
  training loss:		0.199254
  validation loss:		0.015813
  top 1 accuracy:		96.38 %
  top 2 accuracy:		99.75 %
0.1915072202682495
0.18968482315540314
Batch of classes 2 out of 7 batches
Epoch 14 of 30 took 30.690s
  training loss:		0.198551
  validation loss:		0.022000
  top 1 accuracy:		94.25 %
  top 2 accuracy:		98.50 %
0.19162586331367493
0.20028312504291534
Batch of classes 2 out of 7 batches
Epoch 15 of 30 took 31.386s
  training loss:		0.195848
  validation loss:		0.024890
  top 1 accuracy:		93.88 %
  top 2 accuracy:		99.37 %
0.19872280955314636
0.1900816261768341
Batch of classes 2 out of 7 batches
Epoch 16 of 30 took 31.689s
  training loss:		0.196432
  validation loss:		0.058095
  top 1 accuracy:		85.50 %
  top 2 accuracy:		96.38 %
0.1930341273546219
0.18841034173965454
Batch of classes 2 out of 7 batches
Epoch 17 of 30 took 31.410s
  training loss:		0.197147
  validation loss:		0.033711
  top 1 accuracy:		92.50 %
  top 2 accuracy:		99.62 %
0.19969315826892853
0.18845520913600922
Batch of classes 2 out of 7 batches
Epoch 18 of 30 took 31.465s
  training loss:		0.194684
  validation loss:		0.014761
  top 1 accuracy:		97.00 %
  top 2 accuracy:		99.62 %
0.1893163025379181
0.19137893617153168
Batch of classes 2 out of 7 batches
Epoch 19 of 30 took 31.322s
  training loss:		0.192719
  validation loss:		0.022882
  top 1 accuracy:		95.75 %
  top 2 accuracy:		99.75 %
0.188459575176239
0.1868945062160492
Batch of classes 2 out of 7 batches
Epoch 20 of 30 took 32.360s
  training loss:		0.192042
  validation loss:		0.020336
  top 1 accuracy:		95.50 %
  top 2 accuracy:		99.25 %
0.18987081944942474
0.1896233707666397
Batch of classes 2 out of 7 batches
Epoch 21 of 30 took 31.352s
  training loss:		0.189849
  validation loss:		0.016863
  top 1 accuracy:		96.38 %
  top 2 accuracy:		99.37 %
0.1853899508714676
0.18702638149261475
Batch of classes 2 out of 7 batches
Epoch 22 of 30 took 31.356s
  training loss:		0.188806
  validation loss:		0.015354
  top 1 accuracy:		95.88 %
  top 2 accuracy:		99.37 %
0.18503427505493164
0.18818943202495575
Batch of classes 2 out of 7 batches
Epoch 23 of 30 took 31.245s
  training loss:		0.188519
  validation loss:		0.010374
  top 1 accuracy:		97.75 %
  top 2 accuracy:		99.50 %
0.19227954745292664
0.18550507724285126
Batch of classes 2 out of 7 batches
Epoch 24 of 30 took 33.142s
  training loss:		0.189251
  validation loss:		0.014780
  top 1 accuracy:		96.63 %
  top 2 accuracy:		99.50 %
0.1844971925020218
0.18936926126480103
Batch of classes 2 out of 7 batches
Epoch 25 of 30 took 31.324s
  training loss:		0.189221
  validation loss:		0.014561
  top 1 accuracy:		97.12 %
  top 2 accuracy:		99.50 %
0.18630918860435486
0.1928284913301468
Batch of classes 2 out of 7 batches
Epoch 26 of 30 took 32.597s
  training loss:		0.188802
  validation loss:		0.008482
  top 1 accuracy:		98.00 %
  top 2 accuracy:		100.00 %
0.1838834583759308
0.1921994835138321
Batch of classes 2 out of 7 batches
Epoch 27 of 30 took 31.319s
  training loss:		0.188335
  validation loss:		0.009407
  top 1 accuracy:		97.37 %
  top 2 accuracy:		99.87 %
0.1861865073442459
0.18581858277320862
Batch of classes 2 out of 7 batches
Epoch 28 of 30 took 31.371s
  training loss:		0.187980
  validation loss:		0.005992
  top 1 accuracy:		98.62 %
  top 2 accuracy:		100.00 %
0.18498322367668152
0.23066678643226624
Batch of classes 2 out of 7 batches
Epoch 29 of 30 took 31.819s
  training loss:		0.188705
  validation loss:		0.010578
  top 1 accuracy:		97.75 %
  top 2 accuracy:		99.62 %
0.19088293612003326
0.18679749965667725
Batch of classes 2 out of 7 batches
Epoch 30 of 30 took 31.168s
  training loss:		0.188374
  validation loss:		0.013344
  top 1 accuracy:		96.88 %
  top 2 accuracy:		99.75 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(384)
tensor(384)
tensor(384)
tensor(384)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		76.00 %
  top 1 accuracy Hybrid 1       :		56.30 %
  top 1 accuracy NCM            :		79.05 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		96.75 %
  top 1 accuracy Hybrid 1       :		95.35 %
  top 1 accuracy NCM            :		96.60 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		88.88 %
  top 1 accuracy Hybrid 1       :		96.88 %
  top 1 accuracy NCM            :		86.50 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		99.00 %
  top 1 accuracy Hybrid 1       :		99.00 %
  top 1 accuracy NCM            :		99.00 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		79.68 %
  top 1 accuracy Hybrid 1       :		67.89 %
  top 1 accuracy NCM            :		81.18 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		97.39 %
  top 1 accuracy Hybrid 1       :		96.39 %
  top 1 accuracy NCM            :		97.29 %
Classes in this batch: tensor([4, 5])
Data Size: 1572


Before first epoch
  validation loss:		1.060252
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 3 arrives ...
0.4920397996902466
Batch of classes 3 out of 7 batches
Epoch 1 of 30 took 30.799s
  training loss:		0.302027
  validation loss:		0.119677
  top 1 accuracy:		50.57 %
  top 2 accuracy:		91.03 %
0.26800233125686646
Batch of classes 3 out of 7 batches
Epoch 2 of 30 took 30.771s
  training loss:		0.254092
  validation loss:		0.080947
  top 1 accuracy:		75.95 %
  top 2 accuracy:		97.71 %
0.23846641182899475
Batch of classes 3 out of 7 batches
Epoch 3 of 30 took 27.516s
  training loss:		0.234627
  validation loss:		0.087666
  top 1 accuracy:		79.20 %
  top 2 accuracy:		94.85 %
0.2215239703655243
Batch of classes 3 out of 7 batches
Epoch 4 of 30 took 27.289s
  training loss:		0.226943
  validation loss:		0.058223
  top 1 accuracy:		82.82 %
  top 2 accuracy:		95.61 %
0.23673170804977417
Batch of classes 3 out of 7 batches
Epoch 5 of 30 took 27.652s
  training loss:		0.221400
  validation loss:		0.060877
  top 1 accuracy:		86.45 %
  top 2 accuracy:		94.27 %
0.20726633071899414
Batch of classes 3 out of 7 batches
Epoch 6 of 30 took 27.413s
  training loss:		0.217434
  validation loss:		0.028046
  top 1 accuracy:		93.13 %
  top 2 accuracy:		98.66 %
Traceback (most recent call last):
  File "main_icarl_CNND.py", line 579, in <module>
    main()
  File "main_icarl_CNND.py", line 324, in main
    for patterns, labels in train_loader:  # Line 151
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 352, in __iter__
    return self._get_iterator()
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 294, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 801, in __init__
    w.start()
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/popen_fork.py", line 70, in _launch
    self.pid = os.fork()
OSError: [Errno 12] Cannot allocate memory
----------------- Options ---------------
               add_binary: True                          	[default: False]
               batch_size: 32                            	[default: 64]
                   binary: False                         
              binary_loss: sum_b_log                     	[default: sum_b_sig]
            binary_weight: 0.5                           
                blur_prob: 0                             
                 blur_sig: 0.5                           
          checkpoints_dir: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL/checkpoints	[default: ./checkpoints]
                class_bal: False                         
           continue_train: False                         
                 cropSize: 224                           
                 data_aug: False                         
                 dataroot: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/test	[default: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL]
          earlystop_epoch: 5                             
                    epoch: latest                        
                 fine_tun: False                         
                    gpuid: [1]                           
                init_gain: 0.02                          
                  init_lr: 0.0005                        
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2                           
                 jpg_prob: 0                             
                 jpg_qual: 75                            
          label_smoothing: False                         
                 loadSize: 256                           
                    mixup: False                         
              mixup_alpha: 0.1                           
                     mode: binary                        
               model_name: resnet18                      
               model_type: resnet                        
            model_weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth	[default: None]
               multiclass: [0, 0, 1, 0, 0, 0, 0]         	[default: [1]]
                     name: MT_7_bm_sum_b_log05_15        	[default: experiment_name]
                  no_flip: False                         
              num_classes: 2                             
               num_epochs: 30                            	[default: 12]
              num_threads: 4                             
                  outfile: temp_0.1.csv                  
            pretrain_name:                               
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 20                            
         save_latest_freq: 2000                          
                 schedule: [10, 20, 30]                  	[default: [10]]
           serial_batches: False                         
          smoothing_alpha: 0.1                           
                   suffix:                               
                task_name: gaugan,biggan,cyclegan,imle,deepfake,crn,wild	[default: ]
              train_split: train                         
                val_split: val                           
----------------- End -------------------
{'All': 14}
Task order: ['gaugan', 'biggan', 'cyclegan', 'imle', 'deepfake', 'crn', 'wild']
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Classes in this batch: tensor([0, 1])
Data Size: 6000


Before first epoch
  validation loss:		1.309705
  top 1 accuracy:		17.05 %
  top 2 accuracy:		17.30 %
Batch of classes number 1 arrives ...
0.8698064684867859
0.28820183873176575
Batch of classes 1 out of 7 batches
Epoch 1 of 30 took 104.407s
  training loss:		0.310286
  validation loss:		0.045510
  top 1 accuracy:		86.65 %
  top 2 accuracy:		100.00 %
0.2853468060493469
0.26155853271484375
Batch of classes 1 out of 7 batches
Epoch 2 of 30 took 89.270s
  training loss:		0.267971
  validation loss:		0.033304
  top 1 accuracy:		90.95 %
  top 2 accuracy:		100.00 %
0.2521112859249115
0.25477612018585205
Batch of classes 1 out of 7 batches
Epoch 3 of 30 took 106.760s
  training loss:		0.260484
  validation loss:		0.027051
  top 1 accuracy:		92.75 %
  top 2 accuracy:		100.00 %
0.2520894706249237
0.2509647011756897
Batch of classes 1 out of 7 batches
Epoch 4 of 30 took 88.699s
  training loss:		0.257559
  validation loss:		0.021085
  top 1 accuracy:		94.85 %
  top 2 accuracy:		100.00 %
0.26171672344207764
0.2692733705043793
Batch of classes 1 out of 7 batches
Epoch 5 of 30 took 102.434s
  training loss:		0.256665
  validation loss:		0.020042
  top 1 accuracy:		95.15 %
  top 2 accuracy:		100.00 %
0.25171133875846863
0.2619462013244629
Batch of classes 1 out of 7 batches
Epoch 6 of 30 took 85.206s
  training loss:		0.253832
  validation loss:		0.025137
  top 1 accuracy:		92.75 %
  top 2 accuracy:		100.00 %
0.27039635181427
0.24367043375968933
Batch of classes 1 out of 7 batches
Epoch 7 of 30 took 100.554s
  training loss:		0.254356
  validation loss:		0.022438
  top 1 accuracy:		94.25 %
  top 2 accuracy:		100.00 %
0.26048633456230164
0.26505962014198303
Batch of classes 1 out of 7 batches
Epoch 8 of 30 took 63.365s
  training loss:		0.253448
  validation loss:		0.014015
  top 1 accuracy:		96.80 %
  top 2 accuracy:		100.00 %
0.24603486061096191
0.2472040057182312
Batch of classes 1 out of 7 batches
Epoch 9 of 30 took 53.372s
  training loss:		0.251307
  validation loss:		0.018416
  top 1 accuracy:		95.20 %
  top 2 accuracy:		100.00 %
0.26566141843795776
0.2586950361728668
Batch of classes 1 out of 7 batches
Epoch 10 of 30 took 50.026s
  training loss:		0.250099
  validation loss:		0.015675
  top 1 accuracy:		96.10 %
  top 2 accuracy:		100.00 %
0.24302536249160767
0.24328532814979553
Batch of classes 1 out of 7 batches
Epoch 11 of 30 took 53.825s
  training loss:		0.246129
  validation loss:		0.006080
  top 1 accuracy:		99.00 %
  top 2 accuracy:		100.00 %
0.24009977281093597
0.24168889224529266
Batch of classes 1 out of 7 batches
Epoch 12 of 30 took 56.423s
  training loss:		0.241781
  validation loss:		0.005234
  top 1 accuracy:		98.95 %
  top 2 accuracy:		100.00 %
0.24349728226661682
0.2579208314418793
Batch of classes 1 out of 7 batches
Epoch 13 of 30 took 62.217s
  training loss:		0.241149
  validation loss:		0.004672
  top 1 accuracy:		99.10 %
  top 2 accuracy:		100.00 %
0.24424608051776886
0.24155773222446442
Batch of classes 1 out of 7 batches
Epoch 14 of 30 took 58.936s
  training loss:		0.239260
  validation loss:		0.005194
  top 1 accuracy:		98.70 %
  top 2 accuracy:		100.00 %
0.24403604865074158
0.24184753000736237
Batch of classes 1 out of 7 batches
Epoch 15 of 30 took 64.081s
  training loss:		0.239518
  validation loss:		0.003930
  top 1 accuracy:		99.10 %
  top 2 accuracy:		100.00 %
0.23882703483104706
0.23752351105213165
Batch of classes 1 out of 7 batches
Epoch 16 of 30 took 59.791s
  training loss:		0.238622
  validation loss:		0.004864
  top 1 accuracy:		98.85 %
  top 2 accuracy:		100.00 %
0.2402987778186798
0.23355573415756226
Batch of classes 1 out of 7 batches
Epoch 17 of 30 took 50.306s
  training loss:		0.237479
  validation loss:		0.004175
  top 1 accuracy:		99.20 %
  top 2 accuracy:		100.00 %
0.2352067232131958
0.23506228625774384
Batch of classes 1 out of 7 batches
Epoch 18 of 30 took 50.387s
  training loss:		0.236960
  validation loss:		0.007647
  top 1 accuracy:		98.20 %
  top 2 accuracy:		99.95 %
0.23929068446159363
0.23525358736515045
Batch of classes 1 out of 7 batches
Epoch 19 of 30 took 51.774s
  training loss:		0.236504
  validation loss:		0.003912
  top 1 accuracy:		99.00 %
  top 2 accuracy:		100.00 %
0.2347489893436432
0.2392674684524536
Batch of classes 1 out of 7 batches
Epoch 20 of 30 took 49.890s
  training loss:		0.236633
  validation loss:		0.005606
  top 1 accuracy:		98.40 %
  top 2 accuracy:		100.00 %
0.2331707775592804
0.23471304774284363
Batch of classes 1 out of 7 batches
Epoch 21 of 30 took 51.596s
  training loss:		0.235048
  validation loss:		0.002523
  top 1 accuracy:		99.35 %
  top 2 accuracy:		100.00 %
0.2332558035850525
0.23497024178504944
Batch of classes 1 out of 7 batches
Epoch 22 of 30 took 50.756s
  training loss:		0.234411
  validation loss:		0.002062
  top 1 accuracy:		99.40 %
  top 2 accuracy:		100.00 %
0.24997356534004211
0.2337387651205063
Batch of classes 1 out of 7 batches
Epoch 23 of 30 took 51.546s
  training loss:		0.233731
  validation loss:		0.001860
  top 1 accuracy:		99.60 %
  top 2 accuracy:		100.00 %
0.23265157639980316
0.233183816075325
Batch of classes 1 out of 7 batches
Epoch 24 of 30 took 50.502s
  training loss:		0.233191
  validation loss:		0.002746
  top 1 accuracy:		99.30 %
  top 2 accuracy:		100.00 %
0.23328009247779846
0.2407330870628357
Batch of classes 1 out of 7 batches
Epoch 25 of 30 took 50.874s
  training loss:		0.232987
  validation loss:		0.001754
  top 1 accuracy:		99.60 %
  top 2 accuracy:		100.00 %
0.2322235256433487
0.23162436485290527
Batch of classes 1 out of 7 batches
Epoch 26 of 30 took 50.356s
  training loss:		0.232622
  validation loss:		0.002422
  top 1 accuracy:		99.40 %
  top 2 accuracy:		100.00 %
0.23332521319389343
0.2317410260438919
Batch of classes 1 out of 7 batches
Epoch 27 of 30 took 50.952s
  training loss:		0.231933
  validation loss:		0.002796
  top 1 accuracy:		99.30 %
  top 2 accuracy:		100.00 %
0.23109130561351776
0.2322547733783722
Batch of classes 1 out of 7 batches
Epoch 28 of 30 took 49.782s
  training loss:		0.232113
  validation loss:		0.002491
  top 1 accuracy:		99.35 %
  top 2 accuracy:		100.00 %
0.23226675391197205
0.2304321527481079
Batch of classes 1 out of 7 batches
Epoch 29 of 30 took 50.810s
  training loss:		0.231859
  validation loss:		0.002002
  top 1 accuracy:		99.50 %
  top 2 accuracy:		100.00 %
0.23179881274700165
0.23121610283851624
Batch of classes 1 out of 7 batches
Epoch 30 of 30 took 50.932s
  training loss:		0.231292
  validation loss:		0.001854
  top 1 accuracy:		99.70 %
  top 2 accuracy:		100.00 %
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(500)
tensor(500)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		99.60 %
  top 1 accuracy Hybrid 1       :		99.70 %
  top 1 accuracy NCM            :		99.60 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		99.65 %
  top 1 accuracy Hybrid 1       :		99.70 %
  top 1 accuracy NCM            :		99.65 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		99.60 %
  top 1 accuracy Hybrid 1       :		99.70 %
  top 1 accuracy NCM            :		99.60 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		99.65 %
  top 1 accuracy Hybrid 1       :		99.70 %
  top 1 accuracy NCM            :		99.65 %
Classes in this batch: tensor([2, 3])
Data Size: 2400


Before first epoch
  validation loss:		1.672670
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 2 arrives ...
0.8387221097946167
0.3016293942928314
Batch of classes 2 out of 7 batches
Epoch 1 of 30 took 54.503s
  training loss:		0.336301
  validation loss:		0.097844
  top 1 accuracy:		74.25 %
  top 2 accuracy:		99.12 %
0.30031511187553406
0.2828914523124695
Batch of classes 2 out of 7 batches
Epoch 2 of 30 took 34.837s
  training loss:		0.293932
  validation loss:		0.105437
  top 1 accuracy:		78.50 %
  top 2 accuracy:		95.50 %
0.2940823435783386
0.2723870873451233
Batch of classes 2 out of 7 batches
Epoch 3 of 30 took 34.340s
  training loss:		0.282489
  validation loss:		0.080209
  top 1 accuracy:		80.00 %
  top 2 accuracy:		94.25 %
0.28688403964042664
0.269741028547287
Batch of classes 2 out of 7 batches
Epoch 4 of 30 took 31.529s
  training loss:		0.276240
  validation loss:		0.071246
  top 1 accuracy:		84.25 %
  top 2 accuracy:		96.63 %
0.2751239240169525
0.26408278942108154
Batch of classes 2 out of 7 batches
Epoch 5 of 30 took 31.458s
  training loss:		0.271355
  validation loss:		0.067953
  top 1 accuracy:		86.00 %
  top 2 accuracy:		98.25 %
0.2621976137161255
0.26530808210372925
Batch of classes 2 out of 7 batches
Epoch 6 of 30 took 31.038s
  training loss:		0.268003
  validation loss:		0.076423
  top 1 accuracy:		79.12 %
  top 2 accuracy:		98.37 %
0.26002317667007446
0.26387399435043335
Batch of classes 2 out of 7 batches
Epoch 7 of 30 took 31.445s
  training loss:		0.264091
  validation loss:		0.095129
  top 1 accuracy:		77.25 %
  top 2 accuracy:		95.38 %
0.279268741607666
0.27556273341178894
Batch of classes 2 out of 7 batches
Epoch 8 of 30 took 31.091s
  training loss:		0.263404
  validation loss:		0.072279
  top 1 accuracy:		79.37 %
  top 2 accuracy:		94.75 %
0.2522850036621094
0.2542746663093567
Batch of classes 2 out of 7 batches
Epoch 9 of 30 took 31.683s
  training loss:		0.259650
  validation loss:		0.060041
  top 1 accuracy:		85.75 %
  top 2 accuracy:		98.37 %
0.25339722633361816
0.25082430243492126
Batch of classes 2 out of 7 batches
Epoch 10 of 30 took 32.577s
  training loss:		0.257195
  validation loss:		0.048039
  top 1 accuracy:		89.63 %
  top 2 accuracy:		98.50 %
0.24712176620960236
0.24245141446590424
Batch of classes 2 out of 7 batches
Epoch 11 of 30 took 31.255s
  training loss:		0.249393
  validation loss:		0.026151
  top 1 accuracy:		96.13 %
  top 2 accuracy:		99.12 %
0.26536884903907776
0.24977532029151917
Batch of classes 2 out of 7 batches
Epoch 12 of 30 took 31.307s
  training loss:		0.245513
  validation loss:		0.026531
  top 1 accuracy:		93.37 %
  top 2 accuracy:		98.12 %
0.23918062448501587
0.23705880343914032
Batch of classes 2 out of 7 batches
Epoch 13 of 30 took 31.823s
  training loss:		0.243711
  validation loss:		0.025105
  top 1 accuracy:		96.88 %
  top 2 accuracy:		99.50 %
0.23812541365623474
0.23945252597332
Batch of classes 2 out of 7 batches
Epoch 14 of 30 took 30.854s
  training loss:		0.243258
  validation loss:		0.034402
  top 1 accuracy:		94.63 %
  top 2 accuracy:		98.62 %
0.2350010871887207
0.24375836551189423
Batch of classes 2 out of 7 batches
Epoch 15 of 30 took 31.828s
  training loss:		0.240953
  validation loss:		0.038339
  top 1 accuracy:		94.00 %
  top 2 accuracy:		99.25 %
0.23529069125652313
0.23474472761154175
Batch of classes 2 out of 7 batches
Epoch 16 of 30 took 33.524s
  training loss:		0.241210
  validation loss:		0.053697
  top 1 accuracy:		89.25 %
  top 2 accuracy:		96.88 %
0.23827672004699707
0.23679277300834656
Batch of classes 2 out of 7 batches
Epoch 17 of 30 took 34.558s
  training loss:		0.240613
  validation loss:		0.033081
  top 1 accuracy:		96.00 %
  top 2 accuracy:		99.12 %
0.2423805445432663
0.2411014884710312
Batch of classes 2 out of 7 batches
Epoch 18 of 30 took 31.644s
  training loss:		0.241246
  validation loss:		0.010268
  top 1 accuracy:		97.75 %
  top 2 accuracy:		99.50 %
0.23499156534671783
0.2337116003036499
Batch of classes 2 out of 7 batches
Epoch 19 of 30 took 31.296s
  training loss:		0.238298
  validation loss:		0.025976
  top 1 accuracy:		95.00 %
  top 2 accuracy:		99.37 %
0.23354461789131165
0.23600132763385773
Batch of classes 2 out of 7 batches
Epoch 20 of 30 took 31.422s
  training loss:		0.235946
  validation loss:		0.031185
  top 1 accuracy:		94.75 %
  top 2 accuracy:		99.25 %
0.23381581902503967
0.23192031681537628
Batch of classes 2 out of 7 batches
Epoch 21 of 30 took 31.787s
  training loss:		0.235727
  validation loss:		0.017606
  top 1 accuracy:		95.88 %
  top 2 accuracy:		98.75 %
0.23149080574512482
0.23227809369564056
Batch of classes 2 out of 7 batches
Epoch 22 of 30 took 32.902s
  training loss:		0.234974
  validation loss:		0.034768
  top 1 accuracy:		94.00 %
  top 2 accuracy:		99.00 %
0.23134289681911469
0.2339169979095459
Batch of classes 2 out of 7 batches
Epoch 23 of 30 took 31.327s
  training loss:		0.234736
  validation loss:		0.008746
  top 1 accuracy:		98.25 %
  top 2 accuracy:		99.75 %
0.23449014127254486
0.23424512147903442
Batch of classes 2 out of 7 batches
Epoch 24 of 30 took 31.389s
  training loss:		0.235348
  validation loss:		0.023965
  top 1 accuracy:		97.12 %
  top 2 accuracy:		99.00 %
0.2328280210494995
0.24131709337234497
Batch of classes 2 out of 7 batches
Epoch 25 of 30 took 31.283s
  training loss:		0.234817
  validation loss:		0.026668
  top 1 accuracy:		96.38 %
  top 2 accuracy:		99.12 %
0.2336684614419937
0.23787887394428253
Batch of classes 2 out of 7 batches
Epoch 26 of 30 took 31.272s
  training loss:		0.234299
  validation loss:		0.012461
  top 1 accuracy:		97.37 %
  top 2 accuracy:		99.75 %
0.23141443729400635
0.2327936291694641
Batch of classes 2 out of 7 batches
Epoch 27 of 30 took 31.323s
  training loss:		0.234003
  validation loss:		0.024022
  top 1 accuracy:		96.50 %
  top 2 accuracy:		99.25 %
0.2343466430902481
0.2357536405324936
Batch of classes 2 out of 7 batches
Epoch 28 of 30 took 33.310s
  training loss:		0.234172
  validation loss:		0.010046
  top 1 accuracy:		97.87 %
  top 2 accuracy:		100.00 %
0.23405128717422485
0.2698588967323303
Batch of classes 2 out of 7 batches
Epoch 29 of 30 took 33.324s
  training loss:		0.234460
  validation loss:		0.008788
  top 1 accuracy:		98.50 %
  top 2 accuracy:		100.00 %
0.23599770665168762
0.23437723517417908
Batch of classes 2 out of 7 batches
Epoch 30 of 30 took 33.131s
  training loss:		0.234452
  validation loss:		0.029010
  top 1 accuracy:		95.63 %
  top 2 accuracy:		99.12 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(384)
tensor(384)
tensor(384)
tensor(384)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		75.90 %
  top 1 accuracy Hybrid 1       :		56.40 %
  top 1 accuracy NCM            :		78.15 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		96.95 %
  top 1 accuracy Hybrid 1       :		95.55 %
  top 1 accuracy NCM            :		96.80 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		87.88 %
  top 1 accuracy Hybrid 1       :		95.62 %
  top 1 accuracy NCM            :		86.12 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		99.25 %
  top 1 accuracy Hybrid 1       :		99.00 %
  top 1 accuracy NCM            :		99.00 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		79.32 %
  top 1 accuracy Hybrid 1       :		67.61 %
  top 1 accuracy NCM            :		80.43 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		97.61 %
  top 1 accuracy Hybrid 1       :		96.54 %
  top 1 accuracy NCM            :		97.43 %
Classes in this batch: tensor([4, 5])
Data Size: 1572


Before first epoch
  validation loss:		1.037993
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 3 arrives ...
0.4725404977798462
Batch of classes 3 out of 7 batches
Epoch 1 of 30 took 31.500s
  training loss:		nan
  validation loss:		0.115995
  top 1 accuracy:		52.67 %
  top 2 accuracy:		97.52 %
0.3005688786506653
Batch of classes 3 out of 7 batches
Epoch 2 of 30 took 27.760s
  training loss:		0.286915
  validation loss:		0.058493
  top 1 accuracy:		82.06 %
  top 2 accuracy:		98.09 %
0.27274593710899353
Batch of classes 3 out of 7 batches
Epoch 3 of 30 took 26.943s
  training loss:		0.269917
  validation loss:		0.064980
  top 1 accuracy:		82.44 %
  top 2 accuracy:		94.66 %
0.2634156346321106
Batch of classes 3 out of 7 batches
Epoch 4 of 30 took 27.993s
  training loss:		0.263909
  validation loss:		0.045399
  top 1 accuracy:		88.55 %
  top 2 accuracy:		95.80 %
0.2618250250816345
Batch of classes 3 out of 7 batches
Epoch 5 of 30 took 29.541s
  training loss:		0.260317
  validation loss:		0.035960
  top 1 accuracy:		91.79 %
  top 2 accuracy:		97.52 %
0.24843564629554749
Batch of classes 3 out of 7 batches
Epoch 6 of 30 took 27.560s
  training loss:		0.258420
  validation loss:		0.045922
  top 1 accuracy:		87.79 %
  top 2 accuracy:		98.09 %
0.2720242440700531
Batch of classes 3 out of 7 batches
Epoch 7 of 30 took 27.707s
  training loss:		0.259017
  validation loss:		0.022493
  top 1 accuracy:		94.85 %
  top 2 accuracy:		99.24 %
0.24436596035957336
Batch of classes 3 out of 7 batches
Epoch 8 of 30 took 27.614s
  training loss:		0.257526
  validation loss:		0.026449
  top 1 accuracy:		92.75 %
  top 2 accuracy:		99.05 %
0.254245787858963
Batch of classes 3 out of 7 batches
Epoch 9 of 30 took 26.947s
  training loss:		0.253444
  validation loss:		0.028229
  top 1 accuracy:		92.75 %
  top 2 accuracy:		99.05 %
0.24490642547607422
Batch of classes 3 out of 7 batches
Epoch 10 of 30 took 27.245s
  training loss:		0.251463
  validation loss:		0.049960
  top 1 accuracy:		88.36 %
  top 2 accuracy:		97.14 %
0.24954265356063843
Batch of classes 3 out of 7 batches
Epoch 11 of 30 took 27.195s
  training loss:		0.244260
  validation loss:		0.022702
  top 1 accuracy:		94.08 %
  top 2 accuracy:		98.28 %
0.24435511231422424
Batch of classes 3 out of 7 batches
Epoch 12 of 30 took 27.507s
  training loss:		0.240757
  validation loss:		0.013431
  top 1 accuracy:		96.37 %
  top 2 accuracy:		99.24 %
0.2362050861120224
Batch of classes 3 out of 7 batches
Epoch 13 of 30 took 28.750s
  training loss:		0.239848
  validation loss:		0.029496
  top 1 accuracy:		93.13 %
  top 2 accuracy:		97.71 %
0.23715424537658691
Batch of classes 3 out of 7 batches
Epoch 14 of 30 took 27.219s
  training loss:		0.238966
  validation loss:		0.019100
  top 1 accuracy:		95.23 %
  top 2 accuracy:		98.85 %
0.23517769575119019
Batch of classes 3 out of 7 batches
Epoch 15 of 30 took 27.198s
  training loss:		0.239131
  validation loss:		0.011162
  top 1 accuracy:		97.14 %
  top 2 accuracy:		99.43 %
0.23866882920265198
Batch of classes 3 out of 7 batches
Epoch 16 of 30 took 27.158s
  training loss:		0.239245
  validation loss:		0.026193
  top 1 accuracy:		94.66 %
  top 2 accuracy:		98.09 %
0.23440682888031006
Batch of classes 3 out of 7 batches
Epoch 17 of 30 took 27.977s
  training loss:		0.239080
  validation loss:		0.013222
  top 1 accuracy:		96.95 %
  top 2 accuracy:		99.43 %
0.23806972801685333
Batch of classes 3 out of 7 batches
Epoch 18 of 30 took 27.352s
  training loss:		0.236680
  validation loss:		0.012059
  top 1 accuracy:		97.14 %
  top 2 accuracy:		99.05 %
0.2337724268436432
Batch of classes 3 out of 7 batches
Epoch 19 of 30 took 27.235s
  training loss:		0.239054
  validation loss:		0.016856
  top 1 accuracy:		95.99 %
  top 2 accuracy:		98.85 %
0.24083863198757172
Batch of classes 3 out of 7 batches
Epoch 20 of 30 took 27.339s
  training loss:		0.238986
  validation loss:		0.010286
  top 1 accuracy:		97.52 %
  top 2 accuracy:		99.81 %
0.2422494739294052
Batch of classes 3 out of 7 batches
Epoch 21 of 30 took 27.187s
  training loss:		0.238343
  validation loss:		0.009047
  top 1 accuracy:		97.71 %
  top 2 accuracy:		99.24 %
0.23667556047439575
Batch of classes 3 out of 7 batches
Epoch 22 of 30 took 27.265s
  training loss:		0.236513
  validation loss:		0.009332
  top 1 accuracy:		97.14 %
  top 2 accuracy:		100.00 %
0.23234887421131134
Batch of classes 3 out of 7 batches
Epoch 23 of 30 took 27.336s
  training loss:		0.237233
  validation loss:		0.015949
  top 1 accuracy:		95.99 %
  top 2 accuracy:		98.66 %
0.23821209371089935
Batch of classes 3 out of 7 batches
Epoch 24 of 30 took 27.211s
  training loss:		0.236926
  validation loss:		0.013108
  top 1 accuracy:		97.33 %
  top 2 accuracy:		99.43 %
0.23251871764659882
Batch of classes 3 out of 7 batches
Epoch 25 of 30 took 27.222s
  training loss:		0.235282
  validation loss:		0.010478
  top 1 accuracy:		96.95 %
  top 2 accuracy:		99.43 %
0.23204194009304047
Batch of classes 3 out of 7 batches
Epoch 26 of 30 took 28.055s
  training loss:		0.236548
  validation loss:		0.010791
  top 1 accuracy:		97.90 %
  top 2 accuracy:		99.43 %
0.23395214974880219
Batch of classes 3 out of 7 batches
Epoch 27 of 30 took 27.189s
  training loss:		0.234929
  validation loss:		0.007892
  top 1 accuracy:		97.90 %
  top 2 accuracy:		100.00 %
0.2385125756263733
Batch of classes 3 out of 7 batches
Epoch 28 of 30 took 27.245s
  training loss:		0.235181
  validation loss:		0.009422
  top 1 accuracy:		98.47 %
  top 2 accuracy:		100.00 %
0.2376028299331665
Batch of classes 3 out of 7 batches
Epoch 29 of 30 took 27.741s
  training loss:		0.234923
  validation loss:		0.008685
  top 1 accuracy:		97.52 %
  top 2 accuracy:		99.81 %
0.233659029006958
Batch of classes 3 out of 7 batches
Epoch 30 of 30 took 27.014s
  training loss:		0.234249
  validation loss:		0.013914
  top 1 accuracy:		96.56 %
  top 2 accuracy:		99.43 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(256)
tensor(256)
tensor(256)
tensor(256)
tensor(256)
tensor(256)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		75.30 %
  top 1 accuracy Hybrid 1       :		63.10 %
  top 1 accuracy NCM            :		76.55 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		96.10 %
  top 1 accuracy Hybrid 1       :		93.65 %
  top 1 accuracy NCM            :		95.95 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		69.88 %
  top 1 accuracy Hybrid 1       :		62.75 %
  top 1 accuracy NCM            :		70.88 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		94.88 %
  top 1 accuracy Hybrid 1       :		91.12 %
  top 1 accuracy NCM            :		94.75 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		95.61 %
  top 1 accuracy Hybrid 1       :		96.56 %
  top 1 accuracy NCM            :		95.42 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		97.52 %
  top 1 accuracy Hybrid 1       :		97.14 %
  top 1 accuracy NCM            :		97.52 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		77.20 %
  top 1 accuracy Hybrid 1       :		68.29 %
  top 1 accuracy NCM            :		78.16 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		96.03 %
  top 1 accuracy Hybrid 1       :		93.59 %
  top 1 accuracy NCM            :		95.91 %
Classes in this batch: tensor([6, 7])
Data Size: 7656


Before first epoch
  validation loss:		0.817507
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 4 arrives ...
0.5058902502059937
0.2683609127998352
0.251875638961792
Batch of classes 4 out of 7 batches
Epoch 1 of 30 took 210.936s
  training loss:		0.286581
  validation loss:		0.003883
  top 1 accuracy:		99.45 %
  top 2 accuracy:		100.00 %
0.25722965598106384
0.2471819370985031
0.23709207773208618
Batch of classes 4 out of 7 batches
Epoch 2 of 30 took 180.018s
  training loss:		0.244811
  validation loss:		0.007714
  top 1 accuracy:		98.28 %
  top 2 accuracy:		99.41 %
0.2411942481994629
0.23971466720104218
0.23403075337409973
Batch of classes 4 out of 7 batches
Epoch 3 of 30 took 174.191s
  training loss:		0.241263
  validation loss:		0.003324
  top 1 accuracy:		99.37 %
  top 2 accuracy:		99.96 %
0.24758780002593994
0.234939306974411
0.24818751215934753
Batch of classes 4 out of 7 batches
Epoch 4 of 30 took 188.369s
  training loss:		0.239980
  validation loss:		0.001969
  top 1 accuracy:		99.76 %
  top 2 accuracy:		100.00 %
0.2330814003944397
0.244754359126091
0.23677480220794678
Batch of classes 4 out of 7 batches
Epoch 5 of 30 took 198.520s
  training loss:		0.239312
  validation loss:		0.003070
  top 1 accuracy:		99.53 %
  top 2 accuracy:		99.88 %
0.23132531344890594
0.23874397575855255
0.24119435250759125
Batch of classes 4 out of 7 batches
Epoch 6 of 30 took 145.282s
  training loss:		0.236342
  validation loss:		0.000244
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.23449376225471497
0.23150460422039032
0.2350904494524002
Batch of classes 4 out of 7 batches
Epoch 7 of 30 took 144.662s
  training loss:		0.237303
  validation loss:		0.001111
  top 1 accuracy:		99.84 %
  top 2 accuracy:		100.00 %
0.22619237005710602
0.23927821218967438
0.2362520694732666
Batch of classes 4 out of 7 batches
Epoch 8 of 30 took 148.551s
  training loss:		0.237494
  validation loss:		0.009242
  top 1 accuracy:		98.47 %
  top 2 accuracy:		99.96 %
0.24235722422599792
0.2316097617149353
0.2330530434846878
Batch of classes 4 out of 7 batches
Epoch 9 of 30 took 136.241s
  training loss:		0.239572
  validation loss:		0.002210
  top 1 accuracy:		99.37 %
  top 2 accuracy:		100.00 %
0.23442085087299347
0.23811458051204681
0.23658809065818787
Batch of classes 4 out of 7 batches
Epoch 10 of 30 took 139.611s
  training loss:		0.239828
  validation loss:		0.000451
  top 1 accuracy:		99.88 %
  top 2 accuracy:		100.00 %
0.24273799359798431
0.23589913547039032
0.23465798795223236
Batch of classes 4 out of 7 batches
Epoch 11 of 30 took 149.664s
  training loss:		0.234922
  validation loss:		0.000140
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.23377062380313873
0.23298251628875732
0.2343190461397171
Batch of classes 4 out of 7 batches
Epoch 12 of 30 took 134.579s
  training loss:		0.233823
  validation loss:		0.000054
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.23393641412258148
0.23209187388420105
0.23123586177825928
Batch of classes 4 out of 7 batches
Epoch 13 of 30 took 149.162s
  training loss:		0.232220
  validation loss:		0.000123
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.2358703464269638
0.23405620455741882
0.23025427758693695
Batch of classes 4 out of 7 batches
Epoch 14 of 30 took 141.421s
  training loss:		0.234740
  validation loss:		0.000099
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.23333516716957092
0.23140805959701538
0.23250338435173035
Batch of classes 4 out of 7 batches
Epoch 15 of 30 took 149.142s
  training loss:		0.232581
  validation loss:		0.000039
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.2337701916694641
0.23590634763240814
0.23394399881362915
Batch of classes 4 out of 7 batches
Epoch 16 of 30 took 137.402s
  training loss:		0.232261
  validation loss:		0.000208
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.23012970387935638
0.23382021486759186
0.23136508464813232
Batch of classes 4 out of 7 batches
Epoch 17 of 30 took 151.206s
  training loss:		0.232969
  validation loss:		0.000662
  top 1 accuracy:		99.88 %
  top 2 accuracy:		100.00 %
0.23344919085502625
0.23273231089115143
0.23135989904403687
Batch of classes 4 out of 7 batches
Epoch 18 of 30 took 131.690s
  training loss:		0.232695
  validation loss:		0.000410
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.2274605929851532
0.23328888416290283
0.23342658579349518
Batch of classes 4 out of 7 batches
Epoch 19 of 30 took 138.839s
  training loss:		0.233712
  validation loss:		0.000137
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.23513378202915192
0.23288442194461823
0.2331526130437851
Batch of classes 4 out of 7 batches
Epoch 20 of 30 took 145.505s
  training loss:		0.233235
  validation loss:		0.000036
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.23574139177799225
0.23306463658809662
0.23316910862922668
Batch of classes 4 out of 7 batches
Epoch 21 of 30 took 137.272s
  training loss:		0.232141
  validation loss:		0.000053
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.23697508871555328
0.29264429211616516
0.23070400953292847
Batch of classes 4 out of 7 batches
Epoch 22 of 30 took 141.162s
  training loss:		0.233338
  validation loss:		0.000085
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.23187080025672913
0.23272225260734558
0.23224055767059326
Batch of classes 4 out of 7 batches
Epoch 23 of 30 took 145.566s
  training loss:		0.231252
  validation loss:		0.000065
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.2310718595981598
0.23206546902656555
0.23317252099514008
Batch of classes 4 out of 7 batches
Epoch 24 of 30 took 133.033s
  training loss:		0.231919
  validation loss:		0.000074
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.23134903609752655
0.23358957469463348
0.22861836850643158
Batch of classes 4 out of 7 batches
Epoch 25 of 30 took 144.681s
  training loss:		0.232033
  validation loss:		0.000051
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.23111864924430847
0.22730158269405365
0.23263023793697357
Batch of classes 4 out of 7 batches
Epoch 26 of 30 took 146.455s
  training loss:		0.231413
  validation loss:		0.000036
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.23254196345806122
0.23254840075969696
0.22944806516170502
Batch of classes 4 out of 7 batches
Epoch 27 of 30 took 135.410s
  training loss:		0.232124
  validation loss:		0.000056
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.23016364872455597
0.22935189306735992
0.2293536514043808
Batch of classes 4 out of 7 batches
Epoch 28 of 30 took 145.473s
  training loss:		0.231111
  validation loss:		0.000072
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.2290927767753601
0.23455575108528137
0.23237843811511993
Batch of classes 4 out of 7 batches
Epoch 29 of 30 took 133.650s
  training loss:		0.230889
  validation loss:		0.000050
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.2295713871717453
0.23168648779392242
0.230093851685524
Batch of classes 4 out of 7 batches
Epoch 30 of 30 took 137.165s
  training loss:		0.230609
  validation loss:		0.000074
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		75.60 %
  top 1 accuracy Hybrid 1       :		69.80 %
  top 1 accuracy NCM            :		76.50 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		90.65 %
  top 1 accuracy Hybrid 1       :		88.30 %
  top 1 accuracy NCM            :		91.30 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		71.25 %
  top 1 accuracy Hybrid 1       :		65.88 %
  top 1 accuracy NCM            :		71.62 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		96.12 %
  top 1 accuracy Hybrid 1       :		95.62 %
  top 1 accuracy NCM            :		96.00 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		91.03 %
  top 1 accuracy Hybrid 1       :		91.41 %
  top 1 accuracy NCM            :		90.84 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		94.85 %
  top 1 accuracy Hybrid 1       :		94.47 %
  top 1 accuracy NCM            :		94.85 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		100.00 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		100.00 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		86.98 %
  top 1 accuracy Hybrid 1       :		84.31 %
  top 1 accuracy NCM            :		87.32 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		95.83 %
  top 1 accuracy Hybrid 1       :		94.93 %
  top 1 accuracy NCM            :		96.03 %
Classes in this batch: tensor([8, 9])
Data Size: 3248


Before first epoch
  validation loss:		0.722804
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 5 arrives ...
0.5531992316246033
0.3000756502151489
Batch of classes 5 out of 7 batches
Epoch 1 of 30 took 65.197s
  training loss:		0.331711
  validation loss:		0.098421
  top 1 accuracy:		49.54 %
  top 2 accuracy:		99.82 %
0.2899361252784729
0.2778128385543823
Batch of classes 5 out of 7 batches
Epoch 2 of 30 took 43.090s
  training loss:		0.267005
  validation loss:		0.020460
  top 1 accuracy:		94.64 %
  top 2 accuracy:		99.72 %
0.2516257166862488
0.23166193068027496
Batch of classes 5 out of 7 batches
Epoch 3 of 30 took 42.107s
  training loss:		0.247788
  validation loss:		0.018469
  top 1 accuracy:		94.92 %
  top 2 accuracy:		98.89 %
0.2424861490726471
0.24102401733398438
Batch of classes 5 out of 7 batches
Epoch 4 of 30 took 46.345s
  training loss:		0.243975
  validation loss:		0.016627
  top 1 accuracy:		95.84 %
  top 2 accuracy:		99.91 %
0.23339848220348358
0.23906314373016357
Batch of classes 5 out of 7 batches
Epoch 5 of 30 took 42.152s
  training loss:		0.241715
  validation loss:		0.014344
  top 1 accuracy:		96.21 %
  top 2 accuracy:		99.63 %
0.24929943680763245
0.24404850602149963
Batch of classes 5 out of 7 batches
Epoch 6 of 30 took 42.059s
  training loss:		0.242476
  validation loss:		0.020183
  top 1 accuracy:		93.99 %
  top 2 accuracy:		98.52 %
0.23423680663108826
0.2464851588010788
Batch of classes 5 out of 7 batches
Epoch 7 of 30 took 42.513s
  training loss:		0.240773
  validation loss:		0.050006
  top 1 accuracy:		86.41 %
  top 2 accuracy:		99.63 %
0.23532971739768982
0.25269848108291626
Batch of classes 5 out of 7 batches
Epoch 8 of 30 took 42.951s
  training loss:		0.242687
  validation loss:		0.017999
  top 1 accuracy:		94.82 %
  top 2 accuracy:		98.61 %
0.2342534363269806
0.24318204820156097
Batch of classes 5 out of 7 batches
Epoch 9 of 30 took 42.297s
  training loss:		0.238322
  validation loss:		0.013433
  top 1 accuracy:		96.67 %
  top 2 accuracy:		98.98 %
0.24255460500717163
0.24816805124282837
Batch of classes 5 out of 7 batches
Epoch 10 of 30 took 41.970s
  training loss:		0.241557
  validation loss:		0.016214
  top 1 accuracy:		95.10 %
  top 2 accuracy:		97.69 %
0.24822929501533508
0.23634368181228638
Batch of classes 5 out of 7 batches
Epoch 11 of 30 took 42.121s
  training loss:		0.237986
  validation loss:		0.012942
  top 1 accuracy:		96.58 %
  top 2 accuracy:		99.72 %
0.2300720065832138
0.23218047618865967
Batch of classes 5 out of 7 batches
Epoch 12 of 30 took 41.999s
  training loss:		0.233479
  validation loss:		0.012959
  top 1 accuracy:		96.58 %
  top 2 accuracy:		100.00 %
0.2320975661277771
0.2340511828660965
Batch of classes 5 out of 7 batches
Epoch 13 of 30 took 42.077s
  training loss:		0.232768
  validation loss:		0.011311
  top 1 accuracy:		96.67 %
  top 2 accuracy:		99.35 %
0.22848325967788696
0.23242604732513428
Batch of classes 5 out of 7 batches
Epoch 14 of 30 took 42.303s
  training loss:		0.231930
  validation loss:		0.014868
  top 1 accuracy:		96.40 %
  top 2 accuracy:		99.63 %
0.23289644718170166
0.22744394838809967
Batch of classes 5 out of 7 batches
Epoch 15 of 30 took 46.302s
  training loss:		0.231106
  validation loss:		0.011736
  top 1 accuracy:		96.58 %
  top 2 accuracy:		99.82 %
0.2288946807384491
0.2293030172586441
Batch of classes 5 out of 7 batches
Epoch 16 of 30 took 42.151s
  training loss:		0.231127
  validation loss:		0.012002
  top 1 accuracy:		96.40 %
  top 2 accuracy:		99.45 %
0.22812549769878387
0.22564278542995453
Batch of classes 5 out of 7 batches
Epoch 17 of 30 took 42.119s
  training loss:		0.230521
  validation loss:		0.012145
  top 1 accuracy:		96.49 %
  top 2 accuracy:		99.35 %
0.22733965516090393
0.23035575449466705
Batch of classes 5 out of 7 batches
Epoch 18 of 30 took 42.143s
  training loss:		0.231606
  validation loss:		0.013141
  top 1 accuracy:		96.67 %
  top 2 accuracy:		99.45 %
0.2300197035074234
0.2320261001586914
Batch of classes 5 out of 7 batches
Epoch 19 of 30 took 41.958s
  training loss:		0.230873
  validation loss:		0.013326
  top 1 accuracy:		96.49 %
  top 2 accuracy:		99.26 %
0.22770953178405762
0.24472039937973022
Batch of classes 5 out of 7 batches
Epoch 20 of 30 took 41.950s
  training loss:		0.232578
  validation loss:		0.014148
  top 1 accuracy:		96.12 %
  top 2 accuracy:		99.91 %
0.24214968085289001
0.2363925725221634
Batch of classes 5 out of 7 batches
Epoch 21 of 30 took 41.836s
  training loss:		0.234866
  validation loss:		0.012923
  top 1 accuracy:		96.58 %
  top 2 accuracy:		99.54 %
0.237443208694458
0.23740950226783752
Batch of classes 5 out of 7 batches
Epoch 22 of 30 took 42.352s
  training loss:		0.233244
  validation loss:		0.011478
  top 1 accuracy:		96.58 %
  top 2 accuracy:		99.45 %
0.22990870475769043
0.23220983147621155
Batch of classes 5 out of 7 batches
Epoch 23 of 30 took 42.506s
  training loss:		0.232109
  validation loss:		0.013188
  top 1 accuracy:		96.40 %
  top 2 accuracy:		99.35 %
0.2301861196756363
0.2308323085308075
Batch of classes 5 out of 7 batches
Epoch 24 of 30 took 42.780s
  training loss:		0.231899
  validation loss:		0.013060
  top 1 accuracy:		96.49 %
  top 2 accuracy:		99.45 %
0.23195430636405945
0.23305149376392365
Batch of classes 5 out of 7 batches
Epoch 25 of 30 took 42.367s
  training loss:		0.231295
  validation loss:		0.015909
  top 1 accuracy:		96.58 %
  top 2 accuracy:		99.08 %
0.23066313564777374
0.22788046300411224
Batch of classes 5 out of 7 batches
Epoch 26 of 30 took 42.710s
  training loss:		0.230383
  validation loss:		0.013620
  top 1 accuracy:		96.49 %
  top 2 accuracy:		99.45 %
0.23446333408355713
0.2284504920244217
Batch of classes 5 out of 7 batches
Epoch 27 of 30 took 41.871s
  training loss:		0.229907
  validation loss:		0.013080
  top 1 accuracy:		96.49 %
  top 2 accuracy:		99.63 %
0.22819216549396515
0.226115882396698
Batch of classes 5 out of 7 batches
Epoch 28 of 30 took 41.867s
  training loss:		0.229863
  validation loss:		0.014537
  top 1 accuracy:		96.49 %
  top 2 accuracy:		99.17 %
0.22858735918998718
0.2306017279624939
Batch of classes 5 out of 7 batches
Epoch 29 of 30 took 42.085s
  training loss:		0.230488
  validation loss:		0.013024
  top 1 accuracy:		96.58 %
  top 2 accuracy:		99.63 %
0.2330312579870224
0.23308072984218597
Batch of classes 5 out of 7 batches
Epoch 30 of 30 took 42.138s
  training loss:		0.231149
  validation loss:		0.012811
  top 1 accuracy:		96.49 %
  top 2 accuracy:		99.72 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		71.60 %
  top 1 accuracy Hybrid 1       :		63.05 %
  top 1 accuracy NCM            :		72.65 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		87.30 %
  top 1 accuracy Hybrid 1       :		86.05 %
  top 1 accuracy NCM            :		88.40 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		70.50 %
  top 1 accuracy Hybrid 1       :		71.62 %
  top 1 accuracy NCM            :		70.75 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		92.88 %
  top 1 accuracy Hybrid 1       :		89.25 %
  top 1 accuracy NCM            :		92.88 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		87.98 %
  top 1 accuracy Hybrid 1       :		86.64 %
  top 1 accuracy NCM            :		88.36 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		94.08 %
  top 1 accuracy Hybrid 1       :		91.60 %
  top 1 accuracy NCM            :		94.27 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.84 %
  top 1 accuracy Hybrid 1       :		99.84 %
  top 1 accuracy NCM            :		99.84 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		99.96 %
  top 1 accuracy NCM            :		100.00 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		96.49 %
  top 1 accuracy Hybrid 1       :		96.49 %
  top 1 accuracy NCM            :		96.58 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		96.58 %
  top 1 accuracy Hybrid 1       :		96.49 %
  top 1 accuracy NCM            :		96.67 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		86.94 %
  top 1 accuracy Hybrid 1       :		84.51 %
  top 1 accuracy NCM            :		87.31 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		94.55 %
  top 1 accuracy Hybrid 1       :		93.56 %
  top 1 accuracy NCM            :		94.90 %
Classes in this batch: tensor([10, 11])
Data Size: 7658


Before first epoch
  validation loss:		2.334358
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 6 arrives ...
0.5554836988449097
0.291050523519516
0.25510331988334656
Batch of classes 6 out of 7 batches
Epoch 1 of 30 took 201.603s
  training loss:		0.292529
  validation loss:		0.001682
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.24686077237129211
0.25530073046684265
0.2371271401643753
Batch of classes 6 out of 7 batches
Epoch 2 of 30 took 171.139s
  training loss:		0.245006
  validation loss:		0.019086
  top 1 accuracy:		95.89 %
  top 2 accuracy:		99.73 %
0.2436775118112564
0.23527215421199799
0.24374571442604065
Batch of classes 6 out of 7 batches
Epoch 3 of 30 took 172.722s
  training loss:		0.241998
  validation loss:		0.013444
  top 1 accuracy:		97.10 %
  top 2 accuracy:		99.37 %
0.24126271903514862
0.2458183318376541
0.2460830956697464
Batch of classes 6 out of 7 batches
Epoch 4 of 30 took 164.056s
  training loss:		0.242379
  validation loss:		0.005960
  top 1 accuracy:		99.45 %
  top 2 accuracy:		100.00 %
0.24003498256206512
0.2299482524394989
0.25280633568763733
Batch of classes 6 out of 7 batches
Epoch 5 of 30 took 125.174s
  training loss:		0.237524
  validation loss:		0.003077
  top 1 accuracy:		99.88 %
  top 2 accuracy:		100.00 %
0.2437191903591156
0.23694849014282227
0.2318088859319687
Batch of classes 6 out of 7 batches
Epoch 6 of 30 took 115.521s
  training loss:		0.236930
  validation loss:		0.005400
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.23648220300674438
0.24188607931137085
0.23497512936592102
Batch of classes 6 out of 7 batches
Epoch 7 of 30 took 126.180s
  training loss:		0.236093
  validation loss:		0.005465
  top 1 accuracy:		99.10 %
  top 2 accuracy:		99.80 %
0.2444751113653183
0.23488275706768036
0.23097440600395203
Batch of classes 6 out of 7 batches
Epoch 8 of 30 took 100.365s
  training loss:		0.237697
  validation loss:		0.005558
  top 1 accuracy:		99.45 %
  top 2 accuracy:		99.80 %
0.2364777773618698
0.23216700553894043
0.23712365329265594
Batch of classes 6 out of 7 batches
Epoch 9 of 30 took 107.870s
  training loss:		0.239615
  validation loss:		0.002355
  top 1 accuracy:		99.65 %
  top 2 accuracy:		99.96 %
0.23650528490543365
0.23966917395591736
0.234739288687706
Batch of classes 6 out of 7 batches
Epoch 10 of 30 took 130.064s
  training loss:		0.239361
  validation loss:		0.003960
  top 1 accuracy:		99.14 %
  top 2 accuracy:		99.92 %
0.23348362743854523
0.23422104120254517
0.22849367558956146
Batch of classes 6 out of 7 batches
Epoch 11 of 30 took 133.701s
  training loss:		0.232197
  validation loss:		0.001210
  top 1 accuracy:		99.88 %
  top 2 accuracy:		100.00 %
0.23069150745868683
0.23150891065597534
0.23258109390735626
Batch of classes 6 out of 7 batches
Epoch 12 of 30 took 127.289s
  training loss:		0.231995
  validation loss:		0.000537
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.22993619740009308
0.23536787927150726
0.23251782357692719
Batch of classes 6 out of 7 batches
Epoch 13 of 30 took 129.143s
  training loss:		0.231835
  validation loss:		0.000761
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.23266932368278503
0.22698011994361877
0.22846747934818268
Batch of classes 6 out of 7 batches
Epoch 14 of 30 took 120.403s
  training loss:		0.231236
  validation loss:		0.000168
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.22975946962833405
0.22975996136665344
0.22970861196517944
Batch of classes 6 out of 7 batches
Epoch 15 of 30 took 129.006s
  training loss:		0.229921
  validation loss:		0.000390
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.22510284185409546
0.23296453058719635
0.23029710352420807
Batch of classes 6 out of 7 batches
Epoch 16 of 30 took 142.604s
  training loss:		0.232747
  validation loss:		0.000285
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.22910253703594208
0.23106810450553894
0.22815288603305817
Batch of classes 6 out of 7 batches
Epoch 17 of 30 took 125.357s
  training loss:		0.231687
  validation loss:		0.000509
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
0.23109373450279236
0.23364539444446564
0.23217712342739105
Batch of classes 6 out of 7 batches
Epoch 18 of 30 took 127.193s
  training loss:		0.231163
  validation loss:		0.000268
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.22757035493850708
0.23140379786491394
0.23266690969467163
Batch of classes 6 out of 7 batches
Epoch 19 of 30 took 133.403s
  training loss:		0.229462
  validation loss:		0.000266
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.2303125560283661
0.23131494224071503
0.2304321974515915
Batch of classes 6 out of 7 batches
Epoch 20 of 30 took 123.597s
  training loss:		0.230257
  validation loss:		0.000053
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.2311774343252182
0.23395144939422607
0.23383046686649323
Batch of classes 6 out of 7 batches
Epoch 21 of 30 took 125.976s
  training loss:		0.232998
  validation loss:		0.000090
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.23315860331058502
0.22676852345466614
0.23077555000782013
Batch of classes 6 out of 7 batches
Epoch 22 of 30 took 135.114s
  training loss:		0.231475
  validation loss:		0.000127
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.2291141301393509
0.23299868404865265
0.2317710816860199
Batch of classes 6 out of 7 batches
Epoch 23 of 30 took 127.859s
  training loss:		0.230941
  validation loss:		0.000072
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.2299644649028778
0.2284238338470459
0.23009555041790009
Batch of classes 6 out of 7 batches
Epoch 24 of 30 took 136.319s
  training loss:		0.230086
  validation loss:		0.000072
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.2312137484550476
0.230902761220932
0.22984997928142548
Batch of classes 6 out of 7 batches
Epoch 25 of 30 took 144.752s
  training loss:		0.230821
  validation loss:		0.000084
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.22981329262256622
0.23138107359409332
0.2346368134021759
Batch of classes 6 out of 7 batches
Epoch 26 of 30 took 146.523s
  training loss:		0.229565
  validation loss:		0.000111
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.2290644645690918
0.23084811866283417
0.23043805360794067
Batch of classes 6 out of 7 batches
Epoch 27 of 30 took 135.386s
  training loss:		0.231389
  validation loss:		0.000104
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.2315811812877655
0.2275513857603073
0.2304648607969284
Batch of classes 6 out of 7 batches
Epoch 28 of 30 took 133.301s
  training loss:		0.229979
  validation loss:		0.000079
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.22950930893421173
0.23108957707881927
0.22985133528709412
Batch of classes 6 out of 7 batches
Epoch 29 of 30 took 131.393s
  training loss:		0.229653
  validation loss:		0.000080
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.22687236964702606
0.2274862825870514
0.2260165810585022
Batch of classes 6 out of 7 batches
Epoch 30 of 30 took 129.996s
  training loss:		0.228268
  validation loss:		0.000076
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		64.20 %
  top 1 accuracy Hybrid 1       :		49.75 %
  top 1 accuracy NCM            :		64.60 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		84.15 %
  top 1 accuracy Hybrid 1       :		81.10 %
  top 1 accuracy NCM            :		84.05 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		64.75 %
  top 1 accuracy Hybrid 1       :		58.62 %
  top 1 accuracy NCM            :		66.88 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		90.75 %
  top 1 accuracy Hybrid 1       :		88.38 %
  top 1 accuracy NCM            :		91.25 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		88.36 %
  top 1 accuracy Hybrid 1       :		91.41 %
  top 1 accuracy NCM            :		88.55 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		93.32 %
  top 1 accuracy Hybrid 1       :		93.51 %
  top 1 accuracy NCM            :		93.32 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		73.98 %
  top 1 accuracy Hybrid 1       :		50.00 %
  top 1 accuracy NCM            :		71.79 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		99.96 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		94.55 %
  top 1 accuracy Hybrid 1       :		94.55 %
  top 1 accuracy NCM            :		95.01 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		94.64 %
  top 1 accuracy Hybrid 1       :		94.73 %
  top 1 accuracy NCM            :		95.10 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		75.98 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		78.13 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		99.96 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		74.82 %
  top 1 accuracy Hybrid 1       :		71.44 %
  top 1 accuracy NCM            :		75.13 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		94.91 %
  top 1 accuracy Hybrid 1       :		94.09 %
  top 1 accuracy NCM            :		94.96 %
Classes in this batch: tensor([12, 13])
Data Size: 6208


Before first epoch
  validation loss:		0.885543
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 7 arrives ...
0.6081647276878357
0.3059443533420563
0.3081302046775818
Batch of classes 7 out of 7 batches
Epoch 1 of 30 took 94.840s
  training loss:		0.324941
  validation loss:		0.109572
  top 1 accuracy:		51.04 %
  top 2 accuracy:		97.53 %
0.2981070876121521
0.30640262365341187
0.2859582006931305
Batch of classes 7 out of 7 batches
Epoch 2 of 30 took 68.665s
  training loss:		0.288757
  validation loss:		0.097469
  top 1 accuracy:		64.32 %
  top 2 accuracy:		98.40 %
0.28389665484428406
0.26950782537460327
0.286243200302124
Batch of classes 7 out of 7 batches
Epoch 3 of 30 took 69.877s
  training loss:		0.282830
  validation loss:		0.087323
  top 1 accuracy:		68.49 %
  top 2 accuracy:		98.59 %
0.2814346253871918
0.2796589434146881
0.2770586609840393
Batch of classes 7 out of 7 batches
Epoch 4 of 30 took 69.590s
  training loss:		0.278507
  validation loss:		0.078078
  top 1 accuracy:		72.66 %
  top 2 accuracy:		99.81 %
0.2756361961364746
0.28592848777770996
0.27420657873153687
Batch of classes 7 out of 7 batches
Epoch 5 of 30 took 78.465s
  training loss:		0.276414
  validation loss:		0.084161
  top 1 accuracy:		70.58 %
  top 2 accuracy:		98.11 %
0.27222171425819397
0.2731969356536865
0.26299232244491577
Batch of classes 7 out of 7 batches
Epoch 6 of 30 took 68.724s
  training loss:		0.274398
  validation loss:		0.073294
  top 1 accuracy:		76.39 %
  top 2 accuracy:		99.81 %
0.26579779386520386
0.25464358925819397
0.2678375244140625
Batch of classes 7 out of 7 batches
Epoch 7 of 30 took 68.838s
  training loss:		0.272302
  validation loss:		0.079187
  top 1 accuracy:		75.47 %
  top 2 accuracy:		98.98 %
0.2695075571537018
0.2786768674850464
0.2646898329257965
Batch of classes 7 out of 7 batches
Epoch 8 of 30 took 74.409s
  training loss:		0.272188
  validation loss:		0.070735
  top 1 accuracy:		76.83 %
  top 2 accuracy:		99.90 %
0.26306474208831787
0.2642131447792053
0.26820483803749084
Batch of classes 7 out of 7 batches
Epoch 9 of 30 took 73.342s
  training loss:		0.270025
  validation loss:		0.071991
  top 1 accuracy:		76.64 %
  top 2 accuracy:		99.37 %
0.2648201286792755
0.2629542052745819
0.2724841237068176
Batch of classes 7 out of 7 batches
Epoch 10 of 30 took 69.525s
  training loss:		0.268055
  validation loss:		0.072333
  top 1 accuracy:		75.62 %
  top 2 accuracy:		99.61 %
0.2719314992427826
0.24950118362903595
0.2521943151950836
Batch of classes 7 out of 7 batches
Epoch 11 of 30 took 72.086s
  training loss:		0.260841
  validation loss:		0.072850
  top 1 accuracy:		76.49 %
  top 2 accuracy:		99.47 %
0.2775305509567261
0.250080406665802
0.26193177700042725
Batch of classes 7 out of 7 batches
Epoch 12 of 30 took 68.462s
  training loss:		0.257418
  validation loss:		0.067556
  top 1 accuracy:		78.53 %
  top 2 accuracy:		99.81 %
0.2616875171661377
0.2510639727115631
0.2623153328895569
Batch of classes 7 out of 7 batches
Epoch 13 of 30 took 68.023s
  training loss:		0.257555
  validation loss:		0.075909
  top 1 accuracy:		78.53 %
  top 2 accuracy:		98.69 %
0.2545643448829651
0.2673439085483551
0.2507127821445465
Batch of classes 7 out of 7 batches
Epoch 14 of 30 took 67.881s
  training loss:		0.255745
  validation loss:		0.071610
  top 1 accuracy:		78.04 %
  top 2 accuracy:		99.90 %
0.2607913613319397
0.2400270253419876
0.2524625062942505
Batch of classes 7 out of 7 batches
Epoch 15 of 30 took 67.440s
  training loss:		0.254821
  validation loss:		0.067289
  top 1 accuracy:		79.79 %
  top 2 accuracy:		99.61 %
0.24309833347797394
0.2517726719379425
0.26174649596214294
Batch of classes 7 out of 7 batches
Epoch 16 of 30 took 66.674s
  training loss:		0.254010
  validation loss:		0.066489
  top 1 accuracy:		78.14 %
  top 2 accuracy:		99.52 %
0.25024646520614624
0.25055307149887085
0.2494708150625229
Batch of classes 7 out of 7 batches
Epoch 17 of 30 took 68.773s
  training loss:		0.252298
  validation loss:		0.071527
  top 1 accuracy:		79.84 %
  top 2 accuracy:		99.76 %
0.2448769211769104
0.2575362026691437
0.2582508623600006
Batch of classes 7 out of 7 batches
Epoch 18 of 30 took 69.606s
  training loss:		0.252982
  validation loss:		0.070357
  top 1 accuracy:		79.54 %
  top 2 accuracy:		99.61 %
0.25323596596717834
0.25750109553337097
0.2626618444919586
Batch of classes 7 out of 7 batches
Epoch 19 of 30 took 68.182s
  training loss:		0.251551
  validation loss:		0.070335
  top 1 accuracy:		79.45 %
  top 2 accuracy:		99.95 %
0.24995045363903046
0.24633528292179108
0.24598976969718933
Batch of classes 7 out of 7 batches
Epoch 20 of 30 took 67.401s
  training loss:		0.251768
  validation loss:		0.075765
  top 1 accuracy:		78.62 %
  top 2 accuracy:		99.76 %
0.25084322690963745
0.24438495934009552
0.26409441232681274
Batch of classes 7 out of 7 batches
Epoch 21 of 30 took 69.039s
  training loss:		0.248883
  validation loss:		0.077003
  top 1 accuracy:		78.62 %
  top 2 accuracy:		99.71 %
0.2507275342941284
0.24965624511241913
0.25070664286613464
Batch of classes 7 out of 7 batches
Epoch 22 of 30 took 87.932s
  training loss:		0.247246
  validation loss:		0.075988
  top 1 accuracy:		80.08 %
  top 2 accuracy:		99.66 %
0.2315620481967926
0.24127314984798431
0.23525097966194153
Batch of classes 7 out of 7 batches
Epoch 23 of 30 took 86.660s
  training loss:		0.246770
  validation loss:		0.075935
  top 1 accuracy:		79.93 %
  top 2 accuracy:		99.56 %
0.2481929212808609
0.23985536396503448
0.25650498270988464
Batch of classes 7 out of 7 batches
Epoch 24 of 30 took 83.888s
  training loss:		0.247259
  validation loss:		0.078684
  top 1 accuracy:		79.11 %
  top 2 accuracy:		99.52 %
0.24708957970142365
0.2428264021873474
0.24107958376407623
Batch of classes 7 out of 7 batches
Epoch 25 of 30 took 84.198s
  training loss:		0.245988
  validation loss:		0.080207
  top 1 accuracy:		79.64 %
  top 2 accuracy:		98.98 %
0.23938100039958954
0.2423301786184311
0.24434711039066315
Batch of classes 7 out of 7 batches
Epoch 26 of 30 took 87.373s
  training loss:		0.245513
  validation loss:		0.081589
  top 1 accuracy:		79.59 %
  top 2 accuracy:		99.27 %
0.2561644911766052
0.2521265149116516
0.24393899738788605
Batch of classes 7 out of 7 batches
Epoch 27 of 30 took 68.028s
  training loss:		0.245361
  validation loss:		0.076717
  top 1 accuracy:		80.61 %
  top 2 accuracy:		98.98 %
0.23585523664951324
0.2542990744113922
0.2501250207424164
Batch of classes 7 out of 7 batches
Epoch 28 of 30 took 68.401s
  training loss:		0.245056
  validation loss:		0.079841
  top 1 accuracy:		80.17 %
  top 2 accuracy:		99.13 %
0.2520292103290558
0.2353399395942688
0.23839862644672394
Batch of classes 7 out of 7 batches
Epoch 29 of 30 took 67.654s
  training loss:		0.243650
  validation loss:		0.083143
  top 1 accuracy:		79.79 %
  top 2 accuracy:		99.42 %
0.24826957285404205
0.24281805753707886
0.24259711802005768
Batch of classes 7 out of 7 batches
Epoch 30 of 30 took 67.545s
  training loss:		0.244593
  validation loss:		0.089119
  top 1 accuracy:		79.84 %
  top 2 accuracy:		99.37 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		58.45 %
  top 1 accuracy Hybrid 1       :		48.75 %
  top 1 accuracy NCM            :		60.00 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		74.95 %
  top 1 accuracy Hybrid 1       :		74.40 %
  top 1 accuracy NCM            :		75.85 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		51.50 %
  top 1 accuracy Hybrid 1       :		52.25 %
  top 1 accuracy NCM            :		53.00 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		79.00 %
  top 1 accuracy Hybrid 1       :		78.38 %
  top 1 accuracy NCM            :		79.38 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		82.44 %
  top 1 accuracy Hybrid 1       :		85.11 %
  top 1 accuracy NCM            :		82.44 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		89.31 %
  top 1 accuracy Hybrid 1       :		88.36 %
  top 1 accuracy NCM            :		88.74 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		74.06 %
  top 1 accuracy Hybrid 1       :		71.24 %
  top 1 accuracy NCM            :		73.94 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.73 %
  top 1 accuracy Hybrid 1       :		99.65 %
  top 1 accuracy NCM            :		99.65 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		87.99 %
  top 1 accuracy Hybrid 1       :		82.07 %
  top 1 accuracy NCM            :		88.54 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		94.73 %
  top 1 accuracy Hybrid 1       :		92.24 %
  top 1 accuracy NCM            :		94.73 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		75.47 %
  top 1 accuracy Hybrid 1       :		78.10 %
  top 1 accuracy NCM            :		75.55 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.80 %
  top 1 accuracy Hybrid 1       :		99.69 %
  top 1 accuracy NCM            :		99.73 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		79.54 %
  top 1 accuracy Hybrid 1       :		79.84 %
  top 1 accuracy NCM            :		79.88 %
Binary accuracy:
Final results on wild classes:
  top 1 accuracy iCaRL          :		79.79 %
  top 1 accuracy Hybrid 1       :		79.84 %
  top 1 accuracy NCM            :		80.13 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		72.77 %
  top 1 accuracy Hybrid 1       :		70.72 %
  top 1 accuracy NCM            :		73.25 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		89.54 %
  top 1 accuracy Hybrid 1       :		89.09 %
  top 1 accuracy NCM            :		89.72 %
tensor([[[ 99.6500,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 99.7000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 99.6500,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 96.9500,  99.2500,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 95.5500,  99.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 96.8000,  99.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 96.1000,  94.8750,  97.5191,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 93.6500,  91.1250,  97.1374,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 95.9500,  94.7500,  97.5191,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 90.6500,  96.1250,  94.8473, 100.0000,   0.0000,   0.0000,   0.0000],
         [ 88.3000,  95.6250,  94.4657, 100.0000,   0.0000,   0.0000,   0.0000],
         [ 91.3000,  96.0000,  94.8473, 100.0000,   0.0000,   0.0000,   0.0000]],

        [[ 87.3000,  92.8750,  94.0840, 100.0000,  96.5804,   0.0000,   0.0000],
         [ 86.0500,  89.2500,  91.6031,  99.9608,  96.4880,   0.0000,   0.0000],
         [ 88.4000,  92.8750,  94.2748, 100.0000,  96.6728,   0.0000,   0.0000]],

        [[ 84.1500,  90.7500,  93.3206, 100.0000,  94.6396, 100.0000,   0.0000],
         [ 81.1000,  88.3750,  93.5115, 100.0000,  94.7320, 100.0000,   0.0000],
         [ 84.0500,  91.2500,  93.3206,  99.9608,  95.1017,  99.9608,   0.0000]],

        [[ 74.9500,  79.0000,  89.3130,  99.7257,  94.7320,  99.8041,  79.7867],
         [ 74.4000,  78.3750,  88.3588,  99.6473,  92.2366,  99.6865,  79.8352],
         [ 75.8500,  79.3750,  88.7405,  99.6473,  94.7320,  99.7257,  80.1260]]])
tensor([88.1874, 87.5056, 88.3138])
----------------- Options ---------------
               add_binary: True                          	[default: False]
               batch_size: 32                            	[default: 64]
                   binary: False                         
              binary_loss: sum_b_log                     	[default: sum_b_sig]
            binary_weight: 0.7                           	[default: 0.5]
                blur_prob: 0                             
                 blur_sig: 0.5                           
          checkpoints_dir: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL/checkpoints	[default: ./checkpoints]
                class_bal: False                         
           continue_train: False                         
                 cropSize: 224                           
                 data_aug: False                         
                 dataroot: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/test	[default: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL]
          earlystop_epoch: 5                             
                    epoch: latest                        
                 fine_tun: False                         
                    gpuid: [1]                           
                init_gain: 0.02                          
                  init_lr: 0.0005                        
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2                           
                 jpg_prob: 0                             
                 jpg_qual: 75                            
          label_smoothing: False                         
                 loadSize: 256                           
                    mixup: False                         
              mixup_alpha: 0.1                           
                     mode: binary                        
               model_name: resnet18                      
               model_type: resnet                        
            model_weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth	[default: None]
               multiclass: [0, 0, 1, 0, 0, 0, 0]         	[default: [1]]
                     name: MT_7_bm_sum_b_log07_15        	[default: experiment_name]
                  no_flip: False                         
              num_classes: 2                             
               num_epochs: 30                            	[default: 12]
              num_threads: 4                             
                  outfile: temp_0.1.csv                  
            pretrain_name:                               
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 20                            
         save_latest_freq: 2000                          
                 schedule: [10, 20, 30]                  	[default: [10]]
           serial_batches: False                         
          smoothing_alpha: 0.1                           
                   suffix:                               
                task_name: gaugan,biggan,cyclegan,imle,deepfake,crn,wild	[default: ]
              train_split: train                         
                val_split: val                           
----------------- End -------------------
{'All': 14}
Task order: ['gaugan', 'biggan', 'cyclegan', 'imle', 'deepfake', 'crn', 'wild']
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Classes in this batch: tensor([0, 1])
Data Size: 6000


Before first epoch
  validation loss:		1.309705
  top 1 accuracy:		17.05 %
  top 2 accuracy:		17.30 %
Batch of classes number 1 arrives ...
0.7245064973831177
0.37116220593452454
Batch of classes 1 out of 7 batches
Epoch 1 of 30 took 51.486s
  training loss:		0.383114
  validation loss:		0.043722
  top 1 accuracy:		87.00 %
  top 2 accuracy:		100.00 %
0.3667808771133423
0.3528693914413452
Batch of classes 1 out of 7 batches
Epoch 2 of 30 took 50.034s
  training loss:		0.355857
  validation loss:		0.032731
  top 1 accuracy:		90.45 %
  top 2 accuracy:		99.95 %
0.34815648198127747
0.3529169261455536
Batch of classes 1 out of 7 batches
Epoch 3 of 30 took 50.367s
  training loss:		0.350917
  validation loss:		0.040817
  top 1 accuracy:		87.60 %
  top 2 accuracy:		100.00 %
0.35692933201789856
0.34625136852264404
Batch of classes 1 out of 7 batches
Epoch 4 of 30 took 50.501s
  training loss:		0.348161
  validation loss:		0.024001
  top 1 accuracy:		93.50 %
  top 2 accuracy:		100.00 %
0.34322458505630493
0.34688565135002136
Batch of classes 1 out of 7 batches
Epoch 5 of 30 took 51.192s
  training loss:		0.347151
  validation loss:		0.020571
  top 1 accuracy:		95.05 %
  top 2 accuracy:		100.00 %
0.34352028369903564
0.3532138466835022
Batch of classes 1 out of 7 batches
Epoch 6 of 30 took 50.256s
  training loss:		0.346929
  validation loss:		0.026537
  top 1 accuracy:		91.65 %
  top 2 accuracy:		100.00 %
0.35898512601852417
0.33937424421310425
Batch of classes 1 out of 7 batches
Epoch 7 of 30 took 50.517s
  training loss:		0.345549
  validation loss:		0.023175
  top 1 accuracy:		93.25 %
  top 2 accuracy:		100.00 %
0.34460562467575073
0.3528123199939728
Batch of classes 1 out of 7 batches
Epoch 8 of 30 took 50.269s
  training loss:		0.345493
  validation loss:		0.021563
  top 1 accuracy:		94.40 %
  top 2 accuracy:		100.00 %
0.34507638216018677
0.3406094014644623
Batch of classes 1 out of 7 batches
Epoch 9 of 30 took 50.929s
  training loss:		0.343395
  validation loss:		0.021257
  top 1 accuracy:		94.45 %
  top 2 accuracy:		100.00 %
0.3506318926811218
0.3497019410133362
Batch of classes 1 out of 7 batches
Epoch 10 of 30 took 51.026s
  training loss:		0.342527
  validation loss:		0.018792
  top 1 accuracy:		95.20 %
  top 2 accuracy:		100.00 %
0.33760881423950195
0.33648592233657837
Batch of classes 1 out of 7 batches
Epoch 11 of 30 took 51.319s
  training loss:		0.338388
  validation loss:		0.006905
  top 1 accuracy:		98.50 %
  top 2 accuracy:		100.00 %
0.33329659700393677
0.33309751749038696
Batch of classes 1 out of 7 batches
Epoch 12 of 30 took 53.146s
  training loss:		0.335375
  validation loss:		0.005616
  top 1 accuracy:		98.65 %
  top 2 accuracy:		100.00 %
0.3337125778198242
0.33330273628234863
Batch of classes 1 out of 7 batches
Epoch 13 of 30 took 50.589s
  training loss:		0.333526
  validation loss:		0.005762
  top 1 accuracy:		98.60 %
  top 2 accuracy:		100.00 %
0.3330991566181183
0.33523982763290405
Batch of classes 1 out of 7 batches
Epoch 14 of 30 took 50.472s
  training loss:		0.332045
  validation loss:		0.006105
  top 1 accuracy:		98.40 %
  top 2 accuracy:		100.00 %
0.3348964750766754
0.3438783884048462
Batch of classes 1 out of 7 batches
Epoch 15 of 30 took 57.394s
  training loss:		0.333310
  validation loss:		0.005285
  top 1 accuracy:		99.00 %
  top 2 accuracy:		100.00 %
0.33435654640197754
0.3318009674549103
Batch of classes 1 out of 7 batches
Epoch 16 of 30 took 51.400s
  training loss:		0.331381
  validation loss:		0.003835
  top 1 accuracy:		99.10 %
  top 2 accuracy:		100.00 %
0.3383159935474396
0.32621145248413086
Batch of classes 1 out of 7 batches
Epoch 17 of 30 took 50.638s
  training loss:		0.330275
  validation loss:		0.005206
  top 1 accuracy:		98.90 %
  top 2 accuracy:		100.00 %
0.33015912771224976
0.32710200548171997
Batch of classes 1 out of 7 batches
Epoch 18 of 30 took 54.588s
  training loss:		0.329632
  validation loss:		0.006543
  top 1 accuracy:		98.35 %
  top 2 accuracy:		100.00 %
0.33196553587913513
0.3298693299293518
Batch of classes 1 out of 7 batches
Epoch 19 of 30 took 50.756s
  training loss:		0.329712
  validation loss:		0.004692
  top 1 accuracy:		99.00 %
  top 2 accuracy:		100.00 %
0.32773685455322266
0.33171090483665466
Batch of classes 1 out of 7 batches
Epoch 20 of 30 took 52.184s
  training loss:		0.328812
  validation loss:		0.006356
  top 1 accuracy:		98.20 %
  top 2 accuracy:		100.00 %
0.32622280716896057
0.32683151960372925
Batch of classes 1 out of 7 batches
Epoch 21 of 30 took 52.235s
  training loss:		0.327653
  validation loss:		0.003544
  top 1 accuracy:		99.35 %
  top 2 accuracy:		100.00 %
0.32702720165252686
0.32716572284698486
Batch of classes 1 out of 7 batches
Epoch 22 of 30 took 50.336s
  training loss:		0.326822
  validation loss:		0.002868
  top 1 accuracy:		99.30 %
  top 2 accuracy:		100.00 %
0.33384349942207336
0.32587724924087524
Batch of classes 1 out of 7 batches
Epoch 23 of 30 took 51.122s
  training loss:		0.326192
  validation loss:		0.003666
  top 1 accuracy:		99.40 %
  top 2 accuracy:		100.00 %
0.32600483298301697
0.32462841272354126
Batch of classes 1 out of 7 batches
Epoch 24 of 30 took 50.511s
  training loss:		0.325263
  validation loss:		0.003629
  top 1 accuracy:		99.20 %
  top 2 accuracy:		100.00 %
0.3260427713394165
0.3252386152744293
Batch of classes 1 out of 7 batches
Epoch 25 of 30 took 50.402s
  training loss:		0.325235
  validation loss:		0.002560
  top 1 accuracy:		99.40 %
  top 2 accuracy:		100.00 %
0.3253808617591858
0.32379865646362305
Batch of classes 1 out of 7 batches
Epoch 26 of 30 took 50.786s
  training loss:		0.324606
  validation loss:		0.002208
  top 1 accuracy:		99.55 %
  top 2 accuracy:		100.00 %
0.326517254114151
0.32422155141830444
Batch of classes 1 out of 7 batches
Epoch 27 of 30 took 50.733s
  training loss:		0.324305
  validation loss:		0.004012
  top 1 accuracy:		99.25 %
  top 2 accuracy:		100.00 %
0.3245006203651428
0.3238430619239807
Batch of classes 1 out of 7 batches
Epoch 28 of 30 took 51.037s
  training loss:		0.324553
  validation loss:		0.002463
  top 1 accuracy:		99.45 %
  top 2 accuracy:		100.00 %
0.32278844714164734
0.32389798760414124
Batch of classes 1 out of 7 batches
Epoch 29 of 30 took 52.998s
  training loss:		0.324275
  validation loss:		0.002192
  top 1 accuracy:		99.45 %
  top 2 accuracy:		100.00 %
0.3230988383293152
0.3244524300098419
Batch of classes 1 out of 7 batches
Epoch 30 of 30 took 50.821s
  training loss:		0.323380
  validation loss:		0.002966
  top 1 accuracy:		99.15 %
  top 2 accuracy:		100.00 %
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(500)
tensor(500)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		99.35 %
  top 1 accuracy Hybrid 1       :		99.15 %
  top 1 accuracy NCM            :		99.35 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		99.40 %
  top 1 accuracy Hybrid 1       :		99.15 %
  top 1 accuracy NCM            :		99.40 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		99.35 %
  top 1 accuracy Hybrid 1       :		99.15 %
  top 1 accuracy NCM            :		99.35 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		99.40 %
  top 1 accuracy Hybrid 1       :		99.15 %
  top 1 accuracy NCM            :		99.40 %
Classes in this batch: tensor([2, 3])
Data Size: 2400


Before first epoch
  validation loss:		1.395767
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 2 arrives ...
0.638576090335846
0.3778125047683716
Batch of classes 2 out of 7 batches
Epoch 1 of 30 took 32.341s
  training loss:		0.400428
  validation loss:		0.099361
  top 1 accuracy:		70.13 %
  top 2 accuracy:		98.37 %
0.3782740831375122
0.36206501722335815
Batch of classes 2 out of 7 batches
Epoch 2 of 30 took 31.595s
  training loss:		0.370750
  validation loss:		0.067680
  top 1 accuracy:		78.87 %
  top 2 accuracy:		96.88 %
0.36285915970802307
0.3550332188606262
Batch of classes 2 out of 7 batches
Epoch 3 of 30 took 31.242s
  training loss:		0.361619
  validation loss:		0.092674
  top 1 accuracy:		71.13 %
  top 2 accuracy:		89.75 %
0.3698727786540985
0.3548033833503723
Batch of classes 2 out of 7 batches
Epoch 4 of 30 took 31.333s
  training loss:		0.357507
  validation loss:		0.159639
  top 1 accuracy:		52.88 %
  top 2 accuracy:		84.13 %
0.357103556394577
0.34502360224723816
Batch of classes 2 out of 7 batches
Epoch 5 of 30 took 31.557s
  training loss:		0.354485
  validation loss:		0.042887
  top 1 accuracy:		91.50 %
  top 2 accuracy:		99.12 %
0.3445001244544983
0.34226101636886597
Batch of classes 2 out of 7 batches
Epoch 6 of 30 took 31.146s
  training loss:		0.351793
  validation loss:		0.072343
  top 1 accuracy:		79.87 %
  top 2 accuracy:		95.13 %
0.35203155875205994
0.3500078618526459
Batch of classes 2 out of 7 batches
Epoch 7 of 30 took 31.286s
  training loss:		0.348160
  validation loss:		0.070122
  top 1 accuracy:		80.50 %
  top 2 accuracy:		95.00 %
0.3501109778881073
0.3433550298213959
Batch of classes 2 out of 7 batches
Epoch 8 of 30 took 31.925s
  training loss:		0.348144
  validation loss:		0.073796
  top 1 accuracy:		80.75 %
  top 2 accuracy:		95.38 %
0.34383466839790344
0.34208786487579346
Batch of classes 2 out of 7 batches
Epoch 9 of 30 took 32.503s
  training loss:		0.347315
  validation loss:		0.029261
  top 1 accuracy:		93.00 %
  top 2 accuracy:		99.37 %
0.3400154411792755
0.34327706694602966
Batch of classes 2 out of 7 batches
Epoch 10 of 30 took 31.288s
  training loss:		0.345136
  validation loss:		0.035295
  top 1 accuracy:		91.37 %
  top 2 accuracy:		99.00 %
0.3425002992153168
0.3393789827823639
Batch of classes 2 out of 7 batches
Epoch 11 of 30 took 31.185s
  training loss:		0.339648
  validation loss:		0.027889
  top 1 accuracy:		92.37 %
  top 2 accuracy:		98.50 %
0.33776167035102844
0.3310696482658386
Batch of classes 2 out of 7 batches
Epoch 12 of 30 took 31.357s
  training loss:		0.336733
  validation loss:		0.031161
  top 1 accuracy:		92.87 %
  top 2 accuracy:		97.87 %
0.33252015709877014
0.3310067057609558
Batch of classes 2 out of 7 batches
Epoch 13 of 30 took 31.406s
  training loss:		0.335155
  validation loss:		0.018131
  top 1 accuracy:		95.75 %
  top 2 accuracy:		99.12 %
0.3312281370162964
0.33421480655670166
Batch of classes 2 out of 7 batches
Epoch 14 of 30 took 31.711s
  training loss:		0.335264
  validation loss:		0.040763
  top 1 accuracy:		92.87 %
  top 2 accuracy:		98.12 %
0.3289506435394287
0.33775824308395386
Batch of classes 2 out of 7 batches
Epoch 15 of 30 took 31.139s
  training loss:		0.333647
  validation loss:		0.040746
  top 1 accuracy:		90.00 %
  top 2 accuracy:		98.25 %
0.32768896222114563
0.3286995589733124
Batch of classes 2 out of 7 batches
Epoch 16 of 30 took 31.965s
  training loss:		0.333190
  validation loss:		0.030170
  top 1 accuracy:		93.12 %
  top 2 accuracy:		98.50 %
0.3267020881175995
0.33419501781463623
Batch of classes 2 out of 7 batches
Epoch 17 of 30 took 31.356s
  training loss:		0.332559
  validation loss:		0.045930
  top 1 accuracy:		91.37 %
  top 2 accuracy:		99.25 %
0.3390463888645172
0.3321901857852936
Batch of classes 2 out of 7 batches
Epoch 18 of 30 took 31.485s
  training loss:		0.332487
  validation loss:		0.015774
  top 1 accuracy:		96.63 %
  top 2 accuracy:		99.25 %
0.3267022967338562
0.3269766569137573
Batch of classes 2 out of 7 batches
Epoch 19 of 30 took 31.860s
  training loss:		0.330001
  validation loss:		0.031596
  top 1 accuracy:		94.50 %
  top 2 accuracy:		98.12 %
0.3276047706604004
0.33101916313171387
Batch of classes 2 out of 7 batches
Epoch 20 of 30 took 31.473s
  training loss:		0.329719
  validation loss:		0.024866
  top 1 accuracy:		93.75 %
  top 2 accuracy:		98.00 %
0.32546985149383545
0.3266774117946625
Batch of classes 2 out of 7 batches
Epoch 21 of 30 took 32.079s
  training loss:		0.327853
  validation loss:		0.020918
  top 1 accuracy:		95.13 %
  top 2 accuracy:		99.00 %
0.3242461681365967
0.32735228538513184
Batch of classes 2 out of 7 batches
Epoch 22 of 30 took 31.477s
  training loss:		0.328271
  validation loss:		0.019719
  top 1 accuracy:		95.13 %
  top 2 accuracy:		99.25 %
0.3238256871700287
0.3248388469219208
Batch of classes 2 out of 7 batches
Epoch 23 of 30 took 31.396s
  training loss:		0.328548
  validation loss:		0.009141
  top 1 accuracy:		97.75 %
  top 2 accuracy:		99.62 %
0.3272362947463989
0.32740500569343567
Batch of classes 2 out of 7 batches
Epoch 24 of 30 took 31.279s
  training loss:		0.327854
  validation loss:		0.017429
  top 1 accuracy:		96.50 %
  top 2 accuracy:		99.37 %
0.32524389028549194
0.3279987871646881
Batch of classes 2 out of 7 batches
Epoch 25 of 30 took 31.406s
  training loss:		0.328856
  validation loss:		0.017982
  top 1 accuracy:		95.63 %
  top 2 accuracy:		99.25 %
0.32442519068717957
0.32820969820022583
Batch of classes 2 out of 7 batches
Epoch 26 of 30 took 31.579s
  training loss:		0.327825
  validation loss:		0.015635
  top 1 accuracy:		96.88 %
  top 2 accuracy:		99.50 %
0.32354745268821716
0.32831868529319763
Batch of classes 2 out of 7 batches
Epoch 27 of 30 took 31.405s
  training loss:		0.327727
  validation loss:		0.017607
  top 1 accuracy:		96.25 %
  top 2 accuracy:		99.00 %
0.32433441281318665
0.32780560851097107
Batch of classes 2 out of 7 batches
Epoch 28 of 30 took 31.890s
  training loss:		0.328207
  validation loss:		0.011286
  top 1 accuracy:		97.50 %
  top 2 accuracy:		99.75 %
0.3264410197734833
0.3535051941871643
Batch of classes 2 out of 7 batches
Epoch 29 of 30 took 31.522s
  training loss:		0.327573
  validation loss:		0.010489
  top 1 accuracy:		97.37 %
  top 2 accuracy:		99.62 %
0.33309683203697205
0.32764098048210144
Batch of classes 2 out of 7 batches
Epoch 30 of 30 took 31.348s
  training loss:		0.327245
  validation loss:		0.017042
  top 1 accuracy:		96.63 %
  top 2 accuracy:		99.25 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(384)
tensor(384)
tensor(384)
tensor(384)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		75.70 %
  top 1 accuracy Hybrid 1       :		58.05 %
  top 1 accuracy NCM            :		77.60 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		95.80 %
  top 1 accuracy Hybrid 1       :		94.70 %
  top 1 accuracy NCM            :		95.70 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		88.88 %
  top 1 accuracy Hybrid 1       :		96.62 %
  top 1 accuracy NCM            :		87.12 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		98.75 %
  top 1 accuracy Hybrid 1       :		98.88 %
  top 1 accuracy NCM            :		98.75 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		79.46 %
  top 1 accuracy Hybrid 1       :		69.07 %
  top 1 accuracy NCM            :		80.32 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		96.64 %
  top 1 accuracy Hybrid 1       :		95.89 %
  top 1 accuracy NCM            :		96.57 %
Classes in this batch: tensor([4, 5])
Data Size: 1572


Before first epoch
  validation loss:		0.895952
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 3 arrives ...
0.4354584217071533
Batch of classes 3 out of 7 batches
Epoch 1 of 30 took 28.714s
  training loss:		0.393704
  validation loss:		0.122013
  top 1 accuracy:		49.24 %
  top 2 accuracy:		95.42 %
0.3756774067878723
Batch of classes 3 out of 7 batches
Epoch 2 of 30 took 27.329s
  training loss:		0.368608
  validation loss:		0.074359
  top 1 accuracy:		80.15 %
  top 2 accuracy:		97.71 %
0.35508644580841064
Batch of classes 3 out of 7 batches
Epoch 3 of 30 took 27.809s
  training loss:		0.355271
  validation loss:		0.060052
  top 1 accuracy:		83.59 %
  top 2 accuracy:		97.52 %
0.3510790765285492
Batch of classes 3 out of 7 batches
Epoch 4 of 30 took 27.229s
  training loss:		0.349371
  validation loss:		0.041982
  top 1 accuracy:		88.55 %
  top 2 accuracy:		96.37 %
0.348580002784729
Batch of classes 3 out of 7 batches
Epoch 5 of 30 took 27.509s
  training loss:		0.346450
  validation loss:		0.057117
  top 1 accuracy:		86.64 %
  top 2 accuracy:		95.23 %
0.34032267332077026
Batch of classes 3 out of 7 batches
Epoch 6 of 30 took 27.245s
  training loss:		0.344619
  validation loss:		0.048122
  top 1 accuracy:		90.46 %
  top 2 accuracy:		98.09 %
0.3418615162372589
Batch of classes 3 out of 7 batches
Epoch 7 of 30 took 27.451s
  training loss:		0.342553
  validation loss:		0.036851
  top 1 accuracy:		91.60 %
  top 2 accuracy:		97.14 %
0.3427025079727173
Batch of classes 3 out of 7 batches
Epoch 8 of 30 took 28.265s
  training loss:		0.342008
  validation loss:		0.033365
  top 1 accuracy:		92.56 %
  top 2 accuracy:		98.28 %
0.3471331298351288
Batch of classes 3 out of 7 batches
Epoch 9 of 30 took 28.118s
  training loss:		0.339284
  validation loss:		0.033440
  top 1 accuracy:		92.18 %
  top 2 accuracy:		98.09 %
0.330323725938797
Batch of classes 3 out of 7 batches
Epoch 10 of 30 took 27.391s
  training loss:		0.338454
  validation loss:		0.058615
  top 1 accuracy:		85.11 %
  top 2 accuracy:		96.18 %
0.3357820510864258
Batch of classes 3 out of 7 batches
Epoch 11 of 30 took 27.415s
  training loss:		0.333549
  validation loss:		0.028911
  top 1 accuracy:		92.94 %
  top 2 accuracy:		97.33 %
0.331686794757843
Batch of classes 3 out of 7 batches
Epoch 12 of 30 took 27.627s
  training loss:		0.330925
  validation loss:		0.017786
  top 1 accuracy:		95.99 %
  top 2 accuracy:		99.05 %
0.32639122009277344
Batch of classes 3 out of 7 batches
Epoch 13 of 30 took 27.295s
  training loss:		0.329451
  validation loss:		0.039405
  top 1 accuracy:		91.03 %
  top 2 accuracy:		96.76 %
0.3278154730796814
Batch of classes 3 out of 7 batches
Epoch 14 of 30 took 27.140s
  training loss:		0.329978
  validation loss:		0.013544
  top 1 accuracy:		96.95 %
  top 2 accuracy:		99.05 %
0.3264816701412201
Batch of classes 3 out of 7 batches
Epoch 15 of 30 took 27.275s
  training loss:		0.329619
  validation loss:		0.015810
  top 1 accuracy:		96.56 %
  top 2 accuracy:		98.47 %
0.33419573307037354
Batch of classes 3 out of 7 batches
Epoch 16 of 30 took 27.524s
  training loss:		0.328518
  validation loss:		0.037596
  top 1 accuracy:		92.94 %
  top 2 accuracy:		96.76 %
0.3259800374507904
Batch of classes 3 out of 7 batches
Epoch 17 of 30 took 27.427s
  training loss:		0.327610
  validation loss:		0.008770
  top 1 accuracy:		97.90 %
  top 2 accuracy:		99.62 %
0.3237622082233429
Batch of classes 3 out of 7 batches
Epoch 18 of 30 took 27.641s
  training loss:		0.325900
  validation loss:		0.010387
  top 1 accuracy:		97.90 %
  top 2 accuracy:		99.43 %
0.3189992904663086
Batch of classes 3 out of 7 batches
Epoch 19 of 30 took 27.394s
  training loss:		0.328644
  validation loss:		0.011312
  top 1 accuracy:		97.14 %
  top 2 accuracy:		99.62 %
0.33038127422332764
Batch of classes 3 out of 7 batches
Epoch 20 of 30 took 28.238s
  training loss:		0.328066
  validation loss:		0.010290
  top 1 accuracy:		97.14 %
  top 2 accuracy:		100.00 %
0.3282986581325531
Batch of classes 3 out of 7 batches
Epoch 21 of 30 took 27.216s
  training loss:		0.328962
  validation loss:		0.010705
  top 1 accuracy:		97.52 %
  top 2 accuracy:		99.81 %
0.331204891204834
Batch of classes 3 out of 7 batches
Epoch 22 of 30 took 27.577s
  training loss:		0.328449
  validation loss:		0.010379
  top 1 accuracy:		97.52 %
  top 2 accuracy:		99.43 %
0.32438936829566956
Batch of classes 3 out of 7 batches
Epoch 23 of 30 took 27.251s
  training loss:		0.328253
  validation loss:		0.013706
  top 1 accuracy:		96.37 %
  top 2 accuracy:		99.05 %
0.3363321125507355
Batch of classes 3 out of 7 batches
Epoch 24 of 30 took 28.131s
  training loss:		0.327657
  validation loss:		0.016261
  top 1 accuracy:		96.56 %
  top 2 accuracy:		98.66 %
0.32253992557525635
Batch of classes 3 out of 7 batches
Epoch 25 of 30 took 27.888s
  training loss:		0.326139
  validation loss:		0.008647
  top 1 accuracy:		97.52 %
  top 2 accuracy:		99.81 %
0.32244306802749634
Batch of classes 3 out of 7 batches
Epoch 26 of 30 took 27.285s
  training loss:		0.327115
  validation loss:		0.010931
  top 1 accuracy:		98.09 %
  top 2 accuracy:		99.62 %
0.32369399070739746
Batch of classes 3 out of 7 batches
Epoch 27 of 30 took 27.287s
  training loss:		0.326887
  validation loss:		0.007626
  top 1 accuracy:		98.28 %
  top 2 accuracy:		100.00 %
0.33358266949653625
Batch of classes 3 out of 7 batches
Epoch 28 of 30 took 27.567s
  training loss:		0.327109
  validation loss:		0.009670
  top 1 accuracy:		98.28 %
  top 2 accuracy:		99.81 %
0.3361818194389343
Batch of classes 3 out of 7 batches
Epoch 29 of 30 took 27.454s
  training loss:		0.326713
  validation loss:		0.008732
  top 1 accuracy:		98.09 %
  top 2 accuracy:		99.62 %
0.3258492648601532
Batch of classes 3 out of 7 batches
Epoch 30 of 30 took 27.324s
  training loss:		0.325193
  validation loss:		0.007783
  top 1 accuracy:		98.47 %
  top 2 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(256)
tensor(256)
tensor(256)
tensor(256)
tensor(256)
tensor(256)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		76.65 %
  top 1 accuracy Hybrid 1       :		66.30 %
  top 1 accuracy NCM            :		77.35 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		95.70 %
  top 1 accuracy Hybrid 1       :		94.25 %
  top 1 accuracy NCM            :		95.60 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		71.25 %
  top 1 accuracy Hybrid 1       :		62.00 %
  top 1 accuracy NCM            :		72.00 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		95.75 %
  top 1 accuracy Hybrid 1       :		93.12 %
  top 1 accuracy NCM            :		96.00 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		96.37 %
  top 1 accuracy Hybrid 1       :		98.47 %
  top 1 accuracy NCM            :		96.37 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		98.47 %
  top 1 accuracy Hybrid 1       :		98.66 %
  top 1 accuracy NCM            :		98.66 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		78.46 %
  top 1 accuracy Hybrid 1       :		70.34 %
  top 1 accuracy NCM            :		79.06 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		96.15 %
  top 1 accuracy Hybrid 1       :		94.68 %
  top 1 accuracy NCM            :		96.18 %
Classes in this batch: tensor([6, 7])
Data Size: 7656


Before first epoch
  validation loss:		0.693895
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 4 arrives ...
0.4943684935569763
0.3529076874256134
0.3494148552417755
Batch of classes 4 out of 7 batches
Epoch 1 of 30 took 92.709s
  training loss:		0.362952
  validation loss:		0.013870
  top 1 accuracy:		96.94 %
  top 2 accuracy:		99.18 %
0.3397475779056549
0.33002927899360657
0.3332381546497345
Batch of classes 4 out of 7 batches
Epoch 2 of 30 took 93.329s
  training loss:		0.332796
  validation loss:		0.051080
  top 1 accuracy:		85.19 %
  top 2 accuracy:		93.34 %
0.3313473165035248
0.3296850323677063
0.31699255108833313
Batch of classes 4 out of 7 batches
Epoch 3 of 30 took 113.668s
  training loss:		0.330486
  validation loss:		0.003443
  top 1 accuracy:		99.53 %
  top 2 accuracy:		99.96 %
0.32579439878463745
0.32281431555747986
0.33462825417518616
Batch of classes 4 out of 7 batches
Epoch 4 of 30 took 138.122s
  training loss:		0.328124
  validation loss:		0.001905
  top 1 accuracy:		99.73 %
  top 2 accuracy:		100.00 %
0.3228200376033783
0.3308658003807068
0.32217490673065186
Batch of classes 4 out of 7 batches
Epoch 5 of 30 took 129.569s
  training loss:		0.330377
  validation loss:		0.003392
  top 1 accuracy:		99.61 %
  top 2 accuracy:		100.00 %
0.3208032250404358
0.32600849866867065
0.330998957157135
Batch of classes 4 out of 7 batches
Epoch 6 of 30 took 134.696s
  training loss:		0.326624
  validation loss:		0.005330
  top 1 accuracy:		99.06 %
  top 2 accuracy:		100.00 %
0.33258959650993347
0.33160364627838135
0.33229413628578186
Batch of classes 4 out of 7 batches
Epoch 7 of 30 took 140.528s
  training loss:		0.329685
  validation loss:		0.003785
  top 1 accuracy:		99.61 %
  top 2 accuracy:		99.96 %
0.3237333297729492
0.3350147008895874
0.33919045329093933
Batch of classes 4 out of 7 batches
Epoch 8 of 30 took 127.941s
  training loss:		0.329581
  validation loss:		0.022753
  top 1 accuracy:		96.24 %
  top 2 accuracy:		100.00 %
0.3234293758869171
0.32425183057785034
0.3253471851348877
Batch of classes 4 out of 7 batches
Epoch 9 of 30 took 121.365s
  training loss:		0.330344
  validation loss:		0.002221
  top 1 accuracy:		99.69 %
  top 2 accuracy:		100.00 %
0.32797151803970337
0.3359861671924591
0.33046531677246094
Batch of classes 4 out of 7 batches
Epoch 10 of 30 took 133.121s
  training loss:		0.331670
  validation loss:		0.006120
  top 1 accuracy:		98.71 %
  top 2 accuracy:		99.92 %
0.3302256464958191
0.32749930024147034
0.32609686255455017
Batch of classes 4 out of 7 batches
Epoch 11 of 30 took 141.697s
  training loss:		0.325065
  validation loss:		0.000246
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.32030779123306274
0.3236997723579407
0.32206082344055176
Batch of classes 4 out of 7 batches
Epoch 12 of 30 took 123.051s
  training loss:		0.323969
  validation loss:		0.000130
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.32830196619033813
0.3286004364490509
0.32077062129974365
Batch of classes 4 out of 7 batches
Epoch 13 of 30 took 133.709s
  training loss:		0.325613
  validation loss:		0.000261
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.32804346084594727
0.3293747007846832
0.31947600841522217
Batch of classes 4 out of 7 batches
Epoch 14 of 30 took 97.307s
  training loss:		0.325827
  validation loss:		0.000110
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.32633697986602783
0.32227644324302673
0.3245787024497986
Batch of classes 4 out of 7 batches
Epoch 15 of 30 took 127.060s
  training loss:		0.324563
  validation loss:		0.000043
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.3251969814300537
0.32920050621032715
0.322868674993515
Batch of classes 4 out of 7 batches
Epoch 16 of 30 took 119.378s
  training loss:		0.325037
  validation loss:		0.000301
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.3265973925590515
0.3246183693408966
0.32584646344184875
Batch of classes 4 out of 7 batches
Epoch 17 of 30 took 134.463s
  training loss:		0.325248
  validation loss:		0.000129
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.32406577467918396
0.3224819004535675
0.3238374888896942
Batch of classes 4 out of 7 batches
Epoch 18 of 30 took 133.948s
  training loss:		0.322959
  validation loss:		0.005137
  top 1 accuracy:		98.90 %
  top 2 accuracy:		99.65 %
0.3211241364479065
0.3253607749938965
0.32427969574928284
Batch of classes 4 out of 7 batches
Epoch 19 of 30 took 121.412s
  training loss:		0.325576
  validation loss:		0.000510
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.3257431983947754
0.32296738028526306
0.3250212073326111
Batch of classes 4 out of 7 batches
Epoch 20 of 30 took 142.883s
  training loss:		0.323181
  validation loss:		0.000205
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.3269609212875366
0.32495781779289246
0.3280723989009857
Batch of classes 4 out of 7 batches
Epoch 21 of 30 took 91.040s
  training loss:		0.323752
  validation loss:		0.000141
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.32709261775016785
0.3564550280570984
0.31835198402404785
Batch of classes 4 out of 7 batches
Epoch 22 of 30 took 90.018s
  training loss:		0.323026
  validation loss:		0.000334
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.32378995418548584
0.32344740629196167
0.32367923855781555
Batch of classes 4 out of 7 batches
Epoch 23 of 30 took 88.256s
  training loss:		0.322063
  validation loss:		0.000089
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.3239513635635376
0.32027631998062134
0.32292893528938293
Batch of classes 4 out of 7 batches
Epoch 24 of 30 took 88.573s
  training loss:		0.322489
  validation loss:		0.000070
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.31905773282051086
0.320210725069046
0.32193028926849365
Batch of classes 4 out of 7 batches
Epoch 25 of 30 took 89.285s
  training loss:		0.321996
  validation loss:		0.000069
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.3223901689052582
0.32121217250823975
0.320888489484787
Batch of classes 4 out of 7 batches
Epoch 26 of 30 took 92.218s
  training loss:		0.322176
  validation loss:		0.000074
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.3239070177078247
0.320051372051239
0.3183233141899109
Batch of classes 4 out of 7 batches
Epoch 27 of 30 took 103.660s
  training loss:		0.322167
  validation loss:		0.000072
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.32338371872901917
0.31850674748420715
0.31974032521247864
Batch of classes 4 out of 7 batches
Epoch 28 of 30 took 88.099s
  training loss:		0.321645
  validation loss:		0.000079
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.32052579522132874
0.3229818344116211
0.32254281640052795
Batch of classes 4 out of 7 batches
Epoch 29 of 30 took 88.269s
  training loss:		0.321692
  validation loss:		0.000155
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.3189489245414734
0.32223695516586304
0.3225765824317932
Batch of classes 4 out of 7 batches
Epoch 30 of 30 took 112.995s
  training loss:		0.322384
  validation loss:		0.000064
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		69.40 %
  top 1 accuracy Hybrid 1       :		62.55 %
  top 1 accuracy NCM            :		70.30 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		88.50 %
  top 1 accuracy Hybrid 1       :		85.85 %
  top 1 accuracy NCM            :		88.95 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		72.00 %
  top 1 accuracy Hybrid 1       :		70.00 %
  top 1 accuracy NCM            :		72.12 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		95.12 %
  top 1 accuracy Hybrid 1       :		94.88 %
  top 1 accuracy NCM            :		95.12 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		91.03 %
  top 1 accuracy Hybrid 1       :		91.98 %
  top 1 accuracy NCM            :		91.03 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		95.80 %
  top 1 accuracy Hybrid 1       :		95.42 %
  top 1 accuracy NCM            :		95.61 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		100.00 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		100.00 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		84.97 %
  top 1 accuracy Hybrid 1       :		82.45 %
  top 1 accuracy NCM            :		85.30 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		95.05 %
  top 1 accuracy Hybrid 1       :		94.08 %
  top 1 accuracy NCM            :		95.18 %
Classes in this batch: tensor([8, 9])
Data Size: 3248


Before first epoch
  validation loss:		0.568541
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 5 arrives ...
0.5340230464935303
0.3744718134403229
Batch of classes 5 out of 7 batches
Epoch 1 of 30 took 42.955s
  training loss:		0.393279
  validation loss:		0.095769
  top 1 accuracy:		50.09 %
  top 2 accuracy:		99.91 %
0.3688531816005707
0.3551902174949646
Batch of classes 5 out of 7 batches
Epoch 2 of 30 took 42.188s
  training loss:		0.347905
  validation loss:		0.035697
  top 1 accuracy:		90.57 %
  top 2 accuracy:		99.54 %
0.33391210436820984
0.33351072669029236
Batch of classes 5 out of 7 batches
Epoch 3 of 30 took 42.292s
  training loss:		0.336908
  validation loss:		0.027159
  top 1 accuracy:		93.62 %
  top 2 accuracy:		99.35 %
0.3380802273750305
0.3355090022087097
Batch of classes 5 out of 7 batches
Epoch 4 of 30 took 42.452s
  training loss:		0.335639
  validation loss:		0.024002
  top 1 accuracy:		93.35 %
  top 2 accuracy:		99.26 %
0.32836994528770447
0.3254026472568512
Batch of classes 5 out of 7 batches
Epoch 5 of 30 took 42.234s
  training loss:		0.331640
  validation loss:		0.016534
  top 1 accuracy:		95.93 %
  top 2 accuracy:		99.63 %
0.3396553695201874
0.34539535641670227
Batch of classes 5 out of 7 batches
Epoch 6 of 30 took 42.477s
  training loss:		0.333648
  validation loss:		0.018506
  top 1 accuracy:		94.82 %
  top 2 accuracy:		99.63 %
0.32355719804763794
0.3250981271266937
Batch of classes 5 out of 7 batches
Epoch 7 of 30 took 49.125s
  training loss:		0.331114
  validation loss:		0.028296
  top 1 accuracy:		92.79 %
  top 2 accuracy:		99.45 %
0.33226102590560913
0.3306352198123932
Batch of classes 5 out of 7 batches
Epoch 8 of 30 took 42.471s
  training loss:		0.334299
  validation loss:		0.020305
  top 1 accuracy:		95.10 %
  top 2 accuracy:		98.61 %
0.3248908817768097
0.3404751718044281
Batch of classes 5 out of 7 batches
Epoch 9 of 30 took 42.380s
  training loss:		0.331654
  validation loss:		0.013326
  top 1 accuracy:		96.58 %
  top 2 accuracy:		99.17 %
0.3415934443473816
0.33813905715942383
Batch of classes 5 out of 7 batches
Epoch 10 of 30 took 42.073s
  training loss:		0.330248
  validation loss:		0.013386
  top 1 accuracy:		96.49 %
  top 2 accuracy:		99.17 %
0.3303620517253876
0.32268744707107544
Batch of classes 5 out of 7 batches
Epoch 11 of 30 took 50.015s
  training loss:		0.324321
  validation loss:		0.016142
  top 1 accuracy:		96.40 %
  top 2 accuracy:		99.35 %
0.3200671672821045
0.3171619772911072
Batch of classes 5 out of 7 batches
Epoch 12 of 30 took 53.004s
  training loss:		0.321191
  validation loss:		0.017015
  top 1 accuracy:		96.58 %
  top 2 accuracy:		99.82 %
0.3229350745677948
0.3248576521873474
Batch of classes 5 out of 7 batches
Epoch 13 of 30 took 56.112s
  training loss:		0.320742
  validation loss:		0.014644
  top 1 accuracy:		96.67 %
  top 2 accuracy:		99.72 %
0.31439685821533203
0.3187211751937866
Batch of classes 5 out of 7 batches
Epoch 14 of 30 took 53.600s
  training loss:		0.320266
  validation loss:		0.015313
  top 1 accuracy:		96.40 %
  top 2 accuracy:		99.82 %
0.3238353729248047
0.315844863653183
Batch of classes 5 out of 7 batches
Epoch 15 of 30 took 51.995s
  training loss:		0.322402
  validation loss:		0.014377
  top 1 accuracy:		96.58 %
  top 2 accuracy:		99.26 %
0.31617581844329834
0.3182342052459717
Batch of classes 5 out of 7 batches
Epoch 16 of 30 took 45.605s
  training loss:		0.321924
  validation loss:		0.013307
  top 1 accuracy:		96.67 %
  top 2 accuracy:		99.72 %
0.3237214684486389
0.32315489649772644
Batch of classes 5 out of 7 batches
Epoch 17 of 30 took 42.417s
  training loss:		0.321937
  validation loss:		0.014648
  top 1 accuracy:		96.49 %
  top 2 accuracy:		99.82 %
0.32245948910713196
0.32440921664237976
Batch of classes 5 out of 7 batches
Epoch 18 of 30 took 42.085s
  training loss:		0.322452
  validation loss:		0.013797
  top 1 accuracy:		96.49 %
  top 2 accuracy:		99.35 %
0.32060563564300537
0.3178533613681793
Batch of classes 5 out of 7 batches
Epoch 19 of 30 took 41.900s
  training loss:		0.319321
  validation loss:		0.015893
  top 1 accuracy:		96.40 %
  top 2 accuracy:		99.82 %
0.3154860734939575
0.32605600357055664
Batch of classes 5 out of 7 batches
Epoch 20 of 30 took 41.867s
  training loss:		0.320950
  validation loss:		0.013595
  top 1 accuracy:		96.58 %
  top 2 accuracy:		99.63 %
0.3230297267436981
0.3180954158306122
Batch of classes 5 out of 7 batches
Epoch 21 of 30 took 44.609s
  training loss:		0.322015
  validation loss:		0.014913
  top 1 accuracy:		96.58 %
  top 2 accuracy:		99.63 %
0.32659316062927246
0.324543833732605
Batch of classes 5 out of 7 batches
Epoch 22 of 30 took 41.868s
  training loss:		0.320939
  validation loss:		0.013173
  top 1 accuracy:		96.67 %
  top 2 accuracy:		99.91 %
0.3167676031589508
0.3256976008415222
Batch of classes 5 out of 7 batches
Epoch 23 of 30 took 46.339s
  training loss:		0.320585
  validation loss:		0.014206
  top 1 accuracy:		96.67 %
  top 2 accuracy:		99.63 %
0.32220008969306946
0.3198181092739105
Batch of classes 5 out of 7 batches
Epoch 24 of 30 took 42.168s
  training loss:		0.321324
  validation loss:		0.014383
  top 1 accuracy:		96.58 %
  top 2 accuracy:		99.82 %
0.32367146015167236
0.31943970918655396
Batch of classes 5 out of 7 batches
Epoch 25 of 30 took 41.525s
  training loss:		0.321002
  validation loss:		0.014761
  top 1 accuracy:		96.58 %
  top 2 accuracy:		99.91 %
0.31712397933006287
0.3160468339920044
Batch of classes 5 out of 7 batches
Epoch 26 of 30 took 41.630s
  training loss:		0.320869
  validation loss:		0.013824
  top 1 accuracy:		96.67 %
  top 2 accuracy:		99.91 %
0.3290928304195404
0.3160317838191986
Batch of classes 5 out of 7 batches
Epoch 27 of 30 took 47.179s
  training loss:		0.320509
  validation loss:		0.015870
  top 1 accuracy:		96.67 %
  top 2 accuracy:		99.91 %
0.3167330026626587
0.31745845079421997
Batch of classes 5 out of 7 batches
Epoch 28 of 30 took 43.157s
  training loss:		0.321568
  validation loss:		0.013276
  top 1 accuracy:		96.77 %
  top 2 accuracy:		99.63 %
0.3194693326950073
0.3223395347595215
Batch of classes 5 out of 7 batches
Epoch 29 of 30 took 45.586s
  training loss:		0.320598
  validation loss:		0.014828
  top 1 accuracy:		96.67 %
  top 2 accuracy:		99.82 %
0.3203621208667755
0.32516708970069885
Batch of classes 5 out of 7 batches
Epoch 30 of 30 took 44.938s
  training loss:		0.321506
  validation loss:		0.015862
  top 1 accuracy:		96.58 %
  top 2 accuracy:		99.91 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		64.20 %
  top 1 accuracy Hybrid 1       :		47.90 %
  top 1 accuracy NCM            :		64.70 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		85.90 %
  top 1 accuracy Hybrid 1       :		84.40 %
  top 1 accuracy NCM            :		86.30 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		70.25 %
  top 1 accuracy Hybrid 1       :		76.75 %
  top 1 accuracy NCM            :		71.25 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		91.62 %
  top 1 accuracy Hybrid 1       :		87.75 %
  top 1 accuracy NCM            :		91.50 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		88.36 %
  top 1 accuracy Hybrid 1       :		86.83 %
  top 1 accuracy NCM            :		87.98 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		93.70 %
  top 1 accuracy Hybrid 1       :		91.98 %
  top 1 accuracy NCM            :		93.32 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.73 %
  top 1 accuracy Hybrid 1       :		99.88 %
  top 1 accuracy NCM            :		99.65 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.96 %
  top 1 accuracy Hybrid 1       :		99.96 %
  top 1 accuracy NCM            :		99.96 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		96.58 %
  top 1 accuracy Hybrid 1       :		96.58 %
  top 1 accuracy NCM            :		96.77 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		96.58 %
  top 1 accuracy Hybrid 1       :		96.58 %
  top 1 accuracy NCM            :		96.77 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		84.78 %
  top 1 accuracy Hybrid 1       :		80.78 %
  top 1 accuracy NCM            :		85.01 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		93.96 %
  top 1 accuracy Hybrid 1       :		92.96 %
  top 1 accuracy NCM            :		94.06 %
Classes in this batch: tensor([10, 11])
Data Size: 7658


Before first epoch
  validation loss:		1.827027
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 6 arrives ...
Traceback (most recent call last):
  File "main_icarl_CNND.py", line 579, in <module>
    main()
  File "main_icarl_CNND.py", line 324, in main
    for patterns, labels in train_loader:  # Line 151
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 352, in __iter__
    return self._get_iterator()
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 294, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 801, in __init__
    w.start()
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/popen_fork.py", line 70, in _launch
    self.pid = os.fork()
OSError: [Errno 12] Cannot allocate memory
----------------- Options ---------------
               add_binary: True                          	[default: False]
               batch_size: 32                            	[default: 64]
                   binary: False                         
              binary_loss: sum_b_log                     	[default: sum_b_sig]
            binary_weight: 0.8                           	[default: 0.5]
                blur_prob: 0                             
                 blur_sig: 0.5                           
          checkpoints_dir: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL/checkpoints	[default: ./checkpoints]
                class_bal: False                         
           continue_train: False                         
                 cropSize: 224                           
                 data_aug: False                         
                 dataroot: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/test	[default: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL]
          earlystop_epoch: 5                             
                    epoch: latest                        
                 fine_tun: False                         
                    gpuid: [1]                           
                init_gain: 0.02                          
                  init_lr: 0.0005                        
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2                           
                 jpg_prob: 0                             
                 jpg_qual: 75                            
          label_smoothing: False                         
                 loadSize: 256                           
                    mixup: False                         
              mixup_alpha: 0.1                           
                     mode: binary                        
               model_name: resnet18                      
               model_type: resnet                        
            model_weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth	[default: None]
               multiclass: [0, 0, 1, 0, 0, 0, 0]         	[default: [1]]
                     name: MT_7_bm_sum_b_log08_15        	[default: experiment_name]
                  no_flip: False                         
              num_classes: 2                             
               num_epochs: 30                            	[default: 12]
              num_threads: 4                             
                  outfile: temp_0.1.csv                  
            pretrain_name:                               
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 20                            
         save_latest_freq: 2000                          
                 schedule: [10, 20, 30]                  	[default: [10]]
           serial_batches: False                         
          smoothing_alpha: 0.1                           
                   suffix:                               
                task_name: gaugan,biggan,cyclegan,imle,deepfake,crn,wild	[default: ]
              train_split: train                         
                val_split: val                           
----------------- End -------------------
{'All': 14}
Task order: ['gaugan', 'biggan', 'cyclegan', 'imle', 'deepfake', 'crn', 'wild']
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Classes in this batch: tensor([0, 1])
Data Size: 6000


Before first epoch
  validation loss:		1.313428
  top 1 accuracy:		17.25 %
  top 2 accuracy:		17.25 %
Batch of classes number 1 arrives ...
0.6513901948928833
0.4101979732513428
Batch of classes 1 out of 7 batches
Epoch 1 of 30 took 102.046s
  training loss:		0.419893
  validation loss:		0.059963
  top 1 accuracy:		82.15 %
  top 2 accuracy:		100.00 %
0.41160374879837036
0.3994223475456238
Batch of classes 1 out of 7 batches
Epoch 2 of 30 took 71.795s
  training loss:		0.399383
  validation loss:		0.156979
  top 1 accuracy:		66.65 %
  top 2 accuracy:		100.00 %
0.40051889419555664
0.39287644624710083
Batch of classes 1 out of 7 batches
Epoch 3 of 30 took 67.259s
  training loss:		0.396112
  validation loss:		0.031038
  top 1 accuracy:		92.00 %
  top 2 accuracy:		100.00 %
0.39138633012771606
0.3888607919216156
Batch of classes 1 out of 7 batches
Epoch 4 of 30 took 52.671s
  training loss:		0.392844
  validation loss:		0.022990
  top 1 accuracy:		94.15 %
  top 2 accuracy:		100.00 %
0.3901998698711395
0.3885454833507538
Batch of classes 1 out of 7 batches
Epoch 5 of 30 took 51.055s
  training loss:		0.391351
  validation loss:		0.040986
  top 1 accuracy:		88.15 %
  top 2 accuracy:		100.00 %
0.38678857684135437
0.3908308446407318
Batch of classes 1 out of 7 batches
Epoch 6 of 30 took 50.338s
  training loss:		0.389654
  validation loss:		0.016220
  top 1 accuracy:		95.80 %
  top 2 accuracy:		100.00 %
0.38234493136405945
0.38515377044677734
Batch of classes 1 out of 7 batches
Epoch 7 of 30 took 50.464s
  training loss:		0.387989
  validation loss:		0.023024
  top 1 accuracy:		94.35 %
  top 2 accuracy:		100.00 %
0.391981840133667
0.39050769805908203
Batch of classes 1 out of 7 batches
Epoch 8 of 30 took 57.187s
  training loss:		0.387746
  validation loss:		0.022523
  top 1 accuracy:		93.65 %
  top 2 accuracy:		100.00 %
0.39304524660110474
0.38119974732398987
Batch of classes 1 out of 7 batches
Epoch 9 of 30 took 53.186s
  training loss:		0.386711
  validation loss:		0.019501
  top 1 accuracy:		94.55 %
  top 2 accuracy:		100.00 %
0.39257198572158813
0.38740164041519165
Batch of classes 1 out of 7 batches
Epoch 10 of 30 took 50.511s
  training loss:		0.385905
  validation loss:		0.021377
  top 1 accuracy:		94.60 %
  top 2 accuracy:		100.00 %
0.3846360743045807
0.38082683086395264
Batch of classes 1 out of 7 batches
Epoch 11 of 30 took 50.699s
  training loss:		0.383413
  validation loss:		0.009298
  top 1 accuracy:		97.70 %
  top 2 accuracy:		100.00 %
0.3850056827068329
0.38033977150917053
Batch of classes 1 out of 7 batches
Epoch 12 of 30 took 51.565s
  training loss:		0.379817
  validation loss:		0.005524
  top 1 accuracy:		99.00 %
  top 2 accuracy:		100.00 %
0.3872378170490265
0.3769197165966034
Batch of classes 1 out of 7 batches
Epoch 13 of 30 took 52.246s
  training loss:		0.378326
  validation loss:		0.009074
  top 1 accuracy:		97.25 %
  top 2 accuracy:		100.00 %
0.38023996353149414
0.3735002875328064
Batch of classes 1 out of 7 batches
Epoch 14 of 30 took 63.824s
  training loss:		0.376044
  validation loss:		0.007985
  top 1 accuracy:		97.80 %
  top 2 accuracy:		100.00 %
0.37775206565856934
0.37411394715309143
Batch of classes 1 out of 7 batches
Epoch 15 of 30 took 60.305s
  training loss:		0.376571
  validation loss:		0.007020
  top 1 accuracy:		98.40 %
  top 2 accuracy:		100.00 %
0.3837725520133972
0.3755754828453064
Batch of classes 1 out of 7 batches
Epoch 16 of 30 took 51.258s
  training loss:		0.375462
  validation loss:		0.008823
  top 1 accuracy:		97.65 %
  top 2 accuracy:		100.00 %
0.37350526452064514
0.3723427653312683
Batch of classes 1 out of 7 batches
Epoch 17 of 30 took 50.438s
  training loss:		0.374464
  validation loss:		0.007947
  top 1 accuracy:		97.90 %
  top 2 accuracy:		100.00 %
0.37083718180656433
0.37236183881759644
Batch of classes 1 out of 7 batches
Epoch 18 of 30 took 51.462s
  training loss:		0.373906
  validation loss:		0.004343
  top 1 accuracy:		98.75 %
  top 2 accuracy:		100.00 %
0.37154462933540344
0.3722224831581116
Batch of classes 1 out of 7 batches
Epoch 19 of 30 took 53.479s
  training loss:		0.373695
  validation loss:		0.005508
  top 1 accuracy:		98.70 %
  top 2 accuracy:		100.00 %
0.3725854754447937
0.3818536698818207
Batch of classes 1 out of 7 batches
Epoch 20 of 30 took 54.799s
  training loss:		0.374674
  validation loss:		0.009877
  top 1 accuracy:		97.10 %
  top 2 accuracy:		100.00 %
0.3759974539279938
0.37671029567718506
Batch of classes 1 out of 7 batches
Epoch 21 of 30 took 57.780s
  training loss:		0.372702
  validation loss:		0.005008
  top 1 accuracy:		99.10 %
  top 2 accuracy:		100.00 %
0.36990880966186523
0.37018704414367676
Batch of classes 1 out of 7 batches
Epoch 22 of 30 took 58.609s
  training loss:		0.371155
  validation loss:		0.003760
  top 1 accuracy:		99.20 %
  top 2 accuracy:		100.00 %
0.3709823489189148
0.3809017837047577
Batch of classes 1 out of 7 batches
Epoch 23 of 30 took 50.301s
  training loss:		0.371308
  validation loss:		0.004887
  top 1 accuracy:		99.00 %
  top 2 accuracy:		100.00 %
0.36911413073539734
0.36881235241889954
Batch of classes 1 out of 7 batches
Epoch 24 of 30 took 53.006s
  training loss:		0.369425
  validation loss:		0.003462
  top 1 accuracy:		99.40 %
  top 2 accuracy:		100.00 %
0.37021222710609436
0.36920371651649475
Batch of classes 1 out of 7 batches
Epoch 25 of 30 took 50.602s
  training loss:		0.369165
  validation loss:		0.005600
  top 1 accuracy:		98.55 %
  top 2 accuracy:		100.00 %
0.3708184063434601
0.371921181678772
Batch of classes 1 out of 7 batches
Epoch 26 of 30 took 49.906s
  training loss:		0.371698
  validation loss:		0.002831
  top 1 accuracy:		99.25 %
  top 2 accuracy:		100.00 %
0.3726389408111572
0.36943894624710083
Batch of classes 1 out of 7 batches
Epoch 27 of 30 took 51.198s
  training loss:		0.370271
  validation loss:		0.002887
  top 1 accuracy:		99.25 %
  top 2 accuracy:		100.00 %
0.3694215714931488
0.3679349422454834
Batch of classes 1 out of 7 batches
Epoch 28 of 30 took 52.158s
  training loss:		0.368663
  validation loss:		0.002323
  top 1 accuracy:		99.35 %
  top 2 accuracy:		100.00 %
0.3671755790710449
0.37245795130729675
Batch of classes 1 out of 7 batches
Epoch 29 of 30 took 56.327s
  training loss:		0.370877
  validation loss:		0.002733
  top 1 accuracy:		99.40 %
  top 2 accuracy:		100.00 %
0.37039175629615784
0.372267484664917
Batch of classes 1 out of 7 batches
Epoch 30 of 30 took 57.645s
  training loss:		0.369552
  validation loss:		0.002757
  top 1 accuracy:		99.15 %
  top 2 accuracy:		100.00 %
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(500)
tensor(500)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		99.20 %
  top 1 accuracy Hybrid 1       :		99.15 %
  top 1 accuracy NCM            :		99.20 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		99.20 %
  top 1 accuracy Hybrid 1       :		99.15 %
  top 1 accuracy NCM            :		99.20 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		99.20 %
  top 1 accuracy Hybrid 1       :		99.15 %
  top 1 accuracy NCM            :		99.20 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		99.20 %
  top 1 accuracy Hybrid 1       :		99.15 %
  top 1 accuracy NCM            :		99.20 %
Classes in this batch: tensor([2, 3])
Data Size: 2400


Before first epoch
  validation loss:		1.109465
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.63 %
Batch of classes number 2 arrives ...
0.534744381904602
0.41068169474601746
Batch of classes 2 out of 7 batches
Epoch 1 of 30 took 47.903s
  training loss:		0.428144
  validation loss:		0.126387
  top 1 accuracy:		53.12 %
  top 2 accuracy:		94.38 %
0.4087994694709778
0.40592026710510254
Batch of classes 2 out of 7 batches
Epoch 2 of 30 took 31.668s
  training loss:		0.408925
  validation loss:		0.068104
  top 1 accuracy:		82.25 %
  top 2 accuracy:		96.63 %
0.40185678005218506
0.3962962031364441
Batch of classes 2 out of 7 batches
Epoch 3 of 30 took 31.587s
  training loss:		0.402008
  validation loss:		0.090310
  top 1 accuracy:		75.75 %
  top 2 accuracy:		97.75 %
0.40091925859451294
0.39987730979919434
Batch of classes 2 out of 7 batches
Epoch 4 of 30 took 30.678s
  training loss:		0.399176
  validation loss:		0.043708
  top 1 accuracy:		90.38 %
  top 2 accuracy:		99.50 %
0.3901447057723999
0.4032832682132721
Batch of classes 2 out of 7 batches
Epoch 5 of 30 took 31.206s
  training loss:		0.394769
  validation loss:		0.034541
  top 1 accuracy:		91.75 %
  top 2 accuracy:		99.00 %
0.3920014202594757
0.3975377678871155
Batch of classes 2 out of 7 batches
Epoch 6 of 30 took 31.279s
  training loss:		0.395174
  validation loss:		0.111115
  top 1 accuracy:		68.25 %
  top 2 accuracy:		89.88 %
0.39756113290786743
0.38446757197380066
Batch of classes 2 out of 7 batches
Epoch 7 of 30 took 30.979s
  training loss:		0.392951
  validation loss:		0.078094
  top 1 accuracy:		76.75 %
  top 2 accuracy:		96.75 %
0.3859627842903137
0.3852415680885315
Batch of classes 2 out of 7 batches
Epoch 8 of 30 took 31.967s
  training loss:		0.389869
  validation loss:		0.072422
  top 1 accuracy:		78.12 %
  top 2 accuracy:		93.12 %
0.3927827477455139
0.39122381806373596
Batch of classes 2 out of 7 batches
Epoch 9 of 30 took 31.181s
  training loss:		0.389872
  validation loss:		0.041043
  top 1 accuracy:		90.00 %
  top 2 accuracy:		98.25 %
0.3851020336151123
0.3895741403102875
Batch of classes 2 out of 7 batches
Epoch 10 of 30 took 30.990s
  training loss:		0.390292
  validation loss:		0.039724
  top 1 accuracy:		90.38 %
  top 2 accuracy:		98.50 %
0.38777220249176025
0.38256925344467163
Batch of classes 2 out of 7 batches
Epoch 11 of 30 took 30.919s
  training loss:		0.384414
  validation loss:		0.028422
  top 1 accuracy:		92.37 %
  top 2 accuracy:		98.87 %
0.379999577999115
0.38401591777801514
Batch of classes 2 out of 7 batches
Epoch 12 of 30 took 31.014s
  training loss:		0.380816
  validation loss:		0.025882
  top 1 accuracy:		94.50 %
  top 2 accuracy:		99.75 %
0.3771621286869049
0.37543678283691406
Batch of classes 2 out of 7 batches
Epoch 13 of 30 took 31.399s
  training loss:		0.379803
  validation loss:		0.038472
  top 1 accuracy:		90.62 %
  top 2 accuracy:		97.75 %
0.37565022706985474
0.3751479685306549
Batch of classes 2 out of 7 batches
Epoch 14 of 30 took 35.062s
  training loss:		0.377965
  validation loss:		0.020447
  top 1 accuracy:		94.88 %
  top 2 accuracy:		99.62 %
0.37440159916877747
0.37320858240127563
Batch of classes 2 out of 7 batches
Epoch 15 of 30 took 31.316s
  training loss:		0.377252
  validation loss:		0.022887
  top 1 accuracy:		94.25 %
  top 2 accuracy:		99.50 %
0.3713943064212799
0.37462735176086426
Batch of classes 2 out of 7 batches
Epoch 16 of 30 took 30.816s
  training loss:		0.377157
  validation loss:		0.020102
  top 1 accuracy:		94.00 %
  top 2 accuracy:		99.75 %
0.377610445022583
0.376422256231308
Batch of classes 2 out of 7 batches
Epoch 17 of 30 took 31.045s
  training loss:		0.378389
  validation loss:		0.020612
  top 1 accuracy:		94.75 %
  top 2 accuracy:		99.25 %
0.3891102075576782
0.3784175217151642
Batch of classes 2 out of 7 batches
Epoch 18 of 30 took 31.760s
  training loss:		0.379094
  validation loss:		0.021487
  top 1 accuracy:		94.75 %
  top 2 accuracy:		98.75 %
0.3803108036518097
0.37734952569007874
Batch of classes 2 out of 7 batches
Epoch 19 of 30 took 31.494s
  training loss:		0.375845
  validation loss:		0.021080
  top 1 accuracy:		94.63 %
  top 2 accuracy:		99.12 %
0.3740162253379822
0.3810056746006012
Batch of classes 2 out of 7 batches
Epoch 20 of 30 took 31.450s
  training loss:		0.375745
  validation loss:		0.032648
  top 1 accuracy:		92.25 %
  top 2 accuracy:		99.25 %
0.3705246150493622
0.37349221110343933
Batch of classes 2 out of 7 batches
Epoch 21 of 30 took 31.854s
  training loss:		0.374934
  validation loss:		0.009855
  top 1 accuracy:		97.37 %
  top 2 accuracy:		99.62 %
0.37556442618370056
0.3758385479450226
Batch of classes 2 out of 7 batches
Epoch 22 of 30 took 31.486s
  training loss:		0.374146
  validation loss:		0.011640
  top 1 accuracy:		97.62 %
  top 2 accuracy:		99.37 %
0.37892791628837585
0.3728539049625397
Batch of classes 2 out of 7 batches
Epoch 23 of 30 took 31.073s
  training loss:		0.373573
  validation loss:		0.011544
  top 1 accuracy:		97.75 %
  top 2 accuracy:		99.50 %
0.3714887797832489
0.37385547161102295
Batch of classes 2 out of 7 batches
Epoch 24 of 30 took 30.969s
  training loss:		0.374070
  validation loss:		0.014229
  top 1 accuracy:		97.00 %
  top 2 accuracy:		99.62 %
0.37264248728752136
0.37031090259552
Batch of classes 2 out of 7 batches
Epoch 25 of 30 took 31.069s
  training loss:		0.373756
  validation loss:		0.010890
  top 1 accuracy:		97.12 %
  top 2 accuracy:		99.62 %
0.3715914487838745
0.37396225333213806
Batch of classes 2 out of 7 batches
Epoch 26 of 30 took 31.268s
  training loss:		0.374311
  validation loss:		0.009217
  top 1 accuracy:		98.12 %
  top 2 accuracy:		99.75 %
0.3749031126499176
0.3795146942138672
Batch of classes 2 out of 7 batches
Epoch 27 of 30 took 31.514s
  training loss:		0.374428
  validation loss:		0.011768
  top 1 accuracy:		97.00 %
  top 2 accuracy:		99.25 %
0.37083980441093445
0.36971157789230347
Batch of classes 2 out of 7 batches
Epoch 28 of 30 took 31.506s
  training loss:		0.373368
  validation loss:		0.018724
  top 1 accuracy:		96.13 %
  top 2 accuracy:		98.62 %
0.37243250012397766
0.3719114363193512
Batch of classes 2 out of 7 batches
Epoch 29 of 30 took 31.083s
  training loss:		0.373113
  validation loss:		0.011880
  top 1 accuracy:		97.75 %
  top 2 accuracy:		99.50 %
0.37243205308914185
0.3743366003036499
Batch of classes 2 out of 7 batches
Epoch 30 of 30 took 30.464s
  training loss:		0.372641
  validation loss:		0.012343
  top 1 accuracy:		98.00 %
  top 2 accuracy:		99.37 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(384)
tensor(384)
tensor(384)
tensor(384)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		73.45 %
  top 1 accuracy Hybrid 1       :		49.10 %
  top 1 accuracy NCM            :		75.50 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		96.40 %
  top 1 accuracy Hybrid 1       :		94.80 %
  top 1 accuracy NCM            :		96.25 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		91.62 %
  top 1 accuracy Hybrid 1       :		98.00 %
  top 1 accuracy NCM            :		88.75 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		99.00 %
  top 1 accuracy Hybrid 1       :		98.50 %
  top 1 accuracy NCM            :		99.00 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		78.64 %
  top 1 accuracy Hybrid 1       :		63.07 %
  top 1 accuracy NCM            :		79.29 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		97.14 %
  top 1 accuracy Hybrid 1       :		95.86 %
  top 1 accuracy NCM            :		97.04 %
Classes in this batch: tensor([4, 5])
Data Size: 1572


Before first epoch
  validation loss:		0.833993
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 3 arrives ...
0.4675390422344208
Batch of classes 3 out of 7 batches
Epoch 1 of 30 took 30.181s
  training loss:		0.422771
  validation loss:		0.122190
  top 1 accuracy:		53.24 %
  top 2 accuracy:		94.47 %
0.40303632616996765
Batch of classes 3 out of 7 batches
Epoch 2 of 30 took 27.370s
  training loss:		0.408225
  validation loss:		0.098739
  top 1 accuracy:		75.57 %
  top 2 accuracy:		98.66 %
0.40252721309661865
Batch of classes 3 out of 7 batches
Epoch 3 of 30 took 27.326s
  training loss:		0.397617
  validation loss:		0.054056
  top 1 accuracy:		86.45 %
  top 2 accuracy:		95.23 %
0.3874979615211487
Batch of classes 3 out of 7 batches
Epoch 4 of 30 took 27.254s
  training loss:		0.391198
  validation loss:		0.064602
  top 1 accuracy:		83.97 %
  top 2 accuracy:		93.32 %
0.3920677602291107
Batch of classes 3 out of 7 batches
Epoch 5 of 30 took 26.754s
  training loss:		0.389137
  validation loss:		0.043906
  top 1 accuracy:		89.12 %
  top 2 accuracy:		96.76 %
0.388229101896286
Batch of classes 3 out of 7 batches
Epoch 6 of 30 took 27.159s
  training loss:		0.385425
  validation loss:		0.020476
  top 1 accuracy:		94.66 %
  top 2 accuracy:		99.43 %
0.3738695979118347
Batch of classes 3 out of 7 batches
Epoch 7 of 30 took 26.943s
  training loss:		0.385297
  validation loss:		0.023277
  top 1 accuracy:		94.08 %
  top 2 accuracy:		99.43 %
0.3748818337917328
Batch of classes 3 out of 7 batches
Epoch 8 of 30 took 27.106s
  training loss:		0.385037
  validation loss:		0.059006
  top 1 accuracy:		85.50 %
  top 2 accuracy:		95.42 %
0.378785640001297
Batch of classes 3 out of 7 batches
Epoch 9 of 30 took 27.389s
  training loss:		0.383306
  validation loss:		0.038340
  top 1 accuracy:		90.08 %
  top 2 accuracy:		97.14 %
0.38749709725379944
Batch of classes 3 out of 7 batches
Epoch 10 of 30 took 27.355s
  training loss:		0.385676
  validation loss:		0.038513
  top 1 accuracy:		88.55 %
  top 2 accuracy:		97.52 %
0.37522807717323303
Batch of classes 3 out of 7 batches
Epoch 11 of 30 took 27.696s
  training loss:		0.377660
  validation loss:		0.016760
  top 1 accuracy:		95.80 %
  top 2 accuracy:		99.62 %
0.37280771136283875
Batch of classes 3 out of 7 batches
Epoch 12 of 30 took 27.179s
  training loss:		0.376009
  validation loss:		0.015247
  top 1 accuracy:		96.37 %
  top 2 accuracy:		99.24 %
0.38617533445358276
Batch of classes 3 out of 7 batches
Epoch 13 of 30 took 26.214s
  training loss:		0.374712
  validation loss:		0.018011
  top 1 accuracy:		94.66 %
  top 2 accuracy:		98.85 %
0.3757804334163666
Batch of classes 3 out of 7 batches
Epoch 14 of 30 took 27.235s
  training loss:		0.375174
  validation loss:		0.012963
  top 1 accuracy:		96.95 %
  top 2 accuracy:		99.62 %
0.3712322413921356
Batch of classes 3 out of 7 batches
Epoch 15 of 30 took 27.024s
  training loss:		0.375120
  validation loss:		0.011000
  top 1 accuracy:		97.52 %
  top 2 accuracy:		99.62 %
0.3782751262187958
Batch of classes 3 out of 7 batches
Epoch 16 of 30 took 28.725s
  training loss:		0.372856
  validation loss:		0.021596
  top 1 accuracy:		94.47 %
  top 2 accuracy:		99.62 %
0.38474398851394653
Batch of classes 3 out of 7 batches
Epoch 17 of 30 took 29.840s
  training loss:		0.374210
  validation loss:		0.013580
  top 1 accuracy:		97.14 %
  top 2 accuracy:		99.62 %
0.3783175051212311
Batch of classes 3 out of 7 batches
Epoch 18 of 30 took 27.328s
  training loss:		0.375212
  validation loss:		0.013536
  top 1 accuracy:		96.37 %
  top 2 accuracy:		99.05 %
0.372966468334198
Batch of classes 3 out of 7 batches
Epoch 19 of 30 took 27.168s
  training loss:		0.372194
  validation loss:		0.008177
  top 1 accuracy:		98.28 %
  top 2 accuracy:		99.81 %
0.37582117319107056
Batch of classes 3 out of 7 batches
Epoch 20 of 30 took 27.148s
  training loss:		0.370540
  validation loss:		0.017660
  top 1 accuracy:		95.61 %
  top 2 accuracy:		99.24 %
0.3813462257385254
Batch of classes 3 out of 7 batches
Epoch 21 of 30 took 27.323s
  training loss:		0.371508
  validation loss:		0.008890
  top 1 accuracy:		97.90 %
  top 2 accuracy:		99.43 %
0.3695814609527588
Batch of classes 3 out of 7 batches
Epoch 22 of 30 took 27.319s
  training loss:		0.372045
  validation loss:		0.009019
  top 1 accuracy:		98.28 %
  top 2 accuracy:		99.81 %
0.3681565523147583
Batch of classes 3 out of 7 batches
Epoch 23 of 30 took 27.479s
  training loss:		0.370450
  validation loss:		0.014008
  top 1 accuracy:		96.56 %
  top 2 accuracy:		99.62 %
0.36895662546157837
Batch of classes 3 out of 7 batches
Epoch 24 of 30 took 27.466s
  training loss:		0.368294
  validation loss:		0.008783
  top 1 accuracy:		98.09 %
  top 2 accuracy:		100.00 %
0.3717794716358185
Batch of classes 3 out of 7 batches
Epoch 25 of 30 took 28.765s
  training loss:		0.369476
  validation loss:		0.008412
  top 1 accuracy:		98.09 %
  top 2 accuracy:		99.62 %
0.3703271448612213
Batch of classes 3 out of 7 batches
Epoch 26 of 30 took 27.253s
  training loss:		0.371619
  validation loss:		0.011863
  top 1 accuracy:		97.14 %
  top 2 accuracy:		99.43 %
0.36910369992256165
Batch of classes 3 out of 7 batches
Epoch 27 of 30 took 26.656s
  training loss:		0.369914
  validation loss:		0.008463
  top 1 accuracy:		98.09 %
  top 2 accuracy:		99.81 %
0.3722701966762543
Batch of classes 3 out of 7 batches
Epoch 28 of 30 took 27.257s
  training loss:		0.370360
  validation loss:		0.007887
  top 1 accuracy:		98.28 %
  top 2 accuracy:		99.81 %
0.3748873770236969
Batch of classes 3 out of 7 batches
Epoch 29 of 30 took 27.153s
  training loss:		0.370878
  validation loss:		0.009324
  top 1 accuracy:		97.90 %
  top 2 accuracy:		100.00 %
0.36944279074668884
Batch of classes 3 out of 7 batches
Epoch 30 of 30 took 27.777s
  training loss:		0.369605
  validation loss:		0.009245
  top 1 accuracy:		98.09 %
  top 2 accuracy:		99.81 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(256)
tensor(256)
tensor(256)
tensor(256)
tensor(256)
tensor(256)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		76.60 %
  top 1 accuracy Hybrid 1       :		66.35 %
  top 1 accuracy NCM            :		77.60 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		95.95 %
  top 1 accuracy Hybrid 1       :		94.95 %
  top 1 accuracy NCM            :		96.10 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		76.25 %
  top 1 accuracy Hybrid 1       :		74.88 %
  top 1 accuracy NCM            :		75.62 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		96.25 %
  top 1 accuracy Hybrid 1       :		94.88 %
  top 1 accuracy NCM            :		96.38 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		97.14 %
  top 1 accuracy Hybrid 1       :		98.09 %
  top 1 accuracy NCM            :		97.14 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		98.47 %
  top 1 accuracy Hybrid 1       :		98.66 %
  top 1 accuracy NCM            :		98.47 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		79.75 %
  top 1 accuracy Hybrid 1       :		73.41 %
  top 1 accuracy NCM            :		80.20 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		96.42 %
  top 1 accuracy Hybrid 1       :		95.52 %
  top 1 accuracy NCM            :		96.54 %
Classes in this batch: tensor([6, 7])
Data Size: 7656


Before first epoch
  validation loss:		0.816400
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 4 arrives ...
0.4974798560142517
0.41707026958465576
0.3917379677295685
Batch of classes 4 out of 7 batches
Epoch 1 of 30 took 89.424s
  training loss:		0.408488
  validation loss:		0.030634
  top 1 accuracy:		91.58 %
  top 2 accuracy:		97.84 %
0.39410945773124695
0.3742945194244385
0.38449960947036743
Batch of classes 4 out of 7 batches
Epoch 2 of 30 took 88.400s
  training loss:		0.383902
  validation loss:		0.011762
  top 1 accuracy:		98.16 %
  top 2 accuracy:		99.02 %
0.3805987238883972
0.3805251121520996
0.3669694662094116
Batch of classes 4 out of 7 batches
Epoch 3 of 30 took 91.717s
  training loss:		0.379612
  validation loss:		0.005476
  top 1 accuracy:		99.10 %
  top 2 accuracy:		100.00 %
0.37845128774642944
0.370292067527771
0.3695216774940491
Batch of classes 4 out of 7 batches
Epoch 4 of 30 took 112.039s
  training loss:		0.376641
  validation loss:		0.004939
  top 1 accuracy:		99.29 %
  top 2 accuracy:		99.92 %
0.37853652238845825
0.37650617957115173
0.3757842183113098
Batch of classes 4 out of 7 batches
Epoch 5 of 30 took 121.926s
  training loss:		0.379186
  validation loss:		0.003448
  top 1 accuracy:		99.53 %
  top 2 accuracy:		99.80 %
0.37698251008987427
0.3710012137889862
0.37004658579826355
Batch of classes 4 out of 7 batches
Epoch 6 of 30 took 91.234s
  training loss:		0.377415
  validation loss:		0.000885
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.37799015641212463
0.3685164451599121
0.3768196403980255
Batch of classes 4 out of 7 batches
Epoch 7 of 30 took 140.757s
  training loss:		0.375306
  validation loss:		0.001262
  top 1 accuracy:		99.84 %
  top 2 accuracy:		100.00 %
0.37471795082092285
0.3840278685092926
0.3746625781059265
Batch of classes 4 out of 7 batches
Epoch 8 of 30 took 175.607s
  training loss:		0.375607
  validation loss:		0.013554
  top 1 accuracy:		96.75 %
  top 2 accuracy:		98.86 %
0.3834095001220703
0.3762114644050598
0.3724335730075836
Batch of classes 4 out of 7 batches
Epoch 9 of 30 took 206.991s
  training loss:		0.376272
  validation loss:		0.004774
  top 1 accuracy:		99.26 %
  top 2 accuracy:		99.76 %
0.3723374605178833
0.3809109330177307
0.36690235137939453
Batch of classes 4 out of 7 batches
Epoch 10 of 30 took 171.339s
  training loss:		0.376414
  validation loss:		0.004138
  top 1 accuracy:		99.02 %
  top 2 accuracy:		99.65 %
0.3723190128803253
0.37085360288619995
0.3691498637199402
Batch of classes 4 out of 7 batches
Epoch 11 of 30 took 181.918s
  training loss:		0.373216
  validation loss:		0.000398
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.3700394928455353
0.36470484733581543
0.3653813898563385
Batch of classes 4 out of 7 batches
Epoch 12 of 30 took 195.642s
  training loss:		0.369547
  validation loss:		0.000149
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.3681190609931946
0.3677327334880829
0.3708111047744751
Batch of classes 4 out of 7 batches
Epoch 13 of 30 took 141.777s
  training loss:		0.369141
  validation loss:		0.001079
  top 1 accuracy:		99.88 %
  top 2 accuracy:		100.00 %
0.36794987320899963
0.37033724784851074
0.37309500575065613
Batch of classes 4 out of 7 batches
Epoch 14 of 30 took 151.397s
  training loss:		0.369462
  validation loss:		0.000320
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.37321433424949646
0.3711813688278198
0.37066009640693665
Batch of classes 4 out of 7 batches
Epoch 15 of 30 took 191.670s
  training loss:		0.370599
  validation loss:		0.000342
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.3681621849536896
0.37509700655937195
0.3723748028278351
Batch of classes 4 out of 7 batches
Epoch 16 of 30 took 203.967s
  training loss:		0.369555
  validation loss:		0.000253
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.37176406383514404
0.3639466464519501
0.368361234664917
Batch of classes 4 out of 7 batches
Epoch 17 of 30 took 196.066s
  training loss:		0.371125
  validation loss:		0.000626
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.36880749464035034
0.36800485849380493
0.36860862374305725
Batch of classes 4 out of 7 batches
Epoch 18 of 30 took 198.291s
  training loss:		0.370864
  validation loss:		0.000128
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.36721450090408325
0.37094244360923767
0.3651592433452606
Batch of classes 4 out of 7 batches
Epoch 19 of 30 took 202.053s
  training loss:		0.370068
  validation loss:		0.000285
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.3698287308216095
0.37248843908309937
0.37450313568115234
Batch of classes 4 out of 7 batches
Epoch 20 of 30 took 193.274s
  training loss:		0.372360
  validation loss:		0.000279
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.37431129813194275
0.37095093727111816
0.3705425560474396
Batch of classes 4 out of 7 batches
Epoch 21 of 30 took 185.799s
  training loss:		0.370941
  validation loss:		0.000140
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.36707374453544617
0.3720005750656128
0.3682529330253601
Batch of classes 4 out of 7 batches
Epoch 22 of 30 took 176.613s
  training loss:		0.368775
  validation loss:		0.000325
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.36829179525375366
0.3739489018917084
0.37193363904953003
Batch of classes 4 out of 7 batches
Epoch 23 of 30 took 185.413s
  training loss:		0.370208
  validation loss:		0.000147
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.3647352457046509
0.3627319633960724
0.36737072467803955
Batch of classes 4 out of 7 batches
Epoch 24 of 30 took 178.056s
  training loss:		0.369605
  validation loss:		0.000118
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.3716336488723755
0.3673781752586365
0.3681252598762512
Batch of classes 4 out of 7 batches
Epoch 25 of 30 took 173.460s
  training loss:		0.368155
  validation loss:		0.000102
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.3640991151332855
0.3657319247722626
0.36804482340812683
Batch of classes 4 out of 7 batches
Epoch 26 of 30 took 192.702s
  training loss:		0.368508
  validation loss:		0.000105
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.36610713601112366
0.3711833357810974
0.3687763512134552
Batch of classes 4 out of 7 batches
Epoch 27 of 30 took 179.877s
  training loss:		0.368454
  validation loss:		0.000130
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.36629632115364075
0.36428967118263245
0.3736518621444702
Batch of classes 4 out of 7 batches
Epoch 28 of 30 took 206.897s
  training loss:		0.367789
  validation loss:		0.000088
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.3664308786392212
0.36833420395851135
0.36895057559013367
Batch of classes 4 out of 7 batches
Epoch 29 of 30 took 147.382s
  training loss:		0.368378
  validation loss:		0.000099
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.3654581904411316
0.37371188402175903
0.3768385350704193
Batch of classes 4 out of 7 batches
Epoch 30 of 30 took 188.896s
  training loss:		0.368626
  validation loss:		0.000130
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		73.70 %
  top 1 accuracy Hybrid 1       :		65.15 %
  top 1 accuracy NCM            :		73.75 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		92.15 %
  top 1 accuracy Hybrid 1       :		90.35 %
  top 1 accuracy NCM            :		92.45 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		74.00 %
  top 1 accuracy Hybrid 1       :		74.50 %
  top 1 accuracy NCM            :		74.75 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		95.12 %
  top 1 accuracy Hybrid 1       :		95.00 %
  top 1 accuracy NCM            :		95.38 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		91.03 %
  top 1 accuracy Hybrid 1       :		92.56 %
  top 1 accuracy NCM            :		90.84 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		95.61 %
  top 1 accuracy Hybrid 1       :		95.61 %
  top 1 accuracy NCM            :		95.42 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		100.00 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		100.00 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		86.71 %
  top 1 accuracy Hybrid 1       :		84.00 %
  top 1 accuracy NCM            :		86.81 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		96.27 %
  top 1 accuracy Hybrid 1       :		95.64 %
  top 1 accuracy NCM            :		96.39 %
Classes in this batch: tensor([8, 9])
Data Size: 3248


Before first epoch
  validation loss:		0.588983
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 5 arrives ...
Traceback (most recent call last):
  File "main_icarl_CNND.py", line 579, in <module>
    main()
  File "main_icarl_CNND.py", line 324, in main
    for patterns, labels in train_loader:  # Line 151
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 352, in __iter__
    return self._get_iterator()
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 294, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 801, in __init__
    w.start()
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/popen_fork.py", line 70, in _launch
    self.pid = os.fork()
OSError: [Errno 12] Cannot allocate memory
