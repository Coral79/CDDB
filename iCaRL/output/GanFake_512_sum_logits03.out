----------------- Options ---------------
               add_binary: True                          	[default: False]
               batch_size: 32                            	[default: 64]
                   binary: False                         
              binary_loss: sum_a_sig                     	[default: sum_b_sig]
            binary_weight: 0.3                           	[default: 0.5]
                blur_prob: 0                             
                 blur_sig: 0.5                           
          checkpoints_dir: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL/checkpoints	[default: ./checkpoints]
                class_bal: False                         
           continue_train: False                         
                 cropSize: 224                           
                 data_aug: False                         
                 dataroot: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/DoGAN_data/new/GanFake	[default: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL]
          earlystop_epoch: 5                             
                    epoch: latest                        
                 fine_tun: False                         
                    gpuid: [1]                           
                init_gain: 0.02                          
                  init_lr: 0.001                         	[default: 0.0005]
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2                           
                 jpg_prob: 0                             
                 jpg_qual: 75                            
          label_smoothing: False                         
                 loadSize: 256                           
                    mixup: False                         
              mixup_alpha: 0.1                           
                     mode: binary                        
               model_name: resnet18                      
               model_type: resnet                        
            model_weights: None                          
               multiclass: [1, 1, 0, 1, 1]               	[default: [1]]
                     name: icarl_ganfake_512_sum_logits03	[default: experiment_name]
                nb_protos: 512                           	[default: 128]
                  no_flip: False                         
              num_classes: 2                             
               num_epochs: 60                            	[default: 12]
              num_threads: 4                             
                  outfile: temp_0.1.csv                  
            pretrain_name:                               
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 20                            
         save_latest_freq: 2000                          
                 schedule: [20, 40, 60]                  	[default: [10]]
           serial_batches: False                         
          smoothing_alpha: 0.1                           
                   suffix:                               
                task_name: cyclegan,progan256,progan1024,glow,stargan	[default: ]
              train_split: train                         
                val_split: val                           
----------------- End -------------------
{'All': 10}
Task order: ['cyclegan', 'progan256', 'progan1024', 'glow', 'stargan']
Classes in this batch: tensor([0, 1])
Data Size: 7196


Before first epoch
  validation loss:		0.651198
  top 1 accuracy:		41.60 %
  top 2 accuracy:		55.37 %
Batch of classes number 1 arrives ...
0.4588915705680847
0.1477142721414566
0.14068575203418732
Batch of classes 1 out of 5 batches
Epoch 1 of 60 took 138.877s
  training loss:		0.162328
  validation loss:		0.118254
  top 1 accuracy:		77.54 %
  top 2 accuracy:		100.00 %
0.0731901079416275
0.13829275965690613
0.24511075019836426
Batch of classes 1 out of 5 batches
Epoch 2 of 60 took 77.346s
  training loss:		0.126936
  validation loss:		0.273985
  top 1 accuracy:		69.38 %
  top 2 accuracy:		100.00 %
0.07959695905447006
0.05706273019313812
0.08821794390678406
Batch of classes 1 out of 5 batches
Epoch 3 of 60 took 76.733s
  training loss:		0.101104
  validation loss:		0.187244
  top 1 accuracy:		74.10 %
  top 2 accuracy:		100.00 %
0.08766103535890579
0.15531861782073975
0.07542229443788528
Batch of classes 1 out of 5 batches
Epoch 4 of 60 took 77.148s
  training loss:		0.090959
  validation loss:		0.220102
  top 1 accuracy:		74.44 %
  top 2 accuracy:		100.00 %
0.13844101130962372
0.0472816601395607
0.11301852762699127
Batch of classes 1 out of 5 batches
Epoch 5 of 60 took 77.314s
  training loss:		0.079028
  validation loss:		0.371418
  top 1 accuracy:		74.42 %
  top 2 accuracy:		100.00 %
0.02523909881711006
0.0854421928524971
0.07170429825782776
Batch of classes 1 out of 5 batches
Epoch 6 of 60 took 78.426s
  training loss:		0.072364
  validation loss:		0.259167
  top 1 accuracy:		74.31 %
  top 2 accuracy:		100.00 %
0.05600429326295853
0.07978670299053192
0.018732411786913872
Batch of classes 1 out of 5 batches
Epoch 7 of 60 took 77.052s
  training loss:		0.063688
  validation loss:		0.165786
  top 1 accuracy:		77.15 %
  top 2 accuracy:		100.00 %
0.017060978338122368
0.033166591078042984
0.02463989332318306
Batch of classes 1 out of 5 batches
Epoch 8 of 60 took 77.304s
  training loss:		0.045414
  validation loss:		0.798650
  top 1 accuracy:		74.27 %
  top 2 accuracy:		99.50 %
0.03252264857292175
0.015314619988203049
0.032261889427900314
Batch of classes 1 out of 5 batches
Epoch 9 of 60 took 77.315s
  training loss:		0.048767
  validation loss:		0.389560
  top 1 accuracy:		74.44 %
  top 2 accuracy:		100.00 %
0.029978519305586815
0.029947329312562943
0.029747094959020615
Batch of classes 1 out of 5 batches
Epoch 10 of 60 took 77.372s
  training loss:		0.047852
  validation loss:		0.378024
  top 1 accuracy:		74.25 %
  top 2 accuracy:		100.00 %
0.015480076894164085
0.1386428326368332
0.01844801753759384
Batch of classes 1 out of 5 batches
Epoch 11 of 60 took 76.953s
  training loss:		0.035023
  validation loss:		0.334957
  top 1 accuracy:		75.08 %
  top 2 accuracy:		99.96 %
0.11212949454784393
0.06016627699136734
0.026596132665872574
Batch of classes 1 out of 5 batches
Epoch 12 of 60 took 77.268s
  training loss:		0.034673
  validation loss:		0.433096
  top 1 accuracy:		74.94 %
  top 2 accuracy:		99.94 %
0.05626363307237625
0.02104288339614868
0.006991266272962093
Batch of classes 1 out of 5 batches
Epoch 13 of 60 took 77.186s
  training loss:		0.028058
  validation loss:		0.399122
  top 1 accuracy:		75.38 %
  top 2 accuracy:		100.00 %
0.02236899919807911
0.0034352545626461506
0.03046875074505806
Batch of classes 1 out of 5 batches
Epoch 14 of 60 took 77.766s
  training loss:		0.033897
  validation loss:		0.171199
  top 1 accuracy:		78.85 %
  top 2 accuracy:		100.00 %
0.005488779861479998
0.04602871835231781
0.03672259673476219
Batch of classes 1 out of 5 batches
Epoch 15 of 60 took 77.409s
  training loss:		0.030430
  validation loss:		0.341902
  top 1 accuracy:		74.94 %
  top 2 accuracy:		100.00 %
0.011721666902303696
0.010684301145374775
0.0055985357612371445
Batch of classes 1 out of 5 batches
Epoch 16 of 60 took 78.593s
  training loss:		0.030031
  validation loss:		0.327881
  top 1 accuracy:		76.38 %
  top 2 accuracy:		99.96 %
0.08490493893623352
0.0020241769962012768
0.005539849400520325
Batch of classes 1 out of 5 batches
Epoch 17 of 60 took 77.064s
  training loss:		0.022039
  validation loss:		0.138380
  top 1 accuracy:		79.15 %
  top 2 accuracy:		100.00 %
0.05465021729469299
0.0019976478070020676
0.012686401605606079
Batch of classes 1 out of 5 batches
Epoch 18 of 60 took 76.808s
  training loss:		0.026447
  validation loss:		0.686676
  top 1 accuracy:		74.92 %
  top 2 accuracy:		92.60 %
0.049291305243968964
0.034292176365852356
0.005520709324628115
Batch of classes 1 out of 5 batches
Epoch 19 of 60 took 76.726s
  training loss:		0.020933
  validation loss:		0.395862
  top 1 accuracy:		75.13 %
  top 2 accuracy:		98.79 %
0.029527585953474045
0.01355152577161789
0.009438978508114815
Batch of classes 1 out of 5 batches
Epoch 20 of 60 took 77.030s
  training loss:		0.023315
  validation loss:		0.986731
  top 1 accuracy:		74.98 %
  top 2 accuracy:		92.02 %
0.04427843540906906
0.0075020454823970795
0.0026346808299422264
Batch of classes 1 out of 5 batches
Epoch 21 of 60 took 77.492s
  training loss:		0.010799
  validation loss:		0.658319
  top 1 accuracy:		75.08 %
  top 2 accuracy:		96.77 %
0.000731274951249361
0.0069295186549425125
0.00243982276879251
Batch of classes 1 out of 5 batches
Epoch 22 of 60 took 76.780s
  training loss:		0.006554
  validation loss:		0.550310
  top 1 accuracy:		75.10 %
  top 2 accuracy:		96.75 %
0.0001097552158171311
0.010916018858551979
0.008811624720692635
Batch of classes 1 out of 5 batches
Epoch 23 of 60 took 77.259s
  training loss:		0.006807
  validation loss:		0.469355
  top 1 accuracy:		75.29 %
  top 2 accuracy:		97.35 %
0.038970645517110825
0.05970660597085953
0.008111448958516121
Batch of classes 1 out of 5 batches
Epoch 24 of 60 took 77.822s
  training loss:		0.005766
  validation loss:		0.480403
  top 1 accuracy:		75.13 %
  top 2 accuracy:		96.90 %
0.00018085466581396759
0.000747727754060179
0.010282696224749088
Batch of classes 1 out of 5 batches
Epoch 25 of 60 took 77.216s
  training loss:		0.004502
  validation loss:		0.578709
  top 1 accuracy:		75.17 %
  top 2 accuracy:		93.94 %
0.004546839278191328
0.0012425873428583145
7.456005550920963e-05
Batch of classes 1 out of 5 batches
Epoch 26 of 60 took 76.600s
  training loss:		0.006926
  validation loss:		0.529120
  top 1 accuracy:		75.88 %
  top 2 accuracy:		96.98 %
0.000130498840007931
0.00046461494639515877
0.000104583814390935
Batch of classes 1 out of 5 batches
Epoch 27 of 60 took 77.405s
  training loss:		0.006716
  validation loss:		0.433652
  top 1 accuracy:		75.17 %
  top 2 accuracy:		96.88 %
0.00361588504165411
0.00515106413513422
0.0007237426470965147
Batch of classes 1 out of 5 batches
Epoch 28 of 60 took 77.235s
  training loss:		0.006848
  validation loss:		0.398894
  top 1 accuracy:		76.71 %
  top 2 accuracy:		98.37 %
0.0011862465180456638
0.0004079466452822089
0.007511833682656288
Batch of classes 1 out of 5 batches
Epoch 29 of 60 took 77.103s
  training loss:		0.005648
  validation loss:		0.437361
  top 1 accuracy:		75.35 %
  top 2 accuracy:		96.73 %
0.00025010399986058474
0.00015129160601645708
0.000500170630402863
Batch of classes 1 out of 5 batches
Epoch 30 of 60 took 76.841s
  training loss:		0.006405
  validation loss:		0.752290
  top 1 accuracy:		75.02 %
  top 2 accuracy:		92.12 %
4.539524525171146e-05
0.003781369887292385
0.00014808894775342196
Batch of classes 1 out of 5 batches
Epoch 31 of 60 took 77.366s
  training loss:		0.006632
  validation loss:		0.408527
  top 1 accuracy:		75.65 %
  top 2 accuracy:		97.81 %
0.008566084317862988
0.00014228287909645587
0.001173193333670497
Batch of classes 1 out of 5 batches
Epoch 32 of 60 took 77.326s
  training loss:		0.008052
  validation loss:		0.392577
  top 1 accuracy:		75.13 %
  top 2 accuracy:		99.12 %
0.0006029362557455897
0.0001745385816320777
0.00012356106890365481
Batch of classes 1 out of 5 batches
Epoch 33 of 60 took 78.419s
  training loss:		0.006131
  validation loss:		0.350343
  top 1 accuracy:		75.44 %
  top 2 accuracy:		98.96 %
8.663407061249018e-05
0.004933195188641548
0.0024563355837017298
Batch of classes 1 out of 5 batches
Epoch 34 of 60 took 77.737s
  training loss:		0.004971
  validation loss:		0.397445
  top 1 accuracy:		75.17 %
  top 2 accuracy:		97.19 %
0.00820033997297287
0.00018416834063827991
0.028166696429252625
Batch of classes 1 out of 5 batches
Epoch 35 of 60 took 77.399s
  training loss:		0.004379
  validation loss:		0.937693
  top 1 accuracy:		75.08 %
  top 2 accuracy:		89.38 %
0.0004532547027338296
0.0001950843579834327
0.02690829709172249
Batch of classes 1 out of 5 batches
Epoch 36 of 60 took 76.708s
  training loss:		0.003878
  validation loss:		0.336330
  top 1 accuracy:		75.33 %
  top 2 accuracy:		98.62 %
1.2770877219736576e-05
0.0005220763850957155
0.00014374387683346868
Batch of classes 1 out of 5 batches
Epoch 37 of 60 took 76.826s
  training loss:		0.004933
  validation loss:		0.602628
  top 1 accuracy:		75.56 %
  top 2 accuracy:		92.90 %
0.028216898441314697
6.909237708896399e-05
0.00021319898951333016
Batch of classes 1 out of 5 batches
Epoch 38 of 60 took 78.495s
  training loss:		0.006545
  validation loss:		0.378962
  top 1 accuracy:		75.42 %
  top 2 accuracy:		97.15 %
4.3413307139417157e-05
0.00045320612844079733
0.08062198758125305
Batch of classes 1 out of 5 batches
Epoch 39 of 60 took 78.717s
  training loss:		0.004330
  validation loss:		0.599865
  top 1 accuracy:		75.17 %
  top 2 accuracy:		93.06 %
0.018161645159125328
0.0003546595689840615
0.002112337853759527
Batch of classes 1 out of 5 batches
Epoch 40 of 60 took 79.717s
  training loss:		0.005370
  validation loss:		0.310966
  top 1 accuracy:		75.42 %
  top 2 accuracy:		98.77 %
0.0010230919579043984
0.00040946732042357326
0.0003102677292190492
Batch of classes 1 out of 5 batches
Epoch 41 of 60 took 78.795s
  training loss:		0.002820
  validation loss:		0.359776
  top 1 accuracy:		75.38 %
  top 2 accuracy:		98.21 %
0.00010598146764095873
0.0012821798445656896
8.036995131988078e-05
Batch of classes 1 out of 5 batches
Epoch 42 of 60 took 78.821s
  training loss:		0.001868
  validation loss:		0.357956
  top 1 accuracy:		75.27 %
  top 2 accuracy:		98.62 %
0.0007493042503483593
0.0003849235945381224
0.0006137700984254479
Batch of classes 1 out of 5 batches
Epoch 43 of 60 took 78.796s
  training loss:		0.001533
  validation loss:		0.322305
  top 1 accuracy:		75.60 %
  top 2 accuracy:		98.62 %
0.0002576234401203692
1.2566157238325104e-05
0.010931333526968956
Batch of classes 1 out of 5 batches
Epoch 44 of 60 took 78.833s
  training loss:		0.002308
  validation loss:		0.339547
  top 1 accuracy:		75.71 %
  top 2 accuracy:		97.69 %
0.011624173261225224
2.582054366939701e-05
0.00020668719662353396
Batch of classes 1 out of 5 batches
Epoch 45 of 60 took 77.929s
  training loss:		0.002123
  validation loss:		0.346942
  top 1 accuracy:		76.04 %
  top 2 accuracy:		97.37 %
0.0002060194092337042
0.0001063601957866922
0.000413630623370409
Batch of classes 1 out of 5 batches
Epoch 46 of 60 took 78.084s
  training loss:		0.002166
  validation loss:		0.560541
  top 1 accuracy:		75.25 %
  top 2 accuracy:		92.92 %
0.001095238490961492
1.853378489613533e-05
0.00047745241317898035
Batch of classes 1 out of 5 batches
Epoch 47 of 60 took 78.232s
  training loss:		0.002446
  validation loss:		0.641383
  top 1 accuracy:		75.06 %
  top 2 accuracy:		90.83 %
1.6793899703770876e-05
3.32875206368044e-05
0.00019413392874412239
Batch of classes 1 out of 5 batches
Epoch 48 of 60 took 78.594s
  training loss:		0.001211
  validation loss:		0.463067
  top 1 accuracy:		75.13 %
  top 2 accuracy:		92.92 %
0.0004748603096231818
7.164998532971367e-05
3.539128738339059e-05
Batch of classes 1 out of 5 batches
Epoch 49 of 60 took 78.720s
  training loss:		0.001947
  validation loss:		0.330853
  top 1 accuracy:		75.69 %
  top 2 accuracy:		98.02 %
0.0017064152052626014
6.221822695806623e-05
7.469912088708952e-05
Batch of classes 1 out of 5 batches
Epoch 50 of 60 took 78.839s
  training loss:		0.002348
  validation loss:		0.466080
  top 1 accuracy:		75.10 %
  top 2 accuracy:		93.83 %
7.541543891420588e-05
7.955425826366991e-05
3.8053985917940736e-05
Batch of classes 1 out of 5 batches
Epoch 51 of 60 took 78.852s
  training loss:		0.001263
  validation loss:		0.509134
  top 1 accuracy:		75.25 %
  top 2 accuracy:		93.40 %
0.00013974186731502414
0.00027403407148085535
0.0030669565312564373
Batch of classes 1 out of 5 batches
Epoch 52 of 60 took 79.167s
  training loss:		0.001013
  validation loss:		0.404853
  top 1 accuracy:		75.29 %
  top 2 accuracy:		94.90 %
5.320917989592999e-05
1.4310011465568095e-05
9.513344411971048e-05
Batch of classes 1 out of 5 batches
Epoch 53 of 60 took 78.703s
  training loss:		0.001096
  validation loss:		0.369599
  top 1 accuracy:		75.63 %
  top 2 accuracy:		96.90 %
0.00014805304817855358
3.614385423134081e-05
0.030790235847234726
Batch of classes 1 out of 5 batches
Epoch 54 of 60 took 78.768s
  training loss:		0.000792
  validation loss:		0.286177
  top 1 accuracy:		76.44 %
  top 2 accuracy:		97.75 %
0.00048172171227633953
0.00010116367775481194
4.889345746050822e-06
Batch of classes 1 out of 5 batches
Epoch 55 of 60 took 78.720s
  training loss:		0.001804
  validation loss:		0.382752
  top 1 accuracy:		75.71 %
  top 2 accuracy:		96.65 %
2.4608718376839533e-05
4.275215360394213e-06
4.1003222577273846e-05
Batch of classes 1 out of 5 batches
Epoch 56 of 60 took 78.617s
  training loss:		0.001567
  validation loss:		0.400756
  top 1 accuracy:		75.23 %
  top 2 accuracy:		95.73 %
3.097831358900294e-05
0.0002157825801987201
0.0006893272511661053
Batch of classes 1 out of 5 batches
Epoch 57 of 60 took 78.135s
  training loss:		0.000748
  validation loss:		0.505525
  top 1 accuracy:		75.06 %
  top 2 accuracy:		90.23 %
1.4421141713683028e-05
4.6189885324565694e-05
6.0156980907777324e-06
Batch of classes 1 out of 5 batches
Epoch 58 of 60 took 78.883s
  training loss:		0.001320
  validation loss:		0.447268
  top 1 accuracy:		75.31 %
  top 2 accuracy:		93.19 %
2.528218465158716e-05
0.0011930090840905905
1.1507091585372109e-05
Batch of classes 1 out of 5 batches
Epoch 59 of 60 took 79.113s
  training loss:		0.001203
  validation loss:		0.450393
  top 1 accuracy:		75.33 %
  top 2 accuracy:		93.62 %
6.392091563611757e-06
0.000664982944726944
0.0008666469948366284
Batch of classes 1 out of 5 batches
Epoch 60 of 60 took 78.680s
  training loss:		0.000982
  validation loss:		0.322756
  top 1 accuracy:		75.63 %
  top 2 accuracy:		97.31 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(256)
tensor(256)
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		75.33 %
  top 1 accuracy Hybrid 1       :		75.62 %
  top 1 accuracy NCM            :		75.33 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		75.33 %
  top 1 accuracy Hybrid 1       :		75.62 %
  top 1 accuracy NCM            :		75.33 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		75.33 %
  top 1 accuracy Hybrid 1       :		75.62 %
  top 1 accuracy NCM            :		75.33 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		75.33 %
  top 1 accuracy Hybrid 1       :		75.62 %
  top 1 accuracy NCM            :		75.33 %
Classes in this batch: tensor([2, 3])
Data Size: 7200


Before first epoch
  validation loss:		6.208896
  top 1 accuracy:		0.00 %
  top 2 accuracy:		3.04 %
Batch of classes number 2 arrives ...
1.8210036754608154
0.19572965800762177
0.19265517592430115
Batch of classes 2 out of 5 batches
Epoch 1 of 60 took 135.567s
  training loss:		0.315997
  validation loss:		0.081227
  top 1 accuracy:		85.65 %
  top 2 accuracy:		99.25 %
0.2687605619430542
0.16859927773475647
0.15590351819992065
Batch of classes 2 out of 5 batches
Epoch 2 of 60 took 91.836s
  training loss:		0.202363
  validation loss:		0.080039
  top 1 accuracy:		85.29 %
  top 2 accuracy:		99.27 %
0.18097728490829468
0.18090543150901794
0.10807450860738754
Batch of classes 2 out of 5 batches
Epoch 3 of 60 took 92.362s
  training loss:		0.160228
  validation loss:		0.052214
  top 1 accuracy:		91.40 %
  top 2 accuracy:		99.33 %
0.0950029045343399
0.12621861696243286
0.1394755244255066
Batch of classes 2 out of 5 batches
Epoch 4 of 60 took 92.622s
  training loss:		0.130903
  validation loss:		0.045662
  top 1 accuracy:		91.98 %
  top 2 accuracy:		99.87 %
0.08735018223524094
0.15111705660820007
0.1898021250963211
Batch of classes 2 out of 5 batches
Epoch 5 of 60 took 91.977s
  training loss:		0.109649
  validation loss:		0.032475
  top 1 accuracy:		93.88 %
  top 2 accuracy:		99.81 %
0.07292426377534866
0.1323835253715515
0.14190739393234253
Batch of classes 2 out of 5 batches
Epoch 6 of 60 took 91.320s
  training loss:		0.101776
  validation loss:		0.050576
  top 1 accuracy:		89.67 %
  top 2 accuracy:		99.73 %
0.04987312853336334
0.062338799238204956
0.09190064668655396
Batch of classes 2 out of 5 batches
Epoch 7 of 60 took 91.823s
  training loss:		0.102828
  validation loss:		0.039584
  top 1 accuracy:		92.69 %
  top 2 accuracy:		99.65 %
0.06378033012151718
0.07400111854076385
0.11246967315673828
Batch of classes 2 out of 5 batches
Epoch 8 of 60 took 92.026s
  training loss:		0.086430
  validation loss:		0.042319
  top 1 accuracy:		93.15 %
  top 2 accuracy:		99.08 %
0.06008590757846832
0.05575379729270935
0.03733433037996292
Batch of classes 2 out of 5 batches
Epoch 9 of 60 took 91.685s
  training loss:		0.078933
  validation loss:		0.044665
  top 1 accuracy:		90.50 %
  top 2 accuracy:		99.79 %
0.10335563123226166
0.046863555908203125
0.023890336975455284
Batch of classes 2 out of 5 batches
Epoch 10 of 60 took 91.498s
  training loss:		0.077332
  validation loss:		0.023697
  top 1 accuracy:		96.40 %
  top 2 accuracy:		99.73 %
0.14774996042251587
0.16441968083381653
0.06982344388961792
Batch of classes 2 out of 5 batches
Epoch 11 of 60 took 91.011s
  training loss:		0.075555
  validation loss:		0.018252
  top 1 accuracy:		96.83 %
  top 2 accuracy:		99.81 %
0.04368394985795021
0.08977626264095306
0.05821893364191055
Batch of classes 2 out of 5 batches
Epoch 12 of 60 took 90.617s
  training loss:		0.069637
  validation loss:		0.018808
  top 1 accuracy:		96.79 %
  top 2 accuracy:		99.92 %
0.04973936080932617
0.10858552902936935
0.061646804213523865
Batch of classes 2 out of 5 batches
Epoch 13 of 60 took 90.965s
  training loss:		0.070943
  validation loss:		0.018160
  top 1 accuracy:		97.08 %
  top 2 accuracy:		99.92 %
0.0856289491057396
0.03537364304065704
0.021428603678941727
Batch of classes 2 out of 5 batches
Epoch 14 of 60 took 91.714s
  training loss:		0.061558
  validation loss:		0.019470
  top 1 accuracy:		96.67 %
  top 2 accuracy:		99.67 %
0.0744219571352005
0.03156694024801254
0.10017906129360199
Batch of classes 2 out of 5 batches
Epoch 15 of 60 took 91.373s
  training loss:		0.064614
  validation loss:		0.023965
  top 1 accuracy:		95.90 %
  top 2 accuracy:		99.65 %
0.11909417808055878
0.04669820889830589
0.017419330775737762
Batch of classes 2 out of 5 batches
Epoch 16 of 60 took 91.440s
  training loss:		0.058135
  validation loss:		0.035790
  top 1 accuracy:		93.71 %
  top 2 accuracy:		99.00 %
0.09495192766189575
0.02038508653640747
0.05270490050315857
Batch of classes 2 out of 5 batches
Epoch 17 of 60 took 92.151s
  training loss:		0.053993
  validation loss:		0.036073
  top 1 accuracy:		92.81 %
  top 2 accuracy:		99.79 %
0.026399333029985428
0.04888874292373657
0.015744958072900772
Batch of classes 2 out of 5 batches
Epoch 18 of 60 took 92.915s
  training loss:		0.057794
  validation loss:		0.033458
  top 1 accuracy:		93.94 %
  top 2 accuracy:		99.92 %
0.052139151841402054
0.025322414934635162
0.03647594153881073
Batch of classes 2 out of 5 batches
Epoch 19 of 60 took 92.599s
  training loss:		0.056163
  validation loss:		0.017893
  top 1 accuracy:		96.96 %
  top 2 accuracy:		99.94 %
0.03823278844356537
0.051701225340366364
0.01648890972137451
Batch of classes 2 out of 5 batches
Epoch 20 of 60 took 92.198s
  training loss:		0.051458
  validation loss:		0.015819
  top 1 accuracy:		97.25 %
  top 2 accuracy:		99.73 %
0.007871543988585472
0.009491931647062302
0.019030900672078133
Batch of classes 2 out of 5 batches
Epoch 21 of 60 took 91.985s
  training loss:		0.034763
  validation loss:		0.011057
  top 1 accuracy:		98.12 %
  top 2 accuracy:		99.96 %
0.04509398341178894
0.01601698435842991
0.015001319348812103
Batch of classes 2 out of 5 batches
Epoch 22 of 60 took 91.226s
  training loss:		0.027839
  validation loss:		0.009905
  top 1 accuracy:		98.56 %
  top 2 accuracy:		99.94 %
0.03065389022231102
0.04219561070203781
0.0202853512018919
Batch of classes 2 out of 5 batches
Epoch 23 of 60 took 89.902s
  training loss:		0.026877
  validation loss:		0.010793
  top 1 accuracy:		98.12 %
  top 2 accuracy:		99.85 %
0.013706283643841743
0.045187849551439285
0.007969867438077927
Batch of classes 2 out of 5 batches
Epoch 24 of 60 took 91.403s
  training loss:		0.029952
  validation loss:		0.011590
  top 1 accuracy:		98.02 %
  top 2 accuracy:		99.90 %
0.0012278337962925434
0.001745576155371964
0.0059097567573189735
Batch of classes 2 out of 5 batches
Epoch 25 of 60 took 91.233s
  training loss:		0.025578
  validation loss:		0.011019
  top 1 accuracy:		98.23 %
  top 2 accuracy:		99.83 %
0.010517911054193974
0.012211465276777744
0.031235458329319954
Batch of classes 2 out of 5 batches
Epoch 26 of 60 took 91.546s
  training loss:		0.024724
  validation loss:		0.013754
  top 1 accuracy:		97.50 %
  top 2 accuracy:		99.81 %
0.0084362318739295
0.007037593983113766
0.03316451609134674
Batch of classes 2 out of 5 batches
Epoch 27 of 60 took 91.412s
  training loss:		0.023065
  validation loss:		0.014184
  top 1 accuracy:		97.46 %
  top 2 accuracy:		99.85 %
0.0013647102750837803
0.006012055091559887
0.009190029464662075
Batch of classes 2 out of 5 batches
Epoch 28 of 60 took 90.861s
  training loss:		0.020935
  validation loss:		0.012421
  top 1 accuracy:		97.85 %
  top 2 accuracy:		99.83 %
0.010519798845052719
0.017617058008909225
0.06411614269018173
Batch of classes 2 out of 5 batches
Epoch 29 of 60 took 91.293s
  training loss:		0.021865
  validation loss:		0.015342
  top 1 accuracy:		97.40 %
  top 2 accuracy:		99.83 %
0.012558944523334503
0.02873287722468376
0.02666575089097023
Batch of classes 2 out of 5 batches
Epoch 30 of 60 took 91.767s
  training loss:		0.020355
  validation loss:		0.012533
  top 1 accuracy:		97.75 %
  top 2 accuracy:		99.90 %
0.025751130655407906
0.02388644963502884
0.002656423021107912
Batch of classes 2 out of 5 batches
Epoch 31 of 60 took 91.455s
  training loss:		0.020848
  validation loss:		0.008695
  top 1 accuracy:		98.58 %
  top 2 accuracy:		99.87 %
0.04701998829841614
0.01784692518413067
0.028280707076191902
Batch of classes 2 out of 5 batches
Epoch 32 of 60 took 92.126s
  training loss:		0.022507
  validation loss:		0.011026
  top 1 accuracy:		98.23 %
  top 2 accuracy:		99.85 %
0.022833382710814476
0.024243392050266266
0.007945738732814789
Batch of classes 2 out of 5 batches
Epoch 33 of 60 took 92.345s
  training loss:		0.021614
  validation loss:		0.011367
  top 1 accuracy:		98.06 %
  top 2 accuracy:		99.83 %
0.02498054876923561
0.00647764652967453
0.00458171870559454
Batch of classes 2 out of 5 batches
Epoch 34 of 60 took 93.407s
  training loss:		0.019061
  validation loss:		0.008857
  top 1 accuracy:		98.35 %
  top 2 accuracy:		99.90 %
0.016609828919172287
0.020983783528208733
0.014668121933937073
Batch of classes 2 out of 5 batches
Epoch 35 of 60 took 92.145s
  training loss:		0.019401
  validation loss:		0.012212
  top 1 accuracy:		98.08 %
  top 2 accuracy:		99.79 %
0.06760647892951965
0.031091753393411636
0.012310882098972797
Batch of classes 2 out of 5 batches
Epoch 36 of 60 took 92.017s
  training loss:		0.017882
  validation loss:		0.007824
  top 1 accuracy:		98.60 %
  top 2 accuracy:		99.96 %
0.004753974266350269
0.02545003592967987
0.039571087807416916
Batch of classes 2 out of 5 batches
Epoch 37 of 60 took 91.339s
  training loss:		0.016741
  validation loss:		0.005556
  top 1 accuracy:		99.15 %
  top 2 accuracy:		99.94 %
0.010407083667814732
0.01671428792178631
0.020722325891256332
Batch of classes 2 out of 5 batches
Epoch 38 of 60 took 90.758s
  training loss:		0.018745
  validation loss:		0.013761
  top 1 accuracy:		97.77 %
  top 2 accuracy:		99.87 %
0.0130943413823843
0.002691021654754877
0.015289271250367165
Batch of classes 2 out of 5 batches
Epoch 39 of 60 took 91.174s
  training loss:		0.019356
  validation loss:		0.013182
  top 1 accuracy:		97.48 %
  top 2 accuracy:		99.81 %
0.013210345059633255
0.007268027402460575
0.07476867735385895
Batch of classes 2 out of 5 batches
Epoch 40 of 60 took 90.950s
  training loss:		0.015904
  validation loss:		0.008854
  top 1 accuracy:		98.46 %
  top 2 accuracy:		99.94 %
0.1786983758211136
0.007876820862293243
0.005736981984227896
Batch of classes 2 out of 5 batches
Epoch 41 of 60 took 91.718s
  training loss:		0.013233
  validation loss:		0.007809
  top 1 accuracy:		98.71 %
  top 2 accuracy:		99.90 %
0.017891352996230125
0.0052468664944171906
0.01639374904334545
Batch of classes 2 out of 5 batches
Epoch 42 of 60 took 91.228s
  training loss:		0.010480
  validation loss:		0.007965
  top 1 accuracy:		98.62 %
  top 2 accuracy:		99.87 %
0.004694905132055283
0.008115807548165321
0.002927892841398716
Batch of classes 2 out of 5 batches
Epoch 43 of 60 took 91.731s
  training loss:		0.012491
  validation loss:		0.006901
  top 1 accuracy:		98.81 %
  top 2 accuracy:		99.92 %
0.0024679689668118954
0.03443599492311478
0.09393543750047684
Batch of classes 2 out of 5 batches
Epoch 44 of 60 took 91.573s
  training loss:		0.011199
  validation loss:		0.006945
  top 1 accuracy:		98.94 %
  top 2 accuracy:		99.94 %
0.008653603494167328
0.004431594628840685
0.00267519848421216
Batch of classes 2 out of 5 batches
Epoch 45 of 60 took 91.794s
  training loss:		0.010373
  validation loss:		0.008611
  top 1 accuracy:		98.56 %
  top 2 accuracy:		99.96 %
0.012598815374076366
0.006466098595410585
0.044721752405166626
Batch of classes 2 out of 5 batches
Epoch 46 of 60 took 92.177s
  training loss:		0.008900
  validation loss:		0.006222
  top 1 accuracy:		98.98 %
  top 2 accuracy:		99.96 %
0.001622333424165845
0.004610907752066851
0.00039494503289461136
Batch of classes 2 out of 5 batches
Epoch 47 of 60 took 91.722s
  training loss:		0.009069
  validation loss:		0.006961
  top 1 accuracy:		98.87 %
  top 2 accuracy:		99.92 %
0.006709212437272072
0.014190947636961937
0.0014019072987139225
Batch of classes 2 out of 5 batches
Epoch 48 of 60 took 91.504s
  training loss:		0.008599
  validation loss:		0.008595
  top 1 accuracy:		98.60 %
  top 2 accuracy:		99.94 %
0.010094527155160904
0.004727847874164581
0.00869886577129364
Batch of classes 2 out of 5 batches
Epoch 49 of 60 took 91.909s
  training loss:		0.008794
  validation loss:		0.006207
  top 1 accuracy:		99.08 %
  top 2 accuracy:		99.90 %
0.007816396653652191
0.0002797316701617092
0.0005814643227495253
Batch of classes 2 out of 5 batches
Epoch 50 of 60 took 91.803s
  training loss:		0.007677
  validation loss:		0.009628
  top 1 accuracy:		98.29 %
  top 2 accuracy:		99.87 %
0.0026858639903366566
0.009175725281238556
0.018323581665754318
Batch of classes 2 out of 5 batches
Epoch 51 of 60 took 91.882s
  training loss:		0.008364
  validation loss:		0.007411
  top 1 accuracy:		98.65 %
  top 2 accuracy:		99.94 %
0.0022830329835414886
0.001075355801731348
0.0015719558577984571
Batch of classes 2 out of 5 batches
Epoch 52 of 60 took 91.121s
  training loss:		0.007946
  validation loss:		0.006828
  top 1 accuracy:		98.98 %
  top 2 accuracy:		99.96 %
0.0011095295194536448
0.008876052685081959
0.019687922671437263
Batch of classes 2 out of 5 batches
Epoch 53 of 60 took 91.337s
  training loss:		0.008794
  validation loss:		0.005499
  top 1 accuracy:		99.08 %
  top 2 accuracy:		99.96 %
0.0027309844736009836
0.0007719862041994929
0.004327583126723766
Batch of classes 2 out of 5 batches
Epoch 54 of 60 took 91.018s
  training loss:		0.007644
  validation loss:		0.005077
  top 1 accuracy:		99.23 %
  top 2 accuracy:		99.98 %
0.02184865064918995
0.061875782907009125
0.04669041559100151
Batch of classes 2 out of 5 batches
Epoch 55 of 60 took 91.054s
  training loss:		0.008948
  validation loss:		0.007097
  top 1 accuracy:		98.85 %
  top 2 accuracy:		99.94 %
0.001411885372363031
0.0012574088759720325
0.0004438398755155504
Batch of classes 2 out of 5 batches
Epoch 56 of 60 took 91.463s
  training loss:		0.008759
  validation loss:		0.004244
  top 1 accuracy:		99.25 %
  top 2 accuracy:		99.96 %
0.01384844072163105
0.0015960645396262407
0.00400543911382556
Batch of classes 2 out of 5 batches
Epoch 57 of 60 took 92.140s
  training loss:		0.006996
  validation loss:		0.006587
  top 1 accuracy:		98.90 %
  top 2 accuracy:		99.98 %
0.0004095007316209376
0.0019315627869218588
0.011509519070386887
Batch of classes 2 out of 5 batches
Epoch 58 of 60 took 91.904s
  training loss:		0.006625
  validation loss:		0.008905
  top 1 accuracy:		98.54 %
  top 2 accuracy:		99.98 %
0.004789682105183601
0.001977542182430625
0.0013335461262613535
Batch of classes 2 out of 5 batches
Epoch 59 of 60 took 91.903s
  training loss:		0.007053
  validation loss:		0.008236
  top 1 accuracy:		98.62 %
  top 2 accuracy:		99.92 %
0.004367858171463013
0.00160191860049963
0.00029721029568463564
Batch of classes 2 out of 5 batches
Epoch 60 of 60 took 91.605s
  training loss:		0.005382
  validation loss:		0.008058
  top 1 accuracy:		98.50 %
  top 2 accuracy:		99.94 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(128)
tensor(128)
tensor(128)
tensor(128)
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		75.25 %
  top 1 accuracy Hybrid 1       :		69.85 %
  top 1 accuracy NCM            :		75.02 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		76.19 %
  top 1 accuracy Hybrid 1       :		73.17 %
  top 1 accuracy NCM            :		75.94 %
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		97.62 %
  top 1 accuracy Hybrid 1       :		98.50 %
  top 1 accuracy NCM            :		97.50 %
Binary accuracy:
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		98.27 %
  top 1 accuracy Hybrid 1       :		98.71 %
  top 1 accuracy NCM            :		98.15 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		86.44 %
  top 1 accuracy Hybrid 1       :		84.18 %
  top 1 accuracy NCM            :		86.26 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		87.23 %
  top 1 accuracy Hybrid 1       :		85.94 %
  top 1 accuracy NCM            :		87.04 %
Classes in this batch: tensor([4, 5])
Data Size: 7201


Before first epoch
  validation loss:		1.373756
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 3 arrives ...
1.5177586078643799
0.10298371315002441
0.06424100697040558
Batch of classes 3 out of 5 batches
Epoch 1 of 60 took 597.784s
  training loss:		0.206477
  validation loss:		0.035025
  top 1 accuracy:		94.08 %
  top 2 accuracy:		99.65 %
0.1666366159915924
0.024397119879722595
0.05700152367353439
Batch of classes 3 out of 5 batches
Epoch 2 of 60 took 600.048s
  training loss:		0.078015
  validation loss:		0.014348
  top 1 accuracy:		97.52 %
  top 2 accuracy:		99.92 %
0.09995216131210327
0.20101305842399597
0.021975502371788025
Batch of classes 3 out of 5 batches
Epoch 3 of 60 took 589.872s
  training loss:		0.058124
  validation loss:		0.076872
  top 1 accuracy:		89.40 %
  top 2 accuracy:		99.56 %
0.061293378472328186
0.10999542474746704
0.014960121363401413
Batch of classes 3 out of 5 batches
Epoch 4 of 60 took 598.110s
  training loss:		0.045346
  validation loss:		0.053022
  top 1 accuracy:		93.58 %
  top 2 accuracy:		99.42 %
0.024042265489697456
0.010087617672979832
0.09827539324760437
Batch of classes 3 out of 5 batches
Epoch 5 of 60 took 586.632s
  training loss:		0.045436
  validation loss:		0.017961
  top 1 accuracy:		97.33 %
  top 2 accuracy:		99.60 %
0.10751596838235855
0.009918175637722015
0.02124749682843685
Batch of classes 3 out of 5 batches
Epoch 6 of 60 took 582.027s
  training loss:		0.036135
  validation loss:		0.012183
  top 1 accuracy:		98.27 %
  top 2 accuracy:		99.77 %
0.03026767447590828
0.008498840034008026
0.006135567557066679
Batch of classes 3 out of 5 batches
Epoch 7 of 60 took 616.353s
  training loss:		0.035237
  validation loss:		0.019171
  top 1 accuracy:		97.25 %
  top 2 accuracy:		99.44 %
0.03800190985202789
0.05688665807247162
0.013603311032056808
Batch of classes 3 out of 5 batches
Epoch 8 of 60 took 589.730s
  training loss:		0.057465
  validation loss:		0.022592
  top 1 accuracy:		98.12 %
  top 2 accuracy:		99.77 %
0.17341920733451843
0.02646096982061863
0.034423429518938065
Batch of classes 3 out of 5 batches
Epoch 9 of 60 took 590.517s
  training loss:		0.045849
  validation loss:		0.009945
  top 1 accuracy:		98.54 %
  top 2 accuracy:		99.60 %
0.04248332232236862
0.09101702272891998
0.03389409929513931
Batch of classes 3 out of 5 batches
Epoch 10 of 60 took 591.983s
  training loss:		0.039212
  validation loss:		0.061324
  top 1 accuracy:		92.96 %
  top 2 accuracy:		96.29 %
0.037165798246860504
0.04845874011516571
0.01836058683693409
Batch of classes 3 out of 5 batches
Epoch 11 of 60 took 593.488s
  training loss:		0.044796
  validation loss:		0.025943
  top 1 accuracy:		95.77 %
  top 2 accuracy:		99.33 %
0.0015653494047001004
0.16413523256778717
0.007429113611578941
Batch of classes 3 out of 5 batches
Epoch 12 of 60 took 594.509s
  training loss:		0.071553
  validation loss:		0.014720
  top 1 accuracy:		97.52 %
  top 2 accuracy:		99.27 %
0.010527007281780243
0.03424855321645737
0.012487534433603287
Batch of classes 3 out of 5 batches
Epoch 13 of 60 took 584.803s
  training loss:		0.034274
  validation loss:		0.012668
  top 1 accuracy:		98.27 %
  top 2 accuracy:		99.85 %
0.02388758957386017
0.0320027656853199
0.019825764000415802
Batch of classes 3 out of 5 batches
Epoch 14 of 60 took 576.945s
  training loss:		0.026073
  validation loss:		0.010882
  top 1 accuracy:		98.67 %
  top 2 accuracy:		99.79 %
0.010449285618960857
0.07744278758764267
0.003155380953103304
Batch of classes 3 out of 5 batches
Epoch 15 of 60 took 573.277s
  training loss:		0.026723
  validation loss:		0.008929
  top 1 accuracy:		98.50 %
  top 2 accuracy:		99.79 %
0.003649097867310047
0.017180901020765305
0.04884706437587738
Batch of classes 3 out of 5 batches
Epoch 16 of 60 took 578.017s
  training loss:		0.025093
  validation loss:		0.034133
  top 1 accuracy:		95.00 %
  top 2 accuracy:		99.65 %
0.0173396747559309
0.008440123870968819
0.004382682032883167
Batch of classes 3 out of 5 batches
Epoch 17 of 60 took 580.884s
  training loss:		0.034637
  validation loss:		0.005273
  top 1 accuracy:		99.31 %
  top 2 accuracy:		99.92 %
0.014325544238090515
0.01574677973985672
0.054482217878103256
Batch of classes 3 out of 5 batches
Epoch 18 of 60 took 570.543s
  training loss:		0.024698
  validation loss:		0.014538
  top 1 accuracy:		98.33 %
  top 2 accuracy:		99.54 %
0.08189934492111206
0.0050156451761722565
0.024084974080324173
Batch of classes 3 out of 5 batches
Epoch 19 of 60 took 578.119s
  training loss:		0.026323
  validation loss:		0.015153
  top 1 accuracy:		97.65 %
  top 2 accuracy:		99.90 %
0.003726230002939701
0.02541414275765419
0.0013564559631049633
Batch of classes 3 out of 5 batches
Epoch 20 of 60 took 571.225s
  training loss:		0.019786
  validation loss:		0.009511
  top 1 accuracy:		98.56 %
  top 2 accuracy:		99.87 %
0.008747570216655731
0.000572314893361181
0.0066469451412558556
Batch of classes 3 out of 5 batches
Epoch 21 of 60 took 572.986s
  training loss:		0.013387
  validation loss:		0.004082
  top 1 accuracy:		99.44 %
  top 2 accuracy:		99.87 %
0.011434314772486687
0.010158093646168709
0.006384978536516428
Batch of classes 3 out of 5 batches
Epoch 22 of 60 took 572.729s
  training loss:		0.007977
  validation loss:		0.003265
  top 1 accuracy:		99.67 %
  top 2 accuracy:		99.94 %
0.0035006508696824312
0.0029616039246320724
0.10567693412303925
Batch of classes 3 out of 5 batches
Epoch 23 of 60 took 575.608s
  training loss:		0.011319
  validation loss:		0.003183
  top 1 accuracy:		99.54 %
  top 2 accuracy:		99.92 %
0.003874450223520398
0.0003070506500080228
0.0020382232032716274
Batch of classes 3 out of 5 batches
Epoch 24 of 60 took 563.402s
  training loss:		0.008445
  validation loss:		0.007775
  top 1 accuracy:		98.83 %
  top 2 accuracy:		99.90 %
0.01340312696993351
0.0019325381144881248
0.0018565435893833637
Batch of classes 3 out of 5 batches
Epoch 25 of 60 took 575.625s
  training loss:		0.006030
  validation loss:		0.004204
  top 1 accuracy:		99.35 %
  top 2 accuracy:		99.92 %
0.003503786865621805
0.004274279810488224
0.0022268122993409634
Batch of classes 3 out of 5 batches
Epoch 26 of 60 took 565.037s
  training loss:		0.009137
  validation loss:		0.003705
  top 1 accuracy:		99.50 %
  top 2 accuracy:		99.90 %
0.00025162321981042624
0.009251931682229042
0.0044595664367079735
Batch of classes 3 out of 5 batches
Epoch 27 of 60 took 575.011s
  training loss:		0.010053
  validation loss:		0.002738
  top 1 accuracy:		99.65 %
  top 2 accuracy:		99.96 %
0.001202048035338521
0.00176911149173975
0.006945582572370768
Batch of classes 3 out of 5 batches
Epoch 28 of 60 took 561.600s
  training loss:		0.008851
  validation loss:		0.005508
  top 1 accuracy:		99.19 %
  top 2 accuracy:		99.96 %
0.002200904069468379
0.0005708507378585637
0.006471302360296249
Batch of classes 3 out of 5 batches
Epoch 29 of 60 took 577.077s
  training loss:		0.008414
  validation loss:		0.002141
  top 1 accuracy:		99.69 %
  top 2 accuracy:		99.94 %
0.0024579958990216255
0.2393893599510193
0.022555500268936157
Batch of classes 3 out of 5 batches
Epoch 30 of 60 took 543.035s
  training loss:		0.049932
  validation loss:		0.012459
  top 1 accuracy:		98.10 %
  top 2 accuracy:		99.56 %
0.002917530946433544
0.00653898436576128
0.012488419190049171
Batch of classes 3 out of 5 batches
Epoch 31 of 60 took 589.978s
  training loss:		0.014488
  validation loss:		0.010944
  top 1 accuracy:		98.65 %
  top 2 accuracy:		99.71 %
0.0071950312703847885
0.025925591588020325
0.005801790859550238
Batch of classes 3 out of 5 batches
Epoch 32 of 60 took 1142.351s
  training loss:		0.012216
  validation loss:		0.005039
  top 1 accuracy:		99.40 %
  top 2 accuracy:		99.90 %
0.0019710087217390537
0.01758313924074173
0.0018354143248870969
Batch of classes 3 out of 5 batches
Epoch 33 of 60 took 1095.980s
  training loss:		0.012112
  validation loss:		0.005189
  top 1 accuracy:		99.44 %
  top 2 accuracy:		99.98 %
0.020094797015190125
0.0008757540490478277
0.005027962848544121
Batch of classes 3 out of 5 batches
Epoch 34 of 60 took 1285.033s
  training loss:		0.009108
  validation loss:		0.009602
  top 1 accuracy:		99.04 %
  top 2 accuracy:		99.92 %
0.013455331325531006
0.02068306878209114
0.004827440250664949
Batch of classes 3 out of 5 batches
Epoch 35 of 60 took 1278.254s
  training loss:		0.007252
  validation loss:		0.006496
  top 1 accuracy:		99.21 %
  top 2 accuracy:		99.94 %
0.04212784022092819
0.01161003578454256
0.002858551684767008
Batch of classes 3 out of 5 batches
Epoch 36 of 60 took 1284.698s
  training loss:		0.005861
  validation loss:		0.010630
  top 1 accuracy:		98.58 %
  top 2 accuracy:		99.83 %
0.0013720064889639616
0.01055147498846054
0.0025971615687012672
Batch of classes 3 out of 5 batches
Epoch 37 of 60 took 1289.238s
  training loss:		0.008873
  validation loss:		0.005264
  top 1 accuracy:		99.44 %
  top 2 accuracy:		99.92 %
0.0011313526192680001
0.003019839059561491
0.0015615702141076326
Batch of classes 3 out of 5 batches
Epoch 38 of 60 took 1284.578s
  training loss:		0.008079
  validation loss:		0.002972
  top 1 accuracy:		99.65 %
  top 2 accuracy:		99.94 %
0.003981446847319603
0.005379475653171539
0.005016143433749676
Batch of classes 3 out of 5 batches
Epoch 39 of 60 took 1295.607s
  training loss:		0.006946
  validation loss:		0.005647
  top 1 accuracy:		99.40 %
  top 2 accuracy:		99.96 %
0.001135020749643445
0.004565569572150707
0.0040037622675299644
Batch of classes 3 out of 5 batches
Epoch 40 of 60 took 1292.807s
  training loss:		0.005072
  validation loss:		0.005022
  top 1 accuracy:		99.33 %
  top 2 accuracy:		99.94 %
0.0038070890586823225
0.0004717163974419236
0.0027952271047979593
Batch of classes 3 out of 5 batches
Epoch 41 of 60 took 1264.745s
  training loss:		0.006941
  validation loss:		0.002593
  top 1 accuracy:		99.73 %
  top 2 accuracy:		99.96 %
0.0014072251506149769
0.0064490740187466145
0.011942386627197266
Batch of classes 3 out of 5 batches
Epoch 42 of 60 took 808.815s
  training loss:		0.005482
  validation loss:		0.003643
  top 1 accuracy:		99.60 %
  top 2 accuracy:		99.98 %
0.0024404535070061684
0.005079211201518774
0.0036781076341867447
Batch of classes 3 out of 5 batches
Epoch 43 of 60 took 540.815s
  training loss:		0.003442
  validation loss:		0.009567
  top 1 accuracy:		98.75 %
  top 2 accuracy:		99.96 %
0.0013038122560828924
0.00020362426585052162
0.0017140319105237722
Batch of classes 3 out of 5 batches
Epoch 44 of 60 took 542.819s
  training loss:		0.004446
  validation loss:		0.002363
  top 1 accuracy:		99.75 %
  top 2 accuracy:		99.98 %
0.0004846731317229569
0.00012840000272262841
0.0002944589941762388
Batch of classes 3 out of 5 batches
Epoch 45 of 60 took 541.504s
  training loss:		0.003261
  validation loss:		0.003480
  top 1 accuracy:		99.62 %
  top 2 accuracy:		99.98 %
0.0037204972468316555
0.0014741370687261224
0.012544430792331696
Batch of classes 3 out of 5 batches
Epoch 46 of 60 took 533.027s
  training loss:		0.004479
  validation loss:		0.004695
  top 1 accuracy:		99.60 %
  top 2 accuracy:		99.96 %
0.0006598717300221324
0.001533761853352189
0.01637892797589302
Batch of classes 3 out of 5 batches
Epoch 47 of 60 took 534.617s
  training loss:		0.003739
  validation loss:		0.010941
  top 1 accuracy:		98.94 %
  top 2 accuracy:		99.77 %
0.0009862449951469898
0.0016283600125461817
0.0023345700465142727
Batch of classes 3 out of 5 batches
Epoch 48 of 60 took 538.001s
  training loss:		0.007078
  validation loss:		0.004055
  top 1 accuracy:		99.50 %
  top 2 accuracy:		99.96 %
0.0005141583969816566
0.003035289701074362
0.00010344700422137976
Batch of classes 3 out of 5 batches
Epoch 49 of 60 took 534.758s
  training loss:		0.004900
  validation loss:		0.002280
  top 1 accuracy:		99.83 %
  top 2 accuracy:		99.98 %
0.002985279308632016
0.00017618636775296181
0.0014076458755880594
Batch of classes 3 out of 5 batches
Epoch 50 of 60 took 539.024s
  training loss:		0.003113
  validation loss:		0.002294
  top 1 accuracy:		99.75 %
  top 2 accuracy:		99.96 %
0.0001345131895504892
0.00056505884276703
0.0023928091395646334
Batch of classes 3 out of 5 batches
Epoch 51 of 60 took 543.960s
  training loss:		0.003673
  validation loss:		0.003803
  top 1 accuracy:		99.58 %
  top 2 accuracy:		99.94 %
0.007196860853582621
0.00033168267691507936
0.0010981932282447815
Batch of classes 3 out of 5 batches
Epoch 52 of 60 took 536.477s
  training loss:		0.005610
  validation loss:		0.004584
  top 1 accuracy:		99.54 %
  top 2 accuracy:		99.92 %
0.003670562757179141
0.014672335237264633
0.0007982355309650302
Batch of classes 3 out of 5 batches
Epoch 53 of 60 took 540.300s
  training loss:		0.004153
  validation loss:		0.002139
  top 1 accuracy:		99.81 %
  top 2 accuracy:		99.98 %
0.003361984621733427
0.003960574045777321
0.0002204978372901678
Batch of classes 3 out of 5 batches
Epoch 54 of 60 took 535.842s
  training loss:		0.003662
  validation loss:		0.002897
  top 1 accuracy:		99.62 %
  top 2 accuracy:		99.96 %
0.0012585121439769864
0.0002505836309865117
0.00021815422223880887
Batch of classes 3 out of 5 batches
Epoch 55 of 60 took 535.867s
  training loss:		0.004988
  validation loss:		0.013250
  top 1 accuracy:		98.67 %
  top 2 accuracy:		99.87 %
0.00206592190079391
0.00035074871266260743
0.00023825127573218197
Batch of classes 3 out of 5 batches
Epoch 56 of 60 took 540.695s
  training loss:		0.003248
  validation loss:		0.012088
  top 1 accuracy:		98.77 %
  top 2 accuracy:		99.79 %
0.0006307877483777702
0.00022412188991438597
0.002844985108822584
Batch of classes 3 out of 5 batches
Epoch 57 of 60 took 538.109s
  training loss:		0.003072
  validation loss:		0.007484
  top 1 accuracy:		99.35 %
  top 2 accuracy:		99.90 %
0.00012290252197999507
0.002229075413197279
0.00023771950509399176
Batch of classes 3 out of 5 batches
Epoch 58 of 60 took 536.404s
  training loss:		0.002777
  validation loss:		0.006703
  top 1 accuracy:		99.44 %
  top 2 accuracy:		99.94 %
0.0004540703375823796
0.0009209258132614195
0.0004508290148805827
Batch of classes 3 out of 5 batches
Epoch 59 of 60 took 544.950s
  training loss:		0.002110
  validation loss:		0.003022
  top 1 accuracy:		99.65 %
  top 2 accuracy:		99.94 %
0.0003680697118397802
0.00016890505503397435
9.589280671207234e-05
Batch of classes 3 out of 5 batches
Epoch 60 of 60 took 541.787s
  training loss:		0.003224
  validation loss:		0.002829
  top 1 accuracy:		99.75 %
  top 2 accuracy:		99.96 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		63.17 %
  top 1 accuracy Hybrid 1       :		61.56 %
  top 1 accuracy NCM            :		63.69 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		68.12 %
  top 1 accuracy Hybrid 1       :		67.23 %
  top 1 accuracy NCM            :		68.25 %
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		96.38 %
  top 1 accuracy Hybrid 1       :		95.90 %
  top 1 accuracy NCM            :		96.23 %
Binary accuracy:
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		96.67 %
  top 1 accuracy Hybrid 1       :		96.25 %
  top 1 accuracy NCM            :		96.56 %
Final results on progan1024 classes:
  top 1 accuracy iCaRL          :		99.06 %
  top 1 accuracy Hybrid 1       :		99.75 %
  top 1 accuracy NCM            :		99.02 %
Binary accuracy:
Final results on progan1024 classes:
  top 1 accuracy iCaRL          :		99.50 %
  top 1 accuracy Hybrid 1       :		99.79 %
  top 1 accuracy NCM            :		99.50 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		86.20 %
  top 1 accuracy Hybrid 1       :		85.74 %
  top 1 accuracy NCM            :		86.31 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		88.10 %
  top 1 accuracy Hybrid 1       :		87.76 %
  top 1 accuracy NCM            :		88.10 %
Classes in this batch: tensor([6, 7])
Data Size: 7200


Before first epoch
  validation loss:		2.414596
  top 1 accuracy:		0.00 %
  top 2 accuracy:		10.60 %
Batch of classes number 4 arrives ...
2.386971950531006
0.11819400638341904
0.03948071226477623
Batch of classes 4 out of 5 batches
Epoch 1 of 60 took 130.606s
  training loss:		0.267590
  validation loss:		0.023900
  top 1 accuracy:		97.44 %
  top 2 accuracy:		99.83 %
0.04260130971670151
0.055981021374464035
0.04889374226331711
Batch of classes 4 out of 5 batches
Epoch 2 of 60 took 86.985s
  training loss:		0.054816
  validation loss:		0.019675
  top 1 accuracy:		96.88 %
  top 2 accuracy:		99.90 %
0.03945542499423027
0.015776606276631355
0.012370328418910503
Batch of classes 4 out of 5 batches
Epoch 3 of 60 took 86.469s
  training loss:		0.046710
  validation loss:		0.019337
  top 1 accuracy:		97.83 %
  top 2 accuracy:		99.75 %
0.0221524890512228
0.04698621481657028
0.006951740011572838
Batch of classes 4 out of 5 batches
Epoch 4 of 60 took 86.875s
  training loss:		0.043102
  validation loss:		0.051580
  top 1 accuracy:		91.37 %
  top 2 accuracy:		99.37 %
0.03303717076778412
0.05513518676161766
0.009194448590278625
Batch of classes 4 out of 5 batches
Epoch 5 of 60 took 86.826s
  training loss:		0.037206
  validation loss:		0.015955
  top 1 accuracy:		98.56 %
  top 2 accuracy:		99.94 %
0.06767091900110245
0.13892334699630737
0.038909912109375
Batch of classes 4 out of 5 batches
Epoch 6 of 60 took 86.860s
  training loss:		0.037344
  validation loss:		0.012781
  top 1 accuracy:		98.69 %
  top 2 accuracy:		99.87 %
0.06888998299837112
0.05773655325174332
0.006955236196517944
Batch of classes 4 out of 5 batches
Epoch 7 of 60 took 87.185s
  training loss:		0.028155
  validation loss:		0.039311
  top 1 accuracy:		92.87 %
  top 2 accuracy:		99.94 %
0.016112565994262695
0.025196339935064316
0.017519449815154076
Batch of classes 4 out of 5 batches
Epoch 8 of 60 took 86.682s
  training loss:		0.026701
  validation loss:		0.023975
  top 1 accuracy:		97.04 %
  top 2 accuracy:		99.90 %
0.12785083055496216
0.006435526069253683
0.055496908724308014
Batch of classes 4 out of 5 batches
Epoch 9 of 60 took 86.934s
  training loss:		0.037566
  validation loss:		0.008337
  top 1 accuracy:		99.00 %
  top 2 accuracy:		99.90 %
0.0052907452918589115
0.016758371144533157
0.005925500765442848
Batch of classes 4 out of 5 batches
Epoch 10 of 60 took 86.989s
  training loss:		0.031548
  validation loss:		0.033173
  top 1 accuracy:		94.27 %
  top 2 accuracy:		99.75 %
0.01955399289727211
0.014134068973362446
0.02544368989765644
Batch of classes 4 out of 5 batches
Epoch 11 of 60 took 86.827s
  training loss:		0.027701
  validation loss:		0.066469
  top 1 accuracy:		87.42 %
  top 2 accuracy:		99.71 %
0.015629520639777184
0.01563393883407116
0.027451202273368835
Batch of classes 4 out of 5 batches
Epoch 12 of 60 took 86.999s
  training loss:		0.027236
  validation loss:		0.032802
  top 1 accuracy:		94.08 %
  top 2 accuracy:		99.85 %
0.014110386371612549
0.03286843001842499
0.028751231729984283
Batch of classes 4 out of 5 batches
Epoch 13 of 60 took 86.983s
  training loss:		0.025849
  validation loss:		0.203966
  top 1 accuracy:		73.54 %
  top 2 accuracy:		98.10 %
0.11654980480670929
0.014599703252315521
0.05067253112792969
Batch of classes 4 out of 5 batches
Epoch 14 of 60 took 86.682s
  training loss:		0.029916
  validation loss:		0.011376
  top 1 accuracy:		98.81 %
  top 2 accuracy:		99.87 %
0.006370496936142445
0.005334447603672743
0.0035161301493644714
Batch of classes 4 out of 5 batches
Epoch 15 of 60 took 87.381s
  training loss:		0.020090
  validation loss:		0.015673
  top 1 accuracy:		97.85 %
  top 2 accuracy:		99.58 %
0.003906820435076952
0.006606836337596178
0.0022633846383541822
Batch of classes 4 out of 5 batches
Epoch 16 of 60 took 86.841s
  training loss:		0.025796
  validation loss:		0.069136
  top 1 accuracy:		89.02 %
  top 2 accuracy:		99.83 %
0.005564524792134762
0.045781973749399185
0.010869313962757587
Batch of classes 4 out of 5 batches
Epoch 17 of 60 took 86.849s
  training loss:		0.023050
  validation loss:		0.023911
  top 1 accuracy:		96.58 %
  top 2 accuracy:		99.12 %
0.013170408084988594
0.014432622119784355
0.043845318257808685
Batch of classes 4 out of 5 batches
Epoch 18 of 60 took 86.857s
  training loss:		0.020647
  validation loss:		0.083815
  top 1 accuracy:		87.04 %
  top 2 accuracy:		99.58 %
0.005673090927302837
0.020083116367459297
0.014741212129592896
Batch of classes 4 out of 5 batches
Epoch 19 of 60 took 86.877s
  training loss:		0.041822
  validation loss:		0.078741
  top 1 accuracy:		84.83 %
  top 2 accuracy:		99.83 %
0.01831108331680298
0.019291430711746216
0.0032714703120291233
Batch of classes 4 out of 5 batches
Epoch 20 of 60 took 86.703s
  training loss:		0.022866
  validation loss:		0.021205
  top 1 accuracy:		97.27 %
  top 2 accuracy:		99.85 %
0.0031119564082473516
0.007210965268313885
0.01734631322324276
Batch of classes 4 out of 5 batches
Epoch 21 of 60 took 86.729s
  training loss:		0.012448
  validation loss:		0.012451
  top 1 accuracy:		98.06 %
  top 2 accuracy:		99.98 %
0.00829834584146738
0.007234289776533842
0.0038921311497688293
Batch of classes 4 out of 5 batches
Epoch 22 of 60 took 86.784s
  training loss:		0.014848
  validation loss:		0.010396
  top 1 accuracy:		98.83 %
  top 2 accuracy:		99.94 %
0.00233961408957839
0.015221968293190002
0.028156301006674767
Batch of classes 4 out of 5 batches
Epoch 23 of 60 took 88.545s
  training loss:		0.014313
  validation loss:		0.010998
  top 1 accuracy:		98.31 %
  top 2 accuracy:		99.96 %
0.009525635279715061
0.014800066128373146
0.028552886098623276
Batch of classes 4 out of 5 batches
Epoch 24 of 60 took 88.542s
  training loss:		0.013077
  validation loss:		0.008236
  top 1 accuracy:		99.12 %
  top 2 accuracy:		99.92 %
0.06873166561126709
0.0040890430100262165
0.0014734682627022266
Batch of classes 4 out of 5 batches
Epoch 25 of 60 took 88.224s
  training loss:		0.009681
  validation loss:		0.017356
  top 1 accuracy:		97.12 %
  top 2 accuracy:		99.83 %
0.004133465699851513
0.007709654048085213
0.0040922947227954865
Batch of classes 4 out of 5 batches
Epoch 26 of 60 took 88.354s
  training loss:		0.011092
  validation loss:		0.011086
  top 1 accuracy:		98.40 %
  top 2 accuracy:		99.92 %
0.001709876349195838
0.005232196766883135
0.012173345312476158
Batch of classes 4 out of 5 batches
Epoch 27 of 60 took 88.315s
  training loss:		0.010747
  validation loss:		0.014991
  top 1 accuracy:		98.04 %
  top 2 accuracy:		99.85 %
0.0019133463501930237
0.0022597257047891617
0.0011693085543811321
Batch of classes 4 out of 5 batches
Epoch 28 of 60 took 88.021s
  training loss:		0.013656
  validation loss:		0.022507
  top 1 accuracy:		96.44 %
  top 2 accuracy:		99.65 %
0.04232377931475639
0.00885650422424078
0.004102817736566067
Batch of classes 4 out of 5 batches
Epoch 29 of 60 took 87.854s
  training loss:		0.011682
  validation loss:		0.016883
  top 1 accuracy:		97.79 %
  top 2 accuracy:		99.92 %
0.015511423349380493
0.007754325866699219
0.005064112599939108
Batch of classes 4 out of 5 batches
Epoch 30 of 60 took 88.180s
  training loss:		0.019952
  validation loss:		0.006542
  top 1 accuracy:		99.23 %
  top 2 accuracy:		99.94 %
0.009919995442032814
0.0027828942984342575
0.009900649078190327
Batch of classes 4 out of 5 batches
Epoch 31 of 60 took 88.358s
  training loss:		0.008975
  validation loss:		0.017033
  top 1 accuracy:		97.15 %
  top 2 accuracy:		99.75 %
0.003547880332916975
0.0011306873057037592
0.0017279605381190777
Batch of classes 4 out of 5 batches
Epoch 32 of 60 took 88.339s
  training loss:		0.008430
  validation loss:		0.006373
  top 1 accuracy:		99.23 %
  top 2 accuracy:		99.94 %
0.0016593822510913014
0.015874451026320457
0.005277953110635281
Batch of classes 4 out of 5 batches
Epoch 33 of 60 took 88.008s
  training loss:		0.008390
  validation loss:		0.009428
  top 1 accuracy:		99.08 %
  top 2 accuracy:		99.92 %
0.009281116537749767
0.027794016525149345
0.0027673824224621058
Batch of classes 4 out of 5 batches
Epoch 34 of 60 took 88.861s
  training loss:		0.008143
  validation loss:		0.026054
  top 1 accuracy:		95.67 %
  top 2 accuracy:		99.96 %
0.0013842866756021976
0.0030562886968255043
0.0010475183371454477
Batch of classes 4 out of 5 batches
Epoch 35 of 60 took 88.192s
  training loss:		0.008850
  validation loss:		0.025919
  top 1 accuracy:		95.56 %
  top 2 accuracy:		99.92 %
0.0016960733337327838
0.0028123725205659866
0.010727597400546074
Batch of classes 4 out of 5 batches
Epoch 36 of 60 took 88.605s
  training loss:		0.015133
  validation loss:		0.016739
  top 1 accuracy:		97.10 %
  top 2 accuracy:		99.73 %
0.003858069656416774
0.0026246546767652035
0.026869870722293854
Batch of classes 4 out of 5 batches
Epoch 37 of 60 took 88.211s
  training loss:		0.016850
  validation loss:		0.026570
  top 1 accuracy:		95.58 %
  top 2 accuracy:		99.90 %
0.015048595145344734
0.011145154014229774
0.0007950928993523121
Batch of classes 4 out of 5 batches
Epoch 38 of 60 took 88.290s
  training loss:		0.010974
  validation loss:		0.011364
  top 1 accuracy:		98.75 %
  top 2 accuracy:		99.96 %
0.008387372829020023
0.0037864670157432556
0.006117546930909157
Batch of classes 4 out of 5 batches
Epoch 39 of 60 took 88.460s
  training loss:		0.007828
  validation loss:		0.013446
  top 1 accuracy:		98.19 %
  top 2 accuracy:		99.96 %
0.06778319925069809
0.0016654585488140583
0.0020487115252763033
Batch of classes 4 out of 5 batches
Epoch 40 of 60 took 88.506s
  training loss:		0.007766
  validation loss:		0.015895
  top 1 accuracy:		98.04 %
  top 2 accuracy:		99.81 %
0.001429546158760786
0.0017966588493436575
0.004768047481775284
Batch of classes 4 out of 5 batches
Epoch 41 of 60 took 88.334s
  training loss:		0.004882
  validation loss:		0.007647
  top 1 accuracy:		99.15 %
  top 2 accuracy:		99.85 %
0.008852053433656693
0.0002858068037312478
0.008228052407503128
Batch of classes 4 out of 5 batches
Epoch 42 of 60 took 88.214s
  training loss:		0.005466
  validation loss:		0.012541
  top 1 accuracy:		98.56 %
  top 2 accuracy:		99.90 %
0.0035178991965949535
0.0009425381431356072
0.0021842396818101406
Batch of classes 4 out of 5 batches
Epoch 43 of 60 took 88.977s
  training loss:		0.003993
  validation loss:		0.005769
  top 1 accuracy:		99.33 %
  top 2 accuracy:		99.94 %
0.06676775962114334
0.007512849755585194
0.000514986808411777
Batch of classes 4 out of 5 batches
Epoch 44 of 60 took 88.315s
  training loss:		0.007918
  validation loss:		0.009083
  top 1 accuracy:		99.19 %
  top 2 accuracy:		99.92 %
0.0017258735606446862
0.0014003198593854904
0.00042861996917054057
Batch of classes 4 out of 5 batches
Epoch 45 of 60 took 88.150s
  training loss:		0.006136
  validation loss:		0.009871
  top 1 accuracy:		99.02 %
  top 2 accuracy:		99.90 %
0.000911085051484406
0.0009018927812576294
0.010121025145053864
Batch of classes 4 out of 5 batches
Epoch 46 of 60 took 87.992s
  training loss:		0.005252
  validation loss:		0.006318
  top 1 accuracy:		99.12 %
  top 2 accuracy:		99.96 %
0.000541543704457581
0.0006569341057911515
0.005193090997636318
Batch of classes 4 out of 5 batches
Epoch 47 of 60 took 88.113s
  training loss:		0.003721
  validation loss:		0.008884
  top 1 accuracy:		98.94 %
  top 2 accuracy:		99.94 %
0.01488968264311552
0.00204053008928895
0.002110520377755165
Batch of classes 4 out of 5 batches
Epoch 48 of 60 took 88.125s
  training loss:		0.003348
  validation loss:		0.007191
  top 1 accuracy:		98.96 %
  top 2 accuracy:		99.98 %
0.0018603899516165257
0.008027917705476284
0.0021770778112113476
Batch of classes 4 out of 5 batches
Epoch 49 of 60 took 88.104s
  training loss:		0.004263
  validation loss:		0.008275
  top 1 accuracy:		99.02 %
  top 2 accuracy:		99.94 %
0.00031787148327566683
0.003889443352818489
0.0013357429997995496
Batch of classes 4 out of 5 batches
Epoch 50 of 60 took 88.043s
  training loss:		0.006386
  validation loss:		0.004774
  top 1 accuracy:		99.54 %
  top 2 accuracy:		99.98 %
0.001059222617186606
0.0020800339989364147
0.02374856360256672
Batch of classes 4 out of 5 batches
Epoch 51 of 60 took 88.322s
  training loss:		0.005142
  validation loss:		0.005353
  top 1 accuracy:		99.42 %
  top 2 accuracy:		99.98 %
0.0007752396631985903
0.0007879773620516062
0.003189881332218647
Batch of classes 4 out of 5 batches
Epoch 52 of 60 took 87.935s
  training loss:		0.006290
  validation loss:		0.020675
  top 1 accuracy:		97.15 %
  top 2 accuracy:		99.85 %
0.0007344650803133845
0.0018080727895721793
0.0033763577230274677
Batch of classes 4 out of 5 batches
Epoch 53 of 60 took 88.052s
  training loss:		0.004110
  validation loss:		0.008942
  top 1 accuracy:		98.90 %
  top 2 accuracy:		99.98 %
0.03582703322172165
0.00038347174995578825
0.0001626017619855702
Batch of classes 4 out of 5 batches
Epoch 54 of 60 took 88.306s
  training loss:		0.005507
  validation loss:		0.007949
  top 1 accuracy:		98.92 %
  top 2 accuracy:		99.92 %
0.002245191950351
0.00013061941717751324
0.002080729929730296
Batch of classes 4 out of 5 batches
Epoch 55 of 60 took 88.159s
  training loss:		0.002734
  validation loss:		0.004591
  top 1 accuracy:		99.48 %
  top 2 accuracy:		99.98 %
0.008026059716939926
0.0005340934148989618
0.0002570062060840428
Batch of classes 4 out of 5 batches
Epoch 56 of 60 took 88.235s
  training loss:		0.006521
  validation loss:		0.021354
  top 1 accuracy:		95.67 %
  top 2 accuracy:		99.98 %
0.012208040803670883
0.0026280577294528484
0.000486702483613044
Batch of classes 4 out of 5 batches
Epoch 57 of 60 took 88.262s
  training loss:		0.005159
  validation loss:		0.007461
  top 1 accuracy:		99.40 %
  top 2 accuracy:		99.94 %
0.0008997488766908646
0.0008904668502509594
0.0008597722044214606
Batch of classes 4 out of 5 batches
Epoch 58 of 60 took 88.550s
  training loss:		0.003080
  validation loss:		0.007160
  top 1 accuracy:		99.08 %
  top 2 accuracy:		99.90 %
0.0023932629264891148
0.00018902328156400472
0.0008286409429274499
Batch of classes 4 out of 5 batches
Epoch 59 of 60 took 88.439s
  training loss:		0.006738
  validation loss:		0.008729
  top 1 accuracy:		98.62 %
  top 2 accuracy:		99.98 %
0.005748903378844261
0.0012493436224758625
0.0003127209492959082
Batch of classes 4 out of 5 batches
Epoch 60 of 60 took 88.258s
  training loss:		0.004487
  validation loss:		0.006700
  top 1 accuracy:		99.31 %
  top 2 accuracy:		99.96 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		65.81 %
  top 1 accuracy Hybrid 1       :		60.75 %
  top 1 accuracy NCM            :		66.46 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		71.71 %
  top 1 accuracy Hybrid 1       :		70.44 %
  top 1 accuracy NCM            :		71.83 %
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		94.71 %
  top 1 accuracy Hybrid 1       :		94.83 %
  top 1 accuracy NCM            :		94.56 %
Binary accuracy:
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		95.54 %
  top 1 accuracy Hybrid 1       :		95.65 %
  top 1 accuracy NCM            :		95.48 %
Final results on progan1024 classes:
  top 1 accuracy iCaRL          :		91.56 %
  top 1 accuracy Hybrid 1       :		74.67 %
  top 1 accuracy NCM            :		91.38 %
Binary accuracy:
Final results on progan1024 classes:
  top 1 accuracy iCaRL          :		97.81 %
  top 1 accuracy Hybrid 1       :		97.42 %
  top 1 accuracy NCM            :		97.73 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		96.52 %
  top 1 accuracy Hybrid 1       :		99.31 %
  top 1 accuracy NCM            :		96.52 %
Binary accuracy:
Final results on glow classes:
  top 1 accuracy iCaRL          :		99.54 %
  top 1 accuracy Hybrid 1       :		99.73 %
  top 1 accuracy NCM            :		99.54 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		87.15 %
  top 1 accuracy Hybrid 1       :		82.39 %
  top 1 accuracy NCM            :		87.23 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		91.15 %
  top 1 accuracy Hybrid 1       :		90.81 %
  top 1 accuracy NCM            :		91.15 %
Classes in this batch: tensor([8, 9])
Data Size: 7200


Before first epoch
  validation loss:		1.574651
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.42 %
Batch of classes number 5 arrives ...
1.4953367710113525
0.09666664898395538
0.048323310911655426
Batch of classes 5 out of 5 batches
Epoch 1 of 60 took 144.168s
  training loss:		0.124524
  validation loss:		0.011709
  top 1 accuracy:		99.67 %
  top 2 accuracy:		100.00 %
0.03619791567325592
0.044760193675756454
0.011896735988557339
Batch of classes 5 out of 5 batches
Epoch 2 of 60 took 89.100s
  training loss:		0.034069
  validation loss:		0.004985
  top 1 accuracy:		99.60 %
  top 2 accuracy:		99.94 %
0.011165049858391285
0.008845165371894836
0.11367513984441757
Batch of classes 5 out of 5 batches
Epoch 3 of 60 took 89.378s
  training loss:		0.025170
  validation loss:		0.006166
  top 1 accuracy:		99.40 %
  top 2 accuracy:		99.94 %
0.006735810078680515
0.01648852229118347
0.022999737411737442
Batch of classes 5 out of 5 batches
Epoch 4 of 60 took 89.631s
  training loss:		0.024298
  validation loss:		0.014288
  top 1 accuracy:		98.77 %
  top 2 accuracy:		99.77 %
0.023042840883135796
0.03560224920511246
0.07869815826416016
Batch of classes 5 out of 5 batches
Epoch 5 of 60 took 89.566s
  training loss:		0.027836
  validation loss:		0.009167
  top 1 accuracy:		99.40 %
  top 2 accuracy:		99.87 %
0.00613413518294692
0.03008045256137848
0.0025717010721564293
Batch of classes 5 out of 5 batches
Epoch 6 of 60 took 89.224s
  training loss:		0.020298
  validation loss:		0.008334
  top 1 accuracy:		99.27 %
  top 2 accuracy:		99.87 %
0.011111670173704624
0.01022644154727459
0.011949682608246803
Batch of classes 5 out of 5 batches
Epoch 7 of 60 took 88.194s
  training loss:		0.026842
  validation loss:		0.018386
  top 1 accuracy:		98.00 %
  top 2 accuracy:		99.73 %
0.1269434243440628
0.0027936149854213
0.020250312983989716
Batch of classes 5 out of 5 batches
Epoch 8 of 60 took 89.230s
  training loss:		0.023323
  validation loss:		0.007215
  top 1 accuracy:		99.17 %
  top 2 accuracy:		99.98 %
0.01569649949669838
0.005946359597146511
0.002858988009393215
Batch of classes 5 out of 5 batches
Epoch 9 of 60 took 89.309s
  training loss:		0.021609
  validation loss:		0.010244
  top 1 accuracy:		98.71 %
  top 2 accuracy:		99.92 %
0.011110196821391582
0.002699484582990408
0.00431540422141552
Batch of classes 5 out of 5 batches
Epoch 10 of 60 took 89.403s
  training loss:		0.021112
  validation loss:		0.006702
  top 1 accuracy:		99.27 %
  top 2 accuracy:		99.92 %
0.02754868008196354
0.010780691169202328
0.011865772306919098
Batch of classes 5 out of 5 batches
Epoch 11 of 60 took 90.026s
  training loss:		0.022531
  validation loss:		0.004681
  top 1 accuracy:		99.73 %
  top 2 accuracy:		99.96 %
0.048173245042562485
0.006991771515458822
0.008144570514559746
Batch of classes 5 out of 5 batches
Epoch 12 of 60 took 89.278s
  training loss:		0.022235
  validation loss:		0.011862
  top 1 accuracy:		98.85 %
  top 2 accuracy:		99.96 %
0.033200375735759735
0.020798392593860626
0.01210479810833931
Batch of classes 5 out of 5 batches
Epoch 13 of 60 took 89.361s
  training loss:		0.014151
  validation loss:		0.005587
  top 1 accuracy:		99.56 %
  top 2 accuracy:		100.00 %
0.003840766381472349
0.0041360617615282536
0.0026963117998093367
Batch of classes 5 out of 5 batches
Epoch 14 of 60 took 88.944s
  training loss:		0.018992
  validation loss:		0.011518
  top 1 accuracy:		99.04 %
  top 2 accuracy:		99.90 %
0.01452055387198925
0.01347001176327467
0.01834147423505783
Batch of classes 5 out of 5 batches
Epoch 15 of 60 took 88.951s
  training loss:		0.018590
  validation loss:		0.006957
  top 1 accuracy:		99.46 %
  top 2 accuracy:		99.94 %
0.005544885061681271
0.021318580955266953
0.03741172328591347
Batch of classes 5 out of 5 batches
Epoch 16 of 60 took 88.693s
  training loss:		0.020019
  validation loss:		0.005555
  top 1 accuracy:		99.83 %
  top 2 accuracy:		100.00 %
0.006406867876648903
0.05405842512845993
0.015378115698695183
Batch of classes 5 out of 5 batches
Epoch 17 of 60 took 89.335s
  training loss:		0.019400
  validation loss:		0.003540
  top 1 accuracy:		99.54 %
  top 2 accuracy:		99.98 %
0.04843677952885628
0.025972258299589157
0.03256254643201828
Batch of classes 5 out of 5 batches
Epoch 18 of 60 took 88.263s
  training loss:		0.021033
  validation loss:		0.015214
  top 1 accuracy:		98.54 %
  top 2 accuracy:		99.50 %
0.007661490701138973
0.002175744157284498
0.0030819345265626907
Batch of classes 5 out of 5 batches
Epoch 19 of 60 took 89.271s
  training loss:		0.013945
  validation loss:		0.009128
  top 1 accuracy:		98.85 %
  top 2 accuracy:		99.79 %
0.0013509602285921574
0.0034684150014072657
0.028522348031401634
Batch of classes 5 out of 5 batches
Epoch 20 of 60 took 89.444s
  training loss:		0.017210
  validation loss:		0.016391
  top 1 accuracy:		98.33 %
  top 2 accuracy:		99.75 %
0.033240336924791336
0.0025884462520480156
0.0016616876237094402
Batch of classes 5 out of 5 batches
Epoch 21 of 60 took 89.444s
  training loss:		0.011283
  validation loss:		0.010210
  top 1 accuracy:		98.65 %
  top 2 accuracy:		99.98 %
0.0028116595931351185
0.01836046762764454
0.008912894874811172
Batch of classes 5 out of 5 batches
Epoch 22 of 60 took 89.834s
  training loss:		0.012363
  validation loss:		0.009096
  top 1 accuracy:		98.96 %
  top 2 accuracy:		99.96 %
0.0013616392388939857
0.05463017150759697
0.003124465234577656
Batch of classes 5 out of 5 batches
Epoch 23 of 60 took 89.810s
  training loss:		0.008301
  validation loss:		0.005199
  top 1 accuracy:		99.54 %
  top 2 accuracy:		100.00 %
0.004011199343949556
0.003945135045796633
0.027685916051268578
Batch of classes 5 out of 5 batches
Epoch 24 of 60 took 88.975s
  training loss:		0.007042
  validation loss:		0.007550
  top 1 accuracy:		99.52 %
  top 2 accuracy:		99.94 %
0.0018621241906657815
0.0013073753798380494
0.0017954471986740828
Batch of classes 5 out of 5 batches
Epoch 25 of 60 took 89.375s
  training loss:		0.006625
  validation loss:		0.005742
  top 1 accuracy:		99.46 %
  top 2 accuracy:		99.96 %
0.01642020232975483
0.007445149123668671
0.03688037022948265
Batch of classes 5 out of 5 batches
Epoch 26 of 60 took 89.848s
  training loss:		0.006548
  validation loss:		0.004594
  top 1 accuracy:		99.73 %
  top 2 accuracy:		100.00 %
0.01352646667510271
0.002176330890506506
0.001680391957052052
Batch of classes 5 out of 5 batches
Epoch 27 of 60 took 90.070s
  training loss:		0.005446
  validation loss:		0.003610
  top 1 accuracy:		99.56 %
  top 2 accuracy:		99.96 %
0.0015088453656062484
0.000688178522977978
0.0020191653165966272
Batch of classes 5 out of 5 batches
Epoch 28 of 60 took 89.666s
  training loss:		0.004627
  validation loss:		0.008599
  top 1 accuracy:		99.08 %
  top 2 accuracy:		99.92 %
0.00304254237562418
0.0010156123898923397
0.0011264286004006863
Batch of classes 5 out of 5 batches
Epoch 29 of 60 took 89.326s
  training loss:		0.005952
  validation loss:		0.001607
  top 1 accuracy:		99.77 %
  top 2 accuracy:		99.94 %
0.00041913491440936923
0.013720322400331497
0.008758585900068283
Batch of classes 5 out of 5 batches
Epoch 30 of 60 took 89.534s
  training loss:		0.003982
  validation loss:		0.001923
  top 1 accuracy:		99.77 %
  top 2 accuracy:		99.94 %
0.0003936447901651263
0.0002897439117077738
0.005110258236527443
Batch of classes 5 out of 5 batches
Epoch 31 of 60 took 89.852s
  training loss:		0.002857
  validation loss:		0.002162
  top 1 accuracy:		99.73 %
  top 2 accuracy:		99.92 %
0.0008468906162306666
0.0003103790513705462
0.0029263359028846025
Batch of classes 5 out of 5 batches
Epoch 32 of 60 took 89.432s
  training loss:		0.002529
  validation loss:		0.002043
  top 1 accuracy:		99.79 %
  top 2 accuracy:		99.98 %
0.0002916541416198015
0.0002056316297966987
0.00030373487970791757
Batch of classes 5 out of 5 batches
Epoch 33 of 60 took 89.243s
  training loss:		0.003096
  validation loss:		0.004641
  top 1 accuracy:		99.37 %
  top 2 accuracy:		99.98 %
0.004572537261992693
0.001140381908044219
0.00041283731115981936
Batch of classes 5 out of 5 batches
Epoch 34 of 60 took 89.998s
  training loss:		0.002902
  validation loss:		0.006651
  top 1 accuracy:		98.90 %
  top 2 accuracy:		99.85 %
0.0006522554322145879
0.0004354691773187369
0.0006068609654903412
Batch of classes 5 out of 5 batches
Epoch 35 of 60 took 89.587s
  training loss:		0.003783
  validation loss:		0.020488
  top 1 accuracy:		96.50 %
  top 2 accuracy:		99.83 %
0.0074465274810791016
0.0006908844807185233
0.0006884124595671892
Batch of classes 5 out of 5 batches
Epoch 36 of 60 took 89.656s
  training loss:		0.003376
  validation loss:		0.006673
  top 1 accuracy:		99.00 %
  top 2 accuracy:		99.94 %
0.0025583370588719845
0.001517042052000761
0.0005933094653300941
Batch of classes 5 out of 5 batches
Epoch 37 of 60 took 89.486s
  training loss:		0.002962
  validation loss:		0.006986
  top 1 accuracy:		99.02 %
  top 2 accuracy:		99.79 %
0.0005630767554976046
0.0006923573091626167
0.0011089489562436938
Batch of classes 5 out of 5 batches
Epoch 38 of 60 took 89.317s
  training loss:		0.001961
  validation loss:		0.001645
  top 1 accuracy:		99.79 %
  top 2 accuracy:		99.98 %
0.001398812048137188
0.00020745827350765467
0.003666479606181383
Batch of classes 5 out of 5 batches
Epoch 39 of 60 took 89.324s
  training loss:		0.001066
  validation loss:		0.002134
  top 1 accuracy:		99.75 %
  top 2 accuracy:		99.94 %
0.001799928955733776
0.0006674975156784058
0.002462955890223384
Batch of classes 5 out of 5 batches
Epoch 40 of 60 took 89.809s
  training loss:		0.002025
  validation loss:		0.002705
  top 1 accuracy:		99.69 %
  top 2 accuracy:		99.94 %
0.0003884745528921485
0.0012687400449067354
7.77314489823766e-05
Batch of classes 5 out of 5 batches
Epoch 41 of 60 took 89.599s
  training loss:		0.001086
  validation loss:		0.001754
  top 1 accuracy:		99.81 %
  top 2 accuracy:		100.00 %
0.0005637597641907632
6.090358510846272e-05
0.0002870665048249066
Batch of classes 5 out of 5 batches
Epoch 42 of 60 took 90.565s
  training loss:		0.000862
  validation loss:		0.001612
  top 1 accuracy:		99.75 %
  top 2 accuracy:		100.00 %
3.6541823646984994e-05
3.909197403118014e-05
0.00023070622410159558
Batch of classes 5 out of 5 batches
Epoch 43 of 60 took 89.806s
  training loss:		0.000905
  validation loss:		0.002016
  top 1 accuracy:		99.73 %
  top 2 accuracy:		100.00 %
0.0005000539240427315
4.0313851059181616e-05
0.0005848482833243906
Batch of classes 5 out of 5 batches
Epoch 44 of 60 took 89.661s
  training loss:		0.000642
  validation loss:		0.001249
  top 1 accuracy:		99.79 %
  top 2 accuracy:		100.00 %
2.450999090797268e-05
3.633411324699409e-05
0.0002374189643887803
Batch of classes 5 out of 5 batches
Epoch 45 of 60 took 89.520s
  training loss:		0.000531
  validation loss:		0.000707
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
7.072920561768115e-05
0.000385371531592682
8.281937334686518e-05
Batch of classes 5 out of 5 batches
Epoch 46 of 60 took 89.570s
  training loss:		0.000959
  validation loss:		0.000862
  top 1 accuracy:		99.94 %
  top 2 accuracy:		100.00 %
8.236067515099421e-05
0.00012627901742234826
0.0002826642885338515
Batch of classes 5 out of 5 batches
Epoch 47 of 60 took 89.547s
  training loss:		0.000536
  validation loss:		0.000257
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
3.739981184480712e-05
0.00014185128384269774
0.00042087564361281693
Batch of classes 5 out of 5 batches
Epoch 48 of 60 took 89.638s
  training loss:		0.000528
  validation loss:		0.001065
  top 1 accuracy:		99.83 %
  top 2 accuracy:		100.00 %
5.3312975069275126e-05
6.411779031623155e-05
0.0001121723762480542
Batch of classes 5 out of 5 batches
Epoch 49 of 60 took 89.721s
  training loss:		0.000984
  validation loss:		0.000496
  top 1 accuracy:		99.94 %
  top 2 accuracy:		100.00 %
9.483637404628098e-05
0.00015387327584903687
0.00014747047680430114
Batch of classes 5 out of 5 batches
Epoch 50 of 60 took 89.345s
  training loss:		0.000500
  validation loss:		0.001143
  top 1 accuracy:		99.85 %
  top 2 accuracy:		100.00 %
0.00023141392739489675
3.0183204216882586e-05
3.2806608942337334e-05
Batch of classes 5 out of 5 batches
Epoch 51 of 60 took 89.727s
  training loss:		0.000501
  validation loss:		0.000733
  top 1 accuracy:		99.92 %
  top 2 accuracy:		99.98 %
3.684711191453971e-05
0.0003607965772971511
6.400012352969497e-05
Batch of classes 5 out of 5 batches
Epoch 52 of 60 took 95.684s
  training loss:		0.000494
  validation loss:		0.001544
  top 1 accuracy:		99.79 %
  top 2 accuracy:		99.94 %
0.0001715450780466199
0.00019965393585152924
0.00015051974332891405
Batch of classes 5 out of 5 batches
Epoch 53 of 60 took 89.589s
  training loss:		0.000940
  validation loss:		0.001285
  top 1 accuracy:		99.83 %
  top 2 accuracy:		99.98 %
0.0001767466455930844
8.66188493091613e-05
2.7603095077211037e-05
Batch of classes 5 out of 5 batches
Epoch 54 of 60 took 89.419s
  training loss:		0.000463
  validation loss:		0.000477
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
2.9457885830197483e-05
3.273342736065388e-05
0.00017913720512297004
Batch of classes 5 out of 5 batches
Epoch 55 of 60 took 89.232s
  training loss:		0.000576
  validation loss:		0.001363
  top 1 accuracy:		99.83 %
  top 2 accuracy:		100.00 %
0.0005373193416744471
0.00012206171959405765
0.0003127419331576675
Batch of classes 5 out of 5 batches
Epoch 56 of 60 took 89.653s
  training loss:		0.000618
  validation loss:		0.000711
  top 1 accuracy:		99.87 %
  top 2 accuracy:		100.00 %
0.00013505631068255752
0.0016111466102302074
7.197184459073469e-05
Batch of classes 5 out of 5 batches
Epoch 57 of 60 took 89.754s
  training loss:		0.000597
  validation loss:		0.000733
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
0.00033285023528151214
2.7549885999178514e-05
0.00024004089937079698
Batch of classes 5 out of 5 batches
Epoch 58 of 60 took 89.404s
  training loss:		0.000539
  validation loss:		0.002079
  top 1 accuracy:		99.79 %
  top 2 accuracy:		99.98 %
0.0006324232090264559
5.98206534050405e-05
0.00023161203716881573
Batch of classes 5 out of 5 batches
Epoch 59 of 60 took 89.817s
  training loss:		0.000352
  validation loss:		0.001304
  top 1 accuracy:		99.83 %
  top 2 accuracy:		100.00 %
0.00015419824921991676
0.00011682558397296816
0.00022672463092021644
Batch of classes 5 out of 5 batches
Epoch 60 of 60 took 89.453s
  training loss:		0.000593
  validation loss:		0.000603
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(52)
tensor(52)
tensor(52)
tensor(52)
tensor(52)
tensor(52)
tensor(52)
tensor(52)
tensor(52)
tensor(52)
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		68.08 %
  top 1 accuracy Hybrid 1       :		68.85 %
  top 1 accuracy NCM            :		69.42 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		71.38 %
  top 1 accuracy Hybrid 1       :		72.17 %
  top 1 accuracy NCM            :		72.12 %
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		93.04 %
  top 1 accuracy Hybrid 1       :		92.42 %
  top 1 accuracy NCM            :		92.38 %
Binary accuracy:
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		94.27 %
  top 1 accuracy Hybrid 1       :		94.31 %
  top 1 accuracy NCM            :		93.81 %
Final results on progan1024 classes:
  top 1 accuracy iCaRL          :		87.21 %
  top 1 accuracy Hybrid 1       :		58.81 %
  top 1 accuracy NCM            :		87.62 %
Binary accuracy:
Final results on progan1024 classes:
  top 1 accuracy iCaRL          :		97.96 %
  top 1 accuracy Hybrid 1       :		97.56 %
  top 1 accuracy NCM            :		97.90 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		70.62 %
  top 1 accuracy Hybrid 1       :		23.90 %
  top 1 accuracy NCM            :		66.27 %
Binary accuracy:
Final results on glow classes:
  top 1 accuracy iCaRL          :		95.54 %
  top 1 accuracy Hybrid 1       :		73.85 %
  top 1 accuracy NCM            :		96.40 %
Final results on stargan classes:
  top 1 accuracy iCaRL          :		72.38 %
  top 1 accuracy Hybrid 1       :		99.92 %
  top 1 accuracy NCM            :		77.81 %
Binary accuracy:
Final results on stargan classes:
  top 1 accuracy iCaRL          :		99.77 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		99.69 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		78.27 %
  top 1 accuracy Hybrid 1       :		68.78 %
  top 1 accuracy NCM            :		78.70 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		91.78 %
  top 1 accuracy Hybrid 1       :		87.58 %
  top 1 accuracy NCM            :		91.98 %
tensor([[[ 75.3333,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 75.6250,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 75.3333,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 76.1875,  98.2708,   0.0000,   0.0000,   0.0000],
         [ 73.1667,  98.7083,   0.0000,   0.0000,   0.0000],
         [ 75.9375,  98.1458,   0.0000,   0.0000,   0.0000]],

        [[ 68.1250,  96.6667,  99.5000,   0.0000,   0.0000],
         [ 67.2292,  96.2500,  99.7917,   0.0000,   0.0000],
         [ 68.2500,  96.5625,  99.5000,   0.0000,   0.0000]],

        [[ 71.7083,  95.5417,  97.8125,  99.5417,   0.0000],
         [ 70.4375,  95.6458,  97.4167,  99.7292,   0.0000],
         [ 71.8333,  95.4792,  97.7292,  99.5417,   0.0000]],

        [[ 71.3750,  94.2708,  97.9583,  95.5417,  99.7708],
         [ 72.1667,  94.3125,  97.5625,  73.8542, 100.0000],
         [ 72.1250,  93.8125,  97.8958,  96.3958,  99.6875]]])
tensor([91.7833, 87.5792, 91.9833])
