----------------- Options ---------------
               add_binary: True                          	[default: False]
               batch_size: 32                            	[default: 64]
                   binary: False                         
              binary_loss: sum_a_sig                     	[default: sum_b_sig]
            binary_weight: 0.3                           	[default: 0.5]
                blur_prob: 0                             
                 blur_sig: 0.5                           
          checkpoints_dir: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL/checkpoints	[default: ./checkpoints]
                class_bal: False                         
           continue_train: False                         
                 cropSize: 224                           
                 data_aug: False                         
                 dataroot: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/DoGAN_data/new/GanFake	[default: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL]
          earlystop_epoch: 5                             
                    epoch: latest                        
                 fine_tun: False                         
                    gpuid: [1]                           
                init_gain: 0.02                          
                  init_lr: 0.001                         	[default: 0.0005]
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2                           
                 jpg_prob: 0                             
                 jpg_qual: 75                            
          label_smoothing: False                         
                 loadSize: 256                           
                    mixup: False                         
              mixup_alpha: 0.1                           
                     mode: binary                        
               model_name: resnet18                      
               model_type: resnet                        
            model_weights: None                          
               multiclass: [1, 1, 0, 1, 1]               	[default: [1]]
                     name: icarl_ganfake_1024_sum_logits03	[default: experiment_name]
                nb_protos: 1024                          	[default: 128]
                  no_flip: False                         
              num_classes: 2                             
               num_epochs: 60                            	[default: 12]
              num_threads: 4                             
                  outfile: temp_0.1.csv                  
            pretrain_name:                               
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 20                            
         save_latest_freq: 2000                          
                 schedule: [20, 40, 60]                  	[default: [10]]
           serial_batches: False                         
          smoothing_alpha: 0.1                           
                   suffix:                               
                task_name: cyclegan,progan256,progan1024,glow,stargan	[default: ]
              train_split: train                         
                val_split: val                           
----------------- End -------------------
{'All': 10}
Task order: ['cyclegan', 'progan256', 'progan1024', 'glow', 'stargan']
Classes in this batch: tensor([0, 1])
Data Size: 7196


Before first epoch
  validation loss:		0.651198
  top 1 accuracy:		41.60 %
  top 2 accuracy:		55.37 %
Batch of classes number 1 arrives ...
0.4588913917541504
0.12105055153369904
0.11019355058670044
Batch of classes 1 out of 5 batches
Epoch 1 of 60 took 77.785s
  training loss:		0.161422
  validation loss:		0.107377
  top 1 accuracy:		77.44 %
  top 2 accuracy:		100.00 %
0.05805071443319321
0.08736232668161392
0.18617066740989685
Batch of classes 1 out of 5 batches
Epoch 2 of 60 took 76.168s
  training loss:		0.118662
  validation loss:		0.137639
  top 1 accuracy:		75.19 %
  top 2 accuracy:		100.00 %
0.07425364851951599
0.08425097167491913
0.08580932766199112
Batch of classes 1 out of 5 batches
Epoch 3 of 60 took 75.868s
  training loss:		0.092169
  validation loss:		0.116637
  top 1 accuracy:		74.29 %
  top 2 accuracy:		100.00 %
0.07647976279258728
0.1661093831062317
0.04069971293210983
Batch of classes 1 out of 5 batches
Epoch 4 of 60 took 75.965s
  training loss:		0.081285
  validation loss:		0.208938
  top 1 accuracy:		72.73 %
  top 2 accuracy:		100.00 %
0.07000914216041565
0.041492484509944916
0.09593537449836731
Batch of classes 1 out of 5 batches
Epoch 5 of 60 took 75.445s
  training loss:		0.061042
  validation loss:		0.329939
  top 1 accuracy:		74.52 %
  top 2 accuracy:		100.00 %
0.051705747842788696
0.06754165887832642
0.013541709631681442
Batch of classes 1 out of 5 batches
Epoch 6 of 60 took 75.937s
  training loss:		0.050491
  validation loss:		0.345059
  top 1 accuracy:		74.69 %
  top 2 accuracy:		100.00 %
0.053101588040590286
0.1086631566286087
0.005647690966725349
Batch of classes 1 out of 5 batches
Epoch 7 of 60 took 75.453s
  training loss:		0.048488
  validation loss:		0.179749
  top 1 accuracy:		76.27 %
  top 2 accuracy:		100.00 %
0.016214268282055855
0.01675315760076046
0.006698843091726303
Batch of classes 1 out of 5 batches
Epoch 8 of 60 took 75.580s
  training loss:		0.035861
  validation loss:		0.227108
  top 1 accuracy:		77.60 %
  top 2 accuracy:		100.00 %
0.03345111757516861
0.003188052214682102
0.011225876398384571
Batch of classes 1 out of 5 batches
Epoch 9 of 60 took 75.783s
  training loss:		0.034427
  validation loss:		0.366037
  top 1 accuracy:		73.56 %
  top 2 accuracy:		100.00 %
0.0021391427144408226
0.021823696792125702
0.04325401410460472
Batch of classes 1 out of 5 batches
Epoch 10 of 60 took 74.485s
  training loss:		0.032200
  validation loss:		0.400707
  top 1 accuracy:		75.56 %
  top 2 accuracy:		99.85 %
0.06200326234102249
0.03355647623538971
0.03941034898161888
Batch of classes 1 out of 5 batches
Epoch 11 of 60 took 75.954s
  training loss:		0.031040
  validation loss:		0.303917
  top 1 accuracy:		75.23 %
  top 2 accuracy:		100.00 %
0.08210612833499908
0.0018111972603946924
0.006216750480234623
Batch of classes 1 out of 5 batches
Epoch 12 of 60 took 75.779s
  training loss:		0.027251
  validation loss:		1.124201
  top 1 accuracy:		74.98 %
  top 2 accuracy:		92.46 %
0.01395113579928875
0.007691428065299988
0.014303501695394516
Batch of classes 1 out of 5 batches
Epoch 13 of 60 took 75.758s
  training loss:		0.028102
  validation loss:		0.268685
  top 1 accuracy:		75.98 %
  top 2 accuracy:		99.92 %
0.007588990963995457
0.013912929221987724
0.01131562702357769
Batch of classes 1 out of 5 batches
Epoch 14 of 60 took 75.725s
  training loss:		0.037971
  validation loss:		0.135810
  top 1 accuracy:		78.08 %
  top 2 accuracy:		100.00 %
0.013931313529610634
0.00372349563986063
0.02027188427746296
Batch of classes 1 out of 5 batches
Epoch 15 of 60 took 75.845s
  training loss:		0.025209
  validation loss:		1.014787
  top 1 accuracy:		74.87 %
  top 2 accuracy:		93.54 %
0.021738067269325256
0.0016695235390216112
0.010921782813966274
Batch of classes 1 out of 5 batches
Epoch 16 of 60 took 76.239s
  training loss:		0.028524
  validation loss:		0.527702
  top 1 accuracy:		75.17 %
  top 2 accuracy:		97.71 %
0.05491546913981438
0.003798214951530099
0.02112279273569584
Batch of classes 1 out of 5 batches
Epoch 17 of 60 took 76.013s
  training loss:		0.024098
  validation loss:		0.311128
  top 1 accuracy:		75.44 %
  top 2 accuracy:		99.87 %
0.004292766563594341
0.006521296221762896
0.017213139683008194
Batch of classes 1 out of 5 batches
Epoch 18 of 60 took 75.348s
  training loss:		0.027001
  validation loss:		0.273145
  top 1 accuracy:		75.56 %
  top 2 accuracy:		98.00 %
0.013428684324026108
0.04765132814645767
0.08803108334541321
Batch of classes 1 out of 5 batches
Epoch 19 of 60 took 75.561s
  training loss:		0.022128
  validation loss:		0.713288
  top 1 accuracy:		74.94 %
  top 2 accuracy:		96.27 %
0.173097625374794
0.01780293881893158
0.006069375202059746
Batch of classes 1 out of 5 batches
Epoch 20 of 60 took 75.570s
  training loss:		0.025426
  validation loss:		0.398621
  top 1 accuracy:		74.96 %
  top 2 accuracy:		95.96 %
0.0015422645956277847
0.04222472384572029
0.013355069793760777
Batch of classes 1 out of 5 batches
Epoch 21 of 60 took 76.330s
  training loss:		0.008968
  validation loss:		0.291668
  top 1 accuracy:		76.63 %
  top 2 accuracy:		98.52 %
0.00036070350324735045
0.0051790522411465645
0.0006673033349215984
Batch of classes 1 out of 5 batches
Epoch 22 of 60 took 75.883s
  training loss:		0.006970
  validation loss:		0.419021
  top 1 accuracy:		75.25 %
  top 2 accuracy:		97.19 %
0.000514875166118145
0.002622007392346859
0.002128592925146222
Batch of classes 1 out of 5 batches
Epoch 23 of 60 took 76.277s
  training loss:		0.007067
  validation loss:		0.822671
  top 1 accuracy:		75.04 %
  top 2 accuracy:		90.65 %
0.0014663627371191978
0.0026716834399849176
0.021460186690092087
Batch of classes 1 out of 5 batches
Epoch 24 of 60 took 76.014s
  training loss:		0.006435
  validation loss:		0.425325
  top 1 accuracy:		75.31 %
  top 2 accuracy:		96.83 %
0.0005678032757714391
0.002289688913151622
0.0011615982512012124
Batch of classes 1 out of 5 batches
Epoch 25 of 60 took 76.575s
  training loss:		0.008877
  validation loss:		0.374795
  top 1 accuracy:		75.25 %
  top 2 accuracy:		96.94 %
0.0015272704185917974
0.007465837057679892
0.00033227831590920687
Batch of classes 1 out of 5 batches
Epoch 26 of 60 took 76.883s
  training loss:		0.006133
  validation loss:		0.552460
  top 1 accuracy:		74.79 %
  top 2 accuracy:		93.08 %
0.0006811937200836837
0.0001542997924843803
0.00011566768807824701
Batch of classes 1 out of 5 batches
Epoch 27 of 60 took 76.608s
  training loss:		0.004778
  validation loss:		0.463926
  top 1 accuracy:		75.08 %
  top 2 accuracy:		94.67 %
0.0024258734192699194
0.04536681994795799
0.00030112051172181964
Batch of classes 1 out of 5 batches
Epoch 28 of 60 took 76.457s
  training loss:		0.006006
  validation loss:		0.234278
  top 1 accuracy:		77.79 %
  top 2 accuracy:		99.75 %
0.0013870657421648502
0.009484910406172276
0.0030805328860878944
Batch of classes 1 out of 5 batches
Epoch 29 of 60 took 76.018s
  training loss:		0.005027
  validation loss:		0.432170
  top 1 accuracy:		75.08 %
  top 2 accuracy:		96.77 %
0.0004021735512651503
0.00041859340853989124
0.0005114629166200757
Batch of classes 1 out of 5 batches
Epoch 30 of 60 took 76.793s
  training loss:		0.007481
  validation loss:		0.469119
  top 1 accuracy:		75.04 %
  top 2 accuracy:		98.21 %
0.00034025858622044325
0.00036154937697574496
0.00019143919053021818
Batch of classes 1 out of 5 batches
Epoch 31 of 60 took 77.218s
  training loss:		0.005553
  validation loss:		0.342290
  top 1 accuracy:		75.42 %
  top 2 accuracy:		98.17 %
0.0018622472416609526
0.00011164318857481703
0.003179440274834633
Batch of classes 1 out of 5 batches
Epoch 32 of 60 took 76.771s
  training loss:		0.008768
  validation loss:		0.361605
  top 1 accuracy:		76.08 %
  top 2 accuracy:		96.17 %
4.2965235479641706e-05
0.0005685255164280534
0.00013489957200363278
Batch of classes 1 out of 5 batches
Epoch 33 of 60 took 76.647s
  training loss:		0.005958
  validation loss:		0.279625
  top 1 accuracy:		77.17 %
  top 2 accuracy:		98.60 %
0.00017921961261890829
0.010882161557674408
0.00039738218765705824
Batch of classes 1 out of 5 batches
Epoch 34 of 60 took 76.383s
  training loss:		0.006442
  validation loss:		0.317708
  top 1 accuracy:		75.38 %
  top 2 accuracy:		97.73 %
0.00012105792120564729
0.0002265098737552762
0.00702099921181798
Batch of classes 1 out of 5 batches
Epoch 35 of 60 took 76.315s
  training loss:		0.006140
  validation loss:		0.484891
  top 1 accuracy:		75.83 %
  top 2 accuracy:		94.79 %
0.0012224478414282203
1.734106263029389e-05
0.054707061499357224
Batch of classes 1 out of 5 batches
Epoch 36 of 60 took 76.716s
  training loss:		0.004091
  validation loss:		0.533201
  top 1 accuracy:		75.58 %
  top 2 accuracy:		94.27 %
0.0001229812332894653
0.0007569079753011465
0.002388849388808012
Batch of classes 1 out of 5 batches
Epoch 37 of 60 took 76.618s
  training loss:		0.005099
  validation loss:		0.426505
  top 1 accuracy:		75.25 %
  top 2 accuracy:		96.92 %
0.0003936951397918165
0.00030675099696964025
0.024726929143071175
Batch of classes 1 out of 5 batches
Epoch 38 of 60 took 76.657s
  training loss:		0.005841
  validation loss:		0.411101
  top 1 accuracy:		75.40 %
  top 2 accuracy:		94.94 %
0.00039972615195438266
0.00014923085109330714
0.00638471357524395
Batch of classes 1 out of 5 batches
Epoch 39 of 60 took 76.429s
  training loss:		0.005244
  validation loss:		0.383050
  top 1 accuracy:		75.42 %
  top 2 accuracy:		93.92 %
0.001679426059126854
0.01587073504924774
0.0005762148648500443
Batch of classes 1 out of 5 batches
Epoch 40 of 60 took 76.858s
  training loss:		0.006492
  validation loss:		0.471319
  top 1 accuracy:		75.10 %
  top 2 accuracy:		94.17 %
0.00015828857431188226
0.0020565958693623543
0.006227987818419933
Batch of classes 1 out of 5 batches
Epoch 41 of 60 took 76.638s
  training loss:		0.002163
  validation loss:		0.396781
  top 1 accuracy:		75.33 %
  top 2 accuracy:		95.90 %
1.880349009297788e-05
0.0004173096385784447
0.004717725329101086
Batch of classes 1 out of 5 batches
Epoch 42 of 60 took 76.631s
  training loss:		0.002883
  validation loss:		0.351896
  top 1 accuracy:		75.38 %
  top 2 accuracy:		97.17 %
0.0007377099245786667
2.7341156965121627e-05
0.00010876059968722984
Batch of classes 1 out of 5 batches
Epoch 43 of 60 took 76.398s
  training loss:		0.001732
  validation loss:		0.312282
  top 1 accuracy:		76.52 %
  top 2 accuracy:		97.33 %
0.00013492637663148344
3.170083073200658e-05
0.00032986648147925735
Batch of classes 1 out of 5 batches
Epoch 44 of 60 took 77.031s
  training loss:		0.001326
  validation loss:		0.298177
  top 1 accuracy:		76.90 %
  top 2 accuracy:		97.96 %
0.002170286141335964
6.8196706706658e-05
9.946311365638394e-06
Batch of classes 1 out of 5 batches
Epoch 45 of 60 took 76.600s
  training loss:		0.003022
  validation loss:		0.255118
  top 1 accuracy:		77.52 %
  top 2 accuracy:		98.29 %
0.00034531927667558193
0.00037376838736236095
0.0018052305094897747
Batch of classes 1 out of 5 batches
Epoch 46 of 60 took 76.886s
  training loss:		0.002103
  validation loss:		0.610485
  top 1 accuracy:		75.13 %
  top 2 accuracy:		88.83 %
0.000534688588231802
2.965527710330207e-05
0.0010393636766821146
Batch of classes 1 out of 5 batches
Epoch 47 of 60 took 76.127s
  training loss:		0.002696
  validation loss:		0.433401
  top 1 accuracy:		75.23 %
  top 2 accuracy:		93.23 %
4.971015005139634e-05
0.00019098102347925305
0.0011895594652742147
Batch of classes 1 out of 5 batches
Epoch 48 of 60 took 76.684s
  training loss:		0.001954
  validation loss:		0.395376
  top 1 accuracy:		75.50 %
  top 2 accuracy:		96.00 %
0.0002343883679714054
2.7736690753954463e-05
9.435749961994588e-05
Batch of classes 1 out of 5 batches
Epoch 49 of 60 took 76.640s
  training loss:		0.001985
  validation loss:		0.285894
  top 1 accuracy:		76.63 %
  top 2 accuracy:		98.83 %
7.673587970202789e-05
2.1054378521512263e-05
5.77569444430992e-05
Batch of classes 1 out of 5 batches
Epoch 50 of 60 took 76.803s
  training loss:		0.001869
  validation loss:		0.415635
  top 1 accuracy:		75.50 %
  top 2 accuracy:		96.29 %
0.0002657080767676234
3.780298720812425e-05
3.34289507009089e-05
Batch of classes 1 out of 5 batches
Epoch 51 of 60 took 75.795s
  training loss:		0.001736
  validation loss:		0.571719
  top 1 accuracy:		75.04 %
  top 2 accuracy:		92.29 %
3.7641926610376686e-05
0.006807483732700348
0.003396207233890891
Batch of classes 1 out of 5 batches
Epoch 52 of 60 took 76.943s
  training loss:		0.001234
  validation loss:		0.682550
  top 1 accuracy:		75.00 %
  top 2 accuracy:		88.96 %
0.0004898158949799836
0.0009326082654297352
0.00036485842429101467
Batch of classes 1 out of 5 batches
Epoch 53 of 60 took 76.231s
  training loss:		0.001710
  validation loss:		0.659307
  top 1 accuracy:		75.00 %
  top 2 accuracy:		87.17 %
0.00019051888375543058
1.3368977306527086e-05
0.005510821472853422
Batch of classes 1 out of 5 batches
Epoch 54 of 60 took 76.847s
  training loss:		0.001694
  validation loss:		0.551218
  top 1 accuracy:		75.19 %
  top 2 accuracy:		90.27 %
0.0025382093153893948
3.4085252991644666e-05
0.00018156113219447434
Batch of classes 1 out of 5 batches
Epoch 55 of 60 took 75.683s
  training loss:		0.001744
  validation loss:		0.600371
  top 1 accuracy:		75.08 %
  top 2 accuracy:		89.52 %
0.000168984493939206
5.297284587868489e-06
2.6722009351942688e-05
Batch of classes 1 out of 5 batches
Epoch 56 of 60 took 76.831s
  training loss:		0.001196
  validation loss:		0.357216
  top 1 accuracy:		75.69 %
  top 2 accuracy:		96.17 %
3.943729097954929e-05
0.0003787658060900867
0.0003903923206962645
Batch of classes 1 out of 5 batches
Epoch 57 of 60 took 77.122s
  training loss:		0.001237
  validation loss:		0.685433
  top 1 accuracy:		74.98 %
  top 2 accuracy:		82.56 %
0.0011790015269070864
0.00012903109018225223
1.3174909327062778e-05
Batch of classes 1 out of 5 batches
Epoch 58 of 60 took 76.413s
  training loss:		0.000937
  validation loss:		0.816168
  top 1 accuracy:		75.02 %
  top 2 accuracy:		84.13 %
0.00013499519263859838
0.0031950916163623333
0.00015210683341138065
Batch of classes 1 out of 5 batches
Epoch 59 of 60 took 76.596s
  training loss:		0.001379
  validation loss:		0.450666
  top 1 accuracy:		75.25 %
  top 2 accuracy:		92.90 %
2.6607129257172346e-05
0.0006376451929099858
0.0031650266610085964
Batch of classes 1 out of 5 batches
Epoch 60 of 60 took 76.425s
  training loss:		0.000784
  validation loss:		0.707412
  top 1 accuracy:		75.10 %
  top 2 accuracy:		84.06 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(441)
tensor(500)
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		75.17 %
  top 1 accuracy Hybrid 1       :		75.10 %
  top 1 accuracy NCM            :		75.17 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		75.17 %
  top 1 accuracy Hybrid 1       :		75.10 %
  top 1 accuracy NCM            :		75.17 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		75.17 %
  top 1 accuracy Hybrid 1       :		75.10 %
  top 1 accuracy NCM            :		75.17 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		75.17 %
  top 1 accuracy Hybrid 1       :		75.10 %
  top 1 accuracy NCM            :		75.17 %
Classes in this batch: tensor([2, 3])
Data Size: 7200


Before first epoch
  validation loss:		9.407242
  top 1 accuracy:		0.00 %
  top 2 accuracy:		1.77 %
Batch of classes number 2 arrives ...
2.7045552730560303
0.3240548074245453
0.3085606098175049
Batch of classes 2 out of 5 batches
Epoch 1 of 60 took 132.429s
  training loss:		0.384936
  validation loss:		0.119596
  top 1 accuracy:		74.37 %
  top 2 accuracy:		99.65 %
0.28458669781684875
0.21350568532943726
0.23100052773952484
Batch of classes 2 out of 5 batches
Epoch 2 of 60 took 92.200s
  training loss:		0.245140
  validation loss:		0.108229
  top 1 accuracy:		76.02 %
  top 2 accuracy:		96.69 %
0.20359289646148682
0.16196253895759583
0.14864957332611084
Batch of classes 2 out of 5 batches
Epoch 3 of 60 took 92.020s
  training loss:		0.194736
  validation loss:		0.087719
  top 1 accuracy:		82.69 %
  top 2 accuracy:		98.75 %
0.1968212127685547
0.20735487341880798
0.09521089494228363
Batch of classes 2 out of 5 batches
Epoch 4 of 60 took 92.230s
  training loss:		0.131542
  validation loss:		0.045566
  top 1 accuracy:		91.21 %
  top 2 accuracy:		99.50 %
0.1820691078901291
0.12040966004133224
0.09240950644016266
Batch of classes 2 out of 5 batches
Epoch 5 of 60 took 92.373s
  training loss:		0.072743
  validation loss:		0.015971
  top 1 accuracy:		97.23 %
  top 2 accuracy:		99.67 %
0.08691968023777008
0.013098131865262985
0.2574899196624756
Batch of classes 2 out of 5 batches
Epoch 6 of 60 took 92.272s
  training loss:		0.049813
  validation loss:		0.022919
  top 1 accuracy:		96.15 %
  top 2 accuracy:		99.92 %
0.05634346604347229
0.5271961688995361
0.3346412777900696
Batch of classes 2 out of 5 batches
Epoch 7 of 60 took 92.034s
  training loss:		0.285708
  validation loss:		0.169358
  top 1 accuracy:		51.04 %
  top 2 accuracy:		98.73 %
0.3111962676048279
0.33020541071891785
0.3386402428150177
Batch of classes 2 out of 5 batches
Epoch 8 of 60 took 92.264s
  training loss:		0.320499
  validation loss:		0.167761
  top 1 accuracy:		53.71 %
  top 2 accuracy:		98.48 %
0.31303808093070984
0.334056556224823
0.3021935224533081
Batch of classes 2 out of 5 batches
Epoch 9 of 60 took 92.099s
  training loss:		0.312815
  validation loss:		0.153488
  top 1 accuracy:		50.98 %
  top 2 accuracy:		98.77 %
0.29779157042503357
0.3275587260723114
0.30272483825683594
Batch of classes 2 out of 5 batches
Epoch 10 of 60 took 91.874s
  training loss:		0.309359
  validation loss:		0.150610
  top 1 accuracy:		52.33 %
  top 2 accuracy:		98.83 %
0.286588191986084
0.29218780994415283
0.30411651730537415
Batch of classes 2 out of 5 batches
Epoch 11 of 60 took 91.943s
  training loss:		0.304070
  validation loss:		0.146418
  top 1 accuracy:		55.79 %
  top 2 accuracy:		98.81 %
0.2955917716026306
0.27923282980918884
0.29084086418151855
Batch of classes 2 out of 5 batches
Epoch 12 of 60 took 92.281s
  training loss:		0.299325
  validation loss:		0.148500
  top 1 accuracy:		55.25 %
  top 2 accuracy:		97.33 %
0.28843966126441956
0.2824506163597107
0.29668736457824707
Batch of classes 2 out of 5 batches
Epoch 13 of 60 took 92.154s
  training loss:		0.295583
  validation loss:		0.147545
  top 1 accuracy:		53.33 %
  top 2 accuracy:		99.73 %
0.32281559705734253
0.279142826795578
0.35365140438079834
Batch of classes 2 out of 5 batches
Epoch 14 of 60 took 92.260s
  training loss:		0.291185
  validation loss:		0.192814
  top 1 accuracy:		49.90 %
  top 2 accuracy:		92.17 %
0.29169487953186035
0.2701038718223572
0.2809014618396759
Batch of classes 2 out of 5 batches
Epoch 15 of 60 took 92.603s
  training loss:		0.288348
  validation loss:		0.174389
  top 1 accuracy:		52.60 %
  top 2 accuracy:		99.29 %
0.24667951464653015
0.24663108587265015
0.2383577525615692
Batch of classes 2 out of 5 batches
Epoch 16 of 60 took 92.391s
  training loss:		0.265684
  validation loss:		0.203584
  top 1 accuracy:		71.06 %
  top 2 accuracy:		99.62 %
0.3026523292064667
0.16262821853160858
0.11830344796180725
Batch of classes 2 out of 5 batches
Epoch 17 of 60 took 92.109s
  training loss:		0.211930
  validation loss:		0.088874
  top 1 accuracy:		80.10 %
  top 2 accuracy:		99.40 %
0.15680287778377533
0.19433070719242096
0.15991485118865967
Batch of classes 2 out of 5 batches
Epoch 18 of 60 took 92.232s
  training loss:		0.159659
  validation loss:		0.057143
  top 1 accuracy:		88.58 %
  top 2 accuracy:		99.83 %
0.11540769040584564
0.11038564145565033
0.17297303676605225
Batch of classes 2 out of 5 batches
Epoch 19 of 60 took 92.451s
  training loss:		0.136760
  validation loss:		0.043329
  top 1 accuracy:		93.15 %
  top 2 accuracy:		99.46 %
0.15019741654396057
0.14824767410755157
0.10739186406135559
Batch of classes 2 out of 5 batches
Epoch 20 of 60 took 92.315s
  training loss:		0.112346
  validation loss:		0.047761
  top 1 accuracy:		90.90 %
  top 2 accuracy:		99.56 %
0.09277312457561493
0.07058098912239075
0.11048097908496857
Batch of classes 2 out of 5 batches
Epoch 21 of 60 took 91.329s
  training loss:		0.084881
  validation loss:		0.060218
  top 1 accuracy:		90.35 %
  top 2 accuracy:		99.25 %
0.04736851900815964
0.03505002707242966
0.04103851318359375
Batch of classes 2 out of 5 batches
Epoch 22 of 60 took 92.277s
  training loss:		0.082249
  validation loss:		0.039696
  top 1 accuracy:		96.33 %
  top 2 accuracy:		99.81 %
0.028725752606987953
0.05796985328197479
0.04560655727982521
Batch of classes 2 out of 5 batches
Epoch 23 of 60 took 91.951s
  training loss:		0.074410
  validation loss:		0.029178
  top 1 accuracy:		95.50 %
  top 2 accuracy:		99.56 %
0.055385567247867584
0.04184018820524216
0.0496993362903595
Batch of classes 2 out of 5 batches
Epoch 24 of 60 took 92.411s
  training loss:		0.065682
  validation loss:		0.039992
  top 1 accuracy:		93.54 %
  top 2 accuracy:		99.75 %
0.04481834918260574
0.03321754187345505
0.06215040758252144
Batch of classes 2 out of 5 batches
Epoch 25 of 60 took 92.372s
  training loss:		0.069387
  validation loss:		0.036870
  top 1 accuracy:		93.27 %
  top 2 accuracy:		99.60 %
0.0720757395029068
0.0768170952796936
0.03499368950724602
Batch of classes 2 out of 5 batches
Epoch 26 of 60 took 92.349s
  training loss:		0.062870
  validation loss:		0.022303
  top 1 accuracy:		96.29 %
  top 2 accuracy:		99.79 %
0.10159669816493988
0.0674961507320404
0.0613396018743515
Batch of classes 2 out of 5 batches
Epoch 27 of 60 took 92.230s
  training loss:		0.056773
  validation loss:		0.018664
  top 1 accuracy:		97.29 %
  top 2 accuracy:		99.77 %
0.02866886928677559
0.038411159068346024
0.06692101061344147
Batch of classes 2 out of 5 batches
Epoch 28 of 60 took 91.870s
  training loss:		0.056565
  validation loss:		0.095807
  top 1 accuracy:		95.50 %
  top 2 accuracy:		99.08 %
0.0211532823741436
0.04382332041859627
0.02705499343574047
Batch of classes 2 out of 5 batches
Epoch 29 of 60 took 92.547s
  training loss:		0.051519
  validation loss:		0.069419
  top 1 accuracy:		97.94 %
  top 2 accuracy:		99.73 %
0.0431729219853878
0.043264199048280716
0.0999145358800888
Batch of classes 2 out of 5 batches
Epoch 30 of 60 took 92.135s
  training loss:		0.049580
  validation loss:		0.027925
  top 1 accuracy:		96.90 %
  top 2 accuracy:		99.71 %
0.04316973686218262
0.0690331906080246
0.0327925905585289
Batch of classes 2 out of 5 batches
Epoch 31 of 60 took 92.141s
  training loss:		0.046289
  validation loss:		0.018759
  top 1 accuracy:		97.67 %
  top 2 accuracy:		99.79 %
0.026492366567254066
0.016555730253458023
0.026484694331884384
Batch of classes 2 out of 5 batches
Epoch 32 of 60 took 92.368s
  training loss:		0.041037
  validation loss:		0.024722
  top 1 accuracy:		97.12 %
  top 2 accuracy:		99.54 %
0.11604578793048859
0.0763741135597229
0.04386737197637558
Batch of classes 2 out of 5 batches
Epoch 33 of 60 took 92.288s
  training loss:		0.041906
  validation loss:		0.016737
  top 1 accuracy:		97.29 %
  top 2 accuracy:		99.98 %
0.0423850417137146
0.010236257687211037
0.048257581889629364
Batch of classes 2 out of 5 batches
Epoch 34 of 60 took 92.727s
  training loss:		0.036624
  validation loss:		0.029462
  top 1 accuracy:		96.29 %
  top 2 accuracy:		99.10 %
0.048513997346162796
0.03601634502410889
0.03979675471782684
Batch of classes 2 out of 5 batches
Epoch 35 of 60 took 92.381s
  training loss:		0.033442
  validation loss:		0.101003
  top 1 accuracy:		97.33 %
  top 2 accuracy:		99.87 %
0.029100824147462845
0.0393877737224102
0.06587192416191101
Batch of classes 2 out of 5 batches
Epoch 36 of 60 took 91.874s
  training loss:		0.038005
  validation loss:		0.014511
  top 1 accuracy:		98.73 %
  top 2 accuracy:		99.85 %
0.0967266857624054
0.017893029376864433
0.0221138633787632
Batch of classes 2 out of 5 batches
Epoch 37 of 60 took 92.339s
  training loss:		0.030501
  validation loss:		0.020502
  top 1 accuracy:		96.88 %
  top 2 accuracy:		99.92 %
0.026354551315307617
0.03926701843738556
0.04053952544927597
Batch of classes 2 out of 5 batches
Epoch 38 of 60 took 92.470s
  training loss:		0.031957
  validation loss:		0.197196
  top 1 accuracy:		97.12 %
  top 2 accuracy:		99.94 %
0.03939555957913399
0.0219759289175272
0.075028195977211
Batch of classes 2 out of 5 batches
Epoch 39 of 60 took 91.841s
  training loss:		0.029420
  validation loss:		0.014026
  top 1 accuracy:		98.58 %
  top 2 accuracy:		99.90 %
0.017393719404935837
0.00811164453625679
0.024720821529626846
Batch of classes 2 out of 5 batches
Epoch 40 of 60 took 92.361s
  training loss:		0.028362
  validation loss:		0.019106
  top 1 accuracy:		98.96 %
  top 2 accuracy:		99.87 %
0.018794942647218704
0.019465986639261246
0.06341870874166489
Batch of classes 2 out of 5 batches
Epoch 41 of 60 took 92.302s
  training loss:		0.017876
  validation loss:		0.019881
  top 1 accuracy:		98.73 %
  top 2 accuracy:		99.90 %
0.026858225464820862
0.008091912604868412
0.006691009737551212
Batch of classes 2 out of 5 batches
Epoch 42 of 60 took 92.090s
  training loss:		0.015844
  validation loss:		0.005489
  top 1 accuracy:		99.44 %
  top 2 accuracy:		99.90 %
0.04540056735277176
0.005282996688038111
0.013753814622759819
Batch of classes 2 out of 5 batches
Epoch 43 of 60 took 92.165s
  training loss:		0.017269
  validation loss:		0.006127
  top 1 accuracy:		99.35 %
  top 2 accuracy:		99.87 %
0.036128878593444824
0.00562166515737772
0.0101584792137146
Batch of classes 2 out of 5 batches
Epoch 44 of 60 took 92.139s
  training loss:		0.014746
  validation loss:		0.006660
  top 1 accuracy:		99.04 %
  top 2 accuracy:		99.96 %
0.013163512572646141
0.014501689933240414
0.0036692870780825615
Batch of classes 2 out of 5 batches
Epoch 45 of 60 took 92.062s
  training loss:		0.014713
  validation loss:		0.004647
  top 1 accuracy:		99.46 %
  top 2 accuracy:		99.98 %
0.0018144900677725673
0.05144016072154045
0.023339617997407913
Batch of classes 2 out of 5 batches
Epoch 46 of 60 took 92.271s
  training loss:		0.014496
  validation loss:		0.055832
  top 1 accuracy:		98.23 %
  top 2 accuracy:		99.92 %
0.0067939674481749535
0.010007369332015514
0.023588813841342926
Batch of classes 2 out of 5 batches
Epoch 47 of 60 took 92.025s
  training loss:		0.015625
  validation loss:		0.036077
  top 1 accuracy:		98.87 %
  top 2 accuracy:		99.96 %
0.0020718108862638474
0.0014892453327775002
0.004956090822815895
Batch of classes 2 out of 5 batches
Epoch 48 of 60 took 92.022s
  training loss:		0.015033
  validation loss:		0.024133
  top 1 accuracy:		98.40 %
  top 2 accuracy:		99.94 %
0.027192793786525726
0.032110460102558136
0.0014572920044884086
Batch of classes 2 out of 5 batches
Epoch 49 of 60 took 92.516s
  training loss:		0.014201
  validation loss:		0.008266
  top 1 accuracy:		99.25 %
  top 2 accuracy:		99.92 %
0.004081400576978922
0.002323226071894169
0.007258539088070393
Batch of classes 2 out of 5 batches
Epoch 50 of 60 took 92.265s
  training loss:		0.014283
  validation loss:		0.005558
  top 1 accuracy:		99.33 %
  top 2 accuracy:		99.98 %
0.0011527256574481726
0.016507720574736595
0.0011414659675210714
Batch of classes 2 out of 5 batches
Epoch 51 of 60 took 92.253s
  training loss:		0.014148
  validation loss:		0.004572
  top 1 accuracy:		99.52 %
  top 2 accuracy:		99.98 %
0.016677740961313248
0.024969201534986496
0.0018695734906941652
Batch of classes 2 out of 5 batches
Epoch 52 of 60 took 92.253s
  training loss:		0.011175
  validation loss:		0.008526
  top 1 accuracy:		99.04 %
  top 2 accuracy:		99.94 %
0.017455454915761948
0.0027120839804410934
0.010440402664244175
Batch of classes 2 out of 5 batches
Epoch 53 of 60 took 92.547s
  training loss:		0.011222
  validation loss:		0.010787
  top 1 accuracy:		99.27 %
  top 2 accuracy:		99.96 %
0.010704180225729942
0.024303395301103592
0.09913802146911621
Batch of classes 2 out of 5 batches
Epoch 54 of 60 took 92.486s
  training loss:		0.010583
  validation loss:		0.006049
  top 1 accuracy:		99.10 %
  top 2 accuracy:		99.98 %
0.0011945137521252036
0.008675672113895416
0.00458900211378932
Batch of classes 2 out of 5 batches
Epoch 55 of 60 took 92.457s
  training loss:		0.010198
  validation loss:		0.003892
  top 1 accuracy:		99.54 %
  top 2 accuracy:		99.96 %
0.011582196690142155
0.0023218903224915266
0.00489130849018693
Batch of classes 2 out of 5 batches
Epoch 56 of 60 took 92.281s
  training loss:		0.012433
  validation loss:		0.006201
  top 1 accuracy:		99.27 %
  top 2 accuracy:		99.96 %
0.008303826674818993
0.0071322075091302395
0.0017467266879975796
Batch of classes 2 out of 5 batches
Epoch 57 of 60 took 92.320s
  training loss:		0.010746
  validation loss:		0.014426
  top 1 accuracy:		99.04 %
  top 2 accuracy:		100.00 %
0.0005484013236127794
0.024196682497859
0.001502482919022441
Batch of classes 2 out of 5 batches
Epoch 58 of 60 took 91.956s
  training loss:		0.009817
  validation loss:		0.004057
  top 1 accuracy:		99.46 %
  top 2 accuracy:		99.96 %
0.004540140740573406
0.004000784829258919
0.00039687525713816285
Batch of classes 2 out of 5 batches
Epoch 59 of 60 took 92.252s
  training loss:		0.009618
  validation loss:		0.005153
  top 1 accuracy:		99.27 %
  top 2 accuracy:		99.96 %
0.04863552376627922
0.004060187377035618
0.004117823671549559
Batch of classes 2 out of 5 batches
Epoch 60 of 60 took 92.169s
  training loss:		0.009790
  validation loss:		0.007388
  top 1 accuracy:		99.06 %
  top 2 accuracy:		99.96 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(256)
tensor(256)
tensor(256)
tensor(256)
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		62.40 %
  top 1 accuracy Hybrid 1       :		65.29 %
  top 1 accuracy NCM            :		63.71 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		62.94 %
  top 1 accuracy Hybrid 1       :		66.46 %
  top 1 accuracy NCM            :		64.19 %
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		98.46 %
  top 1 accuracy Hybrid 1       :		99.06 %
  top 1 accuracy NCM            :		98.52 %
Binary accuracy:
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		99.46 %
  top 1 accuracy Hybrid 1       :		99.46 %
  top 1 accuracy NCM            :		99.46 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		80.43 %
  top 1 accuracy Hybrid 1       :		82.18 %
  top 1 accuracy NCM            :		81.11 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		81.20 %
  top 1 accuracy Hybrid 1       :		82.96 %
  top 1 accuracy NCM            :		81.82 %
Classes in this batch: tensor([4, 5])
Data Size: 7201


Before first epoch
  validation loss:		1.557120
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 3 arrives ...
1.2894299030303955
0.28591662645339966
0.23443403840065002
Batch of classes 3 out of 5 batches
Epoch 1 of 60 took 1203.720s
  training loss:		0.323548
  validation loss:		0.112874
  top 1 accuracy:		77.54 %
  top 2 accuracy:		98.83 %
0.18472710251808167
0.05645871162414551
0.07426683604717255
Batch of classes 3 out of 5 batches
Epoch 2 of 60 took 1211.100s
  training loss:		0.148767
  validation loss:		0.049204
  top 1 accuracy:		89.13 %
  top 2 accuracy:		99.33 %
0.08542153239250183
0.06663791090250015
0.08341540396213531
Batch of classes 3 out of 5 batches
Epoch 3 of 60 took 1210.838s
  training loss:		0.108287
  validation loss:		0.050934
  top 1 accuracy:		90.40 %
  top 2 accuracy:		98.00 %
0.044113971292972565
0.08918988704681396
0.03168671205639839
Batch of classes 3 out of 5 batches
Epoch 4 of 60 took 1209.211s
  training loss:		0.087383
  validation loss:		0.056283
  top 1 accuracy:		89.98 %
  top 2 accuracy:		98.85 %
0.09822375327348709
0.10737469047307968
0.10328027606010437
Batch of classes 3 out of 5 batches
Epoch 5 of 60 took 1207.996s
  training loss:		0.090903
  validation loss:		0.036359
  top 1 accuracy:		92.29 %
  top 2 accuracy:		99.19 %
0.06761520355939865
0.06574594229459763
0.025692980736494064
Batch of classes 3 out of 5 batches
Epoch 6 of 60 took 1198.532s
  training loss:		0.072741
  validation loss:		0.022369
  top 1 accuracy:		95.98 %
  top 2 accuracy:		99.56 %
0.023245161399245262
0.05483521521091461
0.08286228775978088
Batch of classes 3 out of 5 batches
Epoch 7 of 60 took 1198.596s
  training loss:		0.071045
  validation loss:		0.042584
  top 1 accuracy:		91.75 %
  top 2 accuracy:		99.58 %
0.058498941361904144
0.08048243075609207
0.14341214299201965
Batch of classes 3 out of 5 batches
Epoch 8 of 60 took 1193.446s
  training loss:		0.062914
  validation loss:		0.019678
  top 1 accuracy:		96.81 %
  top 2 accuracy:		99.81 %
0.04280029609799385
0.1715812087059021
0.0269443541765213
Batch of classes 3 out of 5 batches
Epoch 9 of 60 took 1198.559s
  training loss:		0.058734
  validation loss:		0.039632
  top 1 accuracy:		94.19 %
  top 2 accuracy:		99.06 %
0.030533751472830772
0.049508869647979736
0.044050607830286026
Batch of classes 3 out of 5 batches
Epoch 10 of 60 took 1199.868s
  training loss:		0.061405
  validation loss:		0.028868
  top 1 accuracy:		95.50 %
  top 2 accuracy:		99.04 %
0.09966107457876205
0.011879989877343178
0.02120938152074814
Batch of classes 3 out of 5 batches
Epoch 11 of 60 took 1209.207s
  training loss:		0.056434
  validation loss:		0.298880
  top 1 accuracy:		62.27 %
  top 2 accuracy:		83.96 %
0.02619866468012333
0.015363539569079876
0.026975885033607483
Batch of classes 3 out of 5 batches
Epoch 12 of 60 took 1212.111s
  training loss:		0.048042
  validation loss:		0.085432
  top 1 accuracy:		82.71 %
  top 2 accuracy:		96.94 %
0.07633434236049652
0.06285469233989716
0.01903649978339672
Batch of classes 3 out of 5 batches
Epoch 13 of 60 took 1192.514s
  training loss:		0.049136
  validation loss:		0.033329
  top 1 accuracy:		95.04 %
  top 2 accuracy:		98.73 %
0.07517074048519135
0.02149169147014618
0.004412922076880932
Batch of classes 3 out of 5 batches
Epoch 14 of 60 took 1204.278s
  training loss:		0.045594
  validation loss:		0.027538
  top 1 accuracy:		95.10 %
  top 2 accuracy:		98.92 %
0.05812833085656166
0.06742312759160995
0.020066283643245697
Batch of classes 3 out of 5 batches
Epoch 15 of 60 took 1125.031s
  training loss:		0.047246
  validation loss:		0.020820
  top 1 accuracy:		96.67 %
  top 2 accuracy:		99.71 %
0.02136608213186264
0.09187345951795578
0.012728486210107803
Batch of classes 3 out of 5 batches
Epoch 16 of 60 took 1218.475s
  training loss:		0.050481
  validation loss:		0.245334
  top 1 accuracy:		81.42 %
  top 2 accuracy:		98.23 %
0.05151374638080597
0.33339619636535645
0.327100932598114
Batch of classes 3 out of 5 batches
Epoch 17 of 60 took 1045.152s
  training loss:		0.516363
  validation loss:		0.929290
  top 1 accuracy:		50.92 %
  top 2 accuracy:		99.33 %
0.31361621618270874
0.32422804832458496
0.3111298084259033
Batch of classes 3 out of 5 batches
Epoch 18 of 60 took 1012.630s
  training loss:		0.324119
  validation loss:		0.172072
  top 1 accuracy:		51.92 %
  top 2 accuracy:		97.98 %
0.3202371299266815
0.3299776315689087
0.3292625844478607
Batch of classes 3 out of 5 batches
Epoch 19 of 60 took 1223.632s
  training loss:		0.319047
  validation loss:		0.147854
  top 1 accuracy:		51.98 %
  top 2 accuracy:		98.87 %
0.3316291272640228
0.3194120526313782
0.30575108528137207
Batch of classes 3 out of 5 batches
Epoch 20 of 60 took 1225.724s
  training loss:		0.313307
  validation loss:		0.153056
  top 1 accuracy:		54.69 %
  top 2 accuracy:		98.37 %
0.30239957571029663
0.29623422026634216
0.2998959422111511
Batch of classes 3 out of 5 batches
Epoch 21 of 60 took 1222.376s
  training loss:		0.304948
  validation loss:		0.208800
  top 1 accuracy:		58.98 %
  top 2 accuracy:		97.48 %
0.27485156059265137
0.2949323356151581
0.32720598578453064
Batch of classes 3 out of 5 batches
Epoch 22 of 60 took 1228.077s
  training loss:		0.299204
  validation loss:		0.147184
  top 1 accuracy:		63.19 %
  top 2 accuracy:		98.90 %
0.2776147127151489
0.3023163080215454
0.30637460947036743
Batch of classes 3 out of 5 batches
Epoch 23 of 60 took 1219.294s
  training loss:		0.295031
  validation loss:		0.134955
  top 1 accuracy:		62.75 %
  top 2 accuracy:		98.67 %
0.31153160333633423
0.33531343936920166
0.3174574375152588
Batch of classes 3 out of 5 batches
Epoch 24 of 60 took 1202.882s
  training loss:		0.286224
  validation loss:		0.172885
  top 1 accuracy:		59.83 %
  top 2 accuracy:		97.75 %
0.24697580933570862
0.2823987603187561
0.2895675301551819
Batch of classes 3 out of 5 batches
Epoch 25 of 60 took 1247.966s
  training loss:		0.282719
  validation loss:		0.131036
  top 1 accuracy:		65.23 %
  top 2 accuracy:		98.21 %
0.29214760661125183
0.23355042934417725
0.3026905059814453
Batch of classes 3 out of 5 batches
Epoch 26 of 60 took 1312.419s
  training loss:		0.278630
  validation loss:		0.216034
  top 1 accuracy:		54.81 %
  top 2 accuracy:		91.60 %
0.27428919076919556
0.30177029967308044
0.2944019138813019
Batch of classes 3 out of 5 batches
Epoch 27 of 60 took 1330.449s
  training loss:		0.272425
  validation loss:		0.123728
  top 1 accuracy:		66.67 %
  top 2 accuracy:		99.46 %
0.2571421265602112
0.23953363299369812
0.2623421549797058
Batch of classes 3 out of 5 batches
Epoch 28 of 60 took 1324.556s
  training loss:		0.269455
  validation loss:		0.179740
  top 1 accuracy:		54.62 %
  top 2 accuracy:		96.42 %
0.19986467063426971
0.3002447485923767
0.26963865756988525
Batch of classes 3 out of 5 batches
Epoch 29 of 60 took 1237.221s
  training loss:		0.263174
  validation loss:		0.115041
  top 1 accuracy:		71.50 %
  top 2 accuracy:		99.15 %
0.24047282338142395
0.3164474368095398
0.29771700501441956
Batch of classes 3 out of 5 batches
Epoch 30 of 60 took 1252.344s
  training loss:		0.255836
  validation loss:		0.111579
  top 1 accuracy:		73.12 %
  top 2 accuracy:		98.71 %
0.2777687907218933
0.31173476576805115
0.1836269348859787
Batch of classes 3 out of 5 batches
Epoch 31 of 60 took 1280.814s
  training loss:		0.249500
  validation loss:		0.132669
  top 1 accuracy:		67.77 %
  top 2 accuracy:		99.23 %
0.29968497157096863
0.2702583968639374
0.24641376733779907
Batch of classes 3 out of 5 batches
Epoch 32 of 60 took 1299.677s
  training loss:		0.249183
  validation loss:		0.116694
  top 1 accuracy:		71.42 %
  top 2 accuracy:		98.44 %
0.3075111508369446
0.27625706791877747
0.21577465534210205
Batch of classes 3 out of 5 batches
Epoch 33 of 60 took 1307.718s
  training loss:		0.239945
  validation loss:		0.113639
  top 1 accuracy:		74.65 %
  top 2 accuracy:		97.02 %
0.25900524854660034
0.2289852797985077
0.31265342235565186
Batch of classes 3 out of 5 batches
Epoch 34 of 60 took 1296.590s
  training loss:		0.239809
  validation loss:		0.210466
  top 1 accuracy:		60.35 %
  top 2 accuracy:		92.35 %
0.22718170285224915
0.2380763441324234
0.2496805340051651
Batch of classes 3 out of 5 batches
Epoch 35 of 60 took 1212.633s
  training loss:		0.236824
  validation loss:		0.100810
  top 1 accuracy:		77.02 %
  top 2 accuracy:		98.62 %
0.21503597497940063
0.15818734467029572
0.18869349360466003
Batch of classes 3 out of 5 batches
Epoch 36 of 60 took 1223.477s
  training loss:		0.230080
  validation loss:		0.195303
  top 1 accuracy:		61.69 %
  top 2 accuracy:		93.46 %
0.2528943419456482
0.22343438863754272
0.2533922791481018
Batch of classes 3 out of 5 batches
Epoch 37 of 60 took 1312.792s
  training loss:		0.226367
  validation loss:		0.096717
  top 1 accuracy:		76.63 %
  top 2 accuracy:		99.06 %
0.2071339190006256
0.14796321094036102
0.21251899003982544
Batch of classes 3 out of 5 batches
Epoch 38 of 60 took 1293.548s
  training loss:		0.221491
  validation loss:		0.154514
  top 1 accuracy:		66.04 %
  top 2 accuracy:		96.13 %
0.26855185627937317
0.22195309400558472
0.2940358519554138
Batch of classes 3 out of 5 batches
Epoch 39 of 60 took 1286.014s
  training loss:		0.217377
  validation loss:		0.085396
  top 1 accuracy:		82.13 %
  top 2 accuracy:		99.08 %
0.20616012811660767
0.14750221371650696
0.1933889389038086
Batch of classes 3 out of 5 batches
Epoch 40 of 60 took 1294.304s
  training loss:		0.214163
  validation loss:		0.078256
  top 1 accuracy:		82.75 %
  top 2 accuracy:		99.08 %
0.2711702287197113
0.22933876514434814
0.16424304246902466
Batch of classes 3 out of 5 batches
Epoch 41 of 60 took 1243.553s
  training loss:		0.199744
  validation loss:		0.078888
  top 1 accuracy:		82.96 %
  top 2 accuracy:		99.31 %
0.22057092189788818
0.18057376146316528
0.17339879274368286
Batch of classes 3 out of 5 batches
Epoch 42 of 60 took 1208.822s
  training loss:		0.196478
  validation loss:		0.077073
  top 1 accuracy:		83.13 %
  top 2 accuracy:		99.17 %
0.15707378089427948
0.23596705496311188
0.16562023758888245
Batch of classes 3 out of 5 batches
Epoch 43 of 60 took 1211.598s
  training loss:		0.193955
  validation loss:		0.089136
  top 1 accuracy:		79.94 %
  top 2 accuracy:		98.92 %
0.20565761625766754
0.20819306373596191
0.12981963157653809
Batch of classes 3 out of 5 batches
Epoch 44 of 60 took 1193.987s
  training loss:		0.188746
  validation loss:		0.082414
  top 1 accuracy:		82.02 %
  top 2 accuracy:		99.27 %
0.23395979404449463
0.1902180016040802
0.252971351146698
Batch of classes 3 out of 5 batches
Epoch 45 of 60 took 1211.370s
  training loss:		0.186501
  validation loss:		0.099727
  top 1 accuracy:		77.17 %
  top 2 accuracy:		98.56 %
0.13409222662448883
0.17553548514842987
0.2419874668121338
Batch of classes 3 out of 5 batches
Epoch 46 of 60 took 1203.503s
  training loss:		0.181427
  validation loss:		0.074812
  top 1 accuracy:		83.27 %
  top 2 accuracy:		99.52 %
0.13899581134319305
0.20592635869979858
0.14519014954566956
Batch of classes 3 out of 5 batches
Epoch 47 of 60 took 1121.039s
  training loss:		0.182660
  validation loss:		0.088780
  top 1 accuracy:		80.69 %
  top 2 accuracy:		98.67 %
0.1431131362915039
0.1394677758216858
0.21894028782844543
Batch of classes 3 out of 5 batches
Epoch 48 of 60 took 623.771s
  training loss:		0.173900
  validation loss:		0.086280
  top 1 accuracy:		81.46 %
  top 2 accuracy:		98.81 %
0.19830021262168884
0.18446508049964905
0.1710018515586853
Batch of classes 3 out of 5 batches
Epoch 49 of 60 took 606.847s
  training loss:		0.178263
  validation loss:		0.080293
  top 1 accuracy:		82.17 %
  top 2 accuracy:		98.87 %
0.13072243332862854
0.2123696506023407
0.17168056964874268
Batch of classes 3 out of 5 batches
Epoch 50 of 60 took 596.737s
  training loss:		0.178195
  validation loss:		0.079740
  top 1 accuracy:		82.71 %
  top 2 accuracy:		99.12 %
0.20750531554222107
0.17226460576057434
0.20933686196804047
Batch of classes 3 out of 5 batches
Epoch 51 of 60 took 599.239s
  training loss:		0.170653
  validation loss:		0.076348
  top 1 accuracy:		83.98 %
  top 2 accuracy:		98.69 %
0.21244558691978455
0.21549920737743378
0.1970776915550232
Batch of classes 3 out of 5 batches
Epoch 52 of 60 took 594.712s
  training loss:		0.171737
  validation loss:		0.078716
  top 1 accuracy:		82.79 %
  top 2 accuracy:		99.23 %
0.10532687604427338
0.14863555133342743
0.19218304753303528
Batch of classes 3 out of 5 batches
Epoch 53 of 60 took 588.147s
  training loss:		0.163636
  validation loss:		0.059724
  top 1 accuracy:		87.52 %
  top 2 accuracy:		99.27 %
0.14116939902305603
0.12536707520484924
0.18321651220321655
Batch of classes 3 out of 5 batches
Epoch 54 of 60 took 611.722s
  training loss:		0.164024
  validation loss:		0.084822
  top 1 accuracy:		81.98 %
  top 2 accuracy:		98.69 %
0.12717512249946594
0.1488523781299591
0.12399369478225708
Batch of classes 3 out of 5 batches
Epoch 55 of 60 took 589.432s
  training loss:		0.160654
  validation loss:		0.081626
  top 1 accuracy:		82.71 %
  top 2 accuracy:		99.04 %
0.10377420485019684
0.22052237391471863
0.17485463619232178
Batch of classes 3 out of 5 batches
Epoch 56 of 60 took 590.773s
  training loss:		0.157941
  validation loss:		0.106464
  top 1 accuracy:		77.44 %
  top 2 accuracy:		99.06 %
0.1968858242034912
0.11994867026805878
0.17819306254386902
Batch of classes 3 out of 5 batches
Epoch 57 of 60 took 596.371s
  training loss:		0.151920
  validation loss:		0.072055
  top 1 accuracy:		85.31 %
  top 2 accuracy:		99.08 %
0.17152148485183716
0.14194327592849731
0.08773337304592133
Batch of classes 3 out of 5 batches
Epoch 58 of 60 took 595.148s
  training loss:		0.150770
  validation loss:		0.059450
  top 1 accuracy:		87.71 %
  top 2 accuracy:		99.42 %
0.1822519153356552
0.13612736761569977
0.15581683814525604
Batch of classes 3 out of 5 batches
Epoch 59 of 60 took 594.641s
  training loss:		0.152086
  validation loss:		0.081532
  top 1 accuracy:		83.06 %
  top 2 accuracy:		98.98 %
0.22939875721931458
0.11615414917469025
0.06802798062562943
Batch of classes 3 out of 5 batches
Epoch 60 of 60 took 591.209s
  training loss:		0.142902
  validation loss:		0.100597
  top 1 accuracy:		79.27 %
  top 2 accuracy:		98.85 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(171)
tensor(171)
tensor(171)
tensor(171)
tensor(171)
tensor(171)
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		39.42 %
  top 1 accuracy Hybrid 1       :		40.19 %
  top 1 accuracy NCM            :		42.06 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		51.02 %
  top 1 accuracy Hybrid 1       :		49.75 %
  top 1 accuracy NCM            :		52.85 %
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		43.06 %
  top 1 accuracy Hybrid 1       :		43.85 %
  top 1 accuracy NCM            :		44.06 %
Binary accuracy:
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		52.38 %
  top 1 accuracy Hybrid 1       :		52.04 %
  top 1 accuracy NCM            :		54.06 %
Final results on progan1024 classes:
  top 1 accuracy iCaRL          :		81.17 %
  top 1 accuracy Hybrid 1       :		79.27 %
  top 1 accuracy NCM            :		81.29 %
Binary accuracy:
Final results on progan1024 classes:
  top 1 accuracy iCaRL          :		82.96 %
  top 1 accuracy Hybrid 1       :		79.79 %
  top 1 accuracy NCM            :		83.25 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		54.55 %
  top 1 accuracy Hybrid 1       :		54.44 %
  top 1 accuracy NCM            :		55.81 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		62.12 %
  top 1 accuracy Hybrid 1       :		60.53 %
  top 1 accuracy NCM            :		63.39 %
Classes in this batch: tensor([6, 7])
Data Size: 7200


Before first epoch
  validation loss:		1.430660
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 4 arrives ...
1.1528383493423462
0.18075107038021088
0.1258484274148941
Batch of classes 4 out of 5 batches
Epoch 1 of 60 took 134.690s
  training loss:		0.231409
  validation loss:		0.069646
  top 1 accuracy:		88.29 %
  top 2 accuracy:		98.02 %
0.12218306958675385
0.21973277628421783
0.06903845071792603
Batch of classes 4 out of 5 batches
Epoch 2 of 60 took 93.894s
  training loss:		0.119022
  validation loss:		0.068199
  top 1 accuracy:		89.60 %
  top 2 accuracy:		98.15 %
0.05416435748338699
0.059332847595214844
0.04837367683649063
Batch of classes 4 out of 5 batches
Epoch 3 of 60 took 93.892s
  training loss:		0.092479
  validation loss:		0.049344
  top 1 accuracy:		93.46 %
  top 2 accuracy:		99.27 %
0.21877917647361755
0.05399802327156067
0.09760117530822754
Batch of classes 4 out of 5 batches
Epoch 4 of 60 took 92.651s
  training loss:		0.086355
  validation loss:		0.013055
  top 1 accuracy:		98.35 %
  top 2 accuracy:		99.94 %
0.09366714209318161
0.042610518634319305
0.06816659867763519
Batch of classes 4 out of 5 batches
Epoch 5 of 60 took 92.317s
  training loss:		0.069918
  validation loss:		0.122113
  top 1 accuracy:		78.48 %
  top 2 accuracy:		96.40 %
0.04400385916233063
0.2017272263765335
0.05223923176527023
Batch of classes 4 out of 5 batches
Epoch 6 of 60 took 92.283s
  training loss:		0.070549
  validation loss:		0.054108
  top 1 accuracy:		90.10 %
  top 2 accuracy:		93.27 %
0.04636528342962265
0.0591510534286499
0.029418006539344788
Batch of classes 4 out of 5 batches
Epoch 7 of 60 took 92.175s
  training loss:		0.061630
  validation loss:		0.030165
  top 1 accuracy:		95.83 %
  top 2 accuracy:		98.23 %
0.042808376252651215
0.05313766002655029
0.02532006800174713
Batch of classes 4 out of 5 batches
Epoch 8 of 60 took 93.054s
  training loss:		0.053837
  validation loss:		0.029812
  top 1 accuracy:		96.90 %
  top 2 accuracy:		99.50 %
0.02603752538561821
0.06812746077775955
0.1826971173286438
Batch of classes 4 out of 5 batches
Epoch 9 of 60 took 93.397s
  training loss:		0.055972
  validation loss:		0.047943
  top 1 accuracy:		94.23 %
  top 2 accuracy:		98.92 %
0.05184626579284668
0.06876453757286072
0.11104153096675873
Batch of classes 4 out of 5 batches
Epoch 10 of 60 took 92.812s
  training loss:		0.045131
  validation loss:		0.134575
  top 1 accuracy:		78.19 %
  top 2 accuracy:		96.54 %
0.041358642280101776
0.05388234555721283
0.11533202230930328
Batch of classes 4 out of 5 batches
Epoch 11 of 60 took 92.956s
  training loss:		0.054402
  validation loss:		0.027267
  top 1 accuracy:		96.83 %
  top 2 accuracy:		98.85 %
0.028041649609804153
0.06810595095157623
0.04560016095638275
Batch of classes 4 out of 5 batches
Epoch 12 of 60 took 92.455s
  training loss:		0.050691
  validation loss:		0.041670
  top 1 accuracy:		93.40 %
  top 2 accuracy:		98.62 %
0.017881810665130615
0.054063502699136734
0.022353779524564743
Batch of classes 4 out of 5 batches
Epoch 13 of 60 took 91.897s
  training loss:		0.049975
  validation loss:		0.080466
  top 1 accuracy:		88.27 %
  top 2 accuracy:		96.79 %
0.03269442170858383
0.054019950330257416
0.02930201217532158
Batch of classes 4 out of 5 batches
Epoch 14 of 60 took 93.653s
  training loss:		0.041486
  validation loss:		0.048321
  top 1 accuracy:		93.90 %
  top 2 accuracy:		96.94 %
0.014649365097284317
0.024830348789691925
0.016265973448753357
Batch of classes 4 out of 5 batches
Epoch 15 of 60 took 93.781s
  training loss:		0.046402
  validation loss:		0.357617
  top 1 accuracy:		85.44 %
  top 2 accuracy:		98.21 %
0.07499196380376816
0.03193268924951553
0.03278679400682449
Batch of classes 4 out of 5 batches
Epoch 16 of 60 took 93.114s
  training loss:		0.039355
  validation loss:		0.048855
  top 1 accuracy:		97.15 %
  top 2 accuracy:		99.56 %
0.02345309779047966
0.0901830643415451
0.06170521676540375
Batch of classes 4 out of 5 batches
Epoch 17 of 60 took 92.303s
  training loss:		0.037371
  validation loss:		0.051690
  top 1 accuracy:		91.40 %
  top 2 accuracy:		99.25 %
0.013747192919254303
0.021206963807344437
0.03728991746902466
Batch of classes 4 out of 5 batches
Epoch 18 of 60 took 92.764s
  training loss:		0.038384
  validation loss:		0.017372
  top 1 accuracy:		97.12 %
  top 2 accuracy:		99.73 %
0.02311132475733757
0.08905041217803955
0.007828929461538792
Batch of classes 4 out of 5 batches
Epoch 19 of 60 took 92.266s
  training loss:		0.037540
  validation loss:		0.022490
  top 1 accuracy:		97.60 %
  top 2 accuracy:		99.75 %
0.006858904380351305
0.024047020822763443
0.0015352803748100996
Batch of classes 4 out of 5 batches
Epoch 20 of 60 took 93.499s
  training loss:		0.037364
  validation loss:		0.038616
  top 1 accuracy:		93.73 %
  top 2 accuracy:		98.98 %
0.009099767543375492
0.04156612604856491
0.010919353924691677
Batch of classes 4 out of 5 batches
Epoch 21 of 60 took 92.969s
  training loss:		0.023766
  validation loss:		0.047469
  top 1 accuracy:		97.40 %
  top 2 accuracy:		99.69 %
0.025598689913749695
0.016688624396920204
0.01595454104244709
Batch of classes 4 out of 5 batches
Epoch 22 of 60 took 92.897s
  training loss:		0.022329
  validation loss:		0.029879
  top 1 accuracy:		98.50 %
  top 2 accuracy:		99.73 %
0.024330509826540947
0.0023027295246720314
0.03216069936752319
Batch of classes 4 out of 5 batches
Epoch 23 of 60 took 91.675s
  training loss:		0.017838
  validation loss:		0.033691
  top 1 accuracy:		94.46 %
  top 2 accuracy:		99.40 %
0.007568773813545704
0.037582047283649445
0.01015796884894371
Batch of classes 4 out of 5 batches
Epoch 24 of 60 took 91.820s
  training loss:		0.015207
  validation loss:		0.024459
  top 1 accuracy:		98.00 %
  top 2 accuracy:		99.33 %
0.0014220252633094788
0.011128323152661324
0.01570894569158554
Batch of classes 4 out of 5 batches
Epoch 25 of 60 took 91.881s
  training loss:		0.016187
  validation loss:		0.032573
  top 1 accuracy:		96.42 %
  top 2 accuracy:		98.98 %
0.01938208006322384
0.016875164583325386
0.025051599368453026
Batch of classes 4 out of 5 batches
Epoch 26 of 60 took 93.262s
  training loss:		0.014430
  validation loss:		0.020932
  top 1 accuracy:		98.15 %
  top 2 accuracy:		99.37 %
0.0054688770323991776
0.0054620844312012196
0.0041520921513438225
Batch of classes 4 out of 5 batches
Epoch 27 of 60 took 93.347s
  training loss:		0.015873
  validation loss:		0.022222
  top 1 accuracy:		98.12 %
  top 2 accuracy:		99.52 %
0.023535577580332756
0.0026691993698477745
0.01184602826833725
Batch of classes 4 out of 5 batches
Epoch 28 of 60 took 93.117s
  training loss:		0.016043
  validation loss:		0.017436
  top 1 accuracy:		99.15 %
  top 2 accuracy:		99.85 %
0.027545344084501266
0.006787691731005907
0.018645234405994415
Batch of classes 4 out of 5 batches
Epoch 29 of 60 took 92.367s
  training loss:		0.014332
  validation loss:		0.033456
  top 1 accuracy:		95.40 %
  top 2 accuracy:		98.54 %
0.003885701298713684
0.0033634731080383062
0.026489783078432083
Batch of classes 4 out of 5 batches
Epoch 30 of 60 took 91.848s
  training loss:		0.018370
  validation loss:		0.015929
  top 1 accuracy:		98.77 %
  top 2 accuracy:		99.69 %
0.015328392386436462
0.0159623920917511
0.009100785478949547
Batch of classes 4 out of 5 batches
Epoch 31 of 60 took 91.835s
  training loss:		0.013629
  validation loss:		0.013755
  top 1 accuracy:		98.52 %
  top 2 accuracy:		99.67 %
0.005691038444638252
0.0016140502411872149
0.005832483991980553
Batch of classes 4 out of 5 batches
Epoch 32 of 60 took 92.913s
  training loss:		0.014711
  validation loss:		0.013086
  top 1 accuracy:		98.65 %
  top 2 accuracy:		99.71 %
0.0030003152787685394
0.003337527858093381
0.004376956727355719
Batch of classes 4 out of 5 batches
Epoch 33 of 60 took 92.345s
  training loss:		0.011629
  validation loss:		0.012770
  top 1 accuracy:		99.15 %
  top 2 accuracy:		99.77 %
0.014353172853589058
0.0023598922416567802
0.0052948445081710815
Batch of classes 4 out of 5 batches
Epoch 34 of 60 took 92.841s
  training loss:		0.013407
  validation loss:		0.034745
  top 1 accuracy:		98.81 %
  top 2 accuracy:		99.71 %
0.2426561415195465
0.006076430901885033
0.004074992146342993
Batch of classes 4 out of 5 batches
Epoch 35 of 60 took 91.713s
  training loss:		0.013816
  validation loss:		0.025509
  top 1 accuracy:		98.35 %
  top 2 accuracy:		99.67 %
0.008247592486441135
0.0009616290917620063
0.009322229772806168
Batch of classes 4 out of 5 batches
Epoch 36 of 60 took 89.752s
  training loss:		0.008618
  validation loss:		0.047169
  top 1 accuracy:		97.60 %
  top 2 accuracy:		99.60 %
0.002589559182524681
0.004754777066409588
0.002380015328526497
Batch of classes 4 out of 5 batches
Epoch 37 of 60 took 90.185s
  training loss:		0.012939
  validation loss:		0.026671
  top 1 accuracy:		97.10 %
  top 2 accuracy:		99.48 %
0.005765452980995178
0.008208822458982468
0.0018650967394933105
Batch of classes 4 out of 5 batches
Epoch 38 of 60 took 90.845s
  training loss:		0.009393
  validation loss:		0.093639
  top 1 accuracy:		91.40 %
  top 2 accuracy:		97.67 %
0.0032195630483329296
0.018945541232824326
0.0014870197046548128
Batch of classes 4 out of 5 batches
Epoch 39 of 60 took 91.884s
  training loss:		0.008676
  validation loss:		0.016197
  top 1 accuracy:		98.73 %
  top 2 accuracy:		99.67 %
0.0038641965948045254
0.003079865127801895
0.014798778109252453
Batch of classes 4 out of 5 batches
Epoch 40 of 60 took 91.282s
  training loss:		0.008969
  validation loss:		0.018424
  top 1 accuracy:		98.23 %
  top 2 accuracy:		99.67 %
0.0027463887818157673
0.0014230310916900635
0.0004919788334518671
Batch of classes 4 out of 5 batches
Epoch 41 of 60 took 90.570s
  training loss:		0.006117
  validation loss:		0.012238
  top 1 accuracy:		98.60 %
  top 2 accuracy:		99.79 %
0.0021285288967192173
0.00948930811136961
0.006470357999205589
Batch of classes 4 out of 5 batches
Epoch 42 of 60 took 89.814s
  training loss:		0.005469
  validation loss:		0.028592
  top 1 accuracy:		98.77 %
  top 2 accuracy:		99.75 %
0.0003888601204380393
0.0015661184443160892
0.0076645053923130035
Batch of classes 4 out of 5 batches
Epoch 43 of 60 took 90.111s
  training loss:		0.006298
  validation loss:		0.020528
  top 1 accuracy:		97.98 %
  top 2 accuracy:		99.54 %
0.02389751374721527
0.00245246896520257
0.0037780730053782463
Batch of classes 4 out of 5 batches
Epoch 44 of 60 took 89.645s
  training loss:		0.005552
  validation loss:		0.013135
  top 1 accuracy:		99.10 %
  top 2 accuracy:		99.90 %
0.002110668458044529
0.012248839251697063
0.0033199163153767586
Batch of classes 4 out of 5 batches
Epoch 45 of 60 took 90.928s
  training loss:		0.006641
  validation loss:		0.030784
  top 1 accuracy:		98.40 %
  top 2 accuracy:		99.60 %
0.006131683476269245
0.0008720472687855363
0.01379434671252966
Batch of classes 4 out of 5 batches
Epoch 46 of 60 took 90.646s
  training loss:		0.005995
  validation loss:		0.021192
  top 1 accuracy:		98.54 %
  top 2 accuracy:		99.73 %
0.0022409912198781967
0.0005179255385883152
0.00249207834713161
Batch of classes 4 out of 5 batches
Epoch 47 of 60 took 91.035s
  training loss:		0.003342
  validation loss:		0.024017
  top 1 accuracy:		99.00 %
  top 2 accuracy:		99.77 %
0.002654919633641839
0.0038142255507409573
0.00036358239594846964
Batch of classes 4 out of 5 batches
Epoch 48 of 60 took 90.290s
  training loss:		0.004438
  validation loss:		0.013577
  top 1 accuracy:		99.08 %
  top 2 accuracy:		99.83 %
0.004641169216483831
0.0009058538125827909
0.0008649108931422234
Batch of classes 4 out of 5 batches
Epoch 49 of 60 took 90.057s
  training loss:		0.005455
  validation loss:		0.017074
  top 1 accuracy:		98.04 %
  top 2 accuracy:		99.46 %
0.0014208966167643666
0.0012280927039682865
0.0005147010087966919
Batch of classes 4 out of 5 batches
Epoch 50 of 60 took 90.716s
  training loss:		0.004296
  validation loss:		0.016037
  top 1 accuracy:		97.79 %
  top 2 accuracy:		99.52 %
0.0005994519451633096
0.010634382255375385
0.0005498292157426476
Batch of classes 4 out of 5 batches
Epoch 51 of 60 took 91.267s
  training loss:		0.008840
  validation loss:		0.048976
  top 1 accuracy:		97.67 %
  top 2 accuracy:		99.46 %
0.00015906855696812272
0.0009947946527972817
0.00023539899848401546
Batch of classes 4 out of 5 batches
Epoch 52 of 60 took 91.082s
  training loss:		0.003792
  validation loss:		0.012978
  top 1 accuracy:		98.94 %
  top 2 accuracy:		99.75 %
0.017425281926989555
0.0011661092285066843
0.00023343649809248745
Batch of classes 4 out of 5 batches
Epoch 53 of 60 took 90.877s
  training loss:		0.006111
  validation loss:		0.009751
  top 1 accuracy:		99.04 %
  top 2 accuracy:		99.83 %
0.0001816743751987815
0.007100037299096584
0.0006272174650803208
Batch of classes 4 out of 5 batches
Epoch 54 of 60 took 89.395s
  training loss:		0.004011
  validation loss:		0.011675
  top 1 accuracy:		99.10 %
  top 2 accuracy:		99.85 %
0.012777945026755333
7.309469219762832e-05
0.004476204514503479
Batch of classes 4 out of 5 batches
Epoch 55 of 60 took 89.646s
  training loss:		0.002974
  validation loss:		0.009593
  top 1 accuracy:		99.02 %
  top 2 accuracy:		99.77 %
0.0020924010314047337
0.000810464785899967
0.00028304310399107635
Batch of classes 4 out of 5 batches
Epoch 56 of 60 took 89.894s
  training loss:		0.003269
  validation loss:		0.012102
  top 1 accuracy:		99.15 %
  top 2 accuracy:		99.77 %
0.0009647277183830738
0.004843269009143114
0.0020049798768013716
Batch of classes 4 out of 5 batches
Epoch 57 of 60 took 90.461s
  training loss:		0.003502
  validation loss:		0.016384
  top 1 accuracy:		99.04 %
  top 2 accuracy:		99.81 %
0.0005071196355856955
0.0012742702383548021
0.0015148511156439781
Batch of classes 4 out of 5 batches
Epoch 58 of 60 took 90.877s
  training loss:		0.002857
  validation loss:		0.015345
  top 1 accuracy:		99.21 %
  top 2 accuracy:		99.83 %
0.001073195249773562
0.0037003876641392708
0.0002610045194160193
Batch of classes 4 out of 5 batches
Epoch 59 of 60 took 91.189s
  training loss:		0.002603
  validation loss:		0.018343
  top 1 accuracy:		98.77 %
  top 2 accuracy:		99.62 %
0.0029489328153431416
9.122428309638053e-05
0.009300312027335167
Batch of classes 4 out of 5 batches
Epoch 60 of 60 took 90.217s
  training loss:		0.005249
  validation loss:		0.013907
  top 1 accuracy:		99.21 %
  top 2 accuracy:		99.81 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		58.40 %
  top 1 accuracy Hybrid 1       :		56.50 %
  top 1 accuracy NCM            :		61.40 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		62.60 %
  top 1 accuracy Hybrid 1       :		62.67 %
  top 1 accuracy NCM            :		65.23 %
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		96.42 %
  top 1 accuracy Hybrid 1       :		95.42 %
  top 1 accuracy NCM            :		96.10 %
Binary accuracy:
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		97.21 %
  top 1 accuracy Hybrid 1       :		96.08 %
  top 1 accuracy NCM            :		96.94 %
Final results on progan1024 classes:
  top 1 accuracy iCaRL          :		83.02 %
  top 1 accuracy Hybrid 1       :		66.50 %
  top 1 accuracy NCM            :		82.81 %
Binary accuracy:
Final results on progan1024 classes:
  top 1 accuracy iCaRL          :		88.48 %
  top 1 accuracy Hybrid 1       :		84.56 %
  top 1 accuracy NCM            :		88.56 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		97.52 %
  top 1 accuracy Hybrid 1       :		99.21 %
  top 1 accuracy NCM            :		97.48 %
Binary accuracy:
Final results on glow classes:
  top 1 accuracy iCaRL          :		99.54 %
  top 1 accuracy Hybrid 1       :		99.52 %
  top 1 accuracy NCM            :		99.50 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		83.84 %
  top 1 accuracy Hybrid 1       :		79.41 %
  top 1 accuracy NCM            :		84.45 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		86.96 %
  top 1 accuracy Hybrid 1       :		85.71 %
  top 1 accuracy NCM            :		87.56 %
Classes in this batch: tensor([8, 9])
Data Size: 7200


Before first epoch
  validation loss:		1.956363
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.23 %
Batch of classes number 5 arrives ...
Traceback (most recent call last):
  File "main_icarl_CNND.py", line 580, in <module>
    main()
  File "main_icarl_CNND.py", line 324, in main
    for patterns, labels in train_loader:  # Line 151
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 352, in __iter__
    return self._get_iterator()
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 294, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 801, in __init__
    w.start()
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/popen_fork.py", line 70, in _launch
    self.pid = os.fork()
OSError: [Errno 12] Cannot allocate memory
