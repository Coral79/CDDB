----------------- Options ---------------
               add_binary: True                          	[default: False]
               batch_size: 32                            	[default: 64]
                   binary: False                         
              binary_loss: sum_b_log                     	[default: sum_b_sig]
            binary_weight: 0.3                           	[default: 0.5]
                blur_prob: 0                             
                 blur_sig: 0.5                           
          checkpoints_dir: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL/checkpoints	[default: ./checkpoints]
                class_bal: False                         
           continue_train: False                         
                 cropSize: 224                           
                 data_aug: False                         
                 dataroot: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/DoGAN_data/new/GanFake	[default: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL]
          earlystop_epoch: 5                             
                    epoch: latest                        
                 fine_tun: False                         
                    gpuid: [1]                           
                init_gain: 0.02                          
                  init_lr: 0.001                         	[default: 0.0005]
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2                           
                 jpg_prob: 0                             
                 jpg_qual: 75                            
          label_smoothing: False                         
                 loadSize: 256                           
                    mixup: False                         
              mixup_alpha: 0.1                           
                     mode: binary                        
               model_name: resnet18                      
               model_type: resnet                        
            model_weights: None                          
               multiclass: [1, 1, 0, 1, 1]               	[default: [1]]
                     name: icarl_ganfake_1024_sum_log03  	[default: experiment_name]
                nb_protos: 1024                          	[default: 128]
                  no_flip: False                         
              num_classes: 2                             
               num_epochs: 60                            	[default: 12]
              num_threads: 4                             
                  outfile: temp_0.1.csv                  
            pretrain_name:                               
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 20                            
         save_latest_freq: 2000                          
                 schedule: [20, 40, 60]                  	[default: [10]]
           serial_batches: False                         
          smoothing_alpha: 0.1                           
                   suffix:                               
                task_name: cyclegan,progan256,progan1024,glow,stargan	[default: ]
              train_split: train                         
                val_split: val                           
----------------- End -------------------
{'All': 10}
Task order: ['cyclegan', 'progan256', 'progan1024', 'glow', 'stargan']
Classes in this batch: tensor([0, 1])
Data Size: 7196


Before first epoch
  validation loss:		0.651198
  top 1 accuracy:		41.60 %
  top 2 accuracy:		55.37 %
Batch of classes number 1 arrives ...
0.40246689319610596
0.1774301528930664
0.18677376210689545
Batch of classes 1 out of 5 batches
Epoch 1 of 60 took 192.670s
  training loss:		0.197994
  validation loss:		0.073177
  top 1 accuracy:		80.12 %
  top 2 accuracy:		100.00 %
0.17095181345939636
0.17325429618358612
0.22760599851608276
Batch of classes 1 out of 5 batches
Epoch 2 of 60 took 82.214s
  training loss:		0.184019
  validation loss:		0.119409
  top 1 accuracy:		76.69 %
  top 2 accuracy:		100.00 %
0.17754526436328888
0.15440843999385834
0.1727120578289032
Batch of classes 1 out of 5 batches
Epoch 3 of 60 took 82.343s
  training loss:		0.171816
  validation loss:		0.300267
  top 1 accuracy:		71.15 %
  top 2 accuracy:		100.00 %
0.15840041637420654
0.17986200749874115
0.14967839419841766
Batch of classes 1 out of 5 batches
Epoch 4 of 60 took 81.499s
  training loss:		0.167164
  validation loss:		0.181749
  top 1 accuracy:		75.02 %
  top 2 accuracy:		100.00 %
0.15878178179264069
0.16001078486442566
0.1748599112033844
Batch of classes 1 out of 5 batches
Epoch 5 of 60 took 81.811s
  training loss:		0.161211
  validation loss:		0.320979
  top 1 accuracy:		74.52 %
  top 2 accuracy:		100.00 %
0.16004467010498047
0.16319887340068817
0.15288323163986206
Batch of classes 1 out of 5 batches
Epoch 6 of 60 took 82.507s
  training loss:		0.159511
  validation loss:		0.210148
  top 1 accuracy:		75.65 %
  top 2 accuracy:		100.00 %
0.152931347489357
0.1495990753173828
0.14326073229312897
Batch of classes 1 out of 5 batches
Epoch 7 of 60 took 81.660s
  training loss:		0.156732
  validation loss:		0.130647
  top 1 accuracy:		78.02 %
  top 2 accuracy:		100.00 %
0.14815330505371094
0.1504743993282318
0.14061500132083893
Batch of classes 1 out of 5 batches
Epoch 8 of 60 took 82.053s
  training loss:		0.152188
  validation loss:		0.227235
  top 1 accuracy:		75.52 %
  top 2 accuracy:		99.94 %
0.1435883492231369
0.16068428754806519
0.14872406423091888
Batch of classes 1 out of 5 batches
Epoch 9 of 60 took 82.104s
  training loss:		0.151915
  validation loss:		0.318262
  top 1 accuracy:		74.25 %
  top 2 accuracy:		98.77 %
0.14257240295410156
0.1630711853504181
0.16235922276973724
Batch of classes 1 out of 5 batches
Epoch 10 of 60 took 81.558s
  training loss:		0.151806
  validation loss:		1.389722
  top 1 accuracy:		75.79 %
  top 2 accuracy:		86.96 %
0.17901678383350372
0.1532549411058426
0.14866569638252258
Batch of classes 1 out of 5 batches
Epoch 11 of 60 took 82.463s
  training loss:		0.150114
  validation loss:		0.335013
  top 1 accuracy:		75.46 %
  top 2 accuracy:		96.25 %
0.18016059696674347
0.1432710587978363
0.14139299094676971
Batch of classes 1 out of 5 batches
Epoch 12 of 60 took 82.134s
  training loss:		0.147756
  validation loss:		0.561667
  top 1 accuracy:		75.19 %
  top 2 accuracy:		90.25 %
0.14583352208137512
0.1412551999092102
0.14358556270599365
Batch of classes 1 out of 5 batches
Epoch 13 of 60 took 82.129s
  training loss:		0.148481
  validation loss:		0.229561
  top 1 accuracy:		76.19 %
  top 2 accuracy:		99.17 %
0.14577695727348328
0.1396375298500061
0.14049962162971497
Batch of classes 1 out of 5 batches
Epoch 14 of 60 took 81.806s
  training loss:		0.147728
  validation loss:		0.140599
  top 1 accuracy:		77.67 %
  top 2 accuracy:		99.98 %
0.1396489292383194
0.1405012011528015
0.14329896867275238
Batch of classes 1 out of 5 batches
Epoch 15 of 60 took 83.087s
  training loss:		0.147627
  validation loss:		0.416103
  top 1 accuracy:		74.79 %
  top 2 accuracy:		95.54 %
0.15626119077205658
0.14190217852592468
0.14312192797660828
Batch of classes 1 out of 5 batches
Epoch 16 of 60 took 82.155s
  training loss:		0.147636
  validation loss:		0.498016
  top 1 accuracy:		75.00 %
  top 2 accuracy:		94.25 %
0.15907806158065796
0.14284268021583557
0.13989445567131042
Batch of classes 1 out of 5 batches
Epoch 17 of 60 took 82.120s
  training loss:		0.146565
  validation loss:		0.300002
  top 1 accuracy:		75.02 %
  top 2 accuracy:		98.15 %
0.15506325662136078
0.14475728571414948
0.14501802623271942
Batch of classes 1 out of 5 batches
Epoch 18 of 60 took 81.703s
  training loss:		0.149120
  validation loss:		0.220404
  top 1 accuracy:		79.73 %
  top 2 accuracy:		99.58 %
0.14579243957996368
0.1509428322315216
0.14146684110164642
Batch of classes 1 out of 5 batches
Epoch 19 of 60 took 82.157s
  training loss:		0.145870
  validation loss:		0.348872
  top 1 accuracy:		75.15 %
  top 2 accuracy:		98.56 %
0.20212909579277039
0.1392594426870346
0.14560531079769135
Batch of classes 1 out of 5 batches
Epoch 20 of 60 took 82.028s
  training loss:		0.146934
  validation loss:		0.378939
  top 1 accuracy:		75.08 %
  top 2 accuracy:		98.42 %
0.1383962482213974
0.13629598915576935
0.14864933490753174
Batch of classes 1 out of 5 batches
Epoch 21 of 60 took 82.378s
  training loss:		0.140679
  validation loss:		0.302575
  top 1 accuracy:		75.13 %
  top 2 accuracy:		99.96 %
0.13632933795452118
0.13833913207054138
0.13512831926345825
Batch of classes 1 out of 5 batches
Epoch 22 of 60 took 83.167s
  training loss:		0.138749
  validation loss:		0.332264
  top 1 accuracy:		75.21 %
  top 2 accuracy:		99.58 %
0.13595710694789886
0.13936053216457367
0.13754449784755707
Batch of classes 1 out of 5 batches
Epoch 23 of 60 took 81.733s
  training loss:		0.138461
  validation loss:		0.426161
  top 1 accuracy:		75.23 %
  top 2 accuracy:		96.75 %
0.13615809381008148
0.1378396898508072
0.1389298290014267
Batch of classes 1 out of 5 batches
Epoch 24 of 60 took 82.828s
  training loss:		0.137370
  validation loss:		0.431808
  top 1 accuracy:		75.19 %
  top 2 accuracy:		96.31 %
0.13465337455272675
0.13629405200481415
0.1381806582212448
Batch of classes 1 out of 5 batches
Epoch 25 of 60 took 82.029s
  training loss:		0.137793
  validation loss:		0.503071
  top 1 accuracy:		75.04 %
  top 2 accuracy:		94.44 %
0.13459162414073944
0.13850022852420807
0.13479062914848328
Batch of classes 1 out of 5 batches
Epoch 26 of 60 took 81.862s
  training loss:		0.138492
  validation loss:		0.575336
  top 1 accuracy:		75.04 %
  top 2 accuracy:		92.92 %
0.1357615441083908
0.13510747253894806
0.1341995745897293
Batch of classes 1 out of 5 batches
Epoch 27 of 60 took 82.369s
  training loss:		0.137783
  validation loss:		0.434033
  top 1 accuracy:		75.17 %
  top 2 accuracy:		96.73 %
0.14047160744667053
0.13920371234416962
0.13333682715892792
Batch of classes 1 out of 5 batches
Epoch 28 of 60 took 82.646s
  training loss:		0.136006
  validation loss:		0.336313
  top 1 accuracy:		75.50 %
  top 2 accuracy:		98.92 %
0.1348508596420288
0.1332308053970337
0.14940997958183289
Batch of classes 1 out of 5 batches
Epoch 29 of 60 took 82.784s
  training loss:		0.136178
  validation loss:		0.483582
  top 1 accuracy:		74.94 %
  top 2 accuracy:		92.25 %
0.13439664244651794
0.13435138761997223
0.1379096359014511
Batch of classes 1 out of 5 batches
Epoch 30 of 60 took 83.130s
  training loss:		0.136645
  validation loss:		0.354641
  top 1 accuracy:		75.33 %
  top 2 accuracy:		97.65 %
0.13619530200958252
0.13470661640167236
0.1334862858057022
Batch of classes 1 out of 5 batches
Epoch 31 of 60 took 82.015s
  training loss:		0.136428
  validation loss:		0.365489
  top 1 accuracy:		75.06 %
  top 2 accuracy:		99.25 %
0.13408805429935455
0.13365766406059265
0.13891692459583282
Batch of classes 1 out of 5 batches
Epoch 32 of 60 took 82.947s
  training loss:		0.135631
  validation loss:		0.407366
  top 1 accuracy:		75.21 %
  top 2 accuracy:		97.02 %
0.13424094021320343
0.1337512731552124
0.1328682154417038
Batch of classes 1 out of 5 batches
Epoch 33 of 60 took 82.350s
  training loss:		0.135754
  validation loss:		0.334935
  top 1 accuracy:		76.13 %
  top 2 accuracy:		98.35 %
0.13318435847759247
0.14331501722335815
0.1351383775472641
Batch of classes 1 out of 5 batches
Epoch 34 of 60 took 83.208s
  training loss:		0.136353
  validation loss:		0.522433
  top 1 accuracy:		75.00 %
  top 2 accuracy:		91.15 %
0.13226142525672913
0.13247832655906677
0.13338594138622284
Batch of classes 1 out of 5 batches
Epoch 35 of 60 took 82.292s
  training loss:		0.134539
  validation loss:		0.234237
  top 1 accuracy:		78.02 %
  top 2 accuracy:		99.48 %
0.13781701028347015
0.13199470937252045
0.13757608830928802
Batch of classes 1 out of 5 batches
Epoch 36 of 60 took 83.024s
  training loss:		0.134848
  validation loss:		0.492253
  top 1 accuracy:		75.15 %
  top 2 accuracy:		92.54 %
0.13198308646678925
0.13593906164169312
0.13227258622646332
Batch of classes 1 out of 5 batches
Epoch 37 of 60 took 83.705s
  training loss:		0.134732
  validation loss:		0.306203
  top 1 accuracy:		75.48 %
  top 2 accuracy:		99.40 %
0.15046371519565582
0.15666048228740692
0.1438150554895401
Batch of classes 1 out of 5 batches
Epoch 38 of 60 took 82.271s
  training loss:		0.136321
  validation loss:		0.446380
  top 1 accuracy:		75.00 %
  top 2 accuracy:		94.67 %
0.13286706805229187
0.1334390938282013
0.13799867033958435
Batch of classes 1 out of 5 batches
Epoch 39 of 60 took 82.762s
  training loss:		0.134612
  validation loss:		0.237909
  top 1 accuracy:		76.10 %
  top 2 accuracy:		99.50 %
0.13614240288734436
0.13440999388694763
0.1342654526233673
Batch of classes 1 out of 5 batches
Epoch 40 of 60 took 83.427s
  training loss:		0.135253
  validation loss:		0.318567
  top 1 accuracy:		75.31 %
  top 2 accuracy:		99.23 %
0.13366277515888214
0.13439586758613586
0.1331007033586502
Batch of classes 1 out of 5 batches
Epoch 41 of 60 took 82.668s
  training loss:		0.133830
  validation loss:		0.313164
  top 1 accuracy:		75.35 %
  top 2 accuracy:		99.15 %
0.13173529505729675
0.1321038156747818
0.1335357129573822
Batch of classes 1 out of 5 batches
Epoch 42 of 60 took 82.735s
  training loss:		0.133500
  validation loss:		0.328086
  top 1 accuracy:		75.13 %
  top 2 accuracy:		99.10 %
0.13291090726852417
0.13133826851844788
0.13230113685131073
Batch of classes 1 out of 5 batches
Epoch 43 of 60 took 82.654s
  training loss:		0.132700
  validation loss:		0.232022
  top 1 accuracy:		76.81 %
  top 2 accuracy:		99.79 %
0.1316874921321869
0.13094550371170044
0.13254860043525696
Batch of classes 1 out of 5 batches
Epoch 44 of 60 took 83.709s
  training loss:		0.132448
  validation loss:		0.259476
  top 1 accuracy:		76.60 %
  top 2 accuracy:		99.29 %
0.13131199777126312
0.13139256834983826
0.1302456259727478
Batch of classes 1 out of 5 batches
Epoch 45 of 60 took 83.324s
  training loss:		0.132555
  validation loss:		0.102799
  top 1 accuracy:		84.23 %
  top 2 accuracy:		99.98 %
0.13411791622638702
0.13245336711406708
0.13588447868824005
Batch of classes 1 out of 5 batches
Epoch 46 of 60 took 83.026s
  training loss:		0.132632
  validation loss:		0.462147
  top 1 accuracy:		75.04 %
  top 2 accuracy:		93.54 %
0.13336190581321716
0.13028964400291443
0.13079243898391724
Batch of classes 1 out of 5 batches
Epoch 47 of 60 took 83.400s
  training loss:		0.131846
  validation loss:		0.414860
  top 1 accuracy:		75.13 %
  top 2 accuracy:		95.00 %
0.13125154376029968
0.13076569139957428
0.13206486403942108
Batch of classes 1 out of 5 batches
Epoch 48 of 60 took 83.005s
  training loss:		0.131700
  validation loss:		0.345268
  top 1 accuracy:		75.44 %
  top 2 accuracy:		97.40 %
0.1320219486951828
0.13046468794345856
0.13060295581817627
Batch of classes 1 out of 5 batches
Epoch 49 of 60 took 82.738s
  training loss:		0.132083
  validation loss:		0.237965
  top 1 accuracy:		76.65 %
  top 2 accuracy:		99.73 %
0.13169845938682556
0.13110268115997314
0.13194237649440765
Batch of classes 1 out of 5 batches
Epoch 50 of 60 took 81.925s
  training loss:		0.132826
  validation loss:		0.302545
  top 1 accuracy:		75.35 %
  top 2 accuracy:		99.60 %
0.13234134018421173
0.13130740821361542
0.13115519285202026
Batch of classes 1 out of 5 batches
Epoch 51 of 60 took 82.463s
  training loss:		0.132225
  validation loss:		0.431327
  top 1 accuracy:		75.13 %
  top 2 accuracy:		95.15 %
0.13148713111877441
0.13231010735034943
0.13135874271392822
Batch of classes 1 out of 5 batches
Epoch 52 of 60 took 82.076s
  training loss:		0.131891
  validation loss:		0.432017
  top 1 accuracy:		75.17 %
  top 2 accuracy:		95.69 %
0.13264796137809753
0.13553622364997864
0.13250166177749634
Batch of classes 1 out of 5 batches
Epoch 53 of 60 took 82.755s
  training loss:		0.131809
  validation loss:		0.286382
  top 1 accuracy:		75.88 %
  top 2 accuracy:		99.52 %
0.13189706206321716
0.13039584457874298
0.13125991821289062
Batch of classes 1 out of 5 batches
Epoch 54 of 60 took 82.917s
  training loss:		0.131494
  validation loss:		0.347611
  top 1 accuracy:		75.40 %
  top 2 accuracy:		98.23 %
0.1316530555486679
0.13128814101219177
0.131806880235672
Batch of classes 1 out of 5 batches
Epoch 55 of 60 took 83.217s
  training loss:		0.132058
  validation loss:		0.346754
  top 1 accuracy:		75.38 %
  top 2 accuracy:		98.87 %
0.1309361606836319
0.13016894459724426
0.1306256800889969
Batch of classes 1 out of 5 batches
Epoch 56 of 60 took 82.796s
  training loss:		0.131195
  validation loss:		0.386524
  top 1 accuracy:		75.21 %
  top 2 accuracy:		96.50 %
0.13119156658649445
0.1312432885169983
0.13130511343479156
Batch of classes 1 out of 5 batches
Epoch 57 of 60 took 82.985s
  training loss:		0.131435
  validation loss:		0.397446
  top 1 accuracy:		75.06 %
  top 2 accuracy:		97.31 %
0.13133549690246582
0.13192243874073029
0.13075663149356842
Batch of classes 1 out of 5 batches
Epoch 58 of 60 took 82.863s
  training loss:		0.131403
  validation loss:		0.345148
  top 1 accuracy:		75.29 %
  top 2 accuracy:		98.65 %
0.1303054839372635
0.13137482106685638
0.13101379573345184
Batch of classes 1 out of 5 batches
Epoch 59 of 60 took 83.369s
  training loss:		0.131445
  validation loss:		0.366839
  top 1 accuracy:		75.38 %
  top 2 accuracy:		97.35 %
0.13096226751804352
0.13062544167041779
0.13103389739990234
Batch of classes 1 out of 5 batches
Epoch 60 of 60 took 81.503s
  training loss:		0.131421
  validation loss:		0.438448
  top 1 accuracy:		75.10 %
  top 2 accuracy:		95.77 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(430)
tensor(500)
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		75.17 %
  top 1 accuracy Hybrid 1       :		75.10 %
  top 1 accuracy NCM            :		75.17 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		75.17 %
  top 1 accuracy Hybrid 1       :		75.10 %
  top 1 accuracy NCM            :		75.17 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		75.17 %
  top 1 accuracy Hybrid 1       :		75.10 %
  top 1 accuracy NCM            :		75.17 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		75.17 %
  top 1 accuracy Hybrid 1       :		75.10 %
  top 1 accuracy NCM            :		75.17 %
Classes in this batch: tensor([2, 3])
Data Size: 7200


Before first epoch
  validation loss:		3.745172
  top 1 accuracy:		0.00 %
  top 2 accuracy:		44.12 %
Batch of classes number 2 arrives ...
1.0134236812591553
0.25526320934295654
0.2824011445045471
Batch of classes 2 out of 5 batches
Epoch 1 of 60 took 142.057s
  training loss:		0.288268
  validation loss:		0.150251
  top 1 accuracy:		56.73 %
  top 2 accuracy:		97.56 %
0.25288882851600647
0.245481938123703
0.2370263934135437
Batch of classes 2 out of 5 batches
Epoch 2 of 60 took 98.208s
  training loss:		0.245082
  validation loss:		0.129605
  top 1 accuracy:		67.71 %
  top 2 accuracy:		98.33 %
0.23884861171245575
0.2246095836162567
0.2221100628376007
Batch of classes 2 out of 5 batches
Epoch 3 of 60 took 98.114s
  training loss:		0.232387
  validation loss:		0.086719
  top 1 accuracy:		81.44 %
  top 2 accuracy:		99.92 %
0.2313382923603058
0.2186601459980011
0.2027670443058014
Batch of classes 2 out of 5 batches
Epoch 4 of 60 took 98.568s
  training loss:		0.207230
  validation loss:		0.044055
  top 1 accuracy:		92.69 %
  top 2 accuracy:		99.67 %
0.1759020835161209
0.16768169403076172
0.19131125509738922
Batch of classes 2 out of 5 batches
Epoch 5 of 60 took 98.279s
  training loss:		0.193203
  validation loss:		0.049465
  top 1 accuracy:		91.46 %
  top 2 accuracy:		99.33 %
0.1888619214296341
0.20366306602954865
0.2115415632724762
Batch of classes 2 out of 5 batches
Epoch 6 of 60 took 97.655s
  training loss:		0.179677
  validation loss:		0.063593
  top 1 accuracy:		87.00 %
  top 2 accuracy:		99.02 %
0.2004743218421936
0.15342892706394196
0.23487555980682373
Batch of classes 2 out of 5 batches
Epoch 7 of 60 took 98.167s
  training loss:		0.165778
  validation loss:		0.011606
  top 1 accuracy:		98.25 %
  top 2 accuracy:		99.79 %
0.14593738317489624
0.14891821146011353
0.17798782885074615
Batch of classes 2 out of 5 batches
Epoch 8 of 60 took 98.410s
  training loss:		0.157770
  validation loss:		0.057029
  top 1 accuracy:		88.35 %
  top 2 accuracy:		97.54 %
0.15238505601882935
0.15980826318264008
0.14479926228523254
Batch of classes 2 out of 5 batches
Epoch 9 of 60 took 97.602s
  training loss:		0.155309
  validation loss:		0.013806
  top 1 accuracy:		98.00 %
  top 2 accuracy:		99.60 %
0.1594221442937851
0.13615988194942474
0.14554962515830994
Batch of classes 2 out of 5 batches
Epoch 10 of 60 took 97.347s
  training loss:		0.154671
  validation loss:		0.075775
  top 1 accuracy:		90.27 %
  top 2 accuracy:		99.52 %
0.18167327344417572
0.16880430281162262
0.14410622417926788
Batch of classes 2 out of 5 batches
Epoch 11 of 60 took 97.863s
  training loss:		0.153347
  validation loss:		0.019316
  top 1 accuracy:		96.31 %
  top 2 accuracy:		99.73 %
0.14850321412086487
0.14024914801120758
0.14674296975135803
Batch of classes 2 out of 5 batches
Epoch 12 of 60 took 98.148s
  training loss:		0.153757
  validation loss:		0.015635
  top 1 accuracy:		97.65 %
  top 2 accuracy:		99.79 %
0.14122453331947327
0.13952377438545227
0.1476566344499588
Batch of classes 2 out of 5 batches
Epoch 13 of 60 took 97.219s
  training loss:		0.150941
  validation loss:		0.005180
  top 1 accuracy:		99.40 %
  top 2 accuracy:		99.98 %
0.14832161366939545
0.1482754945755005
0.14953939616680145
Batch of classes 2 out of 5 batches
Epoch 14 of 60 took 98.481s
  training loss:		0.151133
  validation loss:		0.011380
  top 1 accuracy:		98.06 %
  top 2 accuracy:		99.85 %
0.15530139207839966
0.1434696465730667
0.15182287991046906
Batch of classes 2 out of 5 batches
Epoch 15 of 60 took 97.740s
  training loss:		0.147498
  validation loss:		0.030914
  top 1 accuracy:		93.94 %
  top 2 accuracy:		99.37 %
0.13558639585971832
0.1543789654970169
0.16842718422412872
Batch of classes 2 out of 5 batches
Epoch 16 of 60 took 98.314s
  training loss:		0.149070
  validation loss:		0.019631
  top 1 accuracy:		96.73 %
  top 2 accuracy:		99.56 %
0.20186203718185425
0.13683854043483734
0.16882872581481934
Batch of classes 2 out of 5 batches
Epoch 17 of 60 took 98.170s
  training loss:		0.151676
  validation loss:		0.010576
  top 1 accuracy:		98.06 %
  top 2 accuracy:		99.87 %
0.13674034178256989
0.1359705626964569
0.14046329259872437
Batch of classes 2 out of 5 batches
Epoch 18 of 60 took 97.797s
  training loss:		0.148329
  validation loss:		0.036791
  top 1 accuracy:		92.62 %
  top 2 accuracy:		98.71 %
0.14494061470031738
0.13875555992126465
0.14470122754573822
Batch of classes 2 out of 5 batches
Epoch 19 of 60 took 99.429s
  training loss:		0.147032
  validation loss:		0.023851
  top 1 accuracy:		95.73 %
  top 2 accuracy:		99.21 %
0.14412514865398407
0.16338901221752167
0.15423187613487244
Batch of classes 2 out of 5 batches
Epoch 20 of 60 took 98.468s
  training loss:		0.153003
  validation loss:		0.009518
  top 1 accuracy:		98.42 %
  top 2 accuracy:		99.65 %
0.1408941000699997
0.13697445392608643
0.1458645462989807
Batch of classes 2 out of 5 batches
Epoch 21 of 60 took 99.400s
  training loss:		0.141317
  validation loss:		0.009881
  top 1 accuracy:		97.90 %
  top 2 accuracy:		100.00 %
0.14250728487968445
0.13637171685695648
0.13737979531288147
Batch of classes 2 out of 5 batches
Epoch 22 of 60 took 99.013s
  training loss:		0.139326
  validation loss:		0.004876
  top 1 accuracy:		99.31 %
  top 2 accuracy:		99.87 %
0.13707678020000458
0.13510800898075104
0.13791228830814362
Batch of classes 2 out of 5 batches
Epoch 23 of 60 took 99.270s
  training loss:		0.139035
  validation loss:		0.005474
  top 1 accuracy:		99.10 %
  top 2 accuracy:		99.90 %
0.13258644938468933
0.14139482378959656
0.1353183537721634
Batch of classes 2 out of 5 batches
Epoch 24 of 60 took 100.186s
  training loss:		0.138304
  validation loss:		0.004803
  top 1 accuracy:		99.35 %
  top 2 accuracy:		100.00 %
0.13810166716575623
0.1382228583097458
0.14250831305980682
Batch of classes 2 out of 5 batches
Epoch 25 of 60 took 98.571s
  training loss:		0.139022
  validation loss:		0.001881
  top 1 accuracy:		99.71 %
  top 2 accuracy:		100.00 %
0.13282528519630432
0.13818982243537903
0.1400534212589264
Batch of classes 2 out of 5 batches
Epoch 26 of 60 took 99.405s
  training loss:		0.137650
  validation loss:		0.015719
  top 1 accuracy:		96.88 %
  top 2 accuracy:		99.92 %
0.13420496881008148
0.13388200104236603
0.133243128657341
Batch of classes 2 out of 5 batches
Epoch 27 of 60 took 100.801s
  training loss:		0.137617
  validation loss:		0.006944
  top 1 accuracy:		98.83 %
  top 2 accuracy:		99.98 %
0.13496133685112
0.13269002735614777
0.15162762999534607
Batch of classes 2 out of 5 batches
Epoch 28 of 60 took 100.155s
  training loss:		0.135734
  validation loss:		0.027816
  top 1 accuracy:		94.58 %
  top 2 accuracy:		99.27 %
0.13370057940483093
0.14276455342769623
0.13561886548995972
Batch of classes 2 out of 5 batches
Epoch 29 of 60 took 99.343s
  training loss:		0.138004
  validation loss:		0.009244
  top 1 accuracy:		98.42 %
  top 2 accuracy:		99.83 %
0.1495082974433899
0.14632350206375122
0.14562520384788513
Batch of classes 2 out of 5 batches
Epoch 30 of 60 took 100.431s
  training loss:		0.139411
  validation loss:		0.005541
  top 1 accuracy:		99.37 %
  top 2 accuracy:		99.96 %
0.14231471717357635
0.13948708772659302
0.14219482243061066
Batch of classes 2 out of 5 batches
Epoch 31 of 60 took 99.810s
  training loss:		0.137955
  validation loss:		0.001820
  top 1 accuracy:		99.79 %
  top 2 accuracy:		99.98 %
0.138712540268898
0.14226816594600677
0.13736195862293243
Batch of classes 2 out of 5 batches
Epoch 32 of 60 took 99.640s
  training loss:		0.137993
  validation loss:		0.005366
  top 1 accuracy:		99.06 %
  top 2 accuracy:		99.98 %
0.13532592356204987
0.13541680574417114
0.13701529800891876
Batch of classes 2 out of 5 batches
Epoch 33 of 60 took 99.701s
  training loss:		0.137946
  validation loss:		0.030344
  top 1 accuracy:		95.29 %
  top 2 accuracy:		99.79 %
0.13689576089382172
0.13564355671405792
0.14037862420082092
Batch of classes 2 out of 5 batches
Epoch 34 of 60 took 99.792s
  training loss:		0.138714
  validation loss:		0.001466
  top 1 accuracy:		99.73 %
  top 2 accuracy:		100.00 %
0.13168394565582275
0.13579052686691284
0.1327546238899231
Batch of classes 2 out of 5 batches
Epoch 35 of 60 took 99.216s
  training loss:		0.135062
  validation loss:		0.032549
  top 1 accuracy:		95.58 %
  top 2 accuracy:		99.56 %
0.1393953263759613
0.13431231677532196
0.13427259027957916
Batch of classes 2 out of 5 batches
Epoch 36 of 60 took 100.232s
  training loss:		0.137981
  validation loss:		0.009043
  top 1 accuracy:		98.10 %
  top 2 accuracy:		99.92 %
0.13573649525642395
0.14417025446891785
0.13814988732337952
Batch of classes 2 out of 5 batches
Epoch 37 of 60 took 99.007s
  training loss:		0.137272
  validation loss:		0.006164
  top 1 accuracy:		99.00 %
  top 2 accuracy:		99.90 %
0.13469795882701874
0.13383254408836365
0.1354771852493286
Batch of classes 2 out of 5 batches
Epoch 38 of 60 took 99.939s
  training loss:		0.137524
  validation loss:		0.001577
  top 1 accuracy:		99.87 %
  top 2 accuracy:		100.00 %
0.14076288044452667
0.13200509548187256
0.13587020337581635
Batch of classes 2 out of 5 batches
Epoch 39 of 60 took 99.958s
  training loss:		0.135350
  validation loss:		0.017844
  top 1 accuracy:		96.69 %
  top 2 accuracy:		99.67 %
0.13430432975292206
0.13547152280807495
0.13179060816764832
Batch of classes 2 out of 5 batches
Epoch 40 of 60 took 99.129s
  training loss:		0.139636
  validation loss:		0.001027
  top 1 accuracy:		99.90 %
  top 2 accuracy:		100.00 %
0.1349896490573883
0.1365739107131958
0.13208463788032532
Batch of classes 2 out of 5 batches
Epoch 41 of 60 took 99.618s
  training loss:		0.134868
  validation loss:		0.009115
  top 1 accuracy:		98.21 %
  top 2 accuracy:		99.87 %
0.13259267807006836
0.1323065161705017
0.13409587740898132
Batch of classes 2 out of 5 batches
Epoch 42 of 60 took 99.219s
  training loss:		0.135203
  validation loss:		0.001517
  top 1 accuracy:		99.83 %
  top 2 accuracy:		99.98 %
0.13680694997310638
0.13315361738204956
0.1338309496641159
Batch of classes 2 out of 5 batches
Epoch 43 of 60 took 99.924s
  training loss:		0.136188
  validation loss:		0.003221
  top 1 accuracy:		99.56 %
  top 2 accuracy:		100.00 %
0.13509510457515717
0.13657519221305847
0.1343904286623001
Batch of classes 2 out of 5 batches
Epoch 44 of 60 took 100.224s
  training loss:		0.134293
  validation loss:		0.011349
  top 1 accuracy:		97.73 %
  top 2 accuracy:		99.92 %
0.13416659832000732
0.13543753325939178
0.14343371987342834
Batch of classes 2 out of 5 batches
Epoch 45 of 60 took 99.451s
  training loss:		0.135901
  validation loss:		0.001018
  top 1 accuracy:		99.81 %
  top 2 accuracy:		100.00 %
0.13848790526390076
0.13335460424423218
0.13237640261650085
Batch of classes 2 out of 5 batches
Epoch 46 of 60 took 99.253s
  training loss:		0.133911
  validation loss:		0.006324
  top 1 accuracy:		98.87 %
  top 2 accuracy:		99.94 %
0.13153015077114105
0.13271564245224
0.1311456263065338
Batch of classes 2 out of 5 batches
Epoch 47 of 60 took 100.959s
  training loss:		0.133140
  validation loss:		0.005810
  top 1 accuracy:		98.85 %
  top 2 accuracy:		99.96 %
0.1331523060798645
0.13324017822742462
0.132807195186615
Batch of classes 2 out of 5 batches
Epoch 48 of 60 took 98.578s
  training loss:		0.135277
  validation loss:		0.011379
  top 1 accuracy:		98.08 %
  top 2 accuracy:		99.79 %
0.13233469426631927
0.13474364578723907
0.13191987574100494
Batch of classes 2 out of 5 batches
Epoch 49 of 60 took 99.841s
  training loss:		0.134523
  validation loss:		0.001300
  top 1 accuracy:		99.77 %
  top 2 accuracy:		100.00 %
0.13394562900066376
0.13359171152114868
0.136207714676857
Batch of classes 2 out of 5 batches
Epoch 50 of 60 took 100.295s
  training loss:		0.134967
  validation loss:		0.000570
  top 1 accuracy:		99.94 %
  top 2 accuracy:		100.00 %
0.1338588148355484
0.13356716930866241
0.1345897763967514
Batch of classes 2 out of 5 batches
Epoch 51 of 60 took 99.695s
  training loss:		0.135278
  validation loss:		0.008296
  top 1 accuracy:		98.44 %
  top 2 accuracy:		99.98 %
0.1351526975631714
0.13505715131759644
0.13269475102424622
Batch of classes 2 out of 5 batches
Epoch 52 of 60 took 99.490s
  training loss:		0.134563
  validation loss:		0.001089
  top 1 accuracy:		99.85 %
  top 2 accuracy:		100.00 %
0.1326655000448227
0.1363915503025055
0.13267196714878082
Batch of classes 2 out of 5 batches
Epoch 53 of 60 took 100.389s
  training loss:		0.135083
  validation loss:		0.005973
  top 1 accuracy:		98.96 %
  top 2 accuracy:		99.96 %
0.13676393032073975
0.13484008610248566
0.13453271985054016
Batch of classes 2 out of 5 batches
Epoch 54 of 60 took 99.425s
  training loss:		0.135285
  validation loss:		0.005031
  top 1 accuracy:		99.15 %
  top 2 accuracy:		99.98 %
0.1326126754283905
0.13279353082180023
0.13359011709690094
Batch of classes 2 out of 5 batches
Epoch 55 of 60 took 99.862s
  training loss:		0.134132
  validation loss:		0.001371
  top 1 accuracy:		99.83 %
  top 2 accuracy:		100.00 %
0.13456691801548004
0.13363097608089447
0.1299031376838684
Batch of classes 2 out of 5 batches
Epoch 56 of 60 took 100.009s
  training loss:		0.133233
  validation loss:		0.001503
  top 1 accuracy:		99.83 %
  top 2 accuracy:		99.98 %
0.13068047165870667
0.13107338547706604
0.13171762228012085
Batch of classes 2 out of 5 batches
Epoch 57 of 60 took 99.140s
  training loss:		0.133879
  validation loss:		0.002099
  top 1 accuracy:		99.67 %
  top 2 accuracy:		99.98 %
0.13359317183494568
0.13292871415615082
0.13200971484184265
Batch of classes 2 out of 5 batches
Epoch 58 of 60 took 99.211s
  training loss:		0.135234
  validation loss:		0.001744
  top 1 accuracy:		99.83 %
  top 2 accuracy:		100.00 %
0.131243497133255
0.13059063255786896
0.13433504104614258
Batch of classes 2 out of 5 batches
Epoch 59 of 60 took 99.443s
  training loss:		0.134412
  validation loss:		0.001303
  top 1 accuracy:		99.79 %
  top 2 accuracy:		99.98 %
0.13364285230636597
0.13289596140384674
0.13251975178718567
Batch of classes 2 out of 5 batches
Epoch 60 of 60 took 99.960s
  training loss:		0.133290
  validation loss:		0.001474
  top 1 accuracy:		99.85 %
  top 2 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(256)
tensor(256)
tensor(256)
tensor(256)
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		74.23 %
  top 1 accuracy Hybrid 1       :		71.46 %
  top 1 accuracy NCM            :		74.06 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		74.67 %
  top 1 accuracy Hybrid 1       :		73.56 %
  top 1 accuracy NCM            :		74.48 %
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		99.31 %
  top 1 accuracy Hybrid 1       :		99.85 %
  top 1 accuracy NCM            :		99.31 %
Binary accuracy:
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		99.69 %
  top 1 accuracy Hybrid 1       :		99.94 %
  top 1 accuracy NCM            :		99.69 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		86.77 %
  top 1 accuracy Hybrid 1       :		85.66 %
  top 1 accuracy NCM            :		86.69 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		87.18 %
  top 1 accuracy Hybrid 1       :		86.75 %
  top 1 accuracy NCM            :		87.08 %
Classes in this batch: tensor([4, 5])
Data Size: 7201


Before first epoch
  validation loss:		1.357404
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 3 arrives ...
1.2414096593856812
0.24794048070907593
0.23962759971618652
Batch of classes 3 out of 5 batches
Epoch 1 of 60 took 1264.296s
  training loss:		0.283185
  validation loss:		0.172636
  top 1 accuracy:		67.46 %
  top 2 accuracy:		92.15 %
0.18041913211345673
0.24628494679927826
0.1851436197757721
Batch of classes 3 out of 5 batches
Epoch 2 of 60 took 1243.498s
  training loss:		0.185683
  validation loss:		0.018945
  top 1 accuracy:		96.67 %
  top 2 accuracy:		99.87 %
0.208907812833786
0.17325296998023987
0.16423745453357697
Batch of classes 3 out of 5 batches
Epoch 3 of 60 took 1244.713s
  training loss:		0.163369
  validation loss:		0.029938
  top 1 accuracy:		94.48 %
  top 2 accuracy:		99.33 %
0.17675018310546875
0.15042415261268616
0.141880065202713
Batch of classes 3 out of 5 batches
Epoch 4 of 60 took 1222.030s
  training loss:		0.158880
  validation loss:		0.034677
  top 1 accuracy:		94.00 %
  top 2 accuracy:		99.35 %
0.14276443421840668
0.1456860601902008
0.14061377942562103
Batch of classes 3 out of 5 batches
Epoch 5 of 60 took 1215.335s
  training loss:		0.154913
  validation loss:		0.028878
  top 1 accuracy:		94.94 %
  top 2 accuracy:		99.58 %
0.15789663791656494
0.15786786377429962
0.16754752397537231
Batch of classes 3 out of 5 batches
Epoch 6 of 60 took 1222.042s
  training loss:		0.153324
  validation loss:		0.009228
  top 1 accuracy:		98.73 %
  top 2 accuracy:		99.96 %
0.15641051530838013
0.1451910138130188
0.1347462683916092
Batch of classes 3 out of 5 batches
Epoch 7 of 60 took 1217.410s
  training loss:		0.149605
  validation loss:		0.018540
  top 1 accuracy:		96.58 %
  top 2 accuracy:		99.85 %
0.17031510174274445
0.13824602961540222
0.15936321020126343
Batch of classes 3 out of 5 batches
Epoch 8 of 60 took 1214.799s
  training loss:		0.157862
  validation loss:		0.044122
  top 1 accuracy:		91.08 %
  top 2 accuracy:		99.81 %
0.1497211456298828
0.14749543368816376
0.1373758167028427
Batch of classes 3 out of 5 batches
Epoch 9 of 60 took 1218.932s
  training loss:		0.149271
  validation loss:		0.038442
  top 1 accuracy:		91.83 %
  top 2 accuracy:		99.92 %
0.1604749858379364
0.13897866010665894
0.14601987600326538
Batch of classes 3 out of 5 batches
Epoch 10 of 60 took 1195.200s
  training loss:		0.153058
  validation loss:		0.296637
  top 1 accuracy:		87.88 %
  top 2 accuracy:		97.42 %
0.14411112666130066
0.14528624713420868
0.15387029945850372
Batch of classes 3 out of 5 batches
Epoch 11 of 60 took 1256.146s
  training loss:		0.145494
  validation loss:		0.024044
  top 1 accuracy:		95.52 %
  top 2 accuracy:		99.79 %
0.14220678806304932
0.14110901951789856
0.14246109127998352
Batch of classes 3 out of 5 batches
Epoch 12 of 60 took 1253.554s
  training loss:		0.148657
  validation loss:		0.124422
  top 1 accuracy:		79.02 %
  top 2 accuracy:		98.10 %
0.13950270414352417
0.14250579476356506
0.14125503599643707
Batch of classes 3 out of 5 batches
Epoch 13 of 60 took 1263.749s
  training loss:		0.146239
  validation loss:		0.007843
  top 1 accuracy:		98.62 %
  top 2 accuracy:		99.87 %
0.14177243411540985
0.13743022084236145
0.1345449537038803
Batch of classes 3 out of 5 batches
Epoch 14 of 60 took 1257.315s
  training loss:		0.146594
  validation loss:		0.019274
  top 1 accuracy:		96.73 %
  top 2 accuracy:		99.73 %
0.15611903369426727
0.1333395540714264
0.13649937510490417
Batch of classes 3 out of 5 batches
Epoch 15 of 60 took 1264.107s
  training loss:		0.143611
  validation loss:		0.017117
  top 1 accuracy:		97.42 %
  top 2 accuracy:		99.90 %
0.1332715004682541
0.13474252820014954
0.13115492463111877
Batch of classes 3 out of 5 batches
Epoch 16 of 60 took 1266.107s
  training loss:		0.141764
  validation loss:		0.251572
  top 1 accuracy:		64.48 %
  top 2 accuracy:		98.00 %
0.1573629230260849
0.1389276385307312
0.1421891748905182
Batch of classes 3 out of 5 batches
Epoch 17 of 60 took 1262.568s
  training loss:		0.151948
  validation loss:		0.096604
  top 1 accuracy:		76.69 %
  top 2 accuracy:		99.27 %
0.1473192274570465
0.15682169795036316
0.14544358849525452
Batch of classes 3 out of 5 batches
Epoch 18 of 60 took 1276.772s
  training loss:		0.141157
  validation loss:		0.057401
  top 1 accuracy:		89.33 %
  top 2 accuracy:		96.92 %
0.14005954563617706
0.15202762186527252
0.13469374179840088
Batch of classes 3 out of 5 batches
Epoch 19 of 60 took 1289.238s
  training loss:		0.143767
  validation loss:		0.191779
  top 1 accuracy:		88.31 %
  top 2 accuracy:		99.00 %
0.16321417689323425
0.17549355328083038
0.13513800501823425
Batch of classes 3 out of 5 batches
Epoch 20 of 60 took 1294.637s
  training loss:		0.141739
  validation loss:		0.009371
  top 1 accuracy:		98.37 %
  top 2 accuracy:		99.96 %
0.14873243868350983
0.13414371013641357
0.1303934007883072
Batch of classes 3 out of 5 batches
Epoch 21 of 60 took 1340.084s
  training loss:		0.134277
  validation loss:		0.002546
  top 1 accuracy:		99.67 %
  top 2 accuracy:		99.98 %
0.1317632794380188
0.1289992779493332
0.13075388967990875
Batch of classes 3 out of 5 batches
Epoch 22 of 60 took 1315.912s
  training loss:		0.132371
  validation loss:		0.004632
  top 1 accuracy:		99.27 %
  top 2 accuracy:		99.96 %
0.12788067758083344
0.13331344723701477
0.13036400079727173
Batch of classes 3 out of 5 batches
Epoch 23 of 60 took 1311.185s
  training loss:		0.132130
  validation loss:		0.004523
  top 1 accuracy:		99.37 %
  top 2 accuracy:		99.98 %
0.132964089512825
0.12936921417713165
0.1343524008989334
Batch of classes 3 out of 5 batches
Epoch 24 of 60 took 1303.970s
  training loss:		0.131765
  validation loss:		0.002092
  top 1 accuracy:		99.67 %
  top 2 accuracy:		99.98 %
0.13948450982570648
0.13058455288410187
0.1305556297302246
Batch of classes 3 out of 5 batches
Epoch 25 of 60 took 1305.091s
  training loss:		0.132563
  validation loss:		0.010301
  top 1 accuracy:		98.15 %
  top 2 accuracy:		99.94 %
0.13965527713298798
0.13186301290988922
0.13302524387836456
Batch of classes 3 out of 5 batches
Epoch 26 of 60 took 1251.408s
  training loss:		0.135457
  validation loss:		0.003133
  top 1 accuracy:		99.52 %
  top 2 accuracy:		99.98 %
0.12798786163330078
0.14191491901874542
0.14171159267425537
Batch of classes 3 out of 5 batches
Epoch 27 of 60 took 1251.447s
  training loss:		0.133647
  validation loss:		0.004341
  top 1 accuracy:		99.33 %
  top 2 accuracy:		100.00 %
0.1297026127576828
0.13244111835956573
0.1328893005847931
Batch of classes 3 out of 5 batches
Epoch 28 of 60 took 1262.714s
  training loss:		0.134299
  validation loss:		0.003673
  top 1 accuracy:		99.46 %
  top 2 accuracy:		99.94 %
0.14124272763729095
0.13083632290363312
0.13717281818389893
Batch of classes 3 out of 5 batches
Epoch 29 of 60 took 1364.722s
  training loss:		0.136574
  validation loss:		0.011148
  top 1 accuracy:		98.17 %
  top 2 accuracy:		99.98 %
0.14330746233463287
0.14305509626865387
0.13063189387321472
Batch of classes 3 out of 5 batches
Epoch 30 of 60 took 1360.006s
  training loss:		0.134598
  validation loss:		0.005712
  top 1 accuracy:		99.15 %
  top 2 accuracy:		100.00 %
0.1330578476190567
0.13701429963111877
0.13801896572113037
Batch of classes 3 out of 5 batches
Epoch 31 of 60 took 1341.446s
  training loss:		0.142096
  validation loss:		0.006214
  top 1 accuracy:		98.85 %
  top 2 accuracy:		99.98 %
0.13453537225723267
0.1319047510623932
0.13250556588172913
Batch of classes 3 out of 5 batches
Epoch 32 of 60 took 1197.809s
  training loss:		0.134416
  validation loss:		0.002885
  top 1 accuracy:		99.58 %
  top 2 accuracy:		99.96 %
0.13173070549964905
0.1320481300354004
0.13915224373340607
Batch of classes 3 out of 5 batches
Epoch 33 of 60 took 1101.130s
  training loss:		0.135072
  validation loss:		0.002120
  top 1 accuracy:		99.65 %
  top 2 accuracy:		100.00 %
0.13615937530994415
0.13261206448078156
0.13462847471237183
Batch of classes 3 out of 5 batches
Epoch 34 of 60 took 1192.706s
  training loss:		0.133431
  validation loss:		0.001935
  top 1 accuracy:		99.67 %
  top 2 accuracy:		100.00 %
0.13232380151748657
0.13820034265518188
0.13204939663410187
Batch of classes 3 out of 5 batches
Epoch 35 of 60 took 1198.537s
  training loss:		0.134744
  validation loss:		0.002348
  top 1 accuracy:		99.60 %
  top 2 accuracy:		99.98 %
0.1334814578294754
0.13179923593997955
0.1300332099199295
Batch of classes 3 out of 5 batches
Epoch 36 of 60 took 1212.615s
  training loss:		0.133095
  validation loss:		0.002497
  top 1 accuracy:		99.62 %
  top 2 accuracy:		99.98 %
0.13333337008953094
0.13438020646572113
0.13153429329395294
Batch of classes 3 out of 5 batches
Epoch 37 of 60 took 1203.820s
  training loss:		0.135795
  validation loss:		0.005574
  top 1 accuracy:		99.31 %
  top 2 accuracy:		99.94 %
0.132547527551651
0.13241510093212128
0.13381214439868927
Batch of classes 3 out of 5 batches
Epoch 38 of 60 took 1163.788s
  training loss:		0.137478
  validation loss:		0.033930
  top 1 accuracy:		94.52 %
  top 2 accuracy:		99.65 %
0.1314597725868225
0.13193786144256592
0.1333523988723755
Batch of classes 3 out of 5 batches
Epoch 39 of 60 took 858.701s
  training loss:		0.133201
  validation loss:		0.009620
  top 1 accuracy:		98.29 %
  top 2 accuracy:		100.00 %
0.13510198891162872
0.1320350617170334
0.13557429611682892
Batch of classes 3 out of 5 batches
Epoch 40 of 60 took 737.275s
  training loss:		0.136200
  validation loss:		0.002091
  top 1 accuracy:		99.69 %
  top 2 accuracy:		100.00 %
0.1349770724773407
0.13375236093997955
0.1346299946308136
Batch of classes 3 out of 5 batches
Epoch 41 of 60 took 617.243s
  training loss:		0.135093
  validation loss:		0.001685
  top 1 accuracy:		99.75 %
  top 2 accuracy:		99.98 %
0.13196909427642822
0.1346433460712433
0.13461299240589142
Batch of classes 3 out of 5 batches
Epoch 42 of 60 took 647.925s
  training loss:		0.134987
  validation loss:		0.001558
  top 1 accuracy:		99.79 %
  top 2 accuracy:		100.00 %
0.1349189132452011
0.1350139081478119
0.13147349655628204
Batch of classes 3 out of 5 batches
Epoch 43 of 60 took 588.233s
  training loss:		0.134738
  validation loss:		0.001724
  top 1 accuracy:		99.75 %
  top 2 accuracy:		100.00 %
0.13286092877388
0.14121456444263458
0.13244691491127014
Batch of classes 3 out of 5 batches
Epoch 44 of 60 took 569.855s
  training loss:		0.134827
  validation loss:		0.002205
  top 1 accuracy:		99.69 %
  top 2 accuracy:		99.98 %
0.1320735663175583
0.13355977833271027
0.1323244571685791
Batch of classes 3 out of 5 batches
Epoch 45 of 60 took 553.036s
  training loss:		0.134584
  validation loss:		0.010882
  top 1 accuracy:		98.33 %
  top 2 accuracy:		100.00 %
0.1321132332086563
0.13432244956493378
0.13521404564380646
Batch of classes 3 out of 5 batches
Epoch 46 of 60 took 584.730s
  training loss:		0.135101
  validation loss:		0.004426
  top 1 accuracy:		99.44 %
  top 2 accuracy:		99.98 %
0.13059109449386597
0.1319008469581604
0.13257735967636108
Batch of classes 3 out of 5 batches
Epoch 47 of 60 took 594.430s
  training loss:		0.133643
  validation loss:		0.001498
  top 1 accuracy:		99.77 %
  top 2 accuracy:		100.00 %
0.13267064094543457
0.1318623274564743
0.132272407412529
Batch of classes 3 out of 5 batches
Epoch 48 of 60 took 937.032s
  training loss:		0.133709
  validation loss:		0.004365
  top 1 accuracy:		99.42 %
  top 2 accuracy:		100.00 %
0.13073673844337463
0.15060800313949585
0.13104499876499176
Batch of classes 3 out of 5 batches
Epoch 49 of 60 took 1112.706s
  training loss:		0.133427
  validation loss:		0.001165
  top 1 accuracy:		99.81 %
  top 2 accuracy:		100.00 %
0.1304107904434204
0.13550381362438202
0.1374070942401886
Batch of classes 3 out of 5 batches
Epoch 50 of 60 took 1030.872s
  training loss:		0.133615
  validation loss:		0.025376
  top 1 accuracy:		97.12 %
  top 2 accuracy:		99.83 %
0.13193102180957794
0.13207876682281494
0.14051610231399536
Batch of classes 3 out of 5 batches
Epoch 51 of 60 took 931.868s
  training loss:		0.133317
  validation loss:		0.005243
  top 1 accuracy:		99.21 %
  top 2 accuracy:		99.98 %
0.13089151680469513
0.13214734196662903
0.13168157637119293
Batch of classes 3 out of 5 batches
Epoch 52 of 60 took 940.250s
  training loss:		0.132810
  validation loss:		0.001665
  top 1 accuracy:		99.77 %
  top 2 accuracy:		100.00 %
0.1323729306459427
0.13009412586688995
0.13533809781074524
Batch of classes 3 out of 5 batches
Epoch 53 of 60 took 949.274s
  training loss:		0.132879
  validation loss:		0.001480
  top 1 accuracy:		99.77 %
  top 2 accuracy:		99.96 %
0.1303369551897049
0.13312800228595734
0.13153764605522156
Batch of classes 3 out of 5 batches
Epoch 54 of 60 took 923.330s
  training loss:		0.133969
  validation loss:		0.007560
  top 1 accuracy:		99.02 %
  top 2 accuracy:		99.96 %
0.1318560689687729
0.13315550982952118
0.13883943855762482
Batch of classes 3 out of 5 batches
Epoch 55 of 60 took 912.946s
  training loss:		0.133815
  validation loss:		0.002787
  top 1 accuracy:		99.50 %
  top 2 accuracy:		100.00 %
0.1315218210220337
0.1326431930065155
0.13114625215530396
Batch of classes 3 out of 5 batches
Epoch 56 of 60 took 930.975s
  training loss:		0.133807
  validation loss:		0.002419
  top 1 accuracy:		99.67 %
  top 2 accuracy:		100.00 %
0.1313208043575287
0.13471075892448425
0.13418057560920715
Batch of classes 3 out of 5 batches
Epoch 57 of 60 took 1349.170s
  training loss:		0.134091
  validation loss:		0.004870
  top 1 accuracy:		99.23 %
  top 2 accuracy:		100.00 %
0.13211245834827423
0.13018850982189178
0.13107521831989288
Batch of classes 3 out of 5 batches
Epoch 58 of 60 took 1466.232s
  training loss:		0.132680
  validation loss:		0.001884
  top 1 accuracy:		99.69 %
  top 2 accuracy:		99.98 %
0.13085198402404785
0.13266389071941376
0.1433097869157791
Batch of classes 3 out of 5 batches
Epoch 59 of 60 took 1257.062s
  training loss:		0.133562
  validation loss:		0.001553
  top 1 accuracy:		99.79 %
  top 2 accuracy:		100.00 %
0.1331014633178711
0.13315659761428833
0.12809710204601288
Batch of classes 3 out of 5 batches
Epoch 60 of 60 took 1230.605s
  training loss:		0.132222
  validation loss:		0.004637
  top 1 accuracy:		99.29 %
  top 2 accuracy:		99.98 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(171)
tensor(171)
tensor(171)
tensor(171)
tensor(171)
tensor(171)
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		72.29 %
  top 1 accuracy Hybrid 1       :		71.29 %
  top 1 accuracy NCM            :		72.25 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		78.46 %
  top 1 accuracy Hybrid 1       :		79.35 %
  top 1 accuracy NCM            :		78.40 %
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		98.40 %
  top 1 accuracy Hybrid 1       :		98.38 %
  top 1 accuracy NCM            :		98.29 %
Binary accuracy:
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		98.83 %
  top 1 accuracy Hybrid 1       :		98.75 %
  top 1 accuracy NCM            :		98.73 %
Final results on progan1024 classes:
  top 1 accuracy iCaRL          :		99.23 %
  top 1 accuracy Hybrid 1       :		99.29 %
  top 1 accuracy NCM            :		99.23 %
Binary accuracy:
Final results on progan1024 classes:
  top 1 accuracy iCaRL          :		99.50 %
  top 1 accuracy Hybrid 1       :		99.38 %
  top 1 accuracy NCM            :		99.50 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		89.97 %
  top 1 accuracy Hybrid 1       :		89.65 %
  top 1 accuracy NCM            :		89.92 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		92.26 %
  top 1 accuracy Hybrid 1       :		92.49 %
  top 1 accuracy NCM            :		92.21 %
Classes in this batch: tensor([6, 7])
Data Size: 7200


Before first epoch
  validation loss:		1.554780
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.12 %
Batch of classes number 4 arrives ...
1.0463993549346924
0.18805401027202606
0.1768915355205536
Batch of classes 4 out of 5 batches
Epoch 1 of 60 took 626.973s
  training loss:		0.241744
  validation loss:		0.023660
  top 1 accuracy:		97.25 %
  top 2 accuracy:		99.81 %
0.18086208403110504
0.15622863173484802
0.20750480890274048
Batch of classes 4 out of 5 batches
Epoch 2 of 60 took 567.153s
  training loss:		0.165919
  validation loss:		0.021031
  top 1 accuracy:		97.65 %
  top 2 accuracy:		99.94 %
0.14646868407726288
0.16141480207443237
0.1555788516998291
Batch of classes 4 out of 5 batches
Epoch 3 of 60 took 567.310s
  training loss:		0.160067
  validation loss:		0.012540
  top 1 accuracy:		98.56 %
  top 2 accuracy:		99.94 %
0.1478462815284729
0.20507141947746277
0.14434267580509186
Batch of classes 4 out of 5 batches
Epoch 4 of 60 took 569.874s
  training loss:		0.157482
  validation loss:		0.029740
  top 1 accuracy:		95.17 %
  top 2 accuracy:		99.33 %
0.16124020516872406
0.14350570738315582
0.1731470823287964
Batch of classes 4 out of 5 batches
Epoch 5 of 60 took 595.531s
  training loss:		0.158318
  validation loss:		0.031309
  top 1 accuracy:		93.85 %
  top 2 accuracy:		99.15 %
0.15063101053237915
0.13988278806209564
0.15353097021579742
Batch of classes 4 out of 5 batches
Epoch 6 of 60 took 583.990s
  training loss:		0.152041
  validation loss:		0.018740
  top 1 accuracy:		96.81 %
  top 2 accuracy:		99.81 %
0.14073669910430908
0.14537498354911804
0.13310973346233368
Batch of classes 4 out of 5 batches
Epoch 7 of 60 took 583.778s
  training loss:		0.152368
  validation loss:		0.019343
  top 1 accuracy:		97.87 %
  top 2 accuracy:		99.62 %
0.15423007309436798
0.1322869211435318
0.15221957862377167
Batch of classes 4 out of 5 batches
Epoch 8 of 60 took 548.818s
  training loss:		0.148516
  validation loss:		0.020983
  top 1 accuracy:		97.90 %
  top 2 accuracy:		99.85 %
0.16893063485622406
0.1424587368965149
0.14015111327171326
Batch of classes 4 out of 5 batches
Epoch 9 of 60 took 622.240s
  training loss:		0.145152
  validation loss:		0.014577
  top 1 accuracy:		99.00 %
  top 2 accuracy:		99.79 %
0.15987564623355865
0.13224297761917114
0.13639718294143677
Batch of classes 4 out of 5 batches
Epoch 10 of 60 took 639.317s
  training loss:		0.144295
  validation loss:		0.035529
  top 1 accuracy:		94.38 %
  top 2 accuracy:		98.42 %
0.18724611401557922
0.1492203176021576
0.13819028437137604
Batch of classes 4 out of 5 batches
Epoch 11 of 60 took 613.363s
  training loss:		0.146256
  validation loss:		0.010551
  top 1 accuracy:		98.19 %
  top 2 accuracy:		99.85 %
0.1477857381105423
0.15260307490825653
0.13815324008464813
Batch of classes 4 out of 5 batches
Epoch 12 of 60 took 549.527s
  training loss:		0.150258
  validation loss:		0.030242
  top 1 accuracy:		95.48 %
  top 2 accuracy:		99.62 %
0.1427193284034729
0.15076953172683716
0.14134421944618225
Batch of classes 4 out of 5 batches
Epoch 13 of 60 took 571.058s
  training loss:		0.148004
  validation loss:		0.017016
  top 1 accuracy:		97.67 %
  top 2 accuracy:		99.71 %
0.14211831986904144
0.15809690952301025
0.14975395798683167
Batch of classes 4 out of 5 batches
Epoch 14 of 60 took 572.554s
  training loss:		0.146474
  validation loss:		0.047380
  top 1 accuracy:		93.56 %
  top 2 accuracy:		99.62 %
0.1765410453081131
0.1400233656167984
0.1375807672739029
Batch of classes 4 out of 5 batches
Epoch 15 of 60 took 578.728s
  training loss:		0.148994
  validation loss:		0.017266
  top 1 accuracy:		97.15 %
  top 2 accuracy:		99.81 %
0.14720489084720612
0.16372808814048767
0.1420207917690277
Batch of classes 4 out of 5 batches
Epoch 16 of 60 took 547.203s
  training loss:		0.148764
  validation loss:		0.018367
  top 1 accuracy:		98.48 %
  top 2 accuracy:		99.73 %
0.13633789122104645
0.1893826276063919
0.14971193671226501
Batch of classes 4 out of 5 batches
Epoch 17 of 60 took 662.890s
  training loss:		0.143729
  validation loss:		0.012258
  top 1 accuracy:		98.25 %
  top 2 accuracy:		99.79 %
0.1372990608215332
0.13876384496688843
0.13303720951080322
Batch of classes 4 out of 5 batches
Epoch 18 of 60 took 682.284s
  training loss:		0.142318
  validation loss:		0.007291
  top 1 accuracy:		99.29 %
  top 2 accuracy:		99.90 %
0.13590341806411743
0.1524403691291809
0.1498180776834488
Batch of classes 4 out of 5 batches
Epoch 19 of 60 took 676.960s
  training loss:		0.144259
  validation loss:		0.074675
  top 1 accuracy:		85.52 %
  top 2 accuracy:		97.85 %
0.13900470733642578
0.1445094645023346
0.13835453987121582
Batch of classes 4 out of 5 batches
Epoch 20 of 60 took 672.569s
  training loss:		0.156241
  validation loss:		0.017130
  top 1 accuracy:		97.12 %
  top 2 accuracy:		99.83 %
0.14046929776668549
0.13924691081047058
0.13866589963436127
Batch of classes 4 out of 5 batches
Epoch 21 of 60 took 689.369s
  training loss:		0.143276
  validation loss:		0.005333
  top 1 accuracy:		99.37 %
  top 2 accuracy:		99.92 %
0.13807463645935059
0.14351403713226318
0.14162632822990417
Batch of classes 4 out of 5 batches
Epoch 22 of 60 took 676.052s
  training loss:		0.141293
  validation loss:		0.007028
  top 1 accuracy:		98.96 %
  top 2 accuracy:		99.94 %
0.14046478271484375
0.14257842302322388
0.13964363932609558
Batch of classes 4 out of 5 batches
Epoch 23 of 60 took 640.415s
  training loss:		0.141333
  validation loss:		0.011898
  top 1 accuracy:		98.08 %
  top 2 accuracy:		99.87 %
0.14286993443965912
0.13763928413391113
0.13681818544864655
Batch of classes 4 out of 5 batches
Epoch 24 of 60 took 656.230s
  training loss:		0.141931
  validation loss:		0.016983
  top 1 accuracy:		98.48 %
  top 2 accuracy:		99.83 %
0.13775882124900818
0.14336422085762024
0.13489475846290588
Batch of classes 4 out of 5 batches
Epoch 25 of 60 took 697.300s
  training loss:		0.138256
  validation loss:		0.011502
  top 1 accuracy:		98.85 %
  top 2 accuracy:		99.87 %
0.13712067902088165
0.1413525491952896
0.1379719227552414
Batch of classes 4 out of 5 batches
Epoch 26 of 60 took 683.891s
  training loss:		0.139679
  validation loss:		0.015587
  top 1 accuracy:		97.75 %
  top 2 accuracy:		99.73 %
0.13579097390174866
0.13995762169361115
0.13689374923706055
Batch of classes 4 out of 5 batches
Epoch 27 of 60 took 587.568s
  training loss:		0.139421
  validation loss:		0.011437
  top 1 accuracy:		98.17 %
  top 2 accuracy:		99.75 %
0.13765588402748108
0.1389455795288086
0.13539385795593262
Batch of classes 4 out of 5 batches
Epoch 28 of 60 took 624.785s
  training loss:		0.139853
  validation loss:		0.012005
  top 1 accuracy:		98.87 %
  top 2 accuracy:		99.81 %
0.13611680269241333
0.134893536567688
0.13522151112556458
Batch of classes 4 out of 5 batches
Epoch 29 of 60 took 617.971s
  training loss:		0.138427
  validation loss:		0.015389
  top 1 accuracy:		97.12 %
  top 2 accuracy:		99.96 %
0.14050519466400146
0.14248526096343994
0.14074453711509705
Batch of classes 4 out of 5 batches
Epoch 30 of 60 took 638.900s
  training loss:		0.140815
  validation loss:		0.006186
  top 1 accuracy:		99.10 %
  top 2 accuracy:		99.92 %
0.13788719475269318
0.13538312911987305
0.13658516108989716
Batch of classes 4 out of 5 batches
Epoch 31 of 60 took 601.989s
  training loss:		0.139514
  validation loss:		0.015326
  top 1 accuracy:		97.23 %
  top 2 accuracy:		99.83 %
0.13939163088798523
0.13815371692180634
0.13696220517158508
Batch of classes 4 out of 5 batches
Epoch 32 of 60 took 655.693s
  training loss:		0.141850
  validation loss:		0.012048
  top 1 accuracy:		98.40 %
  top 2 accuracy:		99.85 %
0.13965994119644165
0.1360415816307068
0.1364797055721283
Batch of classes 4 out of 5 batches
Epoch 33 of 60 took 599.901s
  training loss:		0.139621
  validation loss:		0.010789
  top 1 accuracy:		99.33 %
  top 2 accuracy:		99.90 %
0.13789808750152588
0.16476011276245117
0.1350221484899521
Batch of classes 4 out of 5 batches
Epoch 34 of 60 took 610.815s
  training loss:		0.138970
  validation loss:		0.012203
  top 1 accuracy:		98.75 %
  top 2 accuracy:		99.79 %
0.13292144238948822
0.13718204200267792
0.13338634371757507
Batch of classes 4 out of 5 batches
Epoch 35 of 60 took 596.786s
  training loss:		0.137646
  validation loss:		0.005156
  top 1 accuracy:		99.33 %
  top 2 accuracy:		99.92 %
0.13371440768241882
0.13537274301052094
0.13477171957492828
Batch of classes 4 out of 5 batches
Epoch 36 of 60 took 679.896s
  training loss:		0.138510
  validation loss:		0.015105
  top 1 accuracy:		98.94 %
  top 2 accuracy:		99.83 %
0.13996587693691254
0.13950452208518982
0.13839402794837952
Batch of classes 4 out of 5 batches
Epoch 37 of 60 took 624.431s
  training loss:		0.138717
  validation loss:		0.014021
  top 1 accuracy:		97.42 %
  top 2 accuracy:		99.92 %
0.1391972005367279
0.135599285364151
0.13753943145275116
Batch of classes 4 out of 5 batches
Epoch 38 of 60 took 645.159s
  training loss:		0.138949
  validation loss:		0.006603
  top 1 accuracy:		99.12 %
  top 2 accuracy:		99.83 %
0.13577552139759064
0.13501664996147156
0.1386454850435257
Batch of classes 4 out of 5 batches
Epoch 39 of 60 took 95.312s
  training loss:		0.137192
  validation loss:		0.006342
  top 1 accuracy:		99.23 %
  top 2 accuracy:		99.94 %
0.13716217875480652
0.13301733136177063
0.1370639204978943
Batch of classes 4 out of 5 batches
Epoch 40 of 60 took 95.240s
  training loss:		0.139010
  validation loss:		0.063161
  top 1 accuracy:		90.17 %
  top 2 accuracy:		99.77 %
0.13694296777248383
0.13662059605121613
0.13480384647846222
Batch of classes 4 out of 5 batches
Epoch 41 of 60 took 95.834s
  training loss:		0.139402
  validation loss:		0.008358
  top 1 accuracy:		99.50 %
  top 2 accuracy:		99.90 %
0.13898293673992157
0.13462629914283752
0.13458240032196045
Batch of classes 4 out of 5 batches
Epoch 42 of 60 took 94.828s
  training loss:		0.137595
  validation loss:		0.007046
  top 1 accuracy:		99.06 %
  top 2 accuracy:		99.83 %
0.1342315971851349
0.1437155157327652
0.1359090507030487
Batch of classes 4 out of 5 batches
Epoch 43 of 60 took 95.390s
  training loss:		0.136381
  validation loss:		0.006846
  top 1 accuracy:		99.33 %
  top 2 accuracy:		99.92 %
0.13415037095546722
0.1364317238330841
0.13605494797229767
Batch of classes 4 out of 5 batches
Epoch 44 of 60 took 95.467s
  training loss:		0.137560
  validation loss:		0.006581
  top 1 accuracy:		99.31 %
  top 2 accuracy:		99.90 %
0.13722260296344757
0.1368148773908615
0.1372486650943756
Batch of classes 4 out of 5 batches
Epoch 45 of 60 took 95.129s
  training loss:		0.139317
  validation loss:		0.007896
  top 1 accuracy:		98.85 %
  top 2 accuracy:		99.85 %
0.13599981367588043
0.13498808443546295
0.13544072210788727
Batch of classes 4 out of 5 batches
Epoch 46 of 60 took 95.275s
  training loss:		0.138586
  validation loss:		0.007439
  top 1 accuracy:		99.33 %
  top 2 accuracy:		99.96 %
0.1371837556362152
0.1352798342704773
0.13657698035240173
Batch of classes 4 out of 5 batches
Epoch 47 of 60 took 95.549s
  training loss:		0.137622
  validation loss:		0.008214
  top 1 accuracy:		99.19 %
  top 2 accuracy:		99.90 %
0.1356048732995987
0.13597576320171356
0.1355804055929184
Batch of classes 4 out of 5 batches
Epoch 48 of 60 took 95.032s
  training loss:		0.136969
  validation loss:		0.222937
  top 1 accuracy:		64.60 %
  top 2 accuracy:		99.83 %
0.135985866189003
0.13428153097629547
0.136856347322464
Batch of classes 4 out of 5 batches
Epoch 49 of 60 took 94.765s
  training loss:		0.136260
  validation loss:		0.008154
  top 1 accuracy:		99.27 %
  top 2 accuracy:		99.87 %
0.13685567677021027
0.13587458431720734
0.13657940924167633
Batch of classes 4 out of 5 batches
Epoch 50 of 60 took 94.965s
  training loss:		0.136278
  validation loss:		0.004648
  top 1 accuracy:		99.50 %
  top 2 accuracy:		99.94 %
0.13630075752735138
0.13615627586841583
0.13479377329349518
Batch of classes 4 out of 5 batches
Epoch 51 of 60 took 94.676s
  training loss:		0.137578
  validation loss:		0.011325
  top 1 accuracy:		99.10 %
  top 2 accuracy:		99.87 %
0.13121138513088226
0.13437379896640778
0.13326165080070496
Batch of classes 4 out of 5 batches
Epoch 52 of 60 took 94.813s
  training loss:		0.136473
  validation loss:		0.009472
  top 1 accuracy:		98.54 %
  top 2 accuracy:		99.94 %
0.13489830493927002
0.13466589152812958
0.1341378390789032
Batch of classes 4 out of 5 batches
Epoch 53 of 60 took 96.135s
  training loss:		0.135471
  validation loss:		0.011776
  top 1 accuracy:		98.29 %
  top 2 accuracy:		99.90 %
0.13820096850395203
0.13558915257453918
0.13432087004184723
Batch of classes 4 out of 5 batches
Epoch 54 of 60 took 95.530s
  training loss:		0.138261
  validation loss:		0.006040
  top 1 accuracy:		99.60 %
  top 2 accuracy:		99.96 %
0.13656827807426453
0.13525523245334625
0.13634584844112396
Batch of classes 4 out of 5 batches
Epoch 55 of 60 took 95.423s
  training loss:		0.135893
  validation loss:		0.006950
  top 1 accuracy:		99.48 %
  top 2 accuracy:		99.87 %
0.1402881145477295
0.13443279266357422
0.1372280716896057
Batch of classes 4 out of 5 batches
Epoch 56 of 60 took 95.827s
  training loss:		0.136984
  validation loss:		0.009406
  top 1 accuracy:		99.42 %
  top 2 accuracy:		99.85 %
0.13684514164924622
0.134445920586586
0.13452643156051636
Batch of classes 4 out of 5 batches
Epoch 57 of 60 took 95.438s
  training loss:		0.135547
  validation loss:		0.004546
  top 1 accuracy:		99.44 %
  top 2 accuracy:		99.92 %
0.1336686760187149
0.13699625432491302
0.13231486082077026
Batch of classes 4 out of 5 batches
Epoch 58 of 60 took 95.147s
  training loss:		0.135614
  validation loss:		0.037046
  top 1 accuracy:		92.33 %
  top 2 accuracy:		99.85 %
0.13689135015010834
0.13546441495418549
0.13637152314186096
Batch of classes 4 out of 5 batches
Epoch 59 of 60 took 94.749s
  training loss:		0.136268
  validation loss:		0.007701
  top 1 accuracy:		99.29 %
  top 2 accuracy:		99.96 %
0.13423967361450195
0.1339963972568512
0.13430438935756683
Batch of classes 4 out of 5 batches
Epoch 60 of 60 took 95.810s
  training loss:		0.138514
  validation loss:		0.013487
  top 1 accuracy:		99.29 %
  top 2 accuracy:		99.81 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		71.25 %
  top 1 accuracy Hybrid 1       :		72.08 %
  top 1 accuracy NCM            :		71.33 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		72.31 %
  top 1 accuracy Hybrid 1       :		73.44 %
  top 1 accuracy NCM            :		72.38 %
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		97.71 %
  top 1 accuracy Hybrid 1       :		97.31 %
  top 1 accuracy NCM            :		97.54 %
Binary accuracy:
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		98.38 %
  top 1 accuracy Hybrid 1       :		98.10 %
  top 1 accuracy NCM            :		98.27 %
Final results on progan1024 classes:
  top 1 accuracy iCaRL          :		92.29 %
  top 1 accuracy Hybrid 1       :		71.46 %
  top 1 accuracy NCM            :		92.81 %
Binary accuracy:
Final results on progan1024 classes:
  top 1 accuracy iCaRL          :		97.92 %
  top 1 accuracy Hybrid 1       :		96.79 %
  top 1 accuracy NCM            :		97.92 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		98.96 %
  top 1 accuracy Hybrid 1       :		99.29 %
  top 1 accuracy NCM            :		98.88 %
Binary accuracy:
Final results on glow classes:
  top 1 accuracy iCaRL          :		99.58 %
  top 1 accuracy Hybrid 1       :		99.40 %
  top 1 accuracy NCM            :		99.58 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		90.05 %
  top 1 accuracy Hybrid 1       :		85.04 %
  top 1 accuracy NCM            :		90.14 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		92.05 %
  top 1 accuracy Hybrid 1       :		91.93 %
  top 1 accuracy NCM            :		92.04 %
Classes in this batch: tensor([8, 9])
Data Size: 7200


Before first epoch
  validation loss:		2.307303
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.81 %
Batch of classes number 5 arrives ...
1.373699426651001
0.14520342648029327
0.1465282440185547
Batch of classes 5 out of 5 batches
Epoch 1 of 60 took 142.348s
  training loss:		0.237862
  validation loss:		0.017223
  top 1 accuracy:		98.58 %
  top 2 accuracy:		99.83 %
0.14932949841022491
0.15283605456352234
0.16116519272327423
Batch of classes 5 out of 5 batches
Epoch 2 of 60 took 96.351s
  training loss:		0.154734
  validation loss:		0.007995
  top 1 accuracy:		99.46 %
  top 2 accuracy:		99.87 %
0.17507486045360565
0.15210452675819397
0.1584903597831726
Batch of classes 5 out of 5 batches
Epoch 3 of 60 took 97.029s
  training loss:		0.153431
  validation loss:		0.014217
  top 1 accuracy:		97.92 %
  top 2 accuracy:		99.98 %
0.14349912106990814
0.1533229500055313
0.15989327430725098
Batch of classes 5 out of 5 batches
Epoch 4 of 60 took 96.168s
  training loss:		0.150634
  validation loss:		0.022187
  top 1 accuracy:		96.31 %
  top 2 accuracy:		99.98 %
0.13317030668258667
0.15146200358867645
0.13516853749752045
Batch of classes 5 out of 5 batches
Epoch 5 of 60 took 96.631s
  training loss:		0.148949
  validation loss:		0.006070
  top 1 accuracy:		99.40 %
  top 2 accuracy:		99.85 %
0.15618489682674408
0.142128124833107
0.14342419803142548
Batch of classes 5 out of 5 batches
Epoch 6 of 60 took 95.443s
  training loss:		0.150340
  validation loss:		0.011101
  top 1 accuracy:		98.08 %
  top 2 accuracy:		99.92 %
0.1419200301170349
0.14274609088897705
0.13108626008033752
Batch of classes 5 out of 5 batches
Epoch 7 of 60 took 96.481s
  training loss:		0.144646
  validation loss:		0.012439
  top 1 accuracy:		99.02 %
  top 2 accuracy:		99.92 %
0.13025222718715668
0.12771327793598175
0.133426234126091
Batch of classes 5 out of 5 batches
Epoch 8 of 60 took 95.571s
  training loss:		0.143804
  validation loss:		0.006620
  top 1 accuracy:		99.50 %
  top 2 accuracy:		100.00 %
0.13423685729503632
0.1481987088918686
0.13213403522968292
Batch of classes 5 out of 5 batches
Epoch 9 of 60 took 96.228s
  training loss:		0.147881
  validation loss:		0.013183
  top 1 accuracy:		98.54 %
  top 2 accuracy:		99.85 %
0.13413995504379272
0.1459845006465912
0.14458312094211578
Batch of classes 5 out of 5 batches
Epoch 10 of 60 took 96.198s
  training loss:		0.143786
  validation loss:		0.008764
  top 1 accuracy:		98.85 %
  top 2 accuracy:		99.94 %
0.1802845597267151
0.12850092351436615
0.12779733538627625
Batch of classes 5 out of 5 batches
Epoch 11 of 60 took 95.895s
  training loss:		0.145750
  validation loss:		0.005728
  top 1 accuracy:		99.69 %
  top 2 accuracy:		100.00 %
0.15737265348434448
0.13706910610198975
0.14739345014095306
Batch of classes 5 out of 5 batches
Epoch 12 of 60 took 95.962s
  training loss:		0.144291
  validation loss:		0.017346
  top 1 accuracy:		98.12 %
  top 2 accuracy:		99.90 %
0.13142511248588562
0.1444225162267685
0.14066873490810394
Batch of classes 5 out of 5 batches
Epoch 13 of 60 took 96.203s
  training loss:		0.142771
  validation loss:		0.014861
  top 1 accuracy:		97.73 %
  top 2 accuracy:		99.94 %
0.13304512202739716
0.13652266561985016
0.13160449266433716
Batch of classes 5 out of 5 batches
Epoch 14 of 60 took 95.582s
  training loss:		0.140959
  validation loss:		0.012580
  top 1 accuracy:		98.69 %
  top 2 accuracy:		99.96 %
0.1529768407344818
0.13949638605117798
0.1512226164340973
Batch of classes 5 out of 5 batches
Epoch 15 of 60 took 96.608s
  training loss:		0.143313
  validation loss:		0.006737
  top 1 accuracy:		99.27 %
  top 2 accuracy:		99.92 %
0.14107151329517365
0.1510869264602661
0.1288238763809204
Batch of classes 5 out of 5 batches
Epoch 16 of 60 took 95.696s
  training loss:		0.144750
  validation loss:		0.005482
  top 1 accuracy:		99.29 %
  top 2 accuracy:		99.98 %
0.13051433861255646
0.15036852657794952
0.13764630258083344
Batch of classes 5 out of 5 batches
Epoch 17 of 60 took 95.748s
  training loss:		0.143910
  validation loss:		0.016196
  top 1 accuracy:		97.87 %
  top 2 accuracy:		99.94 %
0.14654915034770966
0.1256483644247055
0.12846381962299347
Batch of classes 5 out of 5 batches
Epoch 18 of 60 took 96.222s
  training loss:		0.141696
  validation loss:		0.030360
  top 1 accuracy:		96.19 %
  top 2 accuracy:		98.73 %
0.14060384035110474
0.15428835153579712
0.14375098049640656
Batch of classes 5 out of 5 batches
Epoch 19 of 60 took 96.254s
  training loss:		0.141888
  validation loss:		0.010307
  top 1 accuracy:		98.98 %
  top 2 accuracy:		99.96 %
0.13750788569450378
0.1364867389202118
0.1452569216489792
Batch of classes 5 out of 5 batches
Epoch 20 of 60 took 95.744s
  training loss:		0.140721
  validation loss:		0.011228
  top 1 accuracy:		98.29 %
  top 2 accuracy:		99.96 %
0.13111571967601776
0.14191919565200806
0.13406310975551605
Batch of classes 5 out of 5 batches
Epoch 21 of 60 took 95.705s
  training loss:		0.136389
  validation loss:		0.009352
  top 1 accuracy:		99.08 %
  top 2 accuracy:		99.96 %
0.12948636710643768
0.13191509246826172
0.1392306089401245
Batch of classes 5 out of 5 batches
Epoch 22 of 60 took 95.495s
  training loss:		0.133690
  validation loss:		0.005164
  top 1 accuracy:		99.44 %
  top 2 accuracy:		99.96 %
0.1343938410282135
0.12664727866649628
0.13282442092895508
Batch of classes 5 out of 5 batches
Epoch 23 of 60 took 96.118s
  training loss:		0.133031
  validation loss:		0.003876
  top 1 accuracy:		99.56 %
  top 2 accuracy:		99.94 %
0.1333242505788803
0.13472872972488403
0.14836253225803375
Batch of classes 5 out of 5 batches
Epoch 24 of 60 took 95.439s
  training loss:		0.134016
  validation loss:		0.003219
  top 1 accuracy:		99.58 %
  top 2 accuracy:		99.96 %
0.13379904627799988
0.13065467774868011
0.1311301738023758
Batch of classes 5 out of 5 batches
Epoch 25 of 60 took 95.724s
  training loss:		0.133678
  validation loss:		0.006214
  top 1 accuracy:		99.08 %
  top 2 accuracy:		99.83 %
0.14311225712299347
0.13424211740493774
0.13174329698085785
Batch of classes 5 out of 5 batches
Epoch 26 of 60 took 96.151s
  training loss:		0.134337
  validation loss:		0.003257
  top 1 accuracy:		99.42 %
  top 2 accuracy:		100.00 %
0.14358612895011902
0.1364123672246933
0.1292332261800766
Batch of classes 5 out of 5 batches
Epoch 27 of 60 took 95.672s
  training loss:		0.133422
  validation loss:		0.002858
  top 1 accuracy:		99.52 %
  top 2 accuracy:		99.96 %
0.12661609053611755
0.13047730922698975
0.1308920830488205
Batch of classes 5 out of 5 batches
Epoch 28 of 60 took 95.795s
  training loss:		0.132684
  validation loss:		0.004497
  top 1 accuracy:		99.35 %
  top 2 accuracy:		99.87 %
0.13961480557918549
0.1344049572944641
0.1308802217245102
Batch of classes 5 out of 5 batches
Epoch 29 of 60 took 97.068s
  training loss:		0.133382
  validation loss:		0.003723
  top 1 accuracy:		99.42 %
  top 2 accuracy:		99.92 %
0.13232235610485077
0.13068197667598724
0.12819968163967133
Batch of classes 5 out of 5 batches
Epoch 30 of 60 took 95.944s
  training loss:		0.133710
  validation loss:		0.002749
  top 1 accuracy:		99.56 %
  top 2 accuracy:		99.96 %
0.13236023485660553
0.13110984861850739
0.12617792189121246
Batch of classes 5 out of 5 batches
Epoch 31 of 60 took 95.306s
  training loss:		0.131816
  validation loss:		0.002760
  top 1 accuracy:		99.50 %
  top 2 accuracy:		99.94 %
0.13248825073242188
0.13029156625270844
0.1284649670124054
Batch of classes 5 out of 5 batches
Epoch 32 of 60 took 96.232s
  training loss:		0.132683
  validation loss:		0.004645
  top 1 accuracy:		99.19 %
  top 2 accuracy:		99.92 %
0.13485312461853027
0.1321059912443161
0.13617165386676788
Batch of classes 5 out of 5 batches
Epoch 33 of 60 took 96.819s
  training loss:		0.133370
  validation loss:		0.003703
  top 1 accuracy:		99.37 %
  top 2 accuracy:		99.90 %
0.13604038953781128
0.13345538079738617
0.1314319372177124
Batch of classes 5 out of 5 batches
Epoch 34 of 60 took 96.267s
  training loss:		0.133590
  validation loss:		0.001780
  top 1 accuracy:		99.79 %
  top 2 accuracy:		99.96 %
0.12826932966709137
0.13224507868289948
0.13487599790096283
Batch of classes 5 out of 5 batches
Epoch 35 of 60 took 95.499s
  training loss:		0.133339
  validation loss:		0.001452
  top 1 accuracy:		99.77 %
  top 2 accuracy:		99.96 %
0.13265593349933624
0.1302143633365631
0.13090981543064117
Batch of classes 5 out of 5 batches
Epoch 36 of 60 took 95.952s
  training loss:		0.134009
  validation loss:		0.002090
  top 1 accuracy:		99.69 %
  top 2 accuracy:		99.96 %
0.13142235577106476
0.1334572285413742
0.1355879157781601
Batch of classes 5 out of 5 batches
Epoch 37 of 60 took 96.313s
  training loss:		0.133257
  validation loss:		0.002050
  top 1 accuracy:		99.69 %
  top 2 accuracy:		99.96 %
0.1360393911600113
0.1296193152666092
0.1368420571088791
Batch of classes 5 out of 5 batches
Epoch 38 of 60 took 96.404s
  training loss:		0.132915
  validation loss:		0.002045
  top 1 accuracy:		99.58 %
  top 2 accuracy:		100.00 %
0.1324494481086731
0.1303226351737976
0.12948644161224365
Batch of classes 5 out of 5 batches
Epoch 39 of 60 took 95.648s
  training loss:		0.133263
  validation loss:		0.005396
  top 1 accuracy:		99.08 %
  top 2 accuracy:		99.90 %
0.1371171772480011
0.13190209865570068
0.1354922503232956
Batch of classes 5 out of 5 batches
Epoch 40 of 60 took 97.725s
  training loss:		0.133137
  validation loss:		0.009247
  top 1 accuracy:		98.50 %
  top 2 accuracy:		99.77 %
0.13034144043922424
0.13069742918014526
0.13290221989154816
Batch of classes 5 out of 5 batches
Epoch 41 of 60 took 95.875s
  training loss:		0.132808
  validation loss:		0.001768
  top 1 accuracy:		99.75 %
  top 2 accuracy:		99.96 %
0.13867896795272827
0.1366962045431137
0.13011357188224792
Batch of classes 5 out of 5 batches
Epoch 42 of 60 took 96.287s
  training loss:		0.132736
  validation loss:		0.001435
  top 1 accuracy:		99.79 %
  top 2 accuracy:		100.00 %
0.13060148060321808
0.13347643613815308
0.12924011051654816
Batch of classes 5 out of 5 batches
Epoch 43 of 60 took 96.046s
  training loss:		0.132376
  validation loss:		0.001480
  top 1 accuracy:		99.77 %
  top 2 accuracy:		100.00 %
0.13068832457065582
0.13251720368862152
0.131167933344841
Batch of classes 5 out of 5 batches
Epoch 44 of 60 took 95.683s
  training loss:		0.131866
  validation loss:		0.001366
  top 1 accuracy:		99.77 %
  top 2 accuracy:		100.00 %
0.1291787177324295
0.13249258697032928
0.1317981779575348
Batch of classes 5 out of 5 batches
Epoch 45 of 60 took 95.509s
  training loss:		0.131342
  validation loss:		0.000362
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.13382528722286224
0.13138656318187714
0.13184942305088043
Batch of classes 5 out of 5 batches
Epoch 46 of 60 took 97.764s
  training loss:		0.131385
  validation loss:		0.000654
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
0.13895554840564728
0.1306360960006714
0.13596776127815247
Batch of classes 5 out of 5 batches
Epoch 47 of 60 took 96.508s
  training loss:		0.131281
  validation loss:		0.000688
  top 1 accuracy:		99.96 %
  top 2 accuracy:		99.96 %
0.13019241392612457
0.13121069967746735
0.13356982171535492
Batch of classes 5 out of 5 batches
Epoch 48 of 60 took 96.658s
  training loss:		0.132024
  validation loss:		0.000765
  top 1 accuracy:		99.87 %
  top 2 accuracy:		99.98 %
0.13363172113895416
0.13307234644889832
0.1306365430355072
Batch of classes 5 out of 5 batches
Epoch 49 of 60 took 95.501s
  training loss:		0.132466
  validation loss:		0.000971
  top 1 accuracy:		99.81 %
  top 2 accuracy:		99.98 %
0.13129965960979462
0.1338501274585724
0.1349864900112152
Batch of classes 5 out of 5 batches
Epoch 50 of 60 took 96.214s
  training loss:		0.132026
  validation loss:		0.000610
  top 1 accuracy:		99.94 %
  top 2 accuracy:		99.98 %
0.1314648985862732
0.13003559410572052
0.13125815987586975
Batch of classes 5 out of 5 batches
Epoch 51 of 60 took 95.524s
  training loss:		0.132430
  validation loss:		0.000510
  top 1 accuracy:		99.87 %
  top 2 accuracy:		99.98 %
0.12934811413288116
0.13449527323246002
0.1335371434688568
Batch of classes 5 out of 5 batches
Epoch 52 of 60 took 95.828s
  training loss:		0.132493
  validation loss:		0.002659
  top 1 accuracy:		99.62 %
  top 2 accuracy:		99.98 %
0.13273616135120392
0.13030706346035004
0.13087162375450134
Batch of classes 5 out of 5 batches
Epoch 53 of 60 took 95.579s
  training loss:		0.132418
  validation loss:		0.001004
  top 1 accuracy:		99.83 %
  top 2 accuracy:		100.00 %
0.13381072878837585
0.13139836490154266
0.1304209679365158
Batch of classes 5 out of 5 batches
Epoch 54 of 60 took 95.935s
  training loss:		0.132590
  validation loss:		0.001376
  top 1 accuracy:		99.83 %
  top 2 accuracy:		99.94 %
0.1326993703842163
0.13550493121147156
0.12915383279323578
Batch of classes 5 out of 5 batches
Epoch 55 of 60 took 96.253s
  training loss:		0.132047
  validation loss:		0.000689
  top 1 accuracy:		99.92 %
  top 2 accuracy:		99.98 %
0.13138943910598755
0.13025692105293274
0.13130240142345428
Batch of classes 5 out of 5 batches
Epoch 56 of 60 took 95.761s
  training loss:		0.132036
  validation loss:		0.000849
  top 1 accuracy:		99.87 %
  top 2 accuracy:		100.00 %
0.13182038068771362
0.1330011785030365
0.12888160347938538
Batch of classes 5 out of 5 batches
Epoch 57 of 60 took 95.694s
  training loss:		0.132123
  validation loss:		0.001207
  top 1 accuracy:		99.73 %
  top 2 accuracy:		99.98 %
0.13216204941272736
0.13195838034152985
0.1325652152299881
Batch of classes 5 out of 5 batches
Epoch 58 of 60 took 96.307s
  training loss:		0.131978
  validation loss:		0.000803
  top 1 accuracy:		99.87 %
  top 2 accuracy:		99.96 %
0.1304721236228943
0.12906786799430847
0.13210220634937286
Batch of classes 5 out of 5 batches
Epoch 59 of 60 took 96.230s
  training loss:		0.131992
  validation loss:		0.000442
  top 1 accuracy:		99.94 %
  top 2 accuracy:		100.00 %
0.12989524006843567
0.1286371648311615
0.13021741807460785
Batch of classes 5 out of 5 batches
Epoch 60 of 60 took 96.398s
  training loss:		0.131285
  validation loss:		0.000871
  top 1 accuracy:		99.90 %
  top 2 accuracy:		99.98 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(103)
tensor(103)
tensor(103)
tensor(103)
tensor(103)
tensor(103)
tensor(103)
tensor(103)
tensor(103)
tensor(103)
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		70.08 %
  top 1 accuracy Hybrid 1       :		71.90 %
  top 1 accuracy NCM            :		70.25 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		73.33 %
  top 1 accuracy Hybrid 1       :		74.96 %
  top 1 accuracy NCM            :		73.08 %
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		95.25 %
  top 1 accuracy Hybrid 1       :		78.62 %
  top 1 accuracy NCM            :		95.56 %
Binary accuracy:
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		95.83 %
  top 1 accuracy Hybrid 1       :		82.33 %
  top 1 accuracy NCM            :		96.15 %
Final results on progan1024 classes:
  top 1 accuracy iCaRL          :		89.71 %
  top 1 accuracy Hybrid 1       :		76.15 %
  top 1 accuracy NCM            :		90.56 %
Binary accuracy:
Final results on progan1024 classes:
  top 1 accuracy iCaRL          :		98.10 %
  top 1 accuracy Hybrid 1       :		96.77 %
  top 1 accuracy NCM            :		97.94 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		63.46 %
  top 1 accuracy Hybrid 1       :		36.85 %
  top 1 accuracy NCM            :		74.02 %
Binary accuracy:
Final results on glow classes:
  top 1 accuracy iCaRL          :		96.73 %
  top 1 accuracy Hybrid 1       :		86.75 %
  top 1 accuracy NCM            :		96.88 %
Final results on stargan classes:
  top 1 accuracy iCaRL          :		82.71 %
  top 1 accuracy Hybrid 1       :		99.90 %
  top 1 accuracy NCM            :		71.83 %
Binary accuracy:
Final results on stargan classes:
  top 1 accuracy iCaRL          :		99.88 %
  top 1 accuracy Hybrid 1       :		99.98 %
  top 1 accuracy NCM            :		99.88 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		80.24 %
  top 1 accuracy Hybrid 1       :		72.68 %
  top 1 accuracy NCM            :		80.45 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		92.78 %
  top 1 accuracy Hybrid 1       :		88.16 %
  top 1 accuracy NCM            :		92.78 %
tensor([[[75.1667,  0.0000,  0.0000,  0.0000,  0.0000],
         [75.1042,  0.0000,  0.0000,  0.0000,  0.0000],
         [75.1667,  0.0000,  0.0000,  0.0000,  0.0000]],

        [[74.6667, 99.6875,  0.0000,  0.0000,  0.0000],
         [73.5625, 99.9375,  0.0000,  0.0000,  0.0000],
         [74.4792, 99.6875,  0.0000,  0.0000,  0.0000]],

        [[78.4583, 98.8333, 99.5000,  0.0000,  0.0000],
         [79.3542, 98.7500, 99.3750,  0.0000,  0.0000],
         [78.3958, 98.7292, 99.5000,  0.0000,  0.0000]],

        [[72.3125, 98.3750, 97.9167, 99.5833,  0.0000],
         [73.4375, 98.1042, 96.7917, 99.3958,  0.0000],
         [72.3750, 98.2708, 97.9167, 99.5833,  0.0000]],

        [[73.3333, 95.8333, 98.1042, 96.7292, 99.8750],
         [74.9583, 82.3333, 96.7708, 86.7500, 99.9792],
         [73.0833, 96.1458, 97.9375, 96.8750, 99.8750]]])
tensor([92.7750, 88.1583, 92.7833])
