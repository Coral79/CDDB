----------------- Options ---------------
               add_binary: False                         
               batch_size: 32                            	[default: 64]
                   binary: False                         
                blur_prob: 0                             
                 blur_sig: 0.5                           
          checkpoints_dir: /scratch_net/kringel/chuqli/CNNDetection/checkpoints	[default: ./checkpoints]
                class_bal: False                         
           continue_train: False                         
                 cropSize: 224                           
                 data_aug: False                         
                 dataroot: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/DoGAN_data/new/GanFake	[default: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL]
          earlystop_epoch: 5                             
                    epoch: latest                        
                 fine_tun: False                         
                    gpuid: [1]                           
                init_gain: 0.02                          
                  init_lr: 0.001                         	[default: 0.0005]
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2                           
                 jpg_prob: 0                             
                 jpg_qual: 75                            
                 loadSize: 256                           
                     mode: binary                        
               model_name: resnet18                      
               model_type: resnet                        
            model_weights: None                          
               multiclass: [1, 1, 0]                     	[default: [1]]
                     name: icarl_ganfake                 	[default: experiment_name]
                  no_flip: False                         
              num_classes: 2                             
               num_epochs: 24                            	[default: 12]
              num_threads: 4                             
                  outfile: temp_0.1.csv                  
            pretrain_name:                               
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 20                            
         save_latest_freq: 2000                          
                 schedule: [10, 20, 30]                  	[default: [10]]
           serial_batches: False                         
                   suffix:                               
                task_name: cyclegan,progan256,progan1024 	[default: ]
              train_split: train                         
                val_split: val                           
----------------- End -------------------
{'All': 6}
Task order: ['cyclegan', 'progan256', 'progan1024']
Classes in this batch: tensor([0, 1])
Data Size: 7196


Before first epoch
  validation loss:		0.730389
  top 1 accuracy:		3.48 %
  top 2 accuracy:		13.17 %
Batch of classes number 1 arrives ...
0.44531822204589844
0.13320808112621307
0.08229488134384155
Batch of classes 1 out of 3 batches
Epoch 1 of 24 took 152.544s
  training loss:		0.125859
  validation loss:		0.362102
  top 1 accuracy:		75.73 %
  top 2 accuracy:		100.00 %
0.0622548833489418
0.05333166569471359
0.06688749045133591
Batch of classes 1 out of 3 batches
Epoch 2 of 24 took 113.365s
  training loss:		0.091508
  validation loss:		0.286266
  top 1 accuracy:		71.96 %
  top 2 accuracy:		100.00 %
0.09063699096441269
0.02744707465171814
0.08435094356536865
Batch of classes 1 out of 3 batches
Epoch 3 of 24 took 92.038s
  training loss:		0.081320
  validation loss:		0.327313
  top 1 accuracy:		75.56 %
  top 2 accuracy:		100.00 %
0.16427013278007507
0.07727064937353134
0.06508169323205948
Batch of classes 1 out of 3 batches
Epoch 4 of 24 took 109.043s
  training loss:		0.070194
  validation loss:		0.146421
  top 1 accuracy:		78.52 %
  top 2 accuracy:		100.00 %
0.0305583905428648
0.037368908524513245
0.024813150987029076
Batch of classes 1 out of 3 batches
Epoch 5 of 24 took 76.852s
  training loss:		0.069488
  validation loss:		0.595058
  top 1 accuracy:		57.85 %
  top 2 accuracy:		100.00 %
0.053246818482875824
0.050621047616004944
0.0417926125228405
Batch of classes 1 out of 3 batches
Epoch 6 of 24 took 96.675s
  training loss:		0.056757
  validation loss:		0.609867
  top 1 accuracy:		69.94 %
  top 2 accuracy:		100.00 %
0.06514638662338257
0.05935821682214737
0.04048670455813408
Batch of classes 1 out of 3 batches
Epoch 7 of 24 took 138.212s
  training loss:		0.044922
  validation loss:		2.032042
  top 1 accuracy:		71.92 %
  top 2 accuracy:		100.00 %
0.06367933750152588
0.08619548380374908
0.0058677466586232185
Batch of classes 1 out of 3 batches
Epoch 8 of 24 took 164.123s
  training loss:		0.041477
  validation loss:		0.568175
  top 1 accuracy:		75.29 %
  top 2 accuracy:		100.00 %
0.01636415906250477
0.06869558244943619
0.014521228149533272
Batch of classes 1 out of 3 batches
Epoch 9 of 24 took 170.802s
  training loss:		0.033678
  validation loss:		0.669880
  top 1 accuracy:		75.06 %
  top 2 accuracy:		100.00 %
0.0330284982919693
0.03832073137164116
0.00267200730741024
Batch of classes 1 out of 3 batches
Epoch 10 of 24 took 172.455s
  training loss:		0.028250
  validation loss:		1.148389
  top 1 accuracy:		74.87 %
  top 2 accuracy:		95.08 %
0.023631056770682335
0.009316976182162762
0.011847580783069134
Batch of classes 1 out of 3 batches
Epoch 11 of 24 took 174.859s
  training loss:		0.016707
  validation loss:		0.404977
  top 1 accuracy:		77.65 %
  top 2 accuracy:		99.96 %
0.02880093827843666
0.009253863245248795
0.05563458427786827
Batch of classes 1 out of 3 batches
Epoch 12 of 24 took 170.910s
  training loss:		0.009223
  validation loss:		0.668149
  top 1 accuracy:		75.15 %
  top 2 accuracy:		99.37 %
0.001061841961927712
0.006657764315605164
0.0005519661353901029
Batch of classes 1 out of 3 batches
Epoch 13 of 24 took 173.206s
  training loss:		0.008733
  validation loss:		0.414524
  top 1 accuracy:		75.60 %
  top 2 accuracy:		100.00 %
0.014177296310663223
0.0014617530396208167
0.0008929595351219177
Batch of classes 1 out of 3 batches
Epoch 14 of 24 took 169.492s
  training loss:		0.007102
  validation loss:		0.751659
  top 1 accuracy:		75.50 %
  top 2 accuracy:		98.48 %
0.00032574794022366405
0.0007506755646318197
0.0014619857538491488
Batch of classes 1 out of 3 batches
Epoch 15 of 24 took 155.196s
  training loss:		0.008912
  validation loss:		0.771188
  top 1 accuracy:		75.17 %
  top 2 accuracy:		98.98 %
0.0009215429308824241
0.0010905613889917731
0.0012464666506275535
Batch of classes 1 out of 3 batches
Epoch 16 of 24 took 154.788s
  training loss:		0.007235
  validation loss:		0.542369
  top 1 accuracy:		75.94 %
  top 2 accuracy:		99.23 %
0.0004994465271010995
0.0001815233554225415
0.01174112968146801
Batch of classes 1 out of 3 batches
Epoch 17 of 24 took 141.646s
  training loss:		0.010279
  validation loss:		0.738357
  top 1 accuracy:		75.04 %
  top 2 accuracy:		98.73 %
0.019024912267923355
0.0009982110932469368
0.0029882844537496567
Batch of classes 1 out of 3 batches
Epoch 18 of 24 took 140.207s
  training loss:		0.006856
  validation loss:		0.408275
  top 1 accuracy:		75.90 %
  top 2 accuracy:		100.00 %
0.01936843991279602
0.0027748537249863148
0.015094326809048653
Batch of classes 1 out of 3 batches
Epoch 19 of 24 took 128.159s
  training loss:		0.010737
  validation loss:		0.679805
  top 1 accuracy:		75.13 %
  top 2 accuracy:		99.42 %
0.001198425074107945
0.007585091050714254
0.0030175778083503246
Batch of classes 1 out of 3 batches
Epoch 20 of 24 took 112.224s
  training loss:		0.007494
  validation loss:		0.646771
  top 1 accuracy:		75.23 %
  top 2 accuracy:		99.35 %
0.0006593374419026077
0.009600083343684673
0.004329667426645756
Batch of classes 1 out of 3 batches
Epoch 21 of 24 took 109.372s
  training loss:		0.003564
  validation loss:		0.503577
  top 1 accuracy:		75.56 %
  top 2 accuracy:		99.87 %
0.0006329905008897185
0.0005541613209061325
0.0010374127887189388
Batch of classes 1 out of 3 batches
Epoch 22 of 24 took 112.389s
  training loss:		0.004013
  validation loss:		0.574961
  top 1 accuracy:		75.48 %
  top 2 accuracy:		99.73 %
0.0006393390940502286
0.01838715933263302
0.0008137215627357364
Batch of classes 1 out of 3 batches
Epoch 23 of 24 took 107.091s
  training loss:		0.002377
  validation loss:		0.563479
  top 1 accuracy:		75.50 %
  top 2 accuracy:		99.71 %
0.000833295751363039
0.0001047662808559835
0.0008535184897482395
Batch of classes 1 out of 3 batches
Epoch 24 of 24 took 92.272s
  training loss:		0.001795
  validation loss:		0.608055
  top 1 accuracy:		75.54 %
  top 2 accuracy:		99.31 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		75.58 %
  top 1 accuracy Hybrid 1       :		75.54 %
  top 1 accuracy NCM            :		75.56 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		75.58 %
  top 1 accuracy Hybrid 1       :		75.54 %
  top 1 accuracy NCM            :		75.56 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		75.58 %
  top 1 accuracy Hybrid 1       :		75.54 %
  top 1 accuracy NCM            :		75.56 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		75.58 %
  top 1 accuracy Hybrid 1       :		75.54 %
  top 1 accuracy NCM            :		75.56 %
Classes in this batch: tensor([2, 3])
Data Size: 7200


Before first epoch
  validation loss:		9.173081
  top 1 accuracy:		0.00 %
  top 2 accuracy:		43.52 %
Batch of classes number 2 arrives ...
1.7304538488388062
0.22423091530799866
0.23699864745140076
Batch of classes 2 out of 3 batches
Epoch 1 of 24 took 179.999s
  training loss:		0.268216
  validation loss:		2.444516
  top 1 accuracy:		0.02 %
  top 2 accuracy:		65.71 %
0.20774579048156738
0.22542868554592133
0.19698315858840942
Batch of classes 2 out of 3 batches
Epoch 2 of 24 took 192.189s
  training loss:		0.205115
  validation loss:		1.871400
  top 1 accuracy:		1.31 %
  top 2 accuracy:		82.23 %
0.2037341296672821
0.12368913739919662
0.05458589643239975
Batch of classes 2 out of 3 batches
Epoch 3 of 24 took 198.822s
  training loss:		0.122465
  validation loss:		1.834160
  top 1 accuracy:		8.60 %
  top 2 accuracy:		93.62 %
0.04952962324023247
0.0488545224070549
0.09877582639455795
Batch of classes 2 out of 3 batches
Epoch 4 of 24 took 200.628s
  training loss:		0.056714
  validation loss:		1.918854
  top 1 accuracy:		0.33 %
  top 2 accuracy:		93.58 %
0.05953733250498772
0.06924507766962051
0.05785329267382622
Batch of classes 2 out of 3 batches
Epoch 5 of 24 took 185.274s
  training loss:		0.051406
  validation loss:		2.987906
  top 1 accuracy:		7.37 %
  top 2 accuracy:		98.21 %
0.010763470083475113
0.009644013829529285
0.025226173922419548
Batch of classes 2 out of 3 batches
Epoch 6 of 24 took 157.166s
  training loss:		0.038170
  validation loss:		1.736908
  top 1 accuracy:		34.71 %
  top 2 accuracy:		97.60 %
0.005886341445147991
0.01863325759768486
0.017604336142539978
Batch of classes 2 out of 3 batches
Epoch 7 of 24 took 92.587s
  training loss:		0.035848
  validation loss:		1.461365
  top 1 accuracy:		24.48 %
  top 2 accuracy:		98.04 %
0.045898571610450745
0.027921687811613083
0.02964135818183422
Batch of classes 2 out of 3 batches
Epoch 8 of 24 took 83.504s
  training loss:		0.030810
  validation loss:		1.433289
  top 1 accuracy:		27.27 %
  top 2 accuracy:		98.37 %
0.0339541919529438
0.061745189130306244
0.010507497005164623
Batch of classes 2 out of 3 batches
Epoch 9 of 24 took 77.026s
  training loss:		0.033264
  validation loss:		1.462510
  top 1 accuracy:		22.15 %
  top 2 accuracy:		94.54 %
0.020561499521136284
0.031116805970668793
0.003503524698317051
Batch of classes 2 out of 3 batches
Epoch 10 of 24 took 69.708s
  training loss:		0.025225
  validation loss:		1.645017
  top 1 accuracy:		3.31 %
  top 2 accuracy:		98.54 %
0.03478402644395828
0.013260255567729473
0.007616268005222082
Batch of classes 2 out of 3 batches
Epoch 11 of 24 took 73.056s
  training loss:		0.015663
  validation loss:		1.566517
  top 1 accuracy:		41.69 %
  top 2 accuracy:		99.35 %
0.004320621956139803
0.0022546309046447277
0.002611976582556963
Batch of classes 2 out of 3 batches
Epoch 12 of 24 took 72.052s
  training loss:		0.011976
  validation loss:		1.666047
  top 1 accuracy:		45.65 %
  top 2 accuracy:		99.42 %
0.0075409128330647945
0.002023737644776702
0.01093575544655323
Batch of classes 2 out of 3 batches
Epoch 13 of 24 took 72.759s
  training loss:		0.009531
  validation loss:		1.734877
  top 1 accuracy:		35.04 %
  top 2 accuracy:		99.40 %
0.007643614895641804
0.019159384071826935
0.004940211772918701
Batch of classes 2 out of 3 batches
Epoch 14 of 24 took 70.092s
  training loss:		0.010368
  validation loss:		1.769233
  top 1 accuracy:		44.58 %
  top 2 accuracy:		99.87 %
0.007066071964800358
0.0049558053724467754
0.004549229051917791
Batch of classes 2 out of 3 batches
Epoch 15 of 24 took 70.879s
  training loss:		0.009957
  validation loss:		1.545461
  top 1 accuracy:		46.83 %
  top 2 accuracy:		99.06 %
0.002426090417429805
0.013598417863249779
0.012313144281506538
Batch of classes 2 out of 3 batches
Epoch 16 of 24 took 70.820s
  training loss:		0.009195
  validation loss:		1.647063
  top 1 accuracy:		57.52 %
  top 2 accuracy:		99.56 %
0.005677300505340099
0.0005257846205495298
0.00637696823105216
Batch of classes 2 out of 3 batches
Epoch 17 of 24 took 72.187s
  training loss:		0.008159
  validation loss:		1.866147
  top 1 accuracy:		54.48 %
  top 2 accuracy:		99.75 %
0.005202252417802811
0.006448210682719946
0.027221601456403732
Batch of classes 2 out of 3 batches
Epoch 18 of 24 took 70.995s
  training loss:		0.008023
  validation loss:		1.771202
  top 1 accuracy:		57.48 %
  top 2 accuracy:		99.73 %
0.0016954008024185896
0.0014672076795250177
0.003821101738139987
Batch of classes 2 out of 3 batches
Epoch 19 of 24 took 81.412s
  training loss:		0.008495
  validation loss:		1.755378
  top 1 accuracy:		59.21 %
  top 2 accuracy:		99.52 %
0.003327462822198868
0.00171836675144732
0.005206744652241468
Batch of classes 2 out of 3 batches
Epoch 20 of 24 took 137.772s
  training loss:		0.009448
  validation loss:		1.650604
  top 1 accuracy:		63.54 %
  top 2 accuracy:		99.62 %
0.011615532450377941
0.009737127460539341
0.02595483884215355
Batch of classes 2 out of 3 batches
Epoch 21 of 24 took 175.191s
  training loss:		0.006361
  validation loss:		1.770681
  top 1 accuracy:		55.19 %
  top 2 accuracy:		99.71 %
0.0012533359695225954
0.001306944410316646
0.0006225870456546545
Batch of classes 2 out of 3 batches
Epoch 22 of 24 took 173.978s
  training loss:		0.005148
  validation loss:		1.713124
  top 1 accuracy:		65.31 %
  top 2 accuracy:		99.56 %
0.002997497096657753
0.0004643224528990686
0.0009406082099303603
Batch of classes 2 out of 3 batches
Epoch 23 of 24 took 134.514s
  training loss:		0.005522
  validation loss:		1.557274
  top 1 accuracy:		70.92 %
  top 2 accuracy:		99.77 %
0.0029801377095282078
0.005997584667056799
0.00045130104990676045
Batch of classes 2 out of 3 batches
Epoch 24 of 24 took 85.921s
  training loss:		0.003739
  validation loss:		1.669952
  top 1 accuracy:		73.33 %
  top 2 accuracy:		99.69 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		70.27 %
  top 1 accuracy Hybrid 1       :		74.02 %
  top 1 accuracy NCM            :		70.17 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		71.40 %
  top 1 accuracy Hybrid 1       :		74.25 %
  top 1 accuracy NCM            :		71.33 %
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		99.48 %
  top 1 accuracy Hybrid 1       :		73.40 %
  top 1 accuracy NCM            :		99.50 %
Binary accuracy:
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		99.67 %
  top 1 accuracy Hybrid 1       :		93.56 %
  top 1 accuracy NCM            :		99.69 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		84.88 %
  top 1 accuracy Hybrid 1       :		73.71 %
  top 1 accuracy NCM            :		84.83 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		85.53 %
  top 1 accuracy Hybrid 1       :		83.91 %
  top 1 accuracy NCM            :		85.51 %
Classes in this batch: tensor([4, 5])
Data Size: 7201


Before first epoch
  validation loss:		2.442339
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 3 arrives ...
3.6423423290252686
0.3620406985282898
0.2239978313446045
Batch of classes 3 out of 3 batches
Epoch 1 of 24 took 1120.119s
  training loss:		0.423250
  validation loss:		0.554349
  top 1 accuracy:		64.02 %
  top 2 accuracy:		89.06 %
0.19364914298057556
0.21655158698558807
0.24165146052837372
Batch of classes 3 out of 3 batches
Epoch 2 of 24 took 1091.177s
  training loss:		0.212668
  validation loss:		0.643254
  top 1 accuracy:		59.94 %
  top 2 accuracy:		86.35 %
0.14828640222549438
0.17926260828971863
0.11960317939519882
Batch of classes 3 out of 3 batches
Epoch 3 of 24 took 1098.259s
  training loss:		0.195621
  validation loss:		0.541377
  top 1 accuracy:		67.69 %
  top 2 accuracy:		90.92 %
0.18397068977355957
0.14655467867851257
0.19180524349212646
Batch of classes 3 out of 3 batches
Epoch 4 of 24 took 1051.904s
  training loss:		0.182333
  validation loss:		0.487602
  top 1 accuracy:		91.85 %
  top 2 accuracy:		97.92 %
0.17418669164180756
0.15092426538467407
0.20879434049129486
Batch of classes 3 out of 3 batches
Epoch 5 of 24 took 1019.922s
  training loss:		0.176575
  validation loss:		0.519903
  top 1 accuracy:		77.52 %
  top 2 accuracy:		95.90 %
0.18643444776535034
0.1646474301815033
0.19958233833312988
Batch of classes 3 out of 3 batches
Epoch 6 of 24 took 1033.325s
  training loss:		0.170957
  validation loss:		0.578201
  top 1 accuracy:		62.21 %
  top 2 accuracy:		79.77 %
0.15863874554634094
0.16614219546318054
0.12466321885585785
Batch of classes 3 out of 3 batches
Epoch 7 of 24 took 1115.604s
  training loss:		0.168615
  validation loss:		0.548890
  top 1 accuracy:		83.92 %
  top 2 accuracy:		93.12 %
0.1568567454814911
0.17641553282737732
0.12362785637378693
Batch of classes 3 out of 3 batches
Epoch 8 of 24 took 1091.400s
  training loss:		0.166220
  validation loss:		0.629494
  top 1 accuracy:		65.04 %
  top 2 accuracy:		81.92 %
0.12988197803497314
0.1598537564277649
0.10859440267086029
Batch of classes 3 out of 3 batches
Epoch 9 of 24 took 1099.637s
  training loss:		0.170473
  validation loss:		0.479314
  top 1 accuracy:		83.90 %
  top 2 accuracy:		91.33 %
0.1684691309928894
0.1383262574672699
0.1423993706703186
Batch of classes 3 out of 3 batches
Epoch 10 of 24 took 1119.088s
  training loss:		0.162212
  validation loss:		0.627759
  top 1 accuracy:		64.29 %
  top 2 accuracy:		76.46 %
0.13416486978530884
0.13583257794380188
0.1559857875108719
Batch of classes 3 out of 3 batches
Epoch 11 of 24 took 1062.259s
  training loss:		0.140722
  validation loss:		0.480700
  top 1 accuracy:		95.44 %
  top 2 accuracy:		99.58 %
0.10744331777095795
0.11881198734045029
0.1298317313194275
Batch of classes 3 out of 3 batches
Epoch 12 of 24 took 1107.359s
  training loss:		0.140731
  validation loss:		0.492894
  top 1 accuracy:		94.96 %
  top 2 accuracy:		99.17 %
0.21126703917980194
0.14096304774284363
0.10750051587820053
Batch of classes 3 out of 3 batches
Epoch 13 of 24 took 1118.993s
  training loss:		0.137753
  validation loss:		0.484178
  top 1 accuracy:		96.77 %
  top 2 accuracy:		99.50 %
0.17851833999156952
0.15432652831077576
0.13874074816703796
Batch of classes 3 out of 3 batches
Epoch 14 of 24 took 1105.846s
  training loss:		0.140038
  validation loss:		0.485136
  top 1 accuracy:		90.08 %
  top 2 accuracy:		98.35 %
0.13250373303890228
0.11119215190410614
0.12748466432094574
Batch of classes 3 out of 3 batches
Epoch 15 of 24 took 1108.411s
  training loss:		0.143163
  validation loss:		0.468756
  top 1 accuracy:		93.56 %
  top 2 accuracy:		98.73 %
0.15425527095794678
0.12520353496074677
0.10674270242452621
Batch of classes 3 out of 3 batches
Epoch 16 of 24 took 1125.801s
  training loss:		0.138541
  validation loss:		0.497879
  top 1 accuracy:		97.52 %
  top 2 accuracy:		99.67 %
0.13652583956718445
0.19284574687480927
0.10886631906032562
Batch of classes 3 out of 3 batches
Epoch 17 of 24 took 1105.571s
  training loss:		0.136863
  validation loss:		0.489992
  top 1 accuracy:		97.15 %
  top 2 accuracy:		99.69 %
0.14058701694011688
0.14466771483421326
0.14136677980422974
Batch of classes 3 out of 3 batches
Epoch 18 of 24 took 1118.604s
  training loss:		0.144389
  validation loss:		0.459607
  top 1 accuracy:		91.40 %
  top 2 accuracy:		97.58 %
0.15707162022590637
0.1329452246427536
0.11469535529613495
Batch of classes 3 out of 3 batches
Epoch 19 of 24 took 1102.665s
  training loss:		0.137114
  validation loss:		0.496925
  top 1 accuracy:		84.56 %
  top 2 accuracy:		96.13 %
0.154696524143219
0.09893614053726196
0.123377226293087
Batch of classes 3 out of 3 batches
Epoch 20 of 24 took 1110.303s
  training loss:		0.138298
  validation loss:		0.521088
  top 1 accuracy:		92.87 %
  top 2 accuracy:		98.79 %
0.1123386025428772
0.1501345932483673
0.1565072238445282
Batch of classes 3 out of 3 batches
Epoch 21 of 24 took 1126.772s
  training loss:		0.132149
  validation loss:		0.491245
  top 1 accuracy:		97.48 %
  top 2 accuracy:		99.73 %
0.15146580338478088
0.12051340192556381
0.14983181655406952
Batch of classes 3 out of 3 batches
Epoch 22 of 24 took 1138.874s
  training loss:		0.127203
  validation loss:		0.478665
  top 1 accuracy:		97.87 %
  top 2 accuracy:		99.81 %
0.14486315846443176
0.1416923850774765
0.126477912068367
Batch of classes 3 out of 3 batches
Epoch 23 of 24 took 1109.638s
  training loss:		0.127934
  validation loss:		0.502576
  top 1 accuracy:		97.52 %
  top 2 accuracy:		99.75 %
0.17091938853263855
0.13477011024951935
0.13026581704616547
Batch of classes 3 out of 3 batches
Epoch 24 of 24 took 1129.927s
  training loss:		0.127546
  validation loss:		0.481603
  top 1 accuracy:		98.17 %
  top 2 accuracy:		99.83 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		66.46 %
  top 1 accuracy Hybrid 1       :		73.15 %
  top 1 accuracy NCM            :		65.52 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		71.85 %
  top 1 accuracy Hybrid 1       :		73.67 %
  top 1 accuracy NCM            :		71.21 %
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		98.27 %
  top 1 accuracy Hybrid 1       :		20.56 %
  top 1 accuracy NCM            :		98.48 %
Binary accuracy:
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		99.15 %
  top 1 accuracy Hybrid 1       :		70.62 %
  top 1 accuracy NCM            :		99.17 %
Final results on progan1024 classes:
  top 1 accuracy iCaRL          :		99.42 %
  top 1 accuracy Hybrid 1       :		98.17 %
  top 1 accuracy NCM            :		99.40 %
Binary accuracy:
Final results on progan1024 classes:
  top 1 accuracy iCaRL          :		99.52 %
  top 1 accuracy Hybrid 1       :		99.12 %
  top 1 accuracy NCM            :		99.50 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		88.05 %
  top 1 accuracy Hybrid 1       :		63.96 %
  top 1 accuracy NCM            :		87.80 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		90.17 %
  top 1 accuracy Hybrid 1       :		81.14 %
  top 1 accuracy NCM            :		89.96 %
----------------- Options ---------------
               add_binary: True                          	[default: False]
               batch_size: 32                            	[default: 64]
                   binary: False                         
                blur_prob: 0                             
                 blur_sig: 0.5                           
          checkpoints_dir: /scratch_net/kringel/chuqli/CNNDetection/checkpoints	[default: ./checkpoints]
                class_bal: False                         
           continue_train: False                         
                 cropSize: 224                           
                 data_aug: False                         
                 dataroot: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/DoGAN_data/new/GanFake	[default: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL]
          earlystop_epoch: 5                             
                    epoch: latest                        
                 fine_tun: False                         
                    gpuid: [1]                           
                init_gain: 0.02                          
                  init_lr: 0.001                         	[default: 0.0005]
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2                           
                 jpg_prob: 0                             
                 jpg_qual: 75                            
                 loadSize: 256                           
                     mode: binary                        
               model_name: resnet18                      
               model_type: resnet                        
            model_weights: None                          
               multiclass: [1, 1, 0]                     	[default: [1]]
                     name: icarl_ganfake_bin             	[default: experiment_name]
                  no_flip: False                         
              num_classes: 2                             
               num_epochs: 24                            	[default: 12]
              num_threads: 4                             
                  outfile: temp_0.1.csv                  
            pretrain_name:                               
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 20                            
         save_latest_freq: 2000                          
                 schedule: [10, 20, 30]                  	[default: [10]]
           serial_batches: False                         
                   suffix:                               
                task_name: cyclegan,progan256,progan1024 	[default: ]
              train_split: train                         
                val_split: val                           
----------------- End -------------------
{'All': 6}
Task order: ['cyclegan', 'progan256', 'progan1024']
Classes in this batch: tensor([0, 1])
Data Size: 7196


Before first epoch
  validation loss:		0.730389
  top 1 accuracy:		3.48 %
  top 2 accuracy:		13.17 %
Batch of classes number 1 arrives ...
0.4681408405303955
0.14321158826351166
0.10808606445789337
Batch of classes 1 out of 3 batches
Epoch 1 of 24 took 171.204s
  training loss:		0.149744
  validation loss:		0.171997
  top 1 accuracy:		81.00 %
  top 2 accuracy:		100.00 %
0.09839493036270142
0.07552415132522583
0.08306579291820526
Batch of classes 1 out of 3 batches
Epoch 2 of 24 took 163.943s
  training loss:		0.104321
  validation loss:		0.271290
  top 1 accuracy:		68.54 %
  top 2 accuracy:		100.00 %
0.07673998922109604
0.06081609055399895
0.08780506253242493
Batch of classes 1 out of 3 batches
Epoch 3 of 24 took 168.872s
  training loss:		0.087192
  validation loss:		2.091109
  top 1 accuracy:		72.15 %
  top 2 accuracy:		100.00 %
0.18672548234462738
0.08756312727928162
0.1450241506099701
Batch of classes 1 out of 3 batches
Epoch 4 of 24 took 167.245s
  training loss:		0.078084
  validation loss:		0.341014
  top 1 accuracy:		75.42 %
  top 2 accuracy:		99.60 %
0.05802140757441521
0.03707421198487282
0.028993306681513786
Batch of classes 1 out of 3 batches
Epoch 5 of 24 took 177.834s
  training loss:		0.072966
  validation loss:		0.530930
  top 1 accuracy:		56.69 %
  top 2 accuracy:		100.00 %
0.04252854362130165
0.040508002042770386
0.04756033793091774
Batch of classes 1 out of 3 batches
Epoch 6 of 24 took 183.084s
  training loss:		0.058991
  validation loss:		0.416815
  top 1 accuracy:		75.13 %
  top 2 accuracy:		100.00 %
0.01974301226437092
0.055533308535814285
0.008510592393577099
Batch of classes 1 out of 3 batches
Epoch 7 of 24 took 183.688s
  training loss:		0.044685
  validation loss:		2.275153
  top 1 accuracy:		75.06 %
  top 2 accuracy:		94.02 %
0.04448232054710388
0.06756100058555603
0.013096117414534092
Batch of classes 1 out of 3 batches
Epoch 8 of 24 took 188.073s
  training loss:		0.042758
  validation loss:		1.235572
  top 1 accuracy:		74.46 %
  top 2 accuracy:		98.40 %
0.026050660759210587
0.02464146353304386
0.02040097862482071
Batch of classes 1 out of 3 batches
Epoch 9 of 24 took 190.439s
  training loss:		0.039206
  validation loss:		0.272198
  top 1 accuracy:		78.42 %
  top 2 accuracy:		99.98 %
0.0267441775649786
0.0427699089050293
0.0102680129930377
Batch of classes 1 out of 3 batches
Epoch 10 of 24 took 193.685s
  training loss:		0.028739
  validation loss:		0.449876
  top 1 accuracy:		75.50 %
  top 2 accuracy:		100.00 %
0.01957574672996998
0.009561705403029919
0.002753887325525284
Batch of classes 1 out of 3 batches
Epoch 11 of 24 took 189.681s
  training loss:		0.013637
  validation loss:		0.405348
  top 1 accuracy:		76.56 %
  top 2 accuracy:		99.96 %
0.04197356849908829
0.004813801031559706
0.017505595460534096
Batch of classes 1 out of 3 batches
Epoch 12 of 24 took 186.732s
  training loss:		0.009359
  validation loss:		0.476693
  top 1 accuracy:		75.46 %
  top 2 accuracy:		99.96 %
0.0021486866753548384
0.02718568593263626
0.0002854264748748392
Batch of classes 1 out of 3 batches
Epoch 13 of 24 took 184.389s
  training loss:		0.008377
  validation loss:		0.523102
  top 1 accuracy:		75.42 %
  top 2 accuracy:		99.71 %
0.022447336465120316
0.002180736279115081
0.003464042441919446
Batch of classes 1 out of 3 batches
Epoch 14 of 24 took 184.146s
  training loss:		0.009806
  validation loss:		0.547371
  top 1 accuracy:		76.21 %
  top 2 accuracy:		99.33 %
0.0011189852375537157
0.0013141436502337456
0.005495321936905384
Batch of classes 1 out of 3 batches
Epoch 15 of 24 took 185.062s
  training loss:		0.009026
  validation loss:		0.580294
  top 1 accuracy:		75.35 %
  top 2 accuracy:		99.23 %
0.0015563121996819973
0.0028365300968289375
0.0003354168147780001
Batch of classes 1 out of 3 batches
Epoch 16 of 24 took 182.801s
  training loss:		0.009159
  validation loss:		0.394667
  top 1 accuracy:		78.81 %
  top 2 accuracy:		99.67 %
0.0011320963967591524
0.0005421068635769188
0.0010803110199049115
Batch of classes 1 out of 3 batches
Epoch 17 of 24 took 192.032s
  training loss:		0.008749
  validation loss:		0.498696
  top 1 accuracy:		79.19 %
  top 2 accuracy:		97.81 %
0.005325975827872753
0.0015215396415442228
0.00076361617539078
Batch of classes 1 out of 3 batches
Epoch 18 of 24 took 189.449s
  training loss:		0.007301
  validation loss:		0.400640
  top 1 accuracy:		76.15 %
  top 2 accuracy:		99.96 %
0.0026056519709527493
0.0031516302842646837
0.003967248369008303
Batch of classes 1 out of 3 batches
Epoch 19 of 24 took 191.133s
  training loss:		0.012277
  validation loss:		0.359298
  top 1 accuracy:		75.63 %
  top 2 accuracy:		99.96 %
0.0010173320770263672
0.0015764306299388409
0.005102070979773998
Batch of classes 1 out of 3 batches
Epoch 20 of 24 took 192.022s
  training loss:		0.007633
  validation loss:		0.618814
  top 1 accuracy:		75.58 %
  top 2 accuracy:		98.25 %
0.013417176902294159
0.015768416225910187
0.003447497496381402
Batch of classes 1 out of 3 batches
Epoch 21 of 24 took 194.187s
  training loss:		0.004949
  validation loss:		0.584305
  top 1 accuracy:		75.29 %
  top 2 accuracy:		99.65 %
0.0008018253138288856
0.00017950081382878125
0.0003872598463203758
Batch of classes 1 out of 3 batches
Epoch 22 of 24 took 190.472s
  training loss:		0.004554
  validation loss:		0.386363
  top 1 accuracy:		76.67 %
  top 2 accuracy:		99.96 %
0.0004695578245446086
0.05481008440256119
0.0001534926996100694
Batch of classes 1 out of 3 batches
Epoch 23 of 24 took 194.556s
  training loss:		0.002510
  validation loss:		0.431441
  top 1 accuracy:		76.02 %
  top 2 accuracy:		99.90 %
0.003052462125197053
0.0005396113265305758
0.015403952449560165
Batch of classes 1 out of 3 batches
Epoch 24 of 24 took 201.263s
  training loss:		0.002172
  validation loss:		0.711523
  top 1 accuracy:		75.19 %
  top 2 accuracy:		98.37 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		75.29 %
  top 1 accuracy Hybrid 1       :		75.19 %
  top 1 accuracy NCM            :		75.27 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		75.29 %
  top 1 accuracy Hybrid 1       :		75.19 %
  top 1 accuracy NCM            :		75.27 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		75.29 %
  top 1 accuracy Hybrid 1       :		75.19 %
  top 1 accuracy NCM            :		75.27 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		75.29 %
  top 1 accuracy Hybrid 1       :		75.19 %
  top 1 accuracy NCM            :		75.27 %
Classes in this batch: tensor([2, 3])
Data Size: 7200


Before first epoch
  validation loss:		12.222155
  top 1 accuracy:		0.00 %
  top 2 accuracy:		44.50 %
Batch of classes number 2 arrives ...
2.010972738265991
0.29047340154647827
0.30252325534820557
Batch of classes 2 out of 3 batches
Epoch 1 of 24 took 190.987s
  training loss:		0.339976
  validation loss:		0.247518
  top 1 accuracy:		63.06 %
  top 2 accuracy:		95.79 %
0.22324708104133606
0.25695839524269104
0.09943703562021255
Batch of classes 2 out of 3 batches
Epoch 2 of 24 took 191.203s
  training loss:		0.190568
  validation loss:		0.041275
  top 1 accuracy:		96.52 %
  top 2 accuracy:		99.75 %
0.11075365543365479
0.12210805714130402
0.0501808226108551
Batch of classes 2 out of 3 batches
Epoch 3 of 24 took 193.280s
  training loss:		0.094857
  validation loss:		0.044911
  top 1 accuracy:		95.23 %
  top 2 accuracy:		99.69 %
0.06275387853384018
0.023873422294855118
0.09861055016517639
Batch of classes 2 out of 3 batches
Epoch 4 of 24 took 191.506s
  training loss:		0.072053
  validation loss:		0.090328
  top 1 accuracy:		89.92 %
  top 2 accuracy:		99.56 %
0.03747403994202614
0.14816127717494965
0.06051505729556084
Batch of classes 2 out of 3 batches
Epoch 5 of 24 took 194.169s
  training loss:		0.058565
  validation loss:		0.012062
  top 1 accuracy:		99.06 %
  top 2 accuracy:		99.94 %
0.04303182661533356
0.012932658195495605
0.04892794042825699
Batch of classes 2 out of 3 batches
Epoch 6 of 24 took 197.294s
  training loss:		0.045537
  validation loss:		0.043382
  top 1 accuracy:		95.71 %
  top 2 accuracy:		99.52 %
0.0055804019793868065
0.045958079397678375
0.09406324476003647
Batch of classes 2 out of 3 batches
Epoch 7 of 24 took 194.056s
  training loss:		0.046499
  validation loss:		0.031354
  top 1 accuracy:		96.79 %
  top 2 accuracy:		99.87 %
0.019330644980072975
0.01735891029238701
0.061888571828603745
Batch of classes 2 out of 3 batches
Epoch 8 of 24 took 198.079s
  training loss:		0.037032
  validation loss:		0.028938
  top 1 accuracy:		96.88 %
  top 2 accuracy:		99.83 %
0.017120301723480225
0.004628578666597605
0.06843726336956024
Batch of classes 2 out of 3 batches
Epoch 9 of 24 took 196.584s
  training loss:		0.043694
  validation loss:		0.013964
  top 1 accuracy:		98.85 %
  top 2 accuracy:		99.77 %
0.009426441043615341
0.02424546703696251
0.01836925931274891
Batch of classes 2 out of 3 batches
Epoch 10 of 24 took 195.461s
  training loss:		0.035027
  validation loss:		0.049581
  top 1 accuracy:		96.23 %
  top 2 accuracy:		99.52 %
0.01716988906264305
0.004423587117344141
0.004582446999847889
Batch of classes 2 out of 3 batches
Epoch 11 of 24 took 188.652s
  training loss:		0.022498
  validation loss:		0.005664
  top 1 accuracy:		99.58 %
  top 2 accuracy:		99.96 %
0.01056687068194151
0.007628777530044317
0.003651412669569254
Batch of classes 2 out of 3 batches
Epoch 12 of 24 took 190.999s
  training loss:		0.014359
  validation loss:		0.008698
  top 1 accuracy:		99.31 %
  top 2 accuracy:		99.96 %
0.03789648786187172
0.004511387553066015
0.0027667470276355743
Batch of classes 2 out of 3 batches
Epoch 13 of 24 took 193.416s
  training loss:		0.013622
  validation loss:		0.006164
  top 1 accuracy:		99.48 %
  top 2 accuracy:		99.98 %
0.017492063343524933
0.02931610867381096
0.06933122873306274
Batch of classes 2 out of 3 batches
Epoch 14 of 24 took 196.758s
  training loss:		0.011471
  validation loss:		0.002521
  top 1 accuracy:		99.81 %
  top 2 accuracy:		99.98 %
0.0019139606738463044
0.00260636443272233
0.00066674331901595
Batch of classes 2 out of 3 batches
Epoch 15 of 24 took 187.285s
  training loss:		0.011250
  validation loss:		0.009423
  top 1 accuracy:		99.31 %
  top 2 accuracy:		100.00 %
0.002075641881674528
0.004679669160395861
0.006689279340207577
Batch of classes 2 out of 3 batches
Epoch 16 of 24 took 185.922s
  training loss:		0.012179
  validation loss:		0.010553
  top 1 accuracy:		99.12 %
  top 2 accuracy:		99.87 %
0.0032480109948664904
0.009330491535365582
0.00919797457754612
Batch of classes 2 out of 3 batches
Epoch 17 of 24 took 182.942s
  training loss:		0.009407
  validation loss:		0.006631
  top 1 accuracy:		99.44 %
  top 2 accuracy:		99.94 %
0.017219463363289833
0.0028246426954865456
0.0036401660181581974
Batch of classes 2 out of 3 batches
Epoch 18 of 24 took 184.162s
  training loss:		0.007902
  validation loss:		0.035917
  top 1 accuracy:		96.33 %
  top 2 accuracy:		99.75 %
0.005995449144393206
0.011569980531930923
0.0021923910826444626
Batch of classes 2 out of 3 batches
Epoch 19 of 24 took 189.836s
  training loss:		0.011875
  validation loss:		0.005545
  top 1 accuracy:		99.54 %
  top 2 accuracy:		99.96 %
0.0007634054636582732
0.012394744902849197
0.001491924049332738
Batch of classes 2 out of 3 batches
Epoch 20 of 24 took 183.502s
  training loss:		0.008538
  validation loss:		0.002618
  top 1 accuracy:		99.83 %
  top 2 accuracy:		100.00 %
0.0035796642769128084
0.003171775722876191
0.0008209994994103909
Batch of classes 2 out of 3 batches
Epoch 21 of 24 took 188.886s
  training loss:		0.006019
  validation loss:		0.002198
  top 1 accuracy:		99.85 %
  top 2 accuracy:		100.00 %
0.0005932420608587563
0.0014771467540413141
0.00034511330886743963
Batch of classes 2 out of 3 batches
Epoch 22 of 24 took 185.856s
  training loss:		0.003221
  validation loss:		0.002960
  top 1 accuracy:		99.81 %
  top 2 accuracy:		99.96 %
0.0003466426278464496
0.009564705193042755
0.0013062660582363605
Batch of classes 2 out of 3 batches
Epoch 23 of 24 took 185.339s
  training loss:		0.003221
  validation loss:		0.002586
  top 1 accuracy:		99.75 %
  top 2 accuracy:		99.96 %
0.0008406102424487472
2.368375862715766e-05
0.000260655942838639
Batch of classes 2 out of 3 batches
Epoch 24 of 24 took 191.164s
  training loss:		0.003152
  validation loss:		0.005329
  top 1 accuracy:		99.52 %
  top 2 accuracy:		99.94 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		73.83 %
  top 1 accuracy Hybrid 1       :		72.17 %
  top 1 accuracy NCM            :		73.92 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		74.10 %
  top 1 accuracy Hybrid 1       :		73.38 %
  top 1 accuracy NCM            :		74.15 %
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		99.17 %
  top 1 accuracy Hybrid 1       :		99.52 %
  top 1 accuracy NCM            :		99.19 %
Binary accuracy:
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		99.60 %
  top 1 accuracy Hybrid 1       :		99.58 %
  top 1 accuracy NCM            :		99.58 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		86.50 %
  top 1 accuracy Hybrid 1       :		85.84 %
  top 1 accuracy NCM            :		86.55 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		86.85 %
  top 1 accuracy Hybrid 1       :		86.48 %
  top 1 accuracy NCM            :		86.86 %
Classes in this batch: tensor([4, 5])
Data Size: 7201


Before first epoch
  validation loss:		2.413269
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 3 arrives ...
2.2613956928253174
0.27059927582740784
0.1388266235589981
Batch of classes 3 out of 3 batches
Epoch 1 of 24 took 1176.322s
  training loss:		0.317199
  validation loss:		0.333529
  top 1 accuracy:		69.10 %
  top 2 accuracy:		93.90 %
0.141159787774086
0.030219512060284615
0.07655428349971771
Batch of classes 3 out of 3 batches
Epoch 2 of 24 took 1180.553s
  training loss:		0.093899
  validation loss:		0.132063
  top 1 accuracy:		86.40 %
  top 2 accuracy:		99.10 %
0.05814889818429947
0.06487083435058594
0.06579844653606415
Batch of classes 3 out of 3 batches
Epoch 3 of 24 took 1145.289s
  training loss:		0.065520
  validation loss:		0.092457
  top 1 accuracy:		90.21 %
  top 2 accuracy:		97.67 %
0.04505545273423195
0.03215619921684265
0.022536439821124077
Batch of classes 3 out of 3 batches
Epoch 4 of 24 took 1174.816s
  training loss:		0.062635
  validation loss:		0.205833
  top 1 accuracy:		77.98 %
  top 2 accuracy:		97.65 %
0.06789739429950714
0.048407215625047684
0.10072623193264008
Batch of classes 3 out of 3 batches
Epoch 5 of 24 took 1190.476s
  training loss:		0.049792
  validation loss:		1.535094
  top 1 accuracy:		55.02 %
  top 2 accuracy:		82.71 %
0.30525922775268555
0.018070120364427567
0.04839329421520233
Batch of classes 3 out of 3 batches
Epoch 6 of 24 took 1170.813s
  training loss:		0.055950
  validation loss:		0.079991
  top 1 accuracy:		91.46 %
  top 2 accuracy:		99.35 %
0.17622306942939758
0.017605550587177277
0.011406238190829754
Batch of classes 3 out of 3 batches
Epoch 7 of 24 took 1138.683s
  training loss:		0.046487
  validation loss:		0.035459
  top 1 accuracy:		96.52 %
  top 2 accuracy:		99.85 %
0.04920198395848274
0.02933165431022644
0.019491611048579216
Batch of classes 3 out of 3 batches
Epoch 8 of 24 took 1157.940s
  training loss:		0.046781
  validation loss:		0.009287
  top 1 accuracy:		99.31 %
  top 2 accuracy:		99.98 %
0.017710182815790176
0.023256998509168625
0.01299101673066616
Batch of classes 3 out of 3 batches
Epoch 9 of 24 took 1132.683s
  training loss:		0.038671
  validation loss:		0.016184
  top 1 accuracy:		98.65 %
  top 2 accuracy:		99.94 %
0.026257004588842392
0.016622059047222137
0.05610894784331322
Batch of classes 3 out of 3 batches
Epoch 10 of 24 took 1113.067s
  training loss:		0.050308
  validation loss:		0.023575
  top 1 accuracy:		97.52 %
  top 2 accuracy:		99.81 %
0.05225791782140732
0.016689499840140343
0.0017788406694307923
Batch of classes 3 out of 3 batches
Epoch 11 of 24 took 1141.165s
  training loss:		0.025756
  validation loss:		0.009982
  top 1 accuracy:		99.00 %
  top 2 accuracy:		99.90 %
0.007405053824186325
0.020927853882312775
0.031856052577495575
Batch of classes 3 out of 3 batches
Epoch 12 of 24 took 1129.561s
  training loss:		0.019336
  validation loss:		0.303657
  top 1 accuracy:		75.23 %
  top 2 accuracy:		99.25 %
0.032744988799095154
0.005320148076862097
0.01512866374105215
Batch of classes 3 out of 3 batches
Epoch 13 of 24 took 1114.857s
  training loss:		0.018611
  validation loss:		0.010974
  top 1 accuracy:		98.96 %
  top 2 accuracy:		99.96 %
0.012432747520506382
0.0072548044845461845
0.004118564538657665
Batch of classes 3 out of 3 batches
Epoch 14 of 24 took 1150.500s
  training loss:		0.014365
  validation loss:		0.005577
  top 1 accuracy:		99.33 %
  top 2 accuracy:		99.98 %
0.04647441953420639
0.02711634337902069
0.040712546557188034
Batch of classes 3 out of 3 batches
Epoch 15 of 24 took 1136.217s
  training loss:		0.010552
  validation loss:		0.003275
  top 1 accuracy:		99.71 %
  top 2 accuracy:		100.00 %
0.026797454804182053
0.0005239944439381361
0.012189727276563644
Batch of classes 3 out of 3 batches
Epoch 16 of 24 took 1102.611s
  training loss:		0.018684
  validation loss:		0.009815
  top 1 accuracy:		99.10 %
  top 2 accuracy:		100.00 %
0.0021249759010970592
0.004797531757503748
0.002364582847803831
Batch of classes 3 out of 3 batches
Epoch 17 of 24 took 1081.139s
  training loss:		0.009954
  validation loss:		0.003265
  top 1 accuracy:		99.73 %
  top 2 accuracy:		99.98 %
0.0037776450626552105
0.0066389162093400955
0.0013723337324336171
Batch of classes 3 out of 3 batches
Epoch 18 of 24 took 1023.581s
  training loss:		0.021747
  validation loss:		0.013319
  top 1 accuracy:		98.67 %
  top 2 accuracy:		99.98 %
0.0008204742916859686
0.0018774194177240133
0.0035359570756554604
Batch of classes 3 out of 3 batches
Epoch 19 of 24 took 1078.886s
  training loss:		0.010180
  validation loss:		0.005306
  top 1 accuracy:		99.56 %
  top 2 accuracy:		100.00 %
0.0024075463879853487
0.030509309843182564
0.0038579285610467196
Batch of classes 3 out of 3 batches
Epoch 20 of 24 took 1140.524s
  training loss:		0.015956
  validation loss:		0.008706
  top 1 accuracy:		99.19 %
  top 2 accuracy:		99.96 %
0.03136768937110901
0.0015568452654406428
0.003954915329813957
Batch of classes 3 out of 3 batches
Epoch 21 of 24 took 1084.591s
  training loss:		0.004923
  validation loss:		0.005361
  top 1 accuracy:		99.54 %
  top 2 accuracy:		99.96 %
0.0006818976253271103
0.01259686704725027
0.0004420574405230582
Batch of classes 3 out of 3 batches
Epoch 22 of 24 took 1053.093s
  training loss:		0.006934
  validation loss:		0.003760
  top 1 accuracy:		99.69 %
  top 2 accuracy:		99.96 %
0.0016163159161806107
0.0022472026757895947
0.0018737002974376082
Batch of classes 3 out of 3 batches
Epoch 23 of 24 took 1065.762s
  training loss:		0.004063
  validation loss:		0.002947
  top 1 accuracy:		99.79 %
  top 2 accuracy:		100.00 %
0.004458179697394371
0.0009263455867767334
0.0001618852693354711
Batch of classes 3 out of 3 batches
Epoch 24 of 24 took 1055.418s
  training loss:		0.003511
  validation loss:		0.003596
  top 1 accuracy:		99.71 %
  top 2 accuracy:		99.98 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		60.35 %
  top 1 accuracy Hybrid 1       :		58.90 %
  top 1 accuracy NCM            :		60.38 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		68.08 %
  top 1 accuracy Hybrid 1       :		66.17 %
  top 1 accuracy NCM            :		67.71 %
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		98.81 %
  top 1 accuracy Hybrid 1       :		98.62 %
  top 1 accuracy NCM            :		98.79 %
Binary accuracy:
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		99.38 %
  top 1 accuracy Hybrid 1       :		99.29 %
  top 1 accuracy NCM            :		99.38 %
Final results on progan1024 classes:
  top 1 accuracy iCaRL          :		99.65 %
  top 1 accuracy Hybrid 1       :		99.71 %
  top 1 accuracy NCM            :		99.65 %
Binary accuracy:
Final results on progan1024 classes:
  top 1 accuracy iCaRL          :		99.81 %
  top 1 accuracy Hybrid 1       :		99.75 %
  top 1 accuracy NCM            :		99.81 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		86.27 %
  top 1 accuracy Hybrid 1       :		85.74 %
  top 1 accuracy NCM            :		86.27 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		89.09 %
  top 1 accuracy Hybrid 1       :		88.40 %
  top 1 accuracy NCM            :		88.97 %
----------------- Options ---------------
               add_binary: False                         
               batch_size: 32                            	[default: 64]
                   binary: True                          	[default: False]
                blur_prob: 0                             
                 blur_sig: 0.5                           
          checkpoints_dir: /scratch_net/kringel/chuqli/CNNDetection/checkpoints	[default: ./checkpoints]
                class_bal: False                         
           continue_train: False                         
                 cropSize: 224                           
                 data_aug: False                         
                 dataroot: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/DoGAN_data/new/GanFake	[default: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL]
          earlystop_epoch: 5                             
                    epoch: latest                        
                 fine_tun: False                         
                    gpuid: [1]                           
                init_gain: 0.02                          
                  init_lr: 0.001                         	[default: 0.0005]
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2                           
                 jpg_prob: 0                             
                 jpg_qual: 75                            
                 loadSize: 256                           
                     mode: binary                        
               model_name: resnet18                      
               model_type: resnet                        
            model_weights: None                          
               multiclass: [1, 1, 0]                     	[default: [1]]
                     name: icarl_ganfake_bin             	[default: experiment_name]
                  no_flip: False                         
              num_classes: 2                             
               num_epochs: 24                            	[default: 12]
              num_threads: 4                             
                  outfile: temp_0.1.csv                  
            pretrain_name:                               
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 20                            
         save_latest_freq: 2000                          
                 schedule: [10, 20, 30]                  	[default: [10]]
           serial_batches: False                         
                   suffix:                               
                task_name: cyclegan,progan256,progan1024 	[default: ]
              train_split: train                         
                val_split: val                           
----------------- End -------------------
{'All': 6}
Task order: ['cyclegan', 'progan256', 'progan1024']
Classes in this batch: tensor([0, 1])
Data Size: 7196


Before first epoch
  validation loss:		0.687699
  top 1 accuracy:		34.38 %
Batch of classes number 1 arrives ...
0.606903076171875
0.29647278785705566
0.32252126932144165
Batch of classes 1 out of 3 batches
Epoch 1 of 24 took 156.105s
  training loss:		0.379789
  validation loss:		0.893094
  top 1 accuracy:		96.88 %
0.24663466215133667
0.12051834166049957
0.17874006927013397
Batch of classes 1 out of 3 batches
Epoch 2 of 24 took 123.494s
  training loss:		0.284211
  validation loss:		0.962402
  top 1 accuracy:		87.50 %
0.19053849577903748
0.2216319888830185
0.18963780999183655
Batch of classes 1 out of 3 batches
Epoch 3 of 24 took 51.190s
  training loss:		0.229889
  validation loss:		0.707787
  top 1 accuracy:		100.00 %
0.06516839563846588
0.46070969104766846
0.0963682234287262
Batch of classes 1 out of 3 batches
Epoch 4 of 24 took 51.673s
  training loss:		0.209353
  validation loss:		2.141105
  top 1 accuracy:		100.00 %
0.13073116540908813
0.12982137501239777
0.053166475147008896
Batch of classes 1 out of 3 batches
Epoch 5 of 24 took 51.648s
  training loss:		0.170483
  validation loss:		0.388121
  top 1 accuracy:		100.00 %
0.24177449941635132
0.21003076434135437
0.07437563687562943
Batch of classes 1 out of 3 batches
Epoch 6 of 24 took 52.019s
  training loss:		0.153199
  validation loss:		0.586057
  top 1 accuracy:		100.00 %
0.18820400536060333
0.18119943141937256
0.04604971408843994
Batch of classes 1 out of 3 batches
Epoch 7 of 24 took 51.990s
  training loss:		0.143053
  validation loss:		3.007817
  top 1 accuracy:		71.88 %
0.13873231410980225
0.014120172709226608
0.07893237471580505
Batch of classes 1 out of 3 batches
Epoch 8 of 24 took 51.726s
  training loss:		0.104094
  validation loss:		2.607865
  top 1 accuracy:		100.00 %
0.056658148765563965
0.01750594563782215
0.0679960697889328
Batch of classes 1 out of 3 batches
Epoch 9 of 24 took 54.592s
  training loss:		0.090511
  validation loss:		1.960382
  top 1 accuracy:		100.00 %
0.03032311238348484
0.06129848212003708
0.022359102964401245
Batch of classes 1 out of 3 batches
Epoch 10 of 24 took 51.989s
  training loss:		0.079576
  validation loss:		0.877464
  top 1 accuracy:		100.00 %
0.2627869248390198
0.013043303042650223
0.0355253741145134
Batch of classes 1 out of 3 batches
Epoch 11 of 24 took 51.603s
  training loss:		0.037493
  validation loss:		1.501456
  top 1 accuracy:		100.00 %
0.023407312110066414
0.001424721791408956
0.0006502042524516582
Batch of classes 1 out of 3 batches
Epoch 12 of 24 took 121.351s
  training loss:		0.022837
  validation loss:		1.361025
  top 1 accuracy:		100.00 %
0.011225167661905289
0.0010925701353698969
0.0037476830184459686
Batch of classes 1 out of 3 batches
Epoch 13 of 24 took 176.987s
  training loss:		0.020574
  validation loss:		1.536742
  top 1 accuracy:		100.00 %
0.0003493040567263961
0.050244271755218506
0.00029175812960602343
Batch of classes 1 out of 3 batches
Epoch 14 of 24 took 103.094s
  training loss:		0.018823
  validation loss:		2.050413
  top 1 accuracy:		100.00 %
0.02338216081261635
0.003966817632317543
0.01751813478767872
Batch of classes 1 out of 3 batches
Epoch 15 of 24 took 56.911s
  training loss:		0.027283
  validation loss:		1.818861
  top 1 accuracy:		100.00 %
0.0006208304548636079
0.0020454167388379574
0.03641499951481819
Batch of classes 1 out of 3 batches
Epoch 16 of 24 took 54.667s
  training loss:		0.019009
  validation loss:		1.687809
  top 1 accuracy:		100.00 %
0.0018002402503043413
0.022443318739533424
0.0009093523258343339
Batch of classes 1 out of 3 batches
Epoch 17 of 24 took 56.584s
  training loss:		0.018911
  validation loss:		2.232046
  top 1 accuracy:		93.75 %
0.006507032550871372
0.022668270394206047
0.0014064249116927385
Batch of classes 1 out of 3 batches
Epoch 18 of 24 took 54.939s
  training loss:		0.023806
  validation loss:		1.274749
  top 1 accuracy:		100.00 %
0.015305183827877045
0.00034596477053128183
0.0007593451882712543
Batch of classes 1 out of 3 batches
Epoch 19 of 24 took 54.279s
  training loss:		0.011899
  validation loss:		1.029193
  top 1 accuracy:		100.00 %
0.0740235224366188
0.0012220070930197835
0.000658266304526478
Batch of classes 1 out of 3 batches
Epoch 20 of 24 took 85.869s
  training loss:		0.023665
  validation loss:		1.316893
  top 1 accuracy:		100.00 %
0.000508636177983135
0.0004482301592361182
0.009879683144390583
Batch of classes 1 out of 3 batches
Epoch 21 of 24 took 63.473s
  training loss:		0.006366
  validation loss:		1.495314
  top 1 accuracy:		100.00 %
7.234668737510219e-05
1.835184230003506e-05
0.0002100778801832348
Batch of classes 1 out of 3 batches
Epoch 22 of 24 took 69.248s
  training loss:		0.005785
  validation loss:		1.716714
  top 1 accuracy:		100.00 %
0.005295414477586746
0.005759969353675842
0.006007479038089514
Batch of classes 1 out of 3 batches
Epoch 23 of 24 took 94.084s
  training loss:		0.006537
  validation loss:		2.229894
  top 1 accuracy:		100.00 %
0.007337000221014023
0.012205725535750389
0.012865180149674416
Batch of classes 1 out of 3 batches
Epoch 24 of 24 took 104.856s
  training loss:		0.006212
  validation loss:		1.887920
  top 1 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		75.06 %
  top 1 accuracy Hybrid 1       :		75.12 %
  top 1 accuracy NCM            :		75.04 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		75.06 %
  top 1 accuracy Hybrid 1       :		75.12 %
  top 1 accuracy NCM            :		75.04 %
Classes in this batch: tensor([2, 3])
Data Size: 7200


Before first epoch
  validation loss:		7.758245
  top 1 accuracy:		0.00 %
Batch of classes number 2 arrives ...
2.0104238986968994
0.6942187547683716
0.549152672290802
Batch of classes 2 out of 3 batches
Epoch 1 of 24 took 162.231s
  training loss:		0.658252
  validation loss:		0.646579
  top 1 accuracy:		37.50 %
0.4721687138080597
0.5859747529029846
0.378689169883728
Batch of classes 2 out of 3 batches
Epoch 2 of 24 took 141.521s
  training loss:		0.491988
  validation loss:		0.217980
  top 1 accuracy:		100.00 %
0.3452843427658081
0.43511688709259033
0.43283015489578247
Batch of classes 2 out of 3 batches
Epoch 3 of 24 took 81.346s
  training loss:		0.398494
  validation loss:		0.195394
  top 1 accuracy:		93.75 %
0.3559420108795166
0.28567448258399963
0.3790426552295685
Batch of classes 2 out of 3 batches
Epoch 4 of 24 took 63.205s
  training loss:		0.358565
  validation loss:		0.128836
  top 1 accuracy:		100.00 %
0.2973802089691162
0.22751063108444214
0.31233641505241394
Batch of classes 2 out of 3 batches
Epoch 5 of 24 took 63.644s
  training loss:		0.337526
  validation loss:		0.414325
  top 1 accuracy:		84.38 %
0.2591056823730469
0.3295237421989441
0.25056424736976624
Batch of classes 2 out of 3 batches
Epoch 6 of 24 took 64.174s
  training loss:		0.337360
  validation loss:		0.219894
  top 1 accuracy:		78.12 %
0.3263257145881653
0.5599977970123291
0.3844093382358551
Batch of classes 2 out of 3 batches
Epoch 7 of 24 took 64.482s
  training loss:		0.320096
  validation loss:		0.426928
  top 1 accuracy:		68.75 %
0.3534405827522278
0.40590208768844604
0.2142249047756195
Batch of classes 2 out of 3 batches
Epoch 8 of 24 took 64.471s
  training loss:		0.310053
  validation loss:		0.165296
  top 1 accuracy:		100.00 %
0.2867478132247925
0.31379759311676025
0.2865225672721863
Batch of classes 2 out of 3 batches
Epoch 9 of 24 took 63.495s
  training loss:		0.304723
  validation loss:		0.188228
  top 1 accuracy:		100.00 %
0.45705288648605347
0.2098122537136078
0.25989118218421936
Batch of classes 2 out of 3 batches
Epoch 10 of 24 took 63.628s
  training loss:		0.314888
  validation loss:		0.184069
  top 1 accuracy:		96.88 %
0.27929675579071045
0.32191333174705505
0.29297947883605957
Batch of classes 2 out of 3 batches
Epoch 11 of 24 took 78.805s
  training loss:		0.278737
  validation loss:		0.151812
  top 1 accuracy:		96.88 %
0.2867494821548462
0.30156898498535156
0.27934277057647705
Batch of classes 2 out of 3 batches
Epoch 12 of 24 took 98.014s
  training loss:		0.274419
  validation loss:		0.152489
  top 1 accuracy:		100.00 %
0.3180917501449585
0.25113868713378906
0.25574788451194763
Batch of classes 2 out of 3 batches
Epoch 13 of 24 took 120.543s
  training loss:		0.273023
  validation loss:		0.162333
  top 1 accuracy:		96.88 %
0.25452789664268494
0.3562118709087372
0.2700417637825012
Batch of classes 2 out of 3 batches
Epoch 14 of 24 took 149.231s
  training loss:		0.277018
  validation loss:		0.143726
  top 1 accuracy:		100.00 %
0.23592975735664368
0.1691230684518814
0.2559274137020111
Batch of classes 2 out of 3 batches
Epoch 15 of 24 took 161.752s
  training loss:		0.273543
  validation loss:		0.147318
  top 1 accuracy:		100.00 %
0.219941645860672
0.33057689666748047
0.263292133808136
Batch of classes 2 out of 3 batches
Epoch 16 of 24 took 166.165s
  training loss:		0.275110
  validation loss:		0.140427
  top 1 accuracy:		100.00 %
0.24396106600761414
0.28516846895217896
0.2516968250274658
Batch of classes 2 out of 3 batches
Epoch 17 of 24 took 173.564s
  training loss:		0.268334
  validation loss:		0.143589
  top 1 accuracy:		100.00 %
0.2742786407470703
0.17712664604187012
0.27363014221191406
Batch of classes 2 out of 3 batches
Epoch 18 of 24 took 150.647s
  training loss:		0.268574
  validation loss:		0.149673
  top 1 accuracy:		100.00 %
0.2668212056159973
0.2818504273891449
0.3182964026927948
Batch of classes 2 out of 3 batches
Epoch 19 of 24 took 115.542s
  training loss:		0.266641
  validation loss:		0.150149
  top 1 accuracy:		100.00 %
0.2377805858850479
0.2745590806007385
0.23399239778518677
Batch of classes 2 out of 3 batches
Epoch 20 of 24 took 81.749s
  training loss:		0.266549
  validation loss:		0.139920
  top 1 accuracy:		100.00 %
0.1774711310863495
0.2655200660228729
0.2312689870595932
Batch of classes 2 out of 3 batches
Epoch 21 of 24 took 92.474s
  training loss:		0.261738
  validation loss:		0.141502
  top 1 accuracy:		100.00 %
0.30048173666000366
0.17771966755390167
0.19429124891757965
Batch of classes 2 out of 3 batches
Epoch 22 of 24 took 79.608s
  training loss:		0.259955
  validation loss:		0.146119
  top 1 accuracy:		100.00 %
0.19391131401062012
0.26464781165122986
0.33089810609817505
Batch of classes 2 out of 3 batches
Epoch 23 of 24 took 75.069s
  training loss:		0.259481
  validation loss:		0.140982
  top 1 accuracy:		100.00 %
0.35286474227905273
0.2815941572189331
0.29107946157455444
Batch of classes 2 out of 3 batches
Epoch 24 of 24 took 71.938s
  training loss:		0.264263
  validation loss:		0.139974
  top 1 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		74.67 %
  top 1 accuracy Hybrid 1       :		75.02 %
  top 1 accuracy NCM            :		74.73 %
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		99.96 %
  top 1 accuracy Hybrid 1       :		99.83 %
  top 1 accuracy NCM            :		99.94 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		87.31 %
  top 1 accuracy Hybrid 1       :		87.43 %
  top 1 accuracy NCM            :		87.33 %
Classes in this batch: tensor([4, 5])
Data Size: 7201


Before first epoch
  validation loss:		0.967876
  top 1 accuracy:		84.38 %
Batch of classes number 3 arrives ...
1.098139762878418
0.41976553201675415
0.3679441511631012
Batch of classes 3 out of 3 batches
Epoch 1 of 24 took 1051.318s
  training loss:		0.444338
  validation loss:		0.375816
  top 1 accuracy:		59.38 %
0.4825040102005005
0.4709143340587616
0.4330769181251526
Batch of classes 3 out of 3 batches
Epoch 2 of 24 took 1066.345s
  training loss:		0.388090
  validation loss:		0.484804
  top 1 accuracy:		100.00 %
0.4657554030418396
0.4163261950016022
0.3623241186141968
Batch of classes 3 out of 3 batches
Epoch 3 of 24 took 1071.610s
  training loss:		0.379964
  validation loss:		0.781027
  top 1 accuracy:		12.50 %
0.5343804359436035
0.40823984146118164
0.3345631957054138
Batch of classes 3 out of 3 batches
Epoch 4 of 24 took 1019.015s
  training loss:		0.372851
  validation loss:		0.165296
  top 1 accuracy:		100.00 %
0.42475512623786926
0.2972108721733093
0.320884644985199
Batch of classes 3 out of 3 batches
Epoch 5 of 24 took 1047.724s
  training loss:		0.361886
  validation loss:		0.309757
  top 1 accuracy:		75.00 %
0.40210068225860596
0.3984166085720062
0.31071317195892334
Batch of classes 3 out of 3 batches
Epoch 6 of 24 took 1088.663s
  training loss:		0.355224
  validation loss:		0.634484
  top 1 accuracy:		56.25 %
0.33761274814605713
0.32634276151657104
0.3488696813583374
Batch of classes 3 out of 3 batches
Epoch 7 of 24 took 1070.666s
  training loss:		0.358442
  validation loss:		0.244559
  top 1 accuracy:		100.00 %
0.3616265654563904
0.38529378175735474
0.2721550762653351
Batch of classes 3 out of 3 batches
Epoch 8 of 24 took 1059.628s
  training loss:		0.345826
  validation loss:		0.494635
  top 1 accuracy:		43.75 %
0.3570619821548462
0.38396090269088745
0.33603477478027344
Batch of classes 3 out of 3 batches
Epoch 9 of 24 took 1086.199s
  training loss:		0.353596
  validation loss:		0.597409
  top 1 accuracy:		56.25 %
0.39841219782829285
0.3965604901313782
0.38805994391441345
Batch of classes 3 out of 3 batches
Epoch 10 of 24 took 1076.092s
  training loss:		0.367721
  validation loss:		0.302284
  top 1 accuracy:		96.88 %
0.31479567289352417
0.3210621774196625
0.36696934700012207
Batch of classes 3 out of 3 batches
Epoch 11 of 24 took 1072.625s
  training loss:		0.323480
  validation loss:		0.161560
  top 1 accuracy:		100.00 %
0.39718806743621826
0.3625364899635315
0.36353811621665955
Batch of classes 3 out of 3 batches
Epoch 12 of 24 took 1103.380s
  training loss:		0.320070
  validation loss:		0.137214
  top 1 accuracy:		100.00 %
0.335092157125473
0.3455658257007599
0.36475974321365356
Batch of classes 3 out of 3 batches
Epoch 13 of 24 took 1114.891s
  training loss:		0.320584
  validation loss:		0.197885
  top 1 accuracy:		96.88 %
0.34967613220214844
0.25760728120803833
0.3107181191444397
Batch of classes 3 out of 3 batches
Epoch 14 of 24 took 1055.882s
  training loss:		0.320505
  validation loss:		0.121684
  top 1 accuracy:		100.00 %
0.3465977907180786
0.3331196904182434
0.34691885113716125
Batch of classes 3 out of 3 batches
Epoch 15 of 24 took 1026.730s
  training loss:		0.313928
  validation loss:		0.173382
  top 1 accuracy:		96.88 %
0.34003233909606934
0.29432806372642517
0.27023056149482727
Batch of classes 3 out of 3 batches
Epoch 16 of 24 took 1074.452s
  training loss:		0.314992
  validation loss:		0.151451
  top 1 accuracy:		100.00 %
0.37627753615379333
0.2742358148097992
0.33247849345207214
Batch of classes 3 out of 3 batches
Epoch 17 of 24 took 1079.244s
  training loss:		0.320879
  validation loss:		0.316792
  top 1 accuracy:		81.25 %
0.32644835114479065
0.31762778759002686
0.32926762104034424
Batch of classes 3 out of 3 batches
Epoch 18 of 24 took 1102.580s
  training loss:		0.318187
  validation loss:		0.148997
  top 1 accuracy:		100.00 %
0.30521708726882935
0.2981654405593872
0.38844892382621765
Batch of classes 3 out of 3 batches
Epoch 19 of 24 took 1089.683s
  training loss:		0.315031
  validation loss:		0.222529
  top 1 accuracy:		93.75 %
0.30519023537635803
0.34765714406967163
0.30212634801864624
Batch of classes 3 out of 3 batches
Epoch 20 of 24 took 1070.601s
  training loss:		0.313768
  validation loss:		0.214751
  top 1 accuracy:		90.62 %
0.4327177405357361
0.2919478416442871
0.2905280292034149
Batch of classes 3 out of 3 batches
Epoch 21 of 24 took 1116.163s
  training loss:		0.308485
  validation loss:		0.147576
  top 1 accuracy:		100.00 %
0.24480774998664856
0.3667363226413727
0.2496529221534729
Batch of classes 3 out of 3 batches
Epoch 22 of 24 took 1186.151s
  training loss:		0.306007
  validation loss:		0.136071
  top 1 accuracy:		100.00 %
0.32068365812301636
0.3636346161365509
0.3310970067977905
Batch of classes 3 out of 3 batches
Epoch 23 of 24 took 1217.470s
  training loss:		0.305627
  validation loss:		0.146185
  top 1 accuracy:		96.88 %
0.2529299259185791
0.3510267734527588
0.30966612696647644
Batch of classes 3 out of 3 batches
Epoch 24 of 24 took 1191.027s
  training loss:		0.312019
  validation loss:		0.134159
  top 1 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		82.65 %
  top 1 accuracy Hybrid 1       :		81.21 %
  top 1 accuracy NCM            :		82.54 %
Final results on progan256 classes:
  top 1 accuracy iCaRL          :		99.42 %
  top 1 accuracy Hybrid 1       :		99.44 %
  top 1 accuracy NCM            :		99.44 %
Final results on progan1024 classes:
  top 1 accuracy iCaRL          :		99.69 %
  top 1 accuracy Hybrid 1       :		99.27 %
  top 1 accuracy NCM            :		99.65 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		93.92 %
  top 1 accuracy Hybrid 1       :		93.31 %
  top 1 accuracy NCM            :		93.88 %
