----------------- Options ---------------
               add_binary: False                         
               batch_size: 32                            	[default: 64]
                   binary: False                         
              binary_loss: sum_b_sig                     
            binary_weight: 0.5                           
                blur_prob: 0                             
                 blur_sig: 0.5                           
          checkpoints_dir: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL/checkpoints	[default: ./checkpoints]
                class_bal: False                         
           continue_train: False                         
                 cropSize: 224                           
                 data_aug: False                         
                 dataroot: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/test	[default: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL]
          earlystop_epoch: 5                             
                    epoch: latest                        
                 fine_tun: False                         
                    gpuid: [1]                           
                init_gain: 0.02                          
                  init_lr: 0.0005                        
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2                           
                 jpg_prob: 0                             
                 jpg_qual: 75                            
          label_smoothing: False                         
                 loadSize: 256                           
                    mixup: False                         
              mixup_alpha: 0.1                           
                     mode: binary                        
               model_name: resnet18                      
               model_type: resnet                        
            model_weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth	[default: None]
               multiclass: [0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0]	[default: [1]]
                     name: icarl_df_12_15                	[default: experiment_name]
                  no_flip: False                         
              num_classes: 2                             
               num_epochs: 30                            	[default: 12]
              num_threads: 4                             
                  outfile: temp_0.1.csv                  
            pretrain_name:                               
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 20                            
         save_latest_freq: 2000                          
                 schedule: [10, 20, 30]                  	[default: [10]]
           serial_batches: False                         
          smoothing_alpha: 0.1                           
                   suffix:                               
                task_name: gaugan,biggan,cyclegan,imle,deepfake,crn,wild,glow,stargan_gf,stylegan,whichfaceisreal,san	[default: ]
              train_split: train                         
                val_split: val                           
----------------- End -------------------
{'All': 24}
Task order: ['gaugan', 'biggan', 'cyclegan', 'imle', 'deepfake', 'crn', 'wild', 'glow', 'stargan_gf', 'stylegan', 'whichfaceisreal', 'san']
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Classes in this batch: tensor([0, 1])
Data Size: 6000


Before first epoch
  validation loss:		1.040402
  top 1 accuracy:		16.90 %
  top 2 accuracy:		17.25 %
Batch of classes number 1 arrives ...
0.9098228216171265
0.03656468167901039
Batch of classes 1 out of 12 batches
Epoch 1 of 30 took 142.383s
  training loss:		0.084698
  validation loss:		0.030882
  top 1 accuracy:		83.95 %
  top 2 accuracy:		100.00 %
0.040193088352680206
0.03573774918913841
Batch of classes 1 out of 12 batches
Epoch 2 of 30 took 137.453s
  training loss:		0.029952
  validation loss:		0.037224
  top 1 accuracy:		78.40 %
  top 2 accuracy:		100.00 %
0.02968408167362213
0.027562357485294342
Batch of classes 1 out of 12 batches
Epoch 3 of 30 took 135.619s
  training loss:		0.021917
  validation loss:		0.024659
  top 1 accuracy:		89.10 %
  top 2 accuracy:		100.00 %
0.013465250842273235
0.010057268664240837
Batch of classes 1 out of 12 batches
Epoch 4 of 30 took 130.816s
  training loss:		0.018173
  validation loss:		0.011380
  top 1 accuracy:		95.05 %
  top 2 accuracy:		100.00 %
0.01424932386726141
0.02429272048175335
Batch of classes 1 out of 12 batches
Epoch 5 of 30 took 147.027s
  training loss:		0.016242
  validation loss:		0.016611
  top 1 accuracy:		92.00 %
  top 2 accuracy:		100.00 %
0.004212462808936834
0.007037514355033636
Batch of classes 1 out of 12 batches
Epoch 6 of 30 took 144.135s
  training loss:		0.014752
  validation loss:		0.018818
  top 1 accuracy:		90.50 %
  top 2 accuracy:		100.00 %
0.010842612944543362
0.007979148998856544
Batch of classes 1 out of 12 batches
Epoch 7 of 30 took 140.284s
  training loss:		0.014774
  validation loss:		0.015851
  top 1 accuracy:		92.15 %
  top 2 accuracy:		100.00 %
0.005789516028016806
0.006351928226649761
Batch of classes 1 out of 12 batches
Epoch 8 of 30 took 137.190s
  training loss:		0.012290
  validation loss:		0.013512
  top 1 accuracy:		93.90 %
  top 2 accuracy:		100.00 %
0.011110788211226463
0.018274914473295212
Batch of classes 1 out of 12 batches
Epoch 9 of 30 took 133.529s
  training loss:		0.010825
  validation loss:		0.015396
  top 1 accuracy:		92.90 %
  top 2 accuracy:		100.00 %
0.004567631520330906
0.009649617597460747
Batch of classes 1 out of 12 batches
Epoch 10 of 30 took 128.710s
  training loss:		0.011510
  validation loss:		0.050594
  top 1 accuracy:		79.30 %
  top 2 accuracy:		100.00 %
0.018718179315328598
0.004281491041183472
Batch of classes 1 out of 12 batches
Epoch 11 of 30 took 61.864s
  training loss:		0.005561
  validation loss:		0.003429
  top 1 accuracy:		98.70 %
  top 2 accuracy:		100.00 %
0.0021718530915677547
0.0027818854432553053
Batch of classes 1 out of 12 batches
Epoch 12 of 30 took 45.911s
  training loss:		0.004199
  validation loss:		0.004215
  top 1 accuracy:		98.45 %
  top 2 accuracy:		100.00 %
0.0009729188750497997
0.004368235357105732
Batch of classes 1 out of 12 batches
Epoch 13 of 30 took 45.757s
  training loss:		0.003193
  validation loss:		0.003691
  top 1 accuracy:		98.35 %
  top 2 accuracy:		100.00 %
0.0027687419205904007
0.010029160417616367
Batch of classes 1 out of 12 batches
Epoch 14 of 30 took 46.170s
  training loss:		0.002879
  validation loss:		0.002769
  top 1 accuracy:		98.85 %
  top 2 accuracy:		100.00 %
0.0030296375043690205
0.00666855601593852
Batch of classes 1 out of 12 batches
Epoch 15 of 30 took 45.612s
  training loss:		0.003380
  validation loss:		0.002966
  top 1 accuracy:		98.95 %
  top 2 accuracy:		100.00 %
0.003935645334422588
0.004448484629392624
Batch of classes 1 out of 12 batches
Epoch 16 of 30 took 45.209s
  training loss:		0.003721
  validation loss:		0.002349
  top 1 accuracy:		99.00 %
  top 2 accuracy:		100.00 %
0.0039934092201292515
0.0022438669111579657
Batch of classes 1 out of 12 batches
Epoch 17 of 30 took 45.215s
  training loss:		0.003228
  validation loss:		0.003424
  top 1 accuracy:		98.50 %
  top 2 accuracy:		100.00 %
0.006656292825937271
0.00022604939294978976
Batch of classes 1 out of 12 batches
Epoch 18 of 30 took 45.130s
  training loss:		0.002169
  validation loss:		0.001631
  top 1 accuracy:		99.20 %
  top 2 accuracy:		100.00 %
0.00014617887791246176
0.0006398535333573818
Batch of classes 1 out of 12 batches
Epoch 19 of 30 took 44.676s
  training loss:		0.002489
  validation loss:		0.001974
  top 1 accuracy:		99.50 %
  top 2 accuracy:		100.00 %
0.0003282236575614661
0.014683367684483528
Batch of classes 1 out of 12 batches
Epoch 20 of 30 took 44.449s
  training loss:		0.003183
  validation loss:		0.003029
  top 1 accuracy:		98.65 %
  top 2 accuracy:		100.00 %
0.007493496872484684
0.0002199299487983808
Batch of classes 1 out of 12 batches
Epoch 21 of 30 took 44.904s
  training loss:		0.001362
  validation loss:		0.001511
  top 1 accuracy:		99.40 %
  top 2 accuracy:		100.00 %
0.0006283501861616969
7.062662916723639e-05
Batch of classes 1 out of 12 batches
Epoch 22 of 30 took 44.976s
  training loss:		0.000654
  validation loss:		0.001123
  top 1 accuracy:		99.45 %
  top 2 accuracy:		100.00 %
4.411409463500604e-05
0.0002457895316183567
Batch of classes 1 out of 12 batches
Epoch 23 of 30 took 45.045s
  training loss:		0.000712
  validation loss:		0.001225
  top 1 accuracy:		99.60 %
  top 2 accuracy:		100.00 %
0.0001754870463628322
5.1241797336842865e-05
Batch of classes 1 out of 12 batches
Epoch 24 of 30 took 45.151s
  training loss:		0.000655
  validation loss:		0.001141
  top 1 accuracy:		99.70 %
  top 2 accuracy:		100.00 %
0.00463890191167593
0.0018716335762292147
Batch of classes 1 out of 12 batches
Epoch 25 of 30 took 45.420s
  training loss:		0.000853
  validation loss:		0.001136
  top 1 accuracy:		99.65 %
  top 2 accuracy:		100.00 %
0.00045141077134758234
0.00010800092422869056
Batch of classes 1 out of 12 batches
Epoch 26 of 30 took 45.032s
  training loss:		0.000750
  validation loss:		0.001621
  top 1 accuracy:		99.25 %
  top 2 accuracy:		100.00 %
0.0020955190993845463
0.0001674793747952208
Batch of classes 1 out of 12 batches
Epoch 27 of 30 took 44.711s
  training loss:		0.000940
  validation loss:		0.001127
  top 1 accuracy:		99.65 %
  top 2 accuracy:		100.00 %
0.0003502260078676045
0.00027298027998767793
Batch of classes 1 out of 12 batches
Epoch 28 of 30 took 45.325s
  training loss:		0.000704
  validation loss:		0.001664
  top 1 accuracy:		99.45 %
  top 2 accuracy:		100.00 %
6.990494148340076e-05
0.00013550871517509222
Batch of classes 1 out of 12 batches
Epoch 29 of 30 took 45.079s
  training loss:		0.000694
  validation loss:		0.001181
  top 1 accuracy:		99.55 %
  top 2 accuracy:		100.00 %
0.0001540191879030317
0.00014086939336266369
Batch of classes 1 out of 12 batches
Epoch 30 of 30 took 44.744s
  training loss:		0.000565
  validation loss:		0.001562
  top 1 accuracy:		99.25 %
  top 2 accuracy:		100.00 %
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(500)
tensor(500)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		99.45 %
  top 1 accuracy Hybrid 1       :		99.25 %
  top 1 accuracy NCM            :		99.45 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		99.45 %
  top 1 accuracy Hybrid 1       :		99.25 %
  top 1 accuracy NCM            :		99.45 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		99.45 %
  top 1 accuracy Hybrid 1       :		99.25 %
  top 1 accuracy NCM            :		99.45 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		99.45 %
  top 1 accuracy Hybrid 1       :		99.25 %
  top 1 accuracy NCM            :		99.45 %
Classes in this batch: tensor([2, 3])
Data Size: 2400


Before first epoch
  validation loss:		0.962055
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.25 %
Batch of classes number 2 arrives ...
0.2858859598636627
0.059787631034851074
Batch of classes 2 out of 12 batches
Epoch 1 of 30 took 28.675s
  training loss:		0.085947
  validation loss:		0.184980
  top 1 accuracy:		15.00 %
  top 2 accuracy:		86.87 %
0.05528948828577995
0.04765965789556503
Batch of classes 2 out of 12 batches
Epoch 2 of 30 took 28.171s
  training loss:		0.058650
  validation loss:		0.193534
  top 1 accuracy:		36.25 %
  top 2 accuracy:		90.38 %
0.0579986497759819
0.04198986291885376
Batch of classes 2 out of 12 batches
Epoch 3 of 30 took 27.718s
  training loss:		0.051934
  validation loss:		0.155283
  top 1 accuracy:		47.00 %
  top 2 accuracy:		84.87 %
0.06484824419021606
0.06501913070678711
Batch of classes 2 out of 12 batches
Epoch 4 of 30 took 27.669s
  training loss:		0.050310
  validation loss:		0.168717
  top 1 accuracy:		26.25 %
  top 2 accuracy:		87.88 %
0.029134944081306458
0.048355646431446075
Batch of classes 2 out of 12 batches
Epoch 5 of 30 took 27.726s
  training loss:		0.048553
  validation loss:		0.187660
  top 1 accuracy:		38.50 %
  top 2 accuracy:		94.00 %
0.04132305830717087
0.044293008744716644
Batch of classes 2 out of 12 batches
Epoch 6 of 30 took 27.500s
  training loss:		0.043989
  validation loss:		0.163016
  top 1 accuracy:		47.75 %
  top 2 accuracy:		92.00 %
0.06202932447195053
0.04824618622660637
Batch of classes 2 out of 12 batches
Epoch 7 of 30 took 27.638s
  training loss:		0.045166
  validation loss:		0.164870
  top 1 accuracy:		46.63 %
  top 2 accuracy:		92.37 %
0.03748048469424248
0.03916793316602707
Batch of classes 2 out of 12 batches
Epoch 8 of 30 took 27.702s
  training loss:		0.042654
  validation loss:		0.157557
  top 1 accuracy:		52.13 %
  top 2 accuracy:		92.12 %
0.04405907541513443
0.032306134700775146
Batch of classes 2 out of 12 batches
Epoch 9 of 30 took 27.559s
  training loss:		0.042451
  validation loss:		0.153771
  top 1 accuracy:		60.62 %
  top 2 accuracy:		96.38 %
0.04663161560893059
0.04528924822807312
Batch of classes 2 out of 12 batches
Epoch 10 of 30 took 27.711s
  training loss:		0.040991
  validation loss:		0.197283
  top 1 accuracy:		44.75 %
  top 2 accuracy:		95.00 %
0.025748342275619507
0.024158401414752007
Batch of classes 2 out of 12 batches
Epoch 11 of 30 took 27.694s
  training loss:		0.032593
  validation loss:		0.167137
  top 1 accuracy:		56.88 %
  top 2 accuracy:		98.00 %
0.032254017889499664
0.031059209257364273
Batch of classes 2 out of 12 batches
Epoch 12 of 30 took 27.914s
  training loss:		0.028841
  validation loss:		0.176818
  top 1 accuracy:		56.12 %
  top 2 accuracy:		97.50 %
0.01690496876835823
0.02858184091746807
Batch of classes 2 out of 12 batches
Epoch 13 of 30 took 27.725s
  training loss:		0.028987
  validation loss:		0.155662
  top 1 accuracy:		65.00 %
  top 2 accuracy:		98.12 %
0.029847880825400352
0.024631600826978683
Batch of classes 2 out of 12 batches
Epoch 14 of 30 took 27.787s
  training loss:		0.027711
  validation loss:		0.185642
  top 1 accuracy:		60.25 %
  top 2 accuracy:		98.37 %
0.023558219894766808
0.034290991723537445
Batch of classes 2 out of 12 batches
Epoch 15 of 30 took 27.735s
  training loss:		0.026986
  validation loss:		0.156570
  top 1 accuracy:		71.13 %
  top 2 accuracy:		97.87 %
0.019909169524908066
0.018272437155246735
Batch of classes 2 out of 12 batches
Epoch 16 of 30 took 27.890s
  training loss:		0.027570
  validation loss:		0.177068
  top 1 accuracy:		57.63 %
  top 2 accuracy:		93.88 %
0.024156298488378525
0.0358143150806427
Batch of classes 2 out of 12 batches
Epoch 17 of 30 took 27.781s
  training loss:		0.026867
  validation loss:		0.192195
  top 1 accuracy:		60.37 %
  top 2 accuracy:		97.62 %
0.034697890281677246
0.03258749097585678
Batch of classes 2 out of 12 batches
Epoch 18 of 30 took 27.921s
  training loss:		0.026001
  validation loss:		0.218443
  top 1 accuracy:		63.50 %
  top 2 accuracy:		96.38 %
0.03459496423602104
0.036327213048934937
Batch of classes 2 out of 12 batches
Epoch 19 of 30 took 27.729s
  training loss:		0.025709
  validation loss:		0.206093
  top 1 accuracy:		64.50 %
  top 2 accuracy:		98.12 %
0.027147799730300903
0.019807618111371994
Batch of classes 2 out of 12 batches
Epoch 20 of 30 took 27.832s
  training loss:		0.024767
  validation loss:		0.223837
  top 1 accuracy:		61.12 %
  top 2 accuracy:		98.00 %
0.026211602613329887
0.01639445871114731
Batch of classes 2 out of 12 batches
Epoch 21 of 30 took 27.687s
  training loss:		0.023717
  validation loss:		0.182422
  top 1 accuracy:		69.63 %
  top 2 accuracy:		98.50 %
0.02174150012433529
0.02856389246881008
Batch of classes 2 out of 12 batches
Epoch 22 of 30 took 28.242s
  training loss:		0.020823
  validation loss:		0.172096
  top 1 accuracy:		73.62 %
  top 2 accuracy:		98.50 %
0.02342977002263069
0.01136596780270338
Batch of classes 2 out of 12 batches
Epoch 23 of 30 took 27.957s
  training loss:		0.021199
  validation loss:		0.178258
  top 1 accuracy:		72.50 %
  top 2 accuracy:		98.62 %
0.026997879147529602
0.017927614971995354
Batch of classes 2 out of 12 batches
Epoch 24 of 30 took 28.075s
  training loss:		0.021100
  validation loss:		0.166164
  top 1 accuracy:		76.63 %
  top 2 accuracy:		98.50 %
0.018582841381430626
0.025472162291407585
Batch of classes 2 out of 12 batches
Epoch 25 of 30 took 27.847s
  training loss:		0.020467
  validation loss:		0.183050
  top 1 accuracy:		72.50 %
  top 2 accuracy:		98.37 %
0.01801670528948307
0.013512364588677883
Batch of classes 2 out of 12 batches
Epoch 26 of 30 took 27.858s
  training loss:		0.020840
  validation loss:		0.183673
  top 1 accuracy:		74.87 %
  top 2 accuracy:		98.50 %
0.015031173825263977
0.015835735946893692
Batch of classes 2 out of 12 batches
Epoch 27 of 30 took 27.930s
  training loss:		0.020733
  validation loss:		0.180395
  top 1 accuracy:		76.38 %
  top 2 accuracy:		98.25 %
0.01756286434829235
0.012189142405986786
Batch of classes 2 out of 12 batches
Epoch 28 of 30 took 27.931s
  training loss:		0.019485
  validation loss:		0.174350
  top 1 accuracy:		77.00 %
  top 2 accuracy:		98.75 %
0.012852380983531475
0.020088069140911102
Batch of classes 2 out of 12 batches
Epoch 29 of 30 took 27.825s
  training loss:		0.020830
  validation loss:		0.184276
  top 1 accuracy:		79.50 %
  top 2 accuracy:		98.62 %
0.013072608038783073
0.025020360946655273
Batch of classes 2 out of 12 batches
Epoch 30 of 30 took 27.977s
  training loss:		0.019787
  validation loss:		0.199408
  top 1 accuracy:		75.25 %
  top 2 accuracy:		98.50 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(384)
tensor(384)
tensor(384)
tensor(384)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		77.90 %
  top 1 accuracy Hybrid 1       :		84.80 %
  top 1 accuracy NCM            :		79.30 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		97.35 %
  top 1 accuracy Hybrid 1       :		97.90 %
  top 1 accuracy NCM            :		97.25 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		83.75 %
  top 1 accuracy Hybrid 1       :		75.25 %
  top 1 accuracy NCM            :		82.75 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		99.00 %
  top 1 accuracy Hybrid 1       :		98.88 %
  top 1 accuracy NCM            :		99.00 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		79.57 %
  top 1 accuracy Hybrid 1       :		82.07 %
  top 1 accuracy NCM            :		80.29 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		97.82 %
  top 1 accuracy Hybrid 1       :		98.18 %
  top 1 accuracy NCM            :		97.75 %
Classes in this batch: tensor([4, 5])
Data Size: 1572


Before first epoch
  validation loss:		0.737276
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 3 arrives ...
0.310632586479187
Batch of classes 3 out of 12 batches
Epoch 1 of 30 took 24.621s
  training loss:		0.119566
  validation loss:		0.289031
  top 1 accuracy:		1.15 %
  top 2 accuracy:		23.47 %
0.10269235074520111
Batch of classes 3 out of 12 batches
Epoch 2 of 30 took 24.143s
  training loss:		0.079398
  validation loss:		0.190772
  top 1 accuracy:		43.51 %
  top 2 accuracy:		65.46 %
0.07015268504619598
Batch of classes 3 out of 12 batches
Epoch 3 of 30 took 24.148s
  training loss:		0.070844
  validation loss:		0.205987
  top 1 accuracy:		46.95 %
  top 2 accuracy:		68.13 %
0.06684722751379013
Batch of classes 3 out of 12 batches
Epoch 4 of 30 took 23.906s
  training loss:		0.066174
  validation loss:		0.245902
  top 1 accuracy:		51.72 %
  top 2 accuracy:		68.13 %
0.05802616477012634
Batch of classes 3 out of 12 batches
Epoch 5 of 30 took 24.093s
  training loss:		0.062966
  validation loss:		0.213899
  top 1 accuracy:		66.41 %
  top 2 accuracy:		76.91 %
0.064562126994133
Batch of classes 3 out of 12 batches
Epoch 6 of 30 took 23.936s
  training loss:		0.066541
  validation loss:		0.242625
  top 1 accuracy:		53.44 %
  top 2 accuracy:		66.22 %
0.05977640300989151
Batch of classes 3 out of 12 batches
Epoch 7 of 30 took 24.067s
  training loss:		0.063666
  validation loss:		0.207036
  top 1 accuracy:		65.84 %
  top 2 accuracy:		80.53 %
0.0709475576877594
Batch of classes 3 out of 12 batches
Epoch 8 of 30 took 24.118s
  training loss:		0.061345
  validation loss:		0.251938
  top 1 accuracy:		62.02 %
  top 2 accuracy:		78.63 %
0.056586287915706635
Batch of classes 3 out of 12 batches
Epoch 9 of 30 took 24.203s
  training loss:		0.060784
  validation loss:		0.198165
  top 1 accuracy:		75.95 %
  top 2 accuracy:		88.36 %
0.04864860326051712
Batch of classes 3 out of 12 batches
Epoch 10 of 30 took 24.069s
  training loss:		0.060116
  validation loss:		0.241834
  top 1 accuracy:		63.36 %
  top 2 accuracy:		75.38 %
0.07546979188919067
Batch of classes 3 out of 12 batches
Epoch 11 of 30 took 24.029s
  training loss:		0.052402
  validation loss:		0.209800
  top 1 accuracy:		78.63 %
  top 2 accuracy:		89.69 %
0.051918886601924896
Batch of classes 3 out of 12 batches
Epoch 12 of 30 took 24.169s
  training loss:		0.049257
  validation loss:		0.211583
  top 1 accuracy:		79.39 %
  top 2 accuracy:		87.98 %
0.040074996650218964
Batch of classes 3 out of 12 batches
Epoch 13 of 30 took 24.301s
  training loss:		0.048643
  validation loss:		0.218564
  top 1 accuracy:		79.58 %
  top 2 accuracy:		89.31 %
0.064117431640625
Batch of classes 3 out of 12 batches
Epoch 14 of 30 took 24.137s
  training loss:		0.051351
  validation loss:		0.210525
  top 1 accuracy:		82.25 %
  top 2 accuracy:		92.37 %
0.052143167704343796
Batch of classes 3 out of 12 batches
Epoch 15 of 30 took 24.588s
  training loss:		0.048118
  validation loss:		0.232240
  top 1 accuracy:		78.44 %
  top 2 accuracy:		88.93 %
0.0458032488822937
Batch of classes 3 out of 12 batches
Epoch 16 of 30 took 24.067s
  training loss:		0.048327
  validation loss:		0.214843
  top 1 accuracy:		84.54 %
  top 2 accuracy:		93.51 %
0.05112578719854355
Batch of classes 3 out of 12 batches
Epoch 17 of 30 took 24.298s
  training loss:		0.048028
  validation loss:		0.213456
  top 1 accuracy:		80.92 %
  top 2 accuracy:		88.93 %
0.06229311227798462
Batch of classes 3 out of 12 batches
Epoch 18 of 30 took 24.136s
  training loss:		0.047519
  validation loss:		0.230829
  top 1 accuracy:		85.50 %
  top 2 accuracy:		93.70 %
0.03748629614710808
Batch of classes 3 out of 12 batches
Epoch 19 of 30 took 24.237s
  training loss:		0.047219
  validation loss:		0.221688
  top 1 accuracy:		86.07 %
  top 2 accuracy:		92.56 %
0.04958567023277283
Batch of classes 3 out of 12 batches
Epoch 20 of 30 took 23.773s
  training loss:		0.046821
  validation loss:		0.238598
  top 1 accuracy:		84.73 %
  top 2 accuracy:		92.37 %
0.04020870476961136
Batch of classes 3 out of 12 batches
Epoch 21 of 30 took 24.147s
  training loss:		0.045094
  validation loss:		0.212421
  top 1 accuracy:		87.40 %
  top 2 accuracy:		93.32 %
0.03258003294467926
Batch of classes 3 out of 12 batches
Epoch 22 of 30 took 23.946s
  training loss:		0.046492
  validation loss:		0.226540
  top 1 accuracy:		84.16 %
  top 2 accuracy:		91.03 %
0.04137337952852249
Batch of classes 3 out of 12 batches
Epoch 23 of 30 took 24.198s
  training loss:		0.044454
  validation loss:		0.209825
  top 1 accuracy:		86.83 %
  top 2 accuracy:		94.27 %
0.04261374473571777
Batch of classes 3 out of 12 batches
Epoch 24 of 30 took 24.359s
  training loss:		0.043413
  validation loss:		0.236300
  top 1 accuracy:		86.07 %
  top 2 accuracy:		93.13 %
0.046018198132514954
Batch of classes 3 out of 12 batches
Epoch 25 of 30 took 24.346s
  training loss:		0.043468
  validation loss:		0.220793
  top 1 accuracy:		88.74 %
  top 2 accuracy:		94.47 %
0.06365179270505905
Batch of classes 3 out of 12 batches
Epoch 26 of 30 took 24.434s
  training loss:		0.042781
  validation loss:		0.216241
  top 1 accuracy:		89.31 %
  top 2 accuracy:		95.42 %
0.04663468152284622
Batch of classes 3 out of 12 batches
Epoch 27 of 30 took 24.343s
  training loss:		0.042773
  validation loss:		0.215403
  top 1 accuracy:		87.98 %
  top 2 accuracy:		94.85 %
0.041208259761333466
Batch of classes 3 out of 12 batches
Epoch 28 of 30 took 23.641s
  training loss:		0.042873
  validation loss:		0.221218
  top 1 accuracy:		86.64 %
  top 2 accuracy:		93.89 %
0.03809019550681114
Batch of classes 3 out of 12 batches
Epoch 29 of 30 took 24.525s
  training loss:		0.043069
  validation loss:		0.230398
  top 1 accuracy:		87.60 %
  top 2 accuracy:		94.47 %
0.054890334606170654
Batch of classes 3 out of 12 batches
Epoch 30 of 30 took 24.240s
  training loss:		0.042715
  validation loss:		0.220766
  top 1 accuracy:		86.83 %
  top 2 accuracy:		93.51 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(256)
tensor(256)
tensor(256)
tensor(256)
tensor(256)
tensor(256)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		75.40 %
  top 1 accuracy Hybrid 1       :		83.25 %
  top 1 accuracy NCM            :		78.20 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		96.55 %
  top 1 accuracy Hybrid 1       :		97.00 %
  top 1 accuracy NCM            :		96.85 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		72.50 %
  top 1 accuracy Hybrid 1       :		67.38 %
  top 1 accuracy NCM            :		69.50 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		97.62 %
  top 1 accuracy Hybrid 1       :		97.62 %
  top 1 accuracy NCM            :		97.88 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		96.18 %
  top 1 accuracy Hybrid 1       :		86.83 %
  top 1 accuracy NCM            :		95.61 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		98.85 %
  top 1 accuracy Hybrid 1       :		96.76 %
  top 1 accuracy NCM            :		98.85 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		77.98 %
  top 1 accuracy Hybrid 1       :		79.99 %
  top 1 accuracy NCM            :		78.85 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		97.17 %
  top 1 accuracy Hybrid 1       :		97.11 %
  top 1 accuracy NCM            :		97.41 %
Classes in this batch: tensor([6, 7])
Data Size: 7656


Before first epoch
  validation loss:		0.734051
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 4 arrives ...
0.44273099303245544
0.10449086129665375
0.0905747041106224
Batch of classes 4 out of 12 batches
Epoch 1 of 30 took 218.337s
  training loss:		0.105669
  validation loss:		0.199550
  top 1 accuracy:		83.74 %
  top 2 accuracy:		91.07 %
0.06833682954311371
0.07699377834796906
0.07583385705947876
Batch of classes 4 out of 12 batches
Epoch 2 of 30 took 187.355s
  training loss:		0.070881
  validation loss:		0.251501
  top 1 accuracy:		92.01 %
  top 2 accuracy:		93.89 %
0.07250800728797913
0.05908200144767761
0.08252587914466858
Batch of classes 4 out of 12 batches
Epoch 3 of 30 took 228.755s
  training loss:		0.069468
  validation loss:		0.220238
  top 1 accuracy:		97.81 %
  top 2 accuracy:		98.82 %
0.05730568990111351
0.06688007712364197
0.06470483541488647
Batch of classes 4 out of 12 batches
Epoch 4 of 30 took 233.230s
  training loss:		0.067468
  validation loss:		0.228960
  top 1 accuracy:		72.34 %
  top 2 accuracy:		77.47 %
0.08783568441867828
0.06640741229057312
0.07661571353673935
Batch of classes 4 out of 12 batches
Epoch 5 of 30 took 236.435s
  training loss:		0.069426
  validation loss:		0.161118
  top 1 accuracy:		99.57 %
  top 2 accuracy:		99.73 %
0.06025751680135727
0.06978714466094971
0.06532555818557739
Batch of classes 4 out of 12 batches
Epoch 6 of 30 took 219.312s
  training loss:		0.065445
  validation loss:		0.210299
  top 1 accuracy:		92.59 %
  top 2 accuracy:		94.87 %
0.061551254242658615
0.07339929044246674
0.06719249486923218
Batch of classes 4 out of 12 batches
Epoch 7 of 30 took 234.087s
  training loss:		0.066678
  validation loss:		0.271806
  top 1 accuracy:		81.31 %
  top 2 accuracy:		84.21 %
0.06257814168930054
0.07098980247974396
0.06380462646484375
Batch of classes 4 out of 12 batches
Epoch 8 of 30 took 234.925s
  training loss:		0.069227
  validation loss:		0.237987
  top 1 accuracy:		92.83 %
  top 2 accuracy:		96.28 %
0.05782650411128998
0.06029204651713371
0.06686641275882721
Batch of classes 4 out of 12 batches
Epoch 9 of 30 took 234.426s
  training loss:		0.065168
  validation loss:		0.231380
  top 1 accuracy:		99.18 %
  top 2 accuracy:		99.41 %
0.05842597410082817
0.0745430514216423
0.07260852307081223
Batch of classes 4 out of 12 batches
Epoch 10 of 30 took 222.877s
  training loss:		0.064839
  validation loss:		0.223962
  top 1 accuracy:		97.69 %
  top 2 accuracy:		99.10 %
0.0604509636759758
0.05648226663470268
0.06443957984447479
Batch of classes 4 out of 12 batches
Epoch 11 of 30 took 234.137s
  training loss:		0.062216
  validation loss:		0.244018
  top 1 accuracy:		99.37 %
  top 2 accuracy:		99.69 %
0.0607658289372921
0.06495407223701477
0.06044698506593704
Batch of classes 4 out of 12 batches
Epoch 12 of 30 took 227.560s
  training loss:		0.061477
  validation loss:		0.220479
  top 1 accuracy:		99.69 %
  top 2 accuracy:		99.84 %
0.06127560883760452
0.06180257722735405
0.05584971606731415
Batch of classes 4 out of 12 batches
Epoch 13 of 30 took 223.093s
  training loss:		0.060734
  validation loss:		0.225124
  top 1 accuracy:		99.53 %
  top 2 accuracy:		99.80 %
0.057721227407455444
0.06775542348623276
0.06174807995557785
Batch of classes 4 out of 12 batches
Epoch 14 of 30 took 226.513s
  training loss:		0.060863
  validation loss:		0.234815
  top 1 accuracy:		99.49 %
  top 2 accuracy:		99.76 %
0.05126066133379936
0.05772586911916733
0.06858139485120773
Batch of classes 4 out of 12 batches
Epoch 15 of 30 took 225.439s
  training loss:		0.060638
  validation loss:		0.210817
  top 1 accuracy:		99.53 %
  top 2 accuracy:		99.80 %
0.054878976196050644
0.06880521029233932
0.05786329507827759
Batch of classes 4 out of 12 batches
Epoch 16 of 30 took 218.207s
  training loss:		0.060112
  validation loss:		0.218699
  top 1 accuracy:		98.94 %
  top 2 accuracy:		99.29 %
0.0665801465511322
0.05393701046705246
0.05999311804771423
Batch of classes 4 out of 12 batches
Epoch 17 of 30 took 220.421s
  training loss:		0.060951
  validation loss:		0.239590
  top 1 accuracy:		99.45 %
  top 2 accuracy:		99.73 %
0.05739155039191246
0.06417322158813477
0.05981088802218437
Batch of classes 4 out of 12 batches
Epoch 18 of 30 took 207.684s
  training loss:		0.060662
  validation loss:		0.225185
  top 1 accuracy:		99.61 %
  top 2 accuracy:		99.73 %
0.062394678592681885
0.06999614089727402
0.0751708373427391
Batch of classes 4 out of 12 batches
Epoch 19 of 30 took 219.155s
  training loss:		0.060145
  validation loss:		0.230539
  top 1 accuracy:		98.79 %
  top 2 accuracy:		99.49 %
0.0678427517414093
0.05594145879149437
0.0550977997481823
Batch of classes 4 out of 12 batches
Epoch 20 of 30 took 189.992s
  training loss:		0.061751
  validation loss:		0.209240
  top 1 accuracy:		98.63 %
  top 2 accuracy:		99.29 %
0.061540063470602036
0.06694771349430084
0.07022761553525925
Batch of classes 4 out of 12 batches
Epoch 21 of 30 took 215.543s
  training loss:		0.061030
  validation loss:		0.225859
  top 1 accuracy:		99.65 %
  top 2 accuracy:		99.76 %
0.05844058096408844
0.06513702869415283
0.05578519403934479
Batch of classes 4 out of 12 batches
Epoch 22 of 30 took 210.838s
  training loss:		0.059933
  validation loss:		0.238021
  top 1 accuracy:		99.88 %
  top 2 accuracy:		99.92 %
0.05879485607147217
0.05532367527484894
0.06513121724128723
Batch of classes 4 out of 12 batches
Epoch 23 of 30 took 207.930s
  training loss:		0.059471
  validation loss:		0.224744
  top 1 accuracy:		99.80 %
  top 2 accuracy:		99.88 %
0.06720389425754547
0.05719446390867233
0.05502406880259514
Batch of classes 4 out of 12 batches
Epoch 24 of 30 took 216.464s
  training loss:		0.059250
  validation loss:		0.224487
  top 1 accuracy:		99.69 %
  top 2 accuracy:		99.80 %
0.05847124382853508
0.06746697425842285
0.052000682801008224
Batch of classes 4 out of 12 batches
Epoch 25 of 30 took 226.611s
  training loss:		0.059447
  validation loss:		0.221007
  top 1 accuracy:		99.61 %
  top 2 accuracy:		99.80 %
0.06829030811786652
0.055297672748565674
0.05401292443275452
Batch of classes 4 out of 12 batches
Epoch 26 of 30 took 209.495s
  training loss:		0.059366
  validation loss:		0.225887
  top 1 accuracy:		99.73 %
  top 2 accuracy:		99.80 %
0.058305345475673676
0.06167905777692795
0.06961404532194138
Batch of classes 4 out of 12 batches
Epoch 27 of 30 took 216.879s
  training loss:		0.059079
  validation loss:		0.215097
  top 1 accuracy:		99.80 %
  top 2 accuracy:		99.88 %
0.0592084638774395
0.05844992399215698
0.05770503729581833
Batch of classes 4 out of 12 batches
Epoch 28 of 30 took 247.067s
  training loss:		0.059240
  validation loss:		0.225332
  top 1 accuracy:		99.96 %
  top 2 accuracy:		99.96 %
0.06253227591514587
0.07071985304355621
0.06737145781517029
Batch of classes 4 out of 12 batches
Epoch 29 of 30 took 268.158s
  training loss:		0.058927
  validation loss:		0.227477
  top 1 accuracy:		99.73 %
  top 2 accuracy:		99.84 %
0.05175069719552994
0.056766800582408905
0.06064442917704582
Batch of classes 4 out of 12 batches
Epoch 30 of 30 took 255.384s
  training loss:		0.059057
  validation loss:		0.228303
  top 1 accuracy:		99.69 %
  top 2 accuracy:		99.92 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		77.00 %
  top 1 accuracy Hybrid 1       :		84.50 %
  top 1 accuracy NCM            :		77.65 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		96.65 %
  top 1 accuracy Hybrid 1       :		95.60 %
  top 1 accuracy NCM            :		96.95 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		69.75 %
  top 1 accuracy Hybrid 1       :		63.00 %
  top 1 accuracy NCM            :		69.38 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		96.38 %
  top 1 accuracy Hybrid 1       :		96.25 %
  top 1 accuracy NCM            :		96.38 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		93.13 %
  top 1 accuracy Hybrid 1       :		78.82 %
  top 1 accuracy NCM            :		93.13 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		97.52 %
  top 1 accuracy Hybrid 1       :		93.70 %
  top 1 accuracy NCM            :		97.33 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.92 %
  top 1 accuracy Hybrid 1       :		99.69 %
  top 1 accuracy NCM            :		99.96 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		99.92 %
  top 1 accuracy NCM            :		100.00 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		87.41 %
  top 1 accuracy Hybrid 1       :		87.66 %
  top 1 accuracy NCM            :		87.59 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		98.14 %
  top 1 accuracy Hybrid 1       :		97.40 %
  top 1 accuracy NCM            :		98.23 %
Classes in this batch: tensor([8, 9])
Data Size: 3248


Before first epoch
  validation loss:		0.676196
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 5 arrives ...
0.35840997099876404
0.1216793954372406
Batch of classes 5 out of 12 batches
Epoch 1 of 30 took 36.908s
  training loss:		0.142885
  validation loss:		0.455314
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
0.12416183948516846
0.09921258687973022
Batch of classes 5 out of 12 batches
Epoch 2 of 30 took 37.049s
  training loss:		0.091239
  validation loss:		0.336425
  top 1 accuracy:		77.54 %
  top 2 accuracy:		82.62 %
0.07659915089607239
0.0776643455028534
Batch of classes 5 out of 12 batches
Epoch 3 of 30 took 36.890s
  training loss:		0.081764
  validation loss:		0.385767
  top 1 accuracy:		62.20 %
  top 2 accuracy:		64.60 %
0.07857821881771088
0.08966946601867676
Batch of classes 5 out of 12 batches
Epoch 4 of 30 took 36.640s
  training loss:		0.077734
  validation loss:		0.396355
  top 1 accuracy:		84.84 %
  top 2 accuracy:		86.60 %
0.07695794105529785
0.08263519406318665
Batch of classes 5 out of 12 batches
Epoch 5 of 30 took 36.878s
  training loss:		0.077621
  validation loss:		0.333404
  top 1 accuracy:		82.16 %
  top 2 accuracy:		85.03 %
0.06848011910915375
0.08084897696971893
Batch of classes 5 out of 12 batches
Epoch 6 of 30 took 36.824s
  training loss:		0.076930
  validation loss:		0.370866
  top 1 accuracy:		84.75 %
  top 2 accuracy:		88.63 %
0.07713022828102112
0.07174426317214966
Batch of classes 5 out of 12 batches
Epoch 7 of 30 took 36.923s
  training loss:		0.074986
  validation loss:		0.357518
  top 1 accuracy:		89.65 %
  top 2 accuracy:		92.05 %
0.0713682770729065
0.07326288521289825
Batch of classes 5 out of 12 batches
Epoch 8 of 30 took 37.105s
  training loss:		0.073166
  validation loss:		0.345948
  top 1 accuracy:		93.16 %
  top 2 accuracy:		93.72 %
0.06424468755722046
0.06966584920883179
Batch of classes 5 out of 12 batches
Epoch 9 of 30 took 39.952s
  training loss:		0.072904
  validation loss:		0.378468
  top 1 accuracy:		86.51 %
  top 2 accuracy:		87.89 %
0.07805849611759186
0.0671231672167778
Batch of classes 5 out of 12 batches
Epoch 10 of 30 took 37.035s
  training loss:		0.075828
  validation loss:		0.337215
  top 1 accuracy:		90.20 %
  top 2 accuracy:		92.79 %
0.06481419503688812
0.07322457432746887
Batch of classes 5 out of 12 batches
Epoch 11 of 30 took 37.098s
  training loss:		0.070323
  validation loss:		0.371085
  top 1 accuracy:		86.04 %
  top 2 accuracy:		88.63 %
0.0735352486371994
0.07465103268623352
Batch of classes 5 out of 12 batches
Epoch 12 of 30 took 36.735s
  training loss:		0.068708
  validation loss:		0.369383
  top 1 accuracy:		91.77 %
  top 2 accuracy:		93.72 %
0.0796041339635849
0.07864805310964584
Batch of classes 5 out of 12 batches
Epoch 13 of 30 took 38.578s
  training loss:		0.068515
  validation loss:		0.362172
  top 1 accuracy:		89.56 %
  top 2 accuracy:		91.22 %
0.06191262602806091
0.080134816467762
Batch of classes 5 out of 12 batches
Epoch 14 of 30 took 36.653s
  training loss:		0.068433
  validation loss:		0.355052
  top 1 accuracy:		93.25 %
  top 2 accuracy:		94.36 %
0.06574057042598724
0.07258498668670654
Batch of classes 5 out of 12 batches
Epoch 15 of 30 took 36.862s
  training loss:		0.068007
  validation loss:		0.361394
  top 1 accuracy:		93.25 %
  top 2 accuracy:		94.55 %
0.06717922538518906
0.07273416221141815
Batch of classes 5 out of 12 batches
Epoch 16 of 30 took 36.738s
  training loss:		0.067667
  validation loss:		0.365416
  top 1 accuracy:		91.87 %
  top 2 accuracy:		93.99 %
0.07189425826072693
0.06557036936283112
Batch of classes 5 out of 12 batches
Epoch 17 of 30 took 36.617s
  training loss:		0.067719
  validation loss:		0.370222
  top 1 accuracy:		90.39 %
  top 2 accuracy:		92.61 %
0.06717651337385178
0.05886710807681084
Batch of classes 5 out of 12 batches
Epoch 18 of 30 took 38.977s
  training loss:		0.067402
  validation loss:		0.361187
  top 1 accuracy:		93.35 %
  top 2 accuracy:		94.45 %
0.06739572435617447
0.06176444888114929
Batch of classes 5 out of 12 batches
Epoch 19 of 30 took 36.776s
  training loss:		0.068708
  validation loss:		0.365428
  top 1 accuracy:		89.46 %
  top 2 accuracy:		91.13 %
0.0745973065495491
0.0608394555747509
Batch of classes 5 out of 12 batches
Epoch 20 of 30 took 36.683s
  training loss:		0.067404
  validation loss:		0.380175
  top 1 accuracy:		91.50 %
  top 2 accuracy:		93.16 %
0.06638401746749878
0.060250818729400635
Batch of classes 5 out of 12 batches
Epoch 21 of 30 took 36.638s
  training loss:		0.066662
  validation loss:		0.365324
  top 1 accuracy:		92.70 %
  top 2 accuracy:		94.36 %
0.05685551092028618
0.07237258553504944
Batch of classes 5 out of 12 batches
Epoch 22 of 30 took 36.775s
  training loss:		0.066042
  validation loss:		0.363854
  top 1 accuracy:		91.68 %
  top 2 accuracy:		93.53 %
0.08101367950439453
0.06070980429649353
Batch of classes 5 out of 12 batches
Epoch 23 of 30 took 37.047s
  training loss:		0.066551
  validation loss:		0.371690
  top 1 accuracy:		91.59 %
  top 2 accuracy:		93.81 %
0.05831310898065567
0.07118242233991623
Batch of classes 5 out of 12 batches
Epoch 24 of 30 took 36.710s
  training loss:		0.066188
  validation loss:		0.355471
  top 1 accuracy:		92.51 %
  top 2 accuracy:		94.36 %
0.06844694167375565
0.06551478058099747
Batch of classes 5 out of 12 batches
Epoch 25 of 30 took 36.716s
  training loss:		0.066198
  validation loss:		0.381935
  top 1 accuracy:		89.83 %
  top 2 accuracy:		92.33 %
0.056078702211380005
0.07670164108276367
Batch of classes 5 out of 12 batches
Epoch 26 of 30 took 36.635s
  training loss:		0.066234
  validation loss:		0.366447
  top 1 accuracy:		91.04 %
  top 2 accuracy:		93.72 %
0.05367417261004448
0.06743830442428589
Batch of classes 5 out of 12 batches
Epoch 27 of 30 took 36.728s
  training loss:		0.065994
  validation loss:		0.366338
  top 1 accuracy:		91.50 %
  top 2 accuracy:		93.72 %
0.06347914040088654
0.06774024665355682
Batch of classes 5 out of 12 batches
Epoch 28 of 30 took 36.579s
  training loss:		0.065949
  validation loss:		0.362516
  top 1 accuracy:		90.67 %
  top 2 accuracy:		93.35 %
0.06048814207315445
0.06696169078350067
Batch of classes 5 out of 12 batches
Epoch 29 of 30 took 36.623s
  training loss:		0.065669
  validation loss:		0.373163
  top 1 accuracy:		91.77 %
  top 2 accuracy:		93.25 %
0.06635971367359161
0.05885970592498779
Batch of classes 5 out of 12 batches
Epoch 30 of 30 took 36.739s
  training loss:		0.065926
  validation loss:		0.360589
  top 1 accuracy:		95.10 %
  top 2 accuracy:		95.66 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		74.90 %
  top 1 accuracy Hybrid 1       :		82.15 %
  top 1 accuracy NCM            :		76.35 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		92.20 %
  top 1 accuracy Hybrid 1       :		89.90 %
  top 1 accuracy NCM            :		92.95 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		66.25 %
  top 1 accuracy Hybrid 1       :		53.88 %
  top 1 accuracy NCM            :		67.12 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		94.88 %
  top 1 accuracy Hybrid 1       :		92.75 %
  top 1 accuracy NCM            :		94.75 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		91.41 %
  top 1 accuracy Hybrid 1       :		69.47 %
  top 1 accuracy NCM            :		91.60 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		96.76 %
  top 1 accuracy Hybrid 1       :		88.74 %
  top 1 accuracy NCM            :		96.56 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.96 %
  top 1 accuracy Hybrid 1       :		97.88 %
  top 1 accuracy NCM            :		99.96 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.96 %
  top 1 accuracy Hybrid 1       :		99.96 %
  top 1 accuracy NCM            :		99.96 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		96.58 %
  top 1 accuracy Hybrid 1       :		95.10 %
  top 1 accuracy NCM            :		96.58 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		96.67 %
  top 1 accuracy Hybrid 1       :		96.77 %
  top 1 accuracy NCM            :		96.67 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		87.71 %
  top 1 accuracy Hybrid 1       :		85.73 %
  top 1 accuracy NCM            :		88.24 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		96.39 %
  top 1 accuracy Hybrid 1       :		94.90 %
  top 1 accuracy NCM            :		96.58 %
Classes in this batch: tensor([10, 11])
Data Size: 7658


Before first epoch
  validation loss:		0.958461
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 6 arrives ...
0.48411497473716736
0.09359949827194214
0.08534972369670868
Batch of classes 6 out of 12 batches
Epoch 1 of 30 took 156.441s
  training loss:		0.121011
  validation loss:		0.441061
  top 1 accuracy:		45.14 %
  top 2 accuracy:		80.21 %
0.1019309014081955
0.10102447122335434
0.09312862157821655
Batch of classes 6 out of 12 batches
Epoch 2 of 30 took 179.029s
  training loss:		0.090262
  validation loss:		0.393039
  top 1 accuracy:		45.22 %
  top 2 accuracy:		76.68 %
0.10137592256069183
0.08523477613925934
0.08066349476575851
Batch of classes 6 out of 12 batches
Epoch 3 of 30 took 179.132s
  training loss:		0.088131
  validation loss:		0.418542
  top 1 accuracy:		47.92 %
  top 2 accuracy:		97.45 %
0.09540219604969025
0.0956997275352478
0.09460016340017319
Batch of classes 6 out of 12 batches
Epoch 4 of 30 took 176.642s
  training loss:		0.089100
  validation loss:		0.415059
  top 1 accuracy:		49.57 %
  top 2 accuracy:		98.63 %
0.08814951032400131
0.08998768776655197
0.0913468599319458
Batch of classes 6 out of 12 batches
Epoch 5 of 30 took 171.976s
  training loss:		0.087320
  validation loss:		0.464362
  top 1 accuracy:		50.74 %
  top 2 accuracy:		94.71 %
0.0775560736656189
0.10249929875135422
0.09378477185964584
Batch of classes 6 out of 12 batches
Epoch 6 of 30 took 174.309s
  training loss:		0.088325
  validation loss:		0.397838
  top 1 accuracy:		56.43 %
  top 2 accuracy:		96.75 %
0.0809900313615799
0.08337423205375671
0.08224380016326904
Batch of classes 6 out of 12 batches
Epoch 7 of 30 took 168.941s
  training loss:		0.087393
  validation loss:		0.519233
  top 1 accuracy:		25.43 %
  top 2 accuracy:		68.65 %
0.09694647043943405
0.09475284069776535
0.08376345038414001
Batch of classes 6 out of 12 batches
Epoch 8 of 30 took 175.057s
  training loss:		0.086116
  validation loss:		0.388669
  top 1 accuracy:		50.31 %
  top 2 accuracy:		85.50 %
0.09631115198135376
0.0812835842370987
0.08792850375175476
Batch of classes 6 out of 12 batches
Epoch 9 of 30 took 175.410s
  training loss:		0.086571
  validation loss:		0.429008
  top 1 accuracy:		52.12 %
  top 2 accuracy:		80.21 %
0.09038746356964111
0.08487646281719208
0.07484301179647446
Batch of classes 6 out of 12 batches
Epoch 10 of 30 took 165.704s
  training loss:		0.086573
  validation loss:		0.412517
  top 1 accuracy:		89.34 %
  top 2 accuracy:		94.87 %
0.08628981560468674
0.09430918097496033
0.09785974025726318
Batch of classes 6 out of 12 batches
Epoch 11 of 30 took 163.685s
  training loss:		0.083209
  validation loss:		0.430754
  top 1 accuracy:		75.67 %
  top 2 accuracy:		97.10 %
0.08771424740552902
0.0809299573302269
0.08662667125463486
Batch of classes 6 out of 12 batches
Epoch 12 of 30 took 168.253s
  training loss:		0.082310
  validation loss:		0.440941
  top 1 accuracy:		91.85 %
  top 2 accuracy:		99.33 %
0.08261317014694214
0.08358222246170044
0.07428810000419617
Batch of classes 6 out of 12 batches
Epoch 13 of 30 took 166.216s
  training loss:		0.082179
  validation loss:		0.426036
  top 1 accuracy:		93.38 %
  top 2 accuracy:		99.57 %
0.08098618686199188
0.08921228349208832
0.07658105343580246
Batch of classes 6 out of 12 batches
Epoch 14 of 30 took 161.365s
  training loss:		0.082047
  validation loss:		0.419108
  top 1 accuracy:		93.42 %
  top 2 accuracy:		99.61 %
0.08754297345876694
0.08002149313688278
0.07944284379482269
Batch of classes 6 out of 12 batches
Epoch 15 of 30 took 160.581s
  training loss:		0.081632
  validation loss:		0.424242
  top 1 accuracy:		91.30 %
  top 2 accuracy:		99.53 %
0.07664312422275543
0.07777684926986694
0.08435836434364319
Batch of classes 6 out of 12 batches
Epoch 16 of 30 took 164.023s
  training loss:		0.081883
  validation loss:		0.452942
  top 1 accuracy:		86.29 %
  top 2 accuracy:		98.67 %
0.07909764349460602
0.08349429816007614
0.08418592065572739
Batch of classes 6 out of 12 batches
Epoch 17 of 30 took 160.790s
  training loss:		0.081648
  validation loss:		0.444325
  top 1 accuracy:		98.08 %
  top 2 accuracy:		99.88 %
0.08268007636070251
0.09264113008975983
0.07824496924877167
Batch of classes 6 out of 12 batches
Epoch 18 of 30 took 161.106s
  training loss:		0.081580
  validation loss:		0.438894
  top 1 accuracy:		95.30 %
  top 2 accuracy:		99.80 %
0.08129625022411346
0.08595536649227142
0.07978935539722443
Batch of classes 6 out of 12 batches
Epoch 19 of 30 took 160.117s
  training loss:		0.082248
  validation loss:		0.438457
  top 1 accuracy:		90.99 %
  top 2 accuracy:		99.18 %
0.07418876886367798
0.08478723466396332
0.07608954608440399
Batch of classes 6 out of 12 batches
Epoch 20 of 30 took 159.978s
  training loss:		0.082128
  validation loss:		0.427994
  top 1 accuracy:		94.91 %
  top 2 accuracy:		99.49 %
0.08156777918338776
0.06887468695640564
0.08922859281301498
Batch of classes 6 out of 12 batches
Epoch 21 of 30 took 159.362s
  training loss:		0.081622
  validation loss:		0.429721
  top 1 accuracy:		94.91 %
  top 2 accuracy:		99.69 %
0.07757687568664551
0.07872018218040466
0.09406508505344391
Batch of classes 6 out of 12 batches
Epoch 22 of 30 took 156.809s
  training loss:		0.080970
  validation loss:		0.434856
  top 1 accuracy:		96.59 %
  top 2 accuracy:		99.92 %
0.08646969497203827
0.085274837911129
0.08336512744426727
Batch of classes 6 out of 12 batches
Epoch 23 of 30 took 150.158s
  training loss:		0.081081
  validation loss:		0.428741
  top 1 accuracy:		96.59 %
  top 2 accuracy:		99.73 %
0.07342356443405151
0.07331015169620514
0.07562413066625595
Batch of classes 6 out of 12 batches
Epoch 24 of 30 took 154.421s
  training loss:		0.080954
  validation loss:		0.430495
  top 1 accuracy:		94.51 %
  top 2 accuracy:		99.80 %
0.08646862208843231
0.08748432248830795
0.07384461909532547
Batch of classes 6 out of 12 batches
Epoch 25 of 30 took 164.482s
  training loss:		0.081028
  validation loss:		0.443382
  top 1 accuracy:		96.12 %
  top 2 accuracy:		99.84 %
0.07930205762386322
0.07877217233181
0.08607861399650574
Batch of classes 6 out of 12 batches
Epoch 26 of 30 took 160.693s
  training loss:		0.080812
  validation loss:		0.426956
  top 1 accuracy:		94.32 %
  top 2 accuracy:		99.80 %
0.08710958808660507
0.07676833122968674
0.07372048497200012
Batch of classes 6 out of 12 batches
Epoch 27 of 30 took 160.261s
  training loss:		0.080710
  validation loss:		0.426583
  top 1 accuracy:		97.49 %
  top 2 accuracy:		99.96 %
0.07497034966945648
0.0836823433637619
0.06839706748723984
Batch of classes 6 out of 12 batches
Epoch 28 of 30 took 158.374s
  training loss:		0.081219
  validation loss:		0.437939
  top 1 accuracy:		87.11 %
  top 2 accuracy:		98.79 %
0.08136483281850815
0.0873805582523346
0.08627718687057495
Batch of classes 6 out of 12 batches
Epoch 29 of 30 took 182.918s
  training loss:		0.080695
  validation loss:		0.436590
  top 1 accuracy:		93.97 %
  top 2 accuracy:		99.92 %
0.08197171986103058
0.07811028510332108
0.07729379832744598
Batch of classes 6 out of 12 batches
Epoch 30 of 30 took 199.700s
  training loss:		0.080919
  validation loss:		0.429921
  top 1 accuracy:		97.22 %
  top 2 accuracy:		99.88 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		66.50 %
  top 1 accuracy Hybrid 1       :		78.10 %
  top 1 accuracy NCM            :		66.25 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		90.85 %
  top 1 accuracy Hybrid 1       :		84.60 %
  top 1 accuracy NCM            :		90.70 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		71.00 %
  top 1 accuracy Hybrid 1       :		48.50 %
  top 1 accuracy NCM            :		70.12 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		91.62 %
  top 1 accuracy Hybrid 1       :		89.75 %
  top 1 accuracy NCM            :		90.88 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		90.65 %
  top 1 accuracy Hybrid 1       :		63.36 %
  top 1 accuracy NCM            :		91.22 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		95.80 %
  top 1 accuracy Hybrid 1       :		87.60 %
  top 1 accuracy NCM            :		95.80 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		72.26 %
  top 1 accuracy Hybrid 1       :		52.59 %
  top 1 accuracy NCM            :		71.51 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.96 %
  top 1 accuracy Hybrid 1       :		99.84 %
  top 1 accuracy NCM            :		99.96 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		96.77 %
  top 1 accuracy Hybrid 1       :		92.33 %
  top 1 accuracy NCM            :		96.67 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		96.86 %
  top 1 accuracy Hybrid 1       :		96.86 %
  top 1 accuracy NCM            :		96.77 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		77.66 %
  top 1 accuracy Hybrid 1       :		97.22 %
  top 1 accuracy NCM            :		78.41 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.96 %
  top 1 accuracy Hybrid 1       :		99.96 %
  top 1 accuracy NCM            :		99.96 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		76.19 %
  top 1 accuracy Hybrid 1       :		74.70 %
  top 1 accuracy NCM            :		76.09 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		96.76 %
  top 1 accuracy Hybrid 1       :		94.81 %
  top 1 accuracy NCM            :		96.66 %
Classes in this batch: tensor([12, 13])
Data Size: 6208


Before first epoch
  validation loss:		0.795893
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 7 arrives ...
0.5196582078933716
0.16258388757705688
0.16337904334068298
Batch of classes 7 out of 12 batches
Epoch 1 of 30 took 90.937s
  training loss:		0.184847
  validation loss:		0.471638
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
0.15514925122261047
0.1630348116159439
0.15292450785636902
Batch of classes 7 out of 12 batches
Epoch 2 of 30 took 93.066s
  training loss:		0.157029
  validation loss:		0.470337
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.05 %
0.16602270305156708
0.1515050232410431
0.15046530961990356
Batch of classes 7 out of 12 batches
Epoch 3 of 30 took 89.075s
  training loss:		0.151342
  validation loss:		0.470284
  top 1 accuracy:		2.38 %
  top 2 accuracy:		3.97 %
0.15261700749397278
0.1386708915233612
0.16295087337493896
Batch of classes 7 out of 12 batches
Epoch 4 of 30 took 91.636s
  training loss:		0.147964
  validation loss:		0.456238
  top 1 accuracy:		0.68 %
  top 2 accuracy:		1.50 %
0.13526374101638794
0.13359907269477844
0.15341658890247345
Batch of classes 7 out of 12 batches
Epoch 5 of 30 took 76.177s
  training loss:		0.146446
  validation loss:		0.442104
  top 1 accuracy:		3.73 %
  top 2 accuracy:		7.76 %
0.12253324687480927
0.1464516818523407
0.1511789709329605
Batch of classes 7 out of 12 batches
Epoch 6 of 30 took 75.481s
  training loss:		0.144407
  validation loss:		0.451175
  top 1 accuracy:		14.25 %
  top 2 accuracy:		18.81 %
0.14106211066246033
0.14348536729812622
0.15267358720302582
Batch of classes 7 out of 12 batches
Epoch 7 of 30 took 88.821s
  training loss:		0.142508
  validation loss:		0.456434
  top 1 accuracy:		6.16 %
  top 2 accuracy:		10.71 %
0.1547890603542328
0.12496207654476166
0.14038735628128052
Batch of classes 7 out of 12 batches
Epoch 8 of 30 took 89.673s
  training loss:		0.141483
  validation loss:		0.467713
  top 1 accuracy:		22.78 %
  top 2 accuracy:		27.63 %
0.1232508048415184
0.13366520404815674
0.1494656801223755
Batch of classes 7 out of 12 batches
Epoch 9 of 30 took 92.204s
  training loss:		0.139993
  validation loss:		0.457897
  top 1 accuracy:		16.19 %
  top 2 accuracy:		22.01 %
0.1478845179080963
0.12963996827602386
0.12388905882835388
Batch of classes 7 out of 12 batches
Epoch 10 of 30 took 80.039s
  training loss:		0.138498
  validation loss:		0.411458
  top 1 accuracy:		19.73 %
  top 2 accuracy:		24.43 %
0.1235971674323082
0.11366590857505798
0.12565192580223083
Batch of classes 7 out of 12 batches
Epoch 11 of 30 took 87.042s
  training loss:		0.131356
  validation loss:		0.432534
  top 1 accuracy:		34.90 %
  top 2 accuracy:		41.49 %
0.10712157189846039
0.1237800344824791
0.12207730859518051
Batch of classes 7 out of 12 batches
Epoch 12 of 30 took 87.574s
  training loss:		0.129307
  validation loss:		0.433631
  top 1 accuracy:		32.53 %
  top 2 accuracy:		39.07 %
0.11877324432134628
0.14664626121520996
0.135877788066864
Batch of classes 7 out of 12 batches
Epoch 13 of 30 took 91.842s
  training loss:		0.128295
  validation loss:		0.451639
  top 1 accuracy:		32.33 %
  top 2 accuracy:		39.41 %
0.11771835386753082
0.11411701142787933
0.13451740145683289
Batch of classes 7 out of 12 batches
Epoch 14 of 30 took 86.213s
  training loss:		0.127493
  validation loss:		0.441989
  top 1 accuracy:		35.72 %
  top 2 accuracy:		42.12 %
0.11165569722652435
0.13398849964141846
0.1133442148566246
Batch of classes 7 out of 12 batches
Epoch 15 of 30 took 89.768s
  training loss:		0.126542
  validation loss:		0.441840
  top 1 accuracy:		36.21 %
  top 2 accuracy:		42.66 %
0.12085235118865967
0.12495763599872589
0.13693547248840332
Batch of classes 7 out of 12 batches
Epoch 16 of 30 took 92.203s
  training loss:		0.125735
  validation loss:		0.440330
  top 1 accuracy:		36.55 %
  top 2 accuracy:		42.03 %
0.14077839255332947
0.12702900171279907
0.1236581802368164
Batch of classes 7 out of 12 batches
Epoch 17 of 30 took 91.400s
  training loss:		0.124988
  validation loss:		0.430484
  top 1 accuracy:		40.77 %
  top 2 accuracy:		47.12 %
0.12008170783519745
0.1368778645992279
0.11745306104421616
Batch of classes 7 out of 12 batches
Epoch 18 of 30 took 93.676s
  training loss:		0.124167
  validation loss:		0.438674
  top 1 accuracy:		35.48 %
  top 2 accuracy:		42.41 %
0.11679007858037949
0.1313275396823883
0.13149498403072357
Batch of classes 7 out of 12 batches
Epoch 19 of 30 took 90.491s
  training loss:		0.123615
  validation loss:		0.438121
  top 1 accuracy:		40.86 %
  top 2 accuracy:		47.89 %
0.10276492685079575
0.12208662927150726
0.12360440194606781
Batch of classes 7 out of 12 batches
Epoch 20 of 30 took 91.786s
  training loss:		0.122726
  validation loss:		0.437774
  top 1 accuracy:		41.15 %
  top 2 accuracy:		46.58 %
0.11594550311565399
0.1099075973033905
0.118028424680233
Batch of classes 7 out of 12 batches
Epoch 21 of 30 took 89.611s
  training loss:		0.119532
  validation loss:		0.441040
  top 1 accuracy:		47.84 %
  top 2 accuracy:		53.71 %
0.13002872467041016
0.13154679536819458
0.12961383163928986
Batch of classes 7 out of 12 batches
Epoch 22 of 30 took 90.683s
  training loss:		0.117562
  validation loss:		0.450479
  top 1 accuracy:		47.36 %
  top 2 accuracy:		53.66 %
0.12853413820266724
0.14239847660064697
0.10651950538158417
Batch of classes 7 out of 12 batches
Epoch 23 of 30 took 88.632s
  training loss:		0.117681
  validation loss:		0.447245
  top 1 accuracy:		45.86 %
  top 2 accuracy:		52.21 %
0.1353524774312973
0.10751651972532272
0.12167622894048691
Batch of classes 7 out of 12 batches
Epoch 24 of 30 took 77.133s
  training loss:		0.117612
  validation loss:		0.448575
  top 1 accuracy:		50.90 %
  top 2 accuracy:		56.42 %
0.12504802644252777
0.13062536716461182
0.12487654387950897
Batch of classes 7 out of 12 batches
Epoch 25 of 30 took 61.290s
  training loss:		0.116144
  validation loss:		0.460855
  top 1 accuracy:		51.14 %
  top 2 accuracy:		57.54 %
0.11958837509155273
0.1249077245593071
0.11477898806333542
Batch of classes 7 out of 12 batches
Epoch 26 of 30 took 60.298s
  training loss:		0.116304
  validation loss:		0.453829
  top 1 accuracy:		50.12 %
  top 2 accuracy:		55.70 %
0.12136006355285645
0.11490174382925034
0.13314609229564667
Batch of classes 7 out of 12 batches
Epoch 27 of 30 took 61.810s
  training loss:		0.115926
  validation loss:		0.454782
  top 1 accuracy:		51.28 %
  top 2 accuracy:		57.05 %
0.11302851885557175
0.1196632832288742
0.11766888201236725
Batch of classes 7 out of 12 batches
Epoch 28 of 30 took 60.510s
  training loss:		0.115175
  validation loss:		0.462678
  top 1 accuracy:		49.49 %
  top 2 accuracy:		55.74 %
0.12259268760681152
0.09988260269165039
0.10505978763103485
Batch of classes 7 out of 12 batches
Epoch 29 of 30 took 58.465s
  training loss:		0.115710
  validation loss:		0.459648
  top 1 accuracy:		52.79 %
  top 2 accuracy:		58.41 %
0.10175999999046326
0.1202157586812973
0.1175394281744957
Batch of classes 7 out of 12 batches
Epoch 30 of 30 took 68.261s
  training loss:		0.115114
  validation loss:		0.460620
  top 1 accuracy:		51.09 %
  top 2 accuracy:		56.76 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		63.55 %
  top 1 accuracy Hybrid 1       :		70.70 %
  top 1 accuracy NCM            :		62.25 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		82.40 %
  top 1 accuracy Hybrid 1       :		78.05 %
  top 1 accuracy NCM            :		82.50 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		56.00 %
  top 1 accuracy Hybrid 1       :		34.75 %
  top 1 accuracy NCM            :		58.75 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		85.75 %
  top 1 accuracy Hybrid 1       :		78.62 %
  top 1 accuracy NCM            :		86.00 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		83.40 %
  top 1 accuracy Hybrid 1       :		60.50 %
  top 1 accuracy NCM            :		83.59 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		92.94 %
  top 1 accuracy Hybrid 1       :		85.11 %
  top 1 accuracy NCM            :		92.94 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		76.84 %
  top 1 accuracy Hybrid 1       :		49.92 %
  top 1 accuracy NCM            :		78.76 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.84 %
  top 1 accuracy Hybrid 1       :		99.61 %
  top 1 accuracy NCM            :		99.80 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		88.35 %
  top 1 accuracy Hybrid 1       :		81.79 %
  top 1 accuracy NCM            :		88.72 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		94.18 %
  top 1 accuracy Hybrid 1       :		95.29 %
  top 1 accuracy NCM            :		94.27 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		72.65 %
  top 1 accuracy Hybrid 1       :		97.69 %
  top 1 accuracy NCM            :		70.69 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.84 %
  top 1 accuracy Hybrid 1       :		99.76 %
  top 1 accuracy NCM            :		99.80 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		75.62 %
  top 1 accuracy Hybrid 1       :		51.09 %
  top 1 accuracy NCM            :		75.08 %
Binary accuracy:
Final results on wild classes:
  top 1 accuracy iCaRL          :		78.53 %
  top 1 accuracy Hybrid 1       :		75.13 %
  top 1 accuracy NCM            :		78.82 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		73.33 %
  top 1 accuracy Hybrid 1       :		66.66 %
  top 1 accuracy NCM            :		73.24 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		91.21 %
  top 1 accuracy Hybrid 1       :		89.04 %
  top 1 accuracy NCM            :		91.29 %
Classes in this batch: tensor([14, 15])
Data Size: 7200


Before first epoch
  validation loss:		0.731562
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 8 arrives ...
0.6434414386749268
0.16480612754821777
0.13454295694828033
Batch of classes 8 out of 12 batches
Epoch 1 of 30 took 235.186s
  training loss:		0.177325
  validation loss:		0.203272
  top 1 accuracy:		82.67 %
  top 2 accuracy:		89.21 %
0.1271733045578003
0.1149856373667717
0.12487363070249557
Batch of classes 8 out of 12 batches
Epoch 2 of 30 took 233.446s
  training loss:		0.127406
  validation loss:		0.247612
  top 1 accuracy:		68.52 %
  top 2 accuracy:		73.10 %
0.14649847149848938
0.11996328085660934
0.11703407764434814
Batch of classes 8 out of 12 batches
Epoch 3 of 30 took 241.144s
  training loss:		0.125062
  validation loss:		0.212726
  top 1 accuracy:		90.35 %
  top 2 accuracy:		93.67 %
0.12732437252998352
0.11673413217067719
0.12620843946933746
Batch of classes 8 out of 12 batches
Epoch 4 of 30 took 238.595s
  training loss:		0.123528
  validation loss:		0.204932
  top 1 accuracy:		92.02 %
  top 2 accuracy:		94.25 %
0.11220280826091766
0.12999948859214783
0.11846434324979782
Batch of classes 8 out of 12 batches
Epoch 5 of 30 took 244.469s
  training loss:		0.122469
  validation loss:		0.211412
  top 1 accuracy:		97.06 %
  top 2 accuracy:		98.19 %
0.11662992835044861
0.11486637592315674
0.1261366605758667
Batch of classes 8 out of 12 batches
Epoch 6 of 30 took 241.726s
  training loss:		0.120196
  validation loss:		0.200822
  top 1 accuracy:		92.42 %
  top 2 accuracy:		94.88 %
0.12378015369176865
0.12090607732534409
0.11863996833562851
Batch of classes 8 out of 12 batches
Epoch 7 of 30 took 239.540s
  training loss:		0.123204
  validation loss:		0.219602
  top 1 accuracy:		96.58 %
  top 2 accuracy:		97.87 %
0.12574774026870728
0.12765400111675262
0.12809067964553833
Batch of classes 8 out of 12 batches
Epoch 8 of 30 took 243.969s
  training loss:		0.121633
  validation loss:		0.313233
  top 1 accuracy:		61.46 %
  top 2 accuracy:		65.04 %
0.12677884101867676
0.12519249320030212
0.11889278888702393
Batch of classes 8 out of 12 batches
Epoch 9 of 30 took 242.202s
  training loss:		0.120952
  validation loss:		0.198833
  top 1 accuracy:		79.08 %
  top 2 accuracy:		88.50 %
0.13660919666290283
0.11341951787471771
0.12562301754951477
Batch of classes 8 out of 12 batches
Epoch 10 of 30 took 242.119s
  training loss:		0.120056
  validation loss:		0.208587
  top 1 accuracy:		87.63 %
  top 2 accuracy:		90.79 %
0.12257707118988037
0.1173103004693985
0.12150725722312927
Batch of classes 8 out of 12 batches
Epoch 11 of 30 took 239.854s
  training loss:		0.116706
  validation loss:		0.197454
  top 1 accuracy:		98.25 %
  top 2 accuracy:		99.00 %
0.12070925533771515
0.11869153380393982
0.11718198657035828
Batch of classes 8 out of 12 batches
Epoch 12 of 30 took 240.665s
  training loss:		0.115629
  validation loss:		0.200091
  top 1 accuracy:		98.50 %
  top 2 accuracy:		99.06 %
0.11018332093954086
0.12360993027687073
0.10985727608203888
Batch of classes 8 out of 12 batches
Epoch 13 of 30 took 236.135s
  training loss:		0.115407
  validation loss:		0.207420
  top 1 accuracy:		96.79 %
  top 2 accuracy:		97.65 %
0.12213705480098724
0.11752059310674667
0.11561451852321625
Batch of classes 8 out of 12 batches
Epoch 14 of 30 took 236.234s
  training loss:		0.115851
  validation loss:		0.195781
  top 1 accuracy:		97.62 %
  top 2 accuracy:		98.48 %
0.10746502131223679
0.11875971406698227
0.12073910236358643
Batch of classes 8 out of 12 batches
Epoch 15 of 30 took 242.077s
  training loss:		0.116115
  validation loss:		0.203410
  top 1 accuracy:		98.35 %
  top 2 accuracy:		98.87 %
0.10750575363636017
0.1112193912267685
0.12411290407180786
Batch of classes 8 out of 12 batches
Epoch 16 of 30 took 239.516s
  training loss:		0.115576
  validation loss:		0.207449
  top 1 accuracy:		98.65 %
  top 2 accuracy:		99.23 %
0.114158034324646
0.11475067585706711
0.11367611587047577
Batch of classes 8 out of 12 batches
Epoch 17 of 30 took 241.988s
  training loss:		0.115540
  validation loss:		0.196828
  top 1 accuracy:		98.17 %
  top 2 accuracy:		99.06 %
0.11244416236877441
0.11573490500450134
0.1083230972290039
Batch of classes 8 out of 12 batches
Epoch 18 of 30 took 243.275s
  training loss:		0.114674
  validation loss:		0.198239
  top 1 accuracy:		97.33 %
  top 2 accuracy:		98.54 %
0.11120947450399399
0.11557888984680176
0.11496920883655548
Batch of classes 8 out of 12 batches
Epoch 19 of 30 took 242.759s
  training loss:		0.114592
  validation loss:		0.199236
  top 1 accuracy:		97.52 %
  top 2 accuracy:		98.21 %
0.11117836087942123
0.1235511302947998
0.11593755334615707
Batch of classes 8 out of 12 batches
Epoch 20 of 30 took 244.696s
  training loss:		0.115280
  validation loss:		0.208274
  top 1 accuracy:		94.65 %
  top 2 accuracy:		96.52 %
0.10967691987752914
0.11943018436431885
0.11022337526082993
Batch of classes 8 out of 12 batches
Epoch 21 of 30 took 242.592s
  training loss:		0.114207
  validation loss:		0.199364
  top 1 accuracy:		98.12 %
  top 2 accuracy:		98.92 %
0.11850175261497498
0.11178138852119446
0.14534884691238403
Batch of classes 8 out of 12 batches
Epoch 22 of 30 took 242.514s
  training loss:		0.114529
  validation loss:		0.201284
  top 1 accuracy:		98.75 %
  top 2 accuracy:		99.12 %
0.11968690156936646
0.11594659090042114
0.12187492847442627
Batch of classes 8 out of 12 batches
Epoch 23 of 30 took 241.803s
  training loss:		0.114437
  validation loss:		0.193623
  top 1 accuracy:		98.85 %
  top 2 accuracy:		99.27 %
0.12055471539497375
0.10775844752788544
0.1153695210814476
Batch of classes 8 out of 12 batches
Epoch 24 of 30 took 242.286s
  training loss:		0.113686
  validation loss:		0.198730
  top 1 accuracy:		98.98 %
  top 2 accuracy:		99.35 %
0.10841052234172821
0.10524711012840271
0.12030065059661865
Batch of classes 8 out of 12 batches
Epoch 25 of 30 took 240.854s
  training loss:		0.114227
  validation loss:		0.205172
  top 1 accuracy:		98.73 %
  top 2 accuracy:		99.25 %
0.11809831112623215
0.10855179280042648
0.11378580331802368
Batch of classes 8 out of 12 batches
Epoch 26 of 30 took 249.987s
  training loss:		0.113890
  validation loss:		0.202878
  top 1 accuracy:		98.79 %
  top 2 accuracy:		99.06 %
0.12240751832723618
0.11388646066188812
0.11773008108139038
Batch of classes 8 out of 12 batches
Epoch 27 of 30 took 242.885s
  training loss:		0.113696
  validation loss:		0.201648
  top 1 accuracy:		98.17 %
  top 2 accuracy:		98.75 %
0.11168202012777328
0.11258571594953537
0.11512649059295654
Batch of classes 8 out of 12 batches
Epoch 28 of 30 took 245.401s
  training loss:		0.114127
  validation loss:		0.207816
  top 1 accuracy:		97.79 %
  top 2 accuracy:		98.60 %
0.10585930198431015
0.115567147731781
0.122711181640625
Batch of classes 8 out of 12 batches
Epoch 29 of 30 took 249.382s
  training loss:		0.113266
  validation loss:		0.198774
  top 1 accuracy:		99.04 %
  top 2 accuracy:		99.42 %
0.10279031842947006
0.11819779872894287
0.1143682450056076
Batch of classes 8 out of 12 batches
Epoch 30 of 30 took 243.654s
  training loss:		0.113672
  validation loss:		0.198840
  top 1 accuracy:		98.40 %
  top 2 accuracy:		98.94 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		61.80 %
  top 1 accuracy Hybrid 1       :		67.70 %
  top 1 accuracy NCM            :		60.40 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		81.05 %
  top 1 accuracy Hybrid 1       :		75.35 %
  top 1 accuracy NCM            :		81.20 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		57.75 %
  top 1 accuracy Hybrid 1       :		32.75 %
  top 1 accuracy NCM            :		59.62 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		85.12 %
  top 1 accuracy Hybrid 1       :		76.50 %
  top 1 accuracy NCM            :		84.75 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		79.96 %
  top 1 accuracy Hybrid 1       :		56.68 %
  top 1 accuracy NCM            :		80.73 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		89.69 %
  top 1 accuracy Hybrid 1       :		83.21 %
  top 1 accuracy NCM            :		90.08 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		79.43 %
  top 1 accuracy Hybrid 1       :		50.00 %
  top 1 accuracy NCM            :		69.75 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.84 %
  top 1 accuracy Hybrid 1       :		99.76 %
  top 1 accuracy NCM            :		99.84 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		89.65 %
  top 1 accuracy Hybrid 1       :		78.56 %
  top 1 accuracy NCM            :		89.65 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		95.29 %
  top 1 accuracy Hybrid 1       :		94.27 %
  top 1 accuracy NCM            :		95.38 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		68.85 %
  top 1 accuracy Hybrid 1       :		97.88 %
  top 1 accuracy NCM            :		78.57 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.92 %
  top 1 accuracy Hybrid 1       :		99.80 %
  top 1 accuracy NCM            :		99.88 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		71.40 %
  top 1 accuracy Hybrid 1       :		33.69 %
  top 1 accuracy NCM            :		71.50 %
Binary accuracy:
Final results on wild classes:
  top 1 accuracy iCaRL          :		75.28 %
  top 1 accuracy Hybrid 1       :		70.29 %
  top 1 accuracy NCM            :		75.47 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		99.19 %
  top 1 accuracy Hybrid 1       :		98.40 %
  top 1 accuracy NCM            :		99.25 %
Binary accuracy:
Final results on glow classes:
  top 1 accuracy iCaRL          :		99.31 %
  top 1 accuracy Hybrid 1       :		99.50 %
  top 1 accuracy NCM            :		99.38 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		80.04 %
  top 1 accuracy Hybrid 1       :		73.02 %
  top 1 accuracy NCM            :		80.02 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		92.96 %
  top 1 accuracy Hybrid 1       :		90.97 %
  top 1 accuracy NCM            :		93.02 %
Classes in this batch: tensor([16, 17])
Data Size: 7200


Before first epoch
  validation loss:		0.830420
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 9 arrives ...
0.5394259691238403
0.14342623949050903
0.15225279331207275
Batch of classes 9 out of 12 batches
Epoch 1 of 30 took 256.680s
  training loss:		0.177131
  validation loss:		0.384847
  top 1 accuracy:		47.19 %
  top 2 accuracy:		96.85 %
0.14277057349681854
0.14631174504756927
0.13745039701461792
Batch of classes 9 out of 12 batches
Epoch 2 of 30 took 253.313s
  training loss:		0.141246
  validation loss:		0.356153
  top 1 accuracy:		50.77 %
  top 2 accuracy:		94.88 %
0.1365637183189392
0.1403154581785202
0.14945891499519348
Batch of classes 9 out of 12 batches
Epoch 3 of 30 took 249.031s
  training loss:		0.141018
  validation loss:		0.307925
  top 1 accuracy:		60.10 %
  top 2 accuracy:		93.15 %
0.13820791244506836
0.13725343346595764
0.14569948613643646
Batch of classes 9 out of 12 batches
Epoch 4 of 30 took 256.480s
  training loss:		0.139339
  validation loss:		0.335357
  top 1 accuracy:		50.56 %
  top 2 accuracy:		92.23 %
0.13553352653980255
0.1391667127609253
0.14308355748653412
Batch of classes 9 out of 12 batches
Epoch 5 of 30 took 249.297s
  training loss:		0.139151
  validation loss:		0.395572
  top 1 accuracy:		46.06 %
  top 2 accuracy:		94.15 %
0.1506761908531189
0.14900459349155426
0.1370439976453781
Batch of classes 9 out of 12 batches
Epoch 6 of 30 took 248.250s
  training loss:		0.139749
  validation loss:		0.368759
  top 1 accuracy:		53.42 %
  top 2 accuracy:		96.02 %
0.13590744137763977
0.13649119436740875
0.1334465742111206
Batch of classes 9 out of 12 batches
Epoch 7 of 30 took 251.898s
  training loss:		0.139542
  validation loss:		0.386032
  top 1 accuracy:		56.17 %
  top 2 accuracy:		98.17 %
0.13901501893997192
0.14170244336128235
0.12766093015670776
Batch of classes 9 out of 12 batches
Epoch 8 of 30 took 249.351s
  training loss:		0.138622
  validation loss:		0.394455
  top 1 accuracy:		50.79 %
  top 2 accuracy:		95.38 %
0.13755139708518982
0.14125880599021912
0.136164590716362
Batch of classes 9 out of 12 batches
Epoch 9 of 30 took 252.664s
  training loss:		0.138659
  validation loss:		0.420001
  top 1 accuracy:		58.21 %
  top 2 accuracy:		99.10 %
0.13517239689826965
0.13198140263557434
0.13144533336162567
Batch of classes 9 out of 12 batches
Epoch 10 of 30 took 252.903s
  training loss:		0.137756
  validation loss:		0.417597
  top 1 accuracy:		34.40 %
  top 2 accuracy:		80.71 %
0.14238648116588593
0.13607054948806763
0.14312142133712769
Batch of classes 9 out of 12 batches
Epoch 11 of 30 took 253.736s
  training loss:		0.135428
  validation loss:		0.407531
  top 1 accuracy:		69.44 %
  top 2 accuracy:		99.19 %
0.12400936335325241
0.1326526254415512
0.1278819739818573
Batch of classes 9 out of 12 batches
Epoch 12 of 30 took 256.136s
  training loss:		0.134116
  validation loss:		0.382821
  top 1 accuracy:		78.75 %
  top 2 accuracy:		99.00 %
0.1276610791683197
0.13816386461257935
0.13569089770317078
Batch of classes 9 out of 12 batches
Epoch 13 of 30 took 257.039s
  training loss:		0.133927
  validation loss:		0.373739
  top 1 accuracy:		62.27 %
  top 2 accuracy:		90.92 %
0.13315969705581665
0.13889357447624207
0.13096317648887634
Batch of classes 9 out of 12 batches
Epoch 14 of 30 took 259.212s
  training loss:		0.133629
  validation loss:		0.422641
  top 1 accuracy:		78.94 %
  top 2 accuracy:		99.50 %
0.12765981256961823
0.13335540890693665
0.13412195444107056
Batch of classes 9 out of 12 batches
Epoch 15 of 30 took 259.819s
  training loss:		0.133626
  validation loss:		0.363999
  top 1 accuracy:		72.56 %
  top 2 accuracy:		95.79 %
0.12969407439231873
0.12921208143234253
0.13116511702537537
Batch of classes 9 out of 12 batches
Epoch 16 of 30 took 260.203s
  training loss:		0.133112
  validation loss:		0.383289
  top 1 accuracy:		85.02 %
  top 2 accuracy:		99.60 %
0.13843637704849243
0.13189488649368286
0.13932043313980103
Batch of classes 9 out of 12 batches
Epoch 17 of 30 took 261.368s
  training loss:		0.133170
  validation loss:		0.427609
  top 1 accuracy:		72.44 %
  top 2 accuracy:		99.12 %
0.13947734236717224
0.12554579973220825
0.13845422863960266
Batch of classes 9 out of 12 batches
Epoch 18 of 30 took 259.412s
  training loss:		0.133218
  validation loss:		0.371481
  top 1 accuracy:		92.69 %
  top 2 accuracy:		99.35 %
0.13189533352851868
0.1364375203847885
0.1265728622674942
Batch of classes 9 out of 12 batches
Epoch 19 of 30 took 261.584s
  training loss:		0.132937
  validation loss:		0.439888
  top 1 accuracy:		89.71 %
  top 2 accuracy:		99.67 %
0.12447641789913177
0.14014624059200287
0.13094624876976013
Batch of classes 9 out of 12 batches
Epoch 20 of 30 took 259.425s
  training loss:		0.133054
  validation loss:		0.401384
  top 1 accuracy:		94.85 %
  top 2 accuracy:		99.77 %
0.12869805097579956
0.13697542250156403
0.13582740724086761
Batch of classes 9 out of 12 batches
Epoch 21 of 30 took 257.939s
  training loss:		0.132633
  validation loss:		0.394308
  top 1 accuracy:		88.69 %
  top 2 accuracy:		99.58 %
0.13708868622779846
0.12473592162132263
0.13316462934017181
Batch of classes 9 out of 12 batches
Epoch 22 of 30 took 258.646s
  training loss:		0.132515
  validation loss:		0.391629
  top 1 accuracy:		95.67 %
  top 2 accuracy:		99.79 %
0.12889832258224487
0.13107913732528687
0.1385560780763626
Batch of classes 9 out of 12 batches
Epoch 23 of 30 took 261.560s
  training loss:		0.132119
  validation loss:		0.394864
  top 1 accuracy:		92.08 %
  top 2 accuracy:		99.85 %
0.13741791248321533
0.1329265683889389
0.12460808455944061
Batch of classes 9 out of 12 batches
Epoch 24 of 30 took 259.218s
  training loss:		0.132472
  validation loss:		0.388591
  top 1 accuracy:		93.54 %
  top 2 accuracy:		99.73 %
0.12502187490463257
0.14360158145427704
0.12617872655391693
Batch of classes 9 out of 12 batches
Epoch 25 of 30 took 262.932s
  training loss:		0.131980
  validation loss:		0.388535
  top 1 accuracy:		92.79 %
  top 2 accuracy:		99.69 %
0.1343451738357544
0.1253257840871811
0.13721615076065063
Batch of classes 9 out of 12 batches
Epoch 26 of 30 took 266.029s
  training loss:		0.131961
  validation loss:		0.396626
  top 1 accuracy:		92.06 %
  top 2 accuracy:		99.73 %
0.13036935031414032
0.13276535272598267
0.12449359893798828
Batch of classes 9 out of 12 batches
Epoch 27 of 30 took 274.765s
  training loss:		0.131977
  validation loss:		0.388665
  top 1 accuracy:		91.17 %
  top 2 accuracy:		99.67 %
0.13408255577087402
0.1438106745481491
0.12780389189720154
Batch of classes 9 out of 12 batches
Epoch 28 of 30 took 294.325s
  training loss:		0.132001
  validation loss:		0.405818
  top 1 accuracy:		92.71 %
  top 2 accuracy:		99.83 %
0.14123137295246124
0.12489845603704453
0.13312095403671265
Batch of classes 9 out of 12 batches
Epoch 29 of 30 took 300.248s
  training loss:		0.131836
  validation loss:		0.395203
  top 1 accuracy:		94.40 %
  top 2 accuracy:		99.83 %
0.13238762319087982
0.13262411952018738
0.14068154990673065
Batch of classes 9 out of 12 batches
Epoch 30 of 30 took 296.209s
  training loss:		0.131978
  validation loss:		0.412911
  top 1 accuracy:		92.10 %
  top 2 accuracy:		99.83 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		58.80 %
  top 1 accuracy Hybrid 1       :		65.05 %
  top 1 accuracy NCM            :		58.40 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		79.10 %
  top 1 accuracy Hybrid 1       :		73.05 %
  top 1 accuracy NCM            :		78.30 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		54.38 %
  top 1 accuracy Hybrid 1       :		29.25 %
  top 1 accuracy NCM            :		55.62 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		82.12 %
  top 1 accuracy Hybrid 1       :		72.75 %
  top 1 accuracy NCM            :		82.62 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		79.58 %
  top 1 accuracy Hybrid 1       :		49.81 %
  top 1 accuracy NCM            :		80.15 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		88.36 %
  top 1 accuracy Hybrid 1       :		79.39 %
  top 1 accuracy NCM            :		87.98 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		76.61 %
  top 1 accuracy Hybrid 1       :		49.88 %
  top 1 accuracy NCM            :		71.59 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.76 %
  top 1 accuracy Hybrid 1       :		99.61 %
  top 1 accuracy NCM            :		99.73 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		89.09 %
  top 1 accuracy Hybrid 1       :		71.90 %
  top 1 accuracy NCM            :		89.00 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		95.84 %
  top 1 accuracy Hybrid 1       :		93.16 %
  top 1 accuracy NCM            :		95.84 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		72.34 %
  top 1 accuracy Hybrid 1       :		97.02 %
  top 1 accuracy NCM            :		77.31 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.76 %
  top 1 accuracy Hybrid 1       :		99.73 %
  top 1 accuracy NCM            :		99.73 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		69.12 %
  top 1 accuracy Hybrid 1       :		28.45 %
  top 1 accuracy NCM            :		68.98 %
Binary accuracy:
Final results on wild classes:
  top 1 accuracy iCaRL          :		74.55 %
  top 1 accuracy Hybrid 1       :		67.86 %
  top 1 accuracy NCM            :		74.89 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		65.73 %
  top 1 accuracy Hybrid 1       :		54.06 %
  top 1 accuracy NCM            :		73.44 %
Binary accuracy:
Final results on glow classes:
  top 1 accuracy iCaRL          :		99.58 %
  top 1 accuracy Hybrid 1       :		97.21 %
  top 1 accuracy NCM            :		99.56 %
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		83.73 %
  top 1 accuracy Hybrid 1       :		92.10 %
  top 1 accuracy NCM            :		74.77 %
Binary accuracy:
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		99.75 %
  top 1 accuracy Hybrid 1       :		99.33 %
  top 1 accuracy NCM            :		99.67 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		72.70 %
  top 1 accuracy Hybrid 1       :		65.77 %
  top 1 accuracy NCM            :		72.42 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		94.16 %
  top 1 accuracy Hybrid 1       :		91.57 %
  top 1 accuracy NCM            :		94.10 %
Classes in this batch: tensor([18, 19])
Data Size: 7188


Before first epoch
  validation loss:		0.684504
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 10 arrives ...
0.5504399538040161
0.19108609855175018
0.18394258618354797
Batch of classes 10 out of 12 batches
Epoch 1 of 30 took 246.658s
  training loss:		0.213730
  validation loss:		0.278598
  top 1 accuracy:		9.02 %
  top 2 accuracy:		32.46 %
0.1760988086462021
0.1709895133972168
0.16177065670490265
Batch of classes 10 out of 12 batches
Epoch 2 of 30 took 252.069s
  training loss:		0.167158
  validation loss:		0.240349
  top 1 accuracy:		71.01 %
  top 2 accuracy:		83.04 %
0.15775340795516968
0.1463688611984253
0.14233693480491638
Batch of classes 10 out of 12 batches
Epoch 3 of 30 took 247.380s
  training loss:		0.157429
  validation loss:		0.258342
  top 1 accuracy:		68.55 %
  top 2 accuracy:		79.78 %
0.16126923263072968
0.1416492760181427
0.1486542820930481
Batch of classes 10 out of 12 batches
Epoch 4 of 30 took 246.096s
  training loss:		0.155031
  validation loss:		0.240273
  top 1 accuracy:		71.89 %
  top 2 accuracy:		83.21 %
0.14211073517799377
0.14335903525352478
0.1544499397277832
Batch of classes 10 out of 12 batches
Epoch 5 of 30 took 245.191s
  training loss:		0.152173
  validation loss:		0.234288
  top 1 accuracy:		65.91 %
  top 2 accuracy:		78.53 %
0.14511418342590332
0.1415933072566986
0.15288975834846497
Batch of classes 10 out of 12 batches
Epoch 6 of 30 took 245.684s
  training loss:		0.150821
  validation loss:		0.280829
  top 1 accuracy:		65.16 %
  top 2 accuracy:		70.63 %
0.15429562330245972
0.14286231994628906
0.1494380086660385
Batch of classes 10 out of 12 batches
Epoch 7 of 30 took 243.414s
  training loss:		0.150579
  validation loss:		0.236692
  top 1 accuracy:		82.50 %
  top 2 accuracy:		90.35 %
0.15384075045585632
0.14210693538188934
0.1417086124420166
Batch of classes 10 out of 12 batches
Epoch 8 of 30 took 244.576s
  training loss:		0.149838
  validation loss:		0.246525
  top 1 accuracy:		77.23 %
  top 2 accuracy:		86.93 %
0.1472545862197876
0.14729920029640198
0.15183398127555847
Batch of classes 10 out of 12 batches
Epoch 9 of 30 took 248.200s
  training loss:		0.148556
  validation loss:		0.234671
  top 1 accuracy:		79.53 %
  top 2 accuracy:		87.13 %
0.14813731610774994
0.14695724844932556
0.1526288241147995
Batch of classes 10 out of 12 batches
Epoch 10 of 30 took 248.936s
  training loss:		0.147636
  validation loss:		0.241860
  top 1 accuracy:		76.61 %
  top 2 accuracy:		83.17 %
0.1518639624118805
0.1548769772052765
0.13599802553653717
Batch of classes 10 out of 12 batches
Epoch 11 of 30 took 248.931s
  training loss:		0.142351
  validation loss:		0.221800
  top 1 accuracy:		93.44 %
  top 2 accuracy:		96.74 %
0.13417376577854156
0.14635854959487915
0.14198969304561615
Batch of classes 10 out of 12 batches
Epoch 12 of 30 took 246.170s
  training loss:		0.141238
  validation loss:		0.227354
  top 1 accuracy:		92.27 %
  top 2 accuracy:		95.86 %
0.13834507763385773
0.14952456951141357
0.1284264624118805
Batch of classes 10 out of 12 batches
Epoch 13 of 30 took 250.758s
  training loss:		0.140979
  validation loss:		0.227207
  top 1 accuracy:		94.78 %
  top 2 accuracy:		97.28 %
0.14448967576026917
0.12799860537052155
0.13831691443920135
Batch of classes 10 out of 12 batches
Epoch 14 of 30 took 252.152s
  training loss:		0.139453
  validation loss:		0.231139
  top 1 accuracy:		95.20 %
  top 2 accuracy:		97.70 %
0.1373242884874344
0.1411103457212448
0.15338346362113953
Batch of classes 10 out of 12 batches
Epoch 15 of 30 took 252.910s
  training loss:		0.139540
  validation loss:		0.222358
  top 1 accuracy:		95.57 %
  top 2 accuracy:		97.83 %
0.13861969113349915
0.12524312734603882
0.14008519053459167
Batch of classes 10 out of 12 batches
Epoch 16 of 30 took 251.671s
  training loss:		0.139481
  validation loss:		0.222641
  top 1 accuracy:		95.32 %
  top 2 accuracy:		97.91 %
0.14472198486328125
0.14120998978614807
0.14147524535655975
Batch of classes 10 out of 12 batches
Epoch 17 of 30 took 238.175s
  training loss:		0.139359
  validation loss:		0.219503
  top 1 accuracy:		94.82 %
  top 2 accuracy:		96.87 %
0.13355326652526855
0.13990627229213715
0.13935557007789612
Batch of classes 10 out of 12 batches
Epoch 18 of 30 took 243.421s
  training loss:		0.139657
  validation loss:		0.233701
  top 1 accuracy:		93.86 %
  top 2 accuracy:		96.57 %
0.13690416514873505
0.13623829185962677
0.14017310738563538
Batch of classes 10 out of 12 batches
Epoch 19 of 30 took 245.771s
  training loss:		0.139302
  validation loss:		0.230922
  top 1 accuracy:		96.37 %
  top 2 accuracy:		98.08 %
0.13353845477104187
0.12952280044555664
0.13873127102851868
Batch of classes 10 out of 12 batches
Epoch 20 of 30 took 245.647s
  training loss:		0.139083
  validation loss:		0.216112
  top 1 accuracy:		96.53 %
  top 2 accuracy:		97.99 %
0.14369408786296844
0.1427329033613205
0.1277417242527008
Batch of classes 10 out of 12 batches
Epoch 21 of 30 took 251.585s
  training loss:		0.137800
  validation loss:		0.230647
  top 1 accuracy:		96.66 %
  top 2 accuracy:		98.71 %
0.13000795245170593
0.12892644107341766
0.1493869125843048
Batch of classes 10 out of 12 batches
Epoch 22 of 30 took 245.438s
  training loss:		0.137048
  validation loss:		0.228326
  top 1 accuracy:		96.78 %
  top 2 accuracy:		98.33 %
0.1333867758512497
0.13026444613933563
0.14290420711040497
Batch of classes 10 out of 12 batches
Epoch 23 of 30 took 242.794s
  training loss:		0.137038
  validation loss:		0.225562
  top 1 accuracy:		97.24 %
  top 2 accuracy:		98.66 %
0.14059947431087494
0.12773625552654266
0.13430660963058472
Batch of classes 10 out of 12 batches
Epoch 24 of 30 took 241.035s
  training loss:		0.136917
  validation loss:		0.229813
  top 1 accuracy:		95.74 %
  top 2 accuracy:		97.87 %
0.13532209396362305
0.13956193625926971
0.1362236738204956
Batch of classes 10 out of 12 batches
Epoch 25 of 30 took 242.338s
  training loss:		0.136807
  validation loss:		0.230231
  top 1 accuracy:		97.54 %
  top 2 accuracy:		98.54 %
0.13244837522506714
0.12814074754714966
0.14907781779766083
Batch of classes 10 out of 12 batches
Epoch 26 of 30 took 245.584s
  training loss:		0.136888
  validation loss:		0.228957
  top 1 accuracy:		95.61 %
  top 2 accuracy:		97.54 %
0.13103193044662476
0.13496699929237366
0.1358688324689865
Batch of classes 10 out of 12 batches
Epoch 27 of 30 took 246.206s
  training loss:		0.136775
  validation loss:		0.224623
  top 1 accuracy:		97.37 %
  top 2 accuracy:		98.62 %
0.13860566914081573
0.13757547736167908
0.15205197036266327
Batch of classes 10 out of 12 batches
Epoch 28 of 30 took 248.358s
  training loss:		0.136873
  validation loss:		0.221990
  top 1 accuracy:		97.58 %
  top 2 accuracy:		98.87 %
0.1358858197927475
0.1268787682056427
0.14383555948734283
Batch of classes 10 out of 12 batches
Epoch 29 of 30 took 246.934s
  training loss:		0.136819
  validation loss:		0.231149
  top 1 accuracy:		96.87 %
  top 2 accuracy:		98.16 %
0.14556121826171875
0.13129501044750214
0.13647620379924774
Batch of classes 10 out of 12 batches
Epoch 30 of 30 took 246.739s
  training loss:		0.136648
  validation loss:		0.225948
  top 1 accuracy:		97.28 %
  top 2 accuracy:		98.75 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		52.65 %
  top 1 accuracy Hybrid 1       :		59.95 %
  top 1 accuracy NCM            :		52.15 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		74.20 %
  top 1 accuracy Hybrid 1       :		69.80 %
  top 1 accuracy NCM            :		72.65 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		41.75 %
  top 1 accuracy Hybrid 1       :		22.12 %
  top 1 accuracy NCM            :		39.75 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		82.50 %
  top 1 accuracy Hybrid 1       :		70.12 %
  top 1 accuracy NCM            :		80.88 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		75.57 %
  top 1 accuracy Hybrid 1       :		48.85 %
  top 1 accuracy NCM            :		76.91 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		87.40 %
  top 1 accuracy Hybrid 1       :		79.39 %
  top 1 accuracy NCM            :		87.98 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		77.08 %
  top 1 accuracy Hybrid 1       :		49.80 %
  top 1 accuracy NCM            :		68.93 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.14 %
  top 1 accuracy Hybrid 1       :		98.94 %
  top 1 accuracy NCM            :		99.14 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		88.45 %
  top 1 accuracy Hybrid 1       :		68.58 %
  top 1 accuracy NCM            :		88.45 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		95.29 %
  top 1 accuracy Hybrid 1       :		94.27 %
  top 1 accuracy NCM            :		95.10 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		71.71 %
  top 1 accuracy Hybrid 1       :		94.63 %
  top 1 accuracy NCM            :		79.94 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.18 %
  top 1 accuracy Hybrid 1       :		99.14 %
  top 1 accuracy NCM            :		99.14 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		64.18 %
  top 1 accuracy Hybrid 1       :		25.16 %
  top 1 accuracy NCM            :		64.66 %
Binary accuracy:
Final results on wild classes:
  top 1 accuracy iCaRL          :		73.15 %
  top 1 accuracy Hybrid 1       :		66.36 %
  top 1 accuracy NCM            :		73.68 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		67.00 %
  top 1 accuracy Hybrid 1       :		82.75 %
  top 1 accuracy NCM            :		69.17 %
Binary accuracy:
Final results on glow classes:
  top 1 accuracy iCaRL          :		98.19 %
  top 1 accuracy Hybrid 1       :		98.58 %
  top 1 accuracy NCM            :		98.19 %
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		81.44 %
  top 1 accuracy Hybrid 1       :		63.58 %
  top 1 accuracy NCM            :		78.46 %
Binary accuracy:
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		98.21 %
  top 1 accuracy Hybrid 1       :		98.50 %
  top 1 accuracy NCM            :		98.19 %
Final results on stylegan classes:
  top 1 accuracy iCaRL          :		98.91 %
  top 1 accuracy Hybrid 1       :		97.28 %
  top 1 accuracy NCM            :		98.79 %
Binary accuracy:
Final results on stylegan classes:
  top 1 accuracy iCaRL          :		99.46 %
  top 1 accuracy Hybrid 1       :		98.83 %
  top 1 accuracy NCM            :		99.46 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		73.64 %
  top 1 accuracy Hybrid 1       :		67.60 %
  top 1 accuracy NCM            :		73.43 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		93.40 %
  top 1 accuracy Hybrid 1       :		91.84 %
  top 1 accuracy NCM            :		93.25 %
Classes in this batch: tensor([20, 21])
Data Size: 1200


Before first epoch
  validation loss:		0.795558
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 11 arrives ...
0.30135539174079895
Batch of classes 11 out of 12 batches
Epoch 1 of 30 took 102.174s
  training loss:		0.215341
  validation loss:		0.428435
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
0.18250730633735657
Batch of classes 11 out of 12 batches
Epoch 2 of 30 took 78.184s
  training loss:		0.178577
  validation loss:		0.368990
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
0.1777953803539276
Batch of classes 11 out of 12 batches
Epoch 3 of 30 took 84.644s
  training loss:		0.175172
  validation loss:		0.416076
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.75 %
0.1454678773880005
Batch of classes 11 out of 12 batches
Epoch 4 of 30 took 88.758s
  training loss:		0.170736
  validation loss:		0.413905
  top 1 accuracy:		5.50 %
  top 2 accuracy:		10.75 %
0.15187150239944458
Batch of classes 11 out of 12 batches
Epoch 5 of 30 took 74.859s
  training loss:		0.168391
  validation loss:		0.422984
  top 1 accuracy:		26.75 %
  top 2 accuracy:		39.00 %
0.17028729617595673
Batch of classes 11 out of 12 batches
Epoch 6 of 30 took 63.448s
  training loss:		0.165108
  validation loss:		0.374903
  top 1 accuracy:		41.25 %
  top 2 accuracy:		48.50 %
0.16303318738937378
Batch of classes 11 out of 12 batches
Epoch 7 of 30 took 56.724s
  training loss:		0.164786
  validation loss:		0.449076
  top 1 accuracy:		46.50 %
  top 2 accuracy:		50.25 %
0.15558086335659027
Batch of classes 11 out of 12 batches
Epoch 8 of 30 took 69.970s
  training loss:		0.163308
  validation loss:		0.404965
  top 1 accuracy:		32.25 %
  top 2 accuracy:		40.50 %
0.1817241907119751
Batch of classes 11 out of 12 batches
Epoch 9 of 30 took 67.760s
  training loss:		0.163312
  validation loss:		0.410166
  top 1 accuracy:		42.25 %
  top 2 accuracy:		49.75 %
0.16879022121429443
Batch of classes 11 out of 12 batches
Epoch 10 of 30 took 69.953s
  training loss:		0.161355
  validation loss:		0.422348
  top 1 accuracy:		50.25 %
  top 2 accuracy:		51.75 %
0.1725875735282898
Batch of classes 11 out of 12 batches
Epoch 11 of 30 took 71.450s
  training loss:		0.157256
  validation loss:		0.387411
  top 1 accuracy:		66.25 %
  top 2 accuracy:		72.25 %
0.1535596251487732
Batch of classes 11 out of 12 batches
Epoch 12 of 30 took 84.714s
  training loss:		0.152482
  validation loss:		0.408329
  top 1 accuracy:		70.75 %
  top 2 accuracy:		75.75 %
0.1621149778366089
Batch of classes 11 out of 12 batches
Epoch 13 of 30 took 86.761s
  training loss:		0.152308
  validation loss:		0.381924
  top 1 accuracy:		69.25 %
  top 2 accuracy:		74.50 %
0.14705327153205872
Batch of classes 11 out of 12 batches
Epoch 14 of 30 took 81.787s
  training loss:		0.152268
  validation loss:		0.382938
  top 1 accuracy:		71.00 %
  top 2 accuracy:		75.00 %
0.13437609374523163
Batch of classes 11 out of 12 batches
Epoch 15 of 30 took 85.818s
  training loss:		0.151162
  validation loss:		0.377773
  top 1 accuracy:		71.75 %
  top 2 accuracy:		76.00 %
0.14939343929290771
Batch of classes 11 out of 12 batches
Epoch 16 of 30 took 77.679s
  training loss:		0.151111
  validation loss:		0.367187
  top 1 accuracy:		77.50 %
  top 2 accuracy:		81.75 %
0.15786564350128174
Batch of classes 11 out of 12 batches
Epoch 17 of 30 took 83.327s
  training loss:		0.151986
  validation loss:		0.372488
  top 1 accuracy:		74.50 %
  top 2 accuracy:		78.50 %
0.15431907773017883
Batch of classes 11 out of 12 batches
Epoch 18 of 30 took 90.936s
  training loss:		0.150413
  validation loss:		0.375781
  top 1 accuracy:		72.75 %
  top 2 accuracy:		76.00 %
0.15791064500808716
Batch of classes 11 out of 12 batches
Epoch 19 of 30 took 90.559s
  training loss:		0.150286
  validation loss:		0.393559
  top 1 accuracy:		73.00 %
  top 2 accuracy:		76.00 %
0.14917564392089844
Batch of classes 11 out of 12 batches
Epoch 20 of 30 took 92.184s
  training loss:		0.151043
  validation loss:		0.366112
  top 1 accuracy:		75.50 %
  top 2 accuracy:		80.00 %
0.14736786484718323
Batch of classes 11 out of 12 batches
Epoch 21 of 30 took 94.819s
  training loss:		0.149571
  validation loss:		0.379514
  top 1 accuracy:		79.75 %
  top 2 accuracy:		81.75 %
0.14012834429740906
Batch of classes 11 out of 12 batches
Epoch 22 of 30 took 85.823s
  training loss:		0.148630
  validation loss:		0.382092
  top 1 accuracy:		75.50 %
  top 2 accuracy:		79.00 %
0.1358601152896881
Batch of classes 11 out of 12 batches
Epoch 23 of 30 took 86.793s
  training loss:		0.148218
  validation loss:		0.380671
  top 1 accuracy:		78.00 %
  top 2 accuracy:		82.25 %
0.14545542001724243
Batch of classes 11 out of 12 batches
Epoch 24 of 30 took 93.099s
  training loss:		0.148616
  validation loss:		0.390410
  top 1 accuracy:		78.75 %
  top 2 accuracy:		81.50 %
0.16305217146873474
Batch of classes 11 out of 12 batches
Epoch 25 of 30 took 76.338s
  training loss:		0.147494
  validation loss:		0.404130
  top 1 accuracy:		78.25 %
  top 2 accuracy:		82.25 %
0.14880090951919556
Batch of classes 11 out of 12 batches
Epoch 26 of 30 took 85.076s
  training loss:		0.147489
  validation loss:		0.378706
  top 1 accuracy:		79.75 %
  top 2 accuracy:		81.25 %
0.1504020094871521
Batch of classes 11 out of 12 batches
Epoch 27 of 30 took 62.177s
  training loss:		0.147588
  validation loss:		0.381078
  top 1 accuracy:		78.50 %
  top 2 accuracy:		81.75 %
0.1492815613746643
Batch of classes 11 out of 12 batches
Epoch 28 of 30 took 54.438s
  training loss:		0.148375
  validation loss:		0.390151
  top 1 accuracy:		80.00 %
  top 2 accuracy:		83.25 %
0.15058669447898865
Batch of classes 11 out of 12 batches
Epoch 29 of 30 took 57.622s
  training loss:		0.147611
  validation loss:		0.380667
  top 1 accuracy:		78.00 %
  top 2 accuracy:		81.00 %
0.16186615824699402
Batch of classes 11 out of 12 batches
Epoch 30 of 30 took 56.707s
  training loss:		0.147330
  validation loss:		0.378208
  top 1 accuracy:		78.75 %
  top 2 accuracy:		83.25 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		50.65 %
  top 1 accuracy Hybrid 1       :		60.10 %
  top 1 accuracy NCM            :		49.25 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		72.20 %
  top 1 accuracy Hybrid 1       :		67.85 %
  top 1 accuracy NCM            :		71.90 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		34.00 %
  top 1 accuracy Hybrid 1       :		21.75 %
  top 1 accuracy NCM            :		36.75 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		77.75 %
  top 1 accuracy Hybrid 1       :		69.75 %
  top 1 accuracy NCM            :		76.00 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		75.95 %
  top 1 accuracy Hybrid 1       :		49.81 %
  top 1 accuracy NCM            :		78.63 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		87.02 %
  top 1 accuracy Hybrid 1       :		78.82 %
  top 1 accuracy NCM            :		88.74 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		75.31 %
  top 1 accuracy Hybrid 1       :		49.76 %
  top 1 accuracy NCM            :		73.35 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.57 %
  top 1 accuracy Hybrid 1       :		99.22 %
  top 1 accuracy NCM            :		99.45 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		89.65 %
  top 1 accuracy Hybrid 1       :		64.97 %
  top 1 accuracy NCM            :		89.46 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		95.38 %
  top 1 accuracy Hybrid 1       :		94.18 %
  top 1 accuracy NCM            :		95.10 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		73.47 %
  top 1 accuracy Hybrid 1       :		95.57 %
  top 1 accuracy NCM            :		75.39 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.69 %
  top 1 accuracy Hybrid 1       :		99.61 %
  top 1 accuracy NCM            :		99.57 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		63.94 %
  top 1 accuracy Hybrid 1       :		21.33 %
  top 1 accuracy NCM            :		63.16 %
Binary accuracy:
Final results on wild classes:
  top 1 accuracy iCaRL          :		72.47 %
  top 1 accuracy Hybrid 1       :		64.57 %
  top 1 accuracy NCM            :		71.93 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		75.52 %
  top 1 accuracy Hybrid 1       :		74.60 %
  top 1 accuracy NCM            :		72.38 %
Binary accuracy:
Final results on glow classes:
  top 1 accuracy iCaRL          :		98.69 %
  top 1 accuracy Hybrid 1       :		98.77 %
  top 1 accuracy NCM            :		98.56 %
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		73.17 %
  top 1 accuracy Hybrid 1       :		71.10 %
  top 1 accuracy NCM            :		74.46 %
Binary accuracy:
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		98.54 %
  top 1 accuracy Hybrid 1       :		98.38 %
  top 1 accuracy NCM            :		98.46 %
Final results on stylegan classes:
  top 1 accuracy iCaRL          :		96.07 %
  top 1 accuracy Hybrid 1       :		82.46 %
  top 1 accuracy NCM            :		96.12 %
Binary accuracy:
Final results on stylegan classes:
  top 1 accuracy iCaRL          :		97.54 %
  top 1 accuracy Hybrid 1       :		92.90 %
  top 1 accuracy NCM            :		97.54 %
Final results on whichfaceisreal classes:
  top 1 accuracy iCaRL          :		94.75 %
  top 1 accuracy Hybrid 1       :		78.75 %
  top 1 accuracy NCM            :		94.75 %
Binary accuracy:
Final results on whichfaceisreal classes:
  top 1 accuracy iCaRL          :		94.75 %
  top 1 accuracy Hybrid 1       :		89.50 %
  top 1 accuracy NCM            :		94.75 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		73.37 %
  top 1 accuracy Hybrid 1       :		65.81 %
  top 1 accuracy NCM            :		72.96 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		93.11 %
  top 1 accuracy Hybrid 1       :		90.95 %
  top 1 accuracy NCM            :		92.94 %
Classes in this batch: tensor([22, 23])
Data Size: 260


Before first epoch
  validation loss:		0.864488
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 12 arrives ...
0.23436424136161804
Batch of classes 12 out of 12 batches
Epoch 1 of 30 took 19.392s
  training loss:		0.173041
  validation loss:		0.444437
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
0.15265043079853058
Batch of classes 12 out of 12 batches
Epoch 2 of 30 took 17.767s
  training loss:		0.157021
  validation loss:		0.408046
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
0.16088412702083588
Batch of classes 12 out of 12 batches
Epoch 3 of 30 took 17.922s
  training loss:		0.155840
  validation loss:		0.445056
  top 1 accuracy:		0.00 %
  top 2 accuracy:		1.11 %
0.1397228240966797
Batch of classes 12 out of 12 batches
Epoch 4 of 30 took 17.973s
  training loss:		0.151481
  validation loss:		0.438235
  top 1 accuracy:		0.00 %
  top 2 accuracy:		1.11 %
0.15005086362361908
Batch of classes 12 out of 12 batches
Epoch 5 of 30 took 18.074s
  training loss:		0.149198
  validation loss:		0.408714
  top 1 accuracy:		0.00 %
  top 2 accuracy:		3.33 %
0.13999633491039276
Batch of classes 12 out of 12 batches
Epoch 6 of 30 took 18.170s
  training loss:		0.149339
  validation loss:		0.435417
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
0.14405235648155212
Batch of classes 12 out of 12 batches
Epoch 7 of 30 took 17.799s
  training loss:		0.145946
  validation loss:		0.418756
  top 1 accuracy:		0.00 %
  top 2 accuracy:		3.33 %
0.14670735597610474
Batch of classes 12 out of 12 batches
Epoch 8 of 30 took 17.857s
  training loss:		0.146309
  validation loss:		0.396037
  top 1 accuracy:		3.33 %
  top 2 accuracy:		13.33 %
0.15691226720809937
Batch of classes 12 out of 12 batches
Epoch 9 of 30 took 18.091s
  training loss:		0.146738
  validation loss:		0.425100
  top 1 accuracy:		0.00 %
  top 2 accuracy:		7.78 %
0.13283708691596985
Batch of classes 12 out of 12 batches
Epoch 10 of 30 took 17.921s
  training loss:		0.147731
  validation loss:		0.397057
  top 1 accuracy:		2.22 %
  top 2 accuracy:		17.78 %
0.13849318027496338
Batch of classes 12 out of 12 batches
Epoch 11 of 30 took 17.724s
  training loss:		0.143103
  validation loss:		0.401617
  top 1 accuracy:		1.11 %
  top 2 accuracy:		13.33 %
0.13798891007900238
Batch of classes 12 out of 12 batches
Epoch 12 of 30 took 17.981s
  training loss:		0.140527
  validation loss:		0.413996
  top 1 accuracy:		2.22 %
  top 2 accuracy:		12.22 %
0.14983288943767548
Batch of classes 12 out of 12 batches
Epoch 13 of 30 took 18.223s
  training loss:		0.141384
  validation loss:		0.408778
  top 1 accuracy:		3.33 %
  top 2 accuracy:		15.56 %
0.14320062100887299
Batch of classes 12 out of 12 batches
Epoch 14 of 30 took 18.050s
  training loss:		0.140587
  validation loss:		0.399620
  top 1 accuracy:		6.67 %
  top 2 accuracy:		16.67 %
0.14289401471614838
Batch of classes 12 out of 12 batches
Epoch 15 of 30 took 17.753s
  training loss:		0.139714
  validation loss:		0.412778
  top 1 accuracy:		5.56 %
  top 2 accuracy:		20.00 %
0.13296645879745483
Batch of classes 12 out of 12 batches
Epoch 16 of 30 took 17.941s
  training loss:		0.139357
  validation loss:		0.408276
  top 1 accuracy:		4.44 %
  top 2 accuracy:		17.78 %
0.12932872772216797
Batch of classes 12 out of 12 batches
Epoch 17 of 30 took 18.194s
  training loss:		0.140091
  validation loss:		0.415705
  top 1 accuracy:		4.44 %
  top 2 accuracy:		17.78 %
0.1333175152540207
Batch of classes 12 out of 12 batches
Epoch 18 of 30 took 17.940s
  training loss:		0.139808
  validation loss:		0.414157
  top 1 accuracy:		10.00 %
  top 2 accuracy:		23.33 %
0.13019691407680511
Batch of classes 12 out of 12 batches
Epoch 19 of 30 took 18.101s
  training loss:		0.138888
  validation loss:		0.407835
  top 1 accuracy:		6.67 %
  top 2 accuracy:		17.78 %
0.1571130007505417
Batch of classes 12 out of 12 batches
Epoch 20 of 30 took 17.958s
  training loss:		0.138485
  validation loss:		0.406682
  top 1 accuracy:		10.00 %
  top 2 accuracy:		23.33 %
0.140211284160614
Batch of classes 12 out of 12 batches
Epoch 21 of 30 took 17.725s
  training loss:		0.138122
  validation loss:		0.414303
  top 1 accuracy:		5.56 %
  top 2 accuracy:		18.89 %
0.13658586144447327
Batch of classes 12 out of 12 batches
Epoch 22 of 30 took 17.799s
  training loss:		0.137535
  validation loss:		0.398671
  top 1 accuracy:		5.56 %
  top 2 accuracy:		15.56 %
0.14348486065864563
Batch of classes 12 out of 12 batches
Epoch 23 of 30 took 17.859s
  training loss:		0.137613
  validation loss:		0.409313
  top 1 accuracy:		7.78 %
  top 2 accuracy:		20.00 %
0.14837923645973206
Batch of classes 12 out of 12 batches
Epoch 24 of 30 took 17.904s
  training loss:		0.138463
  validation loss:		0.410959
  top 1 accuracy:		3.33 %
  top 2 accuracy:		16.67 %
0.13173086941242218
Batch of classes 12 out of 12 batches
Epoch 25 of 30 took 17.780s
  training loss:		0.137126
  validation loss:		0.410885
  top 1 accuracy:		8.89 %
  top 2 accuracy:		21.11 %
0.14060063660144806
Batch of classes 12 out of 12 batches
Epoch 26 of 30 took 18.283s
  training loss:		0.137746
  validation loss:		0.413150
  top 1 accuracy:		6.67 %
  top 2 accuracy:		17.78 %
0.1470624804496765
Batch of classes 12 out of 12 batches
Epoch 27 of 30 took 18.178s
  training loss:		0.136931
  validation loss:		0.413125
  top 1 accuracy:		10.00 %
  top 2 accuracy:		21.11 %
0.14766532182693481
Batch of classes 12 out of 12 batches
Epoch 28 of 30 took 18.022s
  training loss:		0.138052
  validation loss:		0.403059
  top 1 accuracy:		10.00 %
  top 2 accuracy:		21.11 %
0.13138267397880554
Batch of classes 12 out of 12 batches
Epoch 29 of 30 took 18.192s
  training loss:		0.137235
  validation loss:		0.403474
  top 1 accuracy:		5.56 %
  top 2 accuracy:		16.67 %
0.14241033792495728
Batch of classes 12 out of 12 batches
Epoch 30 of 30 took 17.824s
  training loss:		0.137227
  validation loss:		0.411816
  top 1 accuracy:		8.89 %
  top 2 accuracy:		18.89 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		43.80 %
  top 1 accuracy Hybrid 1       :		59.95 %
  top 1 accuracy NCM            :		41.20 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		68.85 %
  top 1 accuracy Hybrid 1       :		67.50 %
  top 1 accuracy NCM            :		69.20 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		36.38 %
  top 1 accuracy Hybrid 1       :		18.00 %
  top 1 accuracy NCM            :		41.38 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		73.12 %
  top 1 accuracy Hybrid 1       :		66.25 %
  top 1 accuracy NCM            :		74.12 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		71.95 %
  top 1 accuracy Hybrid 1       :		47.71 %
  top 1 accuracy NCM            :		74.81 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		86.45 %
  top 1 accuracy Hybrid 1       :		78.24 %
  top 1 accuracy NCM            :		88.36 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		73.35 %
  top 1 accuracy Hybrid 1       :		50.27 %
  top 1 accuracy NCM            :		69.67 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.49 %
  top 1 accuracy Hybrid 1       :		99.53 %
  top 1 accuracy NCM            :		99.45 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		89.19 %
  top 1 accuracy Hybrid 1       :		64.60 %
  top 1 accuracy NCM            :		89.28 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		94.55 %
  top 1 accuracy Hybrid 1       :		92.42 %
  top 1 accuracy NCM            :		94.82 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		75.51 %
  top 1 accuracy Hybrid 1       :		95.73 %
  top 1 accuracy NCM            :		79.11 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.65 %
  top 1 accuracy Hybrid 1       :		99.73 %
  top 1 accuracy NCM            :		99.65 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		63.94 %
  top 1 accuracy Hybrid 1       :		21.13 %
  top 1 accuracy NCM            :		63.50 %
Binary accuracy:
Final results on wild classes:
  top 1 accuracy iCaRL          :		70.09 %
  top 1 accuracy Hybrid 1       :		64.61 %
  top 1 accuracy NCM            :		70.63 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		76.33 %
  top 1 accuracy Hybrid 1       :		78.42 %
  top 1 accuracy NCM            :		75.67 %
Binary accuracy:
Final results on glow classes:
  top 1 accuracy iCaRL          :		98.65 %
  top 1 accuracy Hybrid 1       :		98.69 %
  top 1 accuracy NCM            :		98.69 %
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		72.06 %
  top 1 accuracy Hybrid 1       :		65.83 %
  top 1 accuracy NCM            :		72.19 %
Binary accuracy:
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		98.60 %
  top 1 accuracy Hybrid 1       :		97.23 %
  top 1 accuracy NCM            :		98.73 %
Final results on stylegan classes:
  top 1 accuracy iCaRL          :		84.00 %
  top 1 accuracy Hybrid 1       :		66.83 %
  top 1 accuracy NCM            :		85.46 %
Binary accuracy:
Final results on stylegan classes:
  top 1 accuracy iCaRL          :		93.36 %
  top 1 accuracy Hybrid 1       :		86.05 %
  top 1 accuracy NCM            :		93.69 %
Final results on whichfaceisreal classes:
  top 1 accuracy iCaRL          :		92.00 %
  top 1 accuracy Hybrid 1       :		64.50 %
  top 1 accuracy NCM            :		91.50 %
Binary accuracy:
Final results on whichfaceisreal classes:
  top 1 accuracy iCaRL          :		92.25 %
  top 1 accuracy Hybrid 1       :		85.25 %
  top 1 accuracy NCM            :		91.75 %
Final results on san classes:
  top 1 accuracy iCaRL          :		47.78 %
  top 1 accuracy Hybrid 1       :		8.89 %
  top 1 accuracy NCM            :		46.67 %
Binary accuracy:
Final results on san classes:
  top 1 accuracy iCaRL          :		71.11 %
  top 1 accuracy Hybrid 1       :		54.44 %
  top 1 accuracy NCM            :		71.11 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		71.38 %
  top 1 accuracy Hybrid 1       :		63.37 %
  top 1 accuracy NCM            :		71.38 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		91.87 %
  top 1 accuracy Hybrid 1       :		89.63 %
  top 1 accuracy NCM            :		92.09 %
tensor([[[ 99.4500,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 99.2500,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 99.4500,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 97.3500,  99.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 97.9000,  98.8750,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 97.2500,  99.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 96.5500,  97.6250,  98.8550,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 97.0000,  97.6250,  96.7557,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 96.8500,  97.8750,  98.8550,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 96.6500,  96.3750,  97.5191, 100.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 95.6000,  96.2500,  93.7023,  99.9216,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 96.9500,  96.3750,  97.3282, 100.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 92.2000,  94.8750,  96.7557,  99.9608,  96.6728,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 89.9000,  92.7500,  88.7405,  99.9608,  96.7653,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 92.9500,  94.7500,  96.5649,  99.9608,  96.6728,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 90.8500,  91.6250,  95.8015,  99.9608,  96.8577,  99.9608,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 84.6000,  89.7500,  87.5954,  99.8433,  96.8577,  99.9608,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 90.7000,  90.8750,  95.8015,  99.9608,  96.7653,  99.9608,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 82.4000,  85.7500,  92.9389,  99.8433,  94.1775,  99.8433,  78.5264,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 78.0500,  78.6250,  85.1145,  99.6082,  95.2865,  99.7649,  75.1333,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 82.5000,  86.0000,  92.9389,  99.8041,  94.2699,  99.8041,  78.8173,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 81.0500,  85.1250,  89.6947,  99.8433,  95.2865,  99.9216,  75.2787,
           99.3125,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 75.3500,  76.5000,  83.2061,  99.7649,  94.2699,  99.8041,  70.2860,
           99.5000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 81.2000,  84.7500,  90.0763,  99.8433,  95.3789,  99.8824,  75.4726,
           99.3750,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 79.1000,  82.1250,  88.3588,  99.7649,  95.8410,  99.7649,  74.5516,
           99.5833,  99.7500,   0.0000,   0.0000,   0.0000],
         [ 73.0500,  72.7500,  79.3893,  99.6082,  93.1608,  99.7257,  67.8623,
           97.2083,  99.3333,   0.0000,   0.0000,   0.0000],
         [ 78.3000,  82.6250,  87.9771,  99.7257,  95.8410,  99.7257,  74.8909,
           99.5625,  99.6667,   0.0000,   0.0000,   0.0000]],

        [[ 74.2000,  82.5000,  87.4046,  99.1379,  95.2865,  99.1771,  73.1459,
           98.1875,  98.2083,  99.4570,   0.0000,   0.0000],
         [ 69.8000,  70.1250,  79.3893,  98.9420,  94.2699,  99.1379,  66.3597,
           98.5833,  98.5000,  98.8304,   0.0000,   0.0000],
         [ 72.6500,  80.8750,  87.9771,  99.1379,  95.1017,  99.1379,  73.6791,
           98.1875,  98.1875,  99.4570,   0.0000,   0.0000]],

        [[ 72.2000,  77.7500,  87.0229,  99.5690,  95.3789,  99.6865,  72.4673,
           98.6875,  98.5417,  97.5355,  94.7500,   0.0000],
         [ 67.8500,  69.7500,  78.8168,  99.2163,  94.1775,  99.6082,  64.5662,
           98.7708,  98.3750,  92.8989,  89.5000,   0.0000],
         [ 71.9000,  76.0000,  88.7405,  99.4514,  95.1017,  99.5690,  71.9341,
           98.5625,  98.4583,  97.5355,  94.7500,   0.0000]],

        [[ 68.8500,  73.1250,  86.4504,  99.4906,  94.5471,  99.6473,  70.0921,
           98.6458,  98.6042,  93.3584,  92.2500,  71.1111],
         [ 67.5000,  66.2500,  78.2443,  99.5298,  92.4214,  99.7257,  64.6146,
           98.6875,  97.2292,  86.0485,  85.2500,  54.4444],
         [ 69.2000,  74.1250,  88.3588,  99.4514,  94.8244,  99.6473,  70.6253,
           98.6875,  98.7292,  93.6926,  91.7500,  71.1111]]])
tensor([87.1810, 82.4954, 87.5169])
----------------- Options ---------------
               add_binary: False                         
               batch_size: 32                            	[default: 64]
                   binary: True                          	[default: False]
              binary_loss: sum_b_sig                     
            binary_weight: 0.5                           
                blur_prob: 0                             
                 blur_sig: 0.5                           
          checkpoints_dir: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL/checkpoints	[default: ./checkpoints]
                class_bal: False                         
           continue_train: False                         
                 cropSize: 224                           
                 data_aug: False                         
                 dataroot: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/test	[default: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL]
          earlystop_epoch: 5                             
                    epoch: latest                        
                 fine_tun: False                         
                    gpuid: [1]                           
                init_gain: 0.02                          
                  init_lr: 0.0005                        
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2                           
                 jpg_prob: 0                             
                 jpg_qual: 75                            
          label_smoothing: False                         
                 loadSize: 256                           
                    mixup: False                         
              mixup_alpha: 0.1                           
                     mode: binary                        
               model_name: resnet18                      
               model_type: resnet                        
            model_weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth	[default: None]
               multiclass: [0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0]	[default: [1]]
                     name: icarl_df_12_binary_15         	[default: experiment_name]
                  no_flip: False                         
              num_classes: 2                             
               num_epochs: 30                            	[default: 12]
              num_threads: 4                             
                  outfile: temp_0.1.csv                  
            pretrain_name:                               
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 20                            
         save_latest_freq: 2000                          
                 schedule: [10, 20, 30]                  	[default: [10]]
           serial_batches: False                         
          smoothing_alpha: 0.1                           
                   suffix:                               
                task_name: gaugan,biggan,cyclegan,imle,deepfake,crn,wild,glow,stargan_gf,stylegan,whichfaceisreal,san	[default: ]
              train_split: train                         
                val_split: val                           
----------------- End -------------------
{'All': 24}
Task order: ['gaugan', 'biggan', 'cyclegan', 'imle', 'deepfake', 'crn', 'wild', 'glow', 'stargan_gf', 'stylegan', 'whichfaceisreal', 'san']
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Classes in this batch: tensor([0, 1])
Data Size: 6000


Before first epoch
  validation loss:		4.725966
  top 1 accuracy:		75.00 %
Batch of classes number 1 arrives ...
18.556678771972656
0.5927494764328003
Batch of classes 1 out of 12 batches
Epoch 1 of 30 took 144.765s
  training loss:		0.982644
  validation loss:		0.307004
  top 1 accuracy:		87.50 %
0.35985833406448364
0.3855288326740265
Batch of classes 1 out of 12 batches
Epoch 2 of 30 took 99.589s
  training loss:		0.262298
  validation loss:		0.211894
  top 1 accuracy:		100.00 %
0.18176500499248505
0.1660938262939453
Batch of classes 1 out of 12 batches
Epoch 3 of 30 took 53.679s
  training loss:		0.173518
  validation loss:		0.283894
  top 1 accuracy:		68.75 %
0.07713328301906586
0.06431545317173004
Batch of classes 1 out of 12 batches
Epoch 4 of 30 took 47.282s
  training loss:		0.134098
  validation loss:		0.213576
  top 1 accuracy:		87.50 %
0.08055558055639267
0.07161139696836472
Batch of classes 1 out of 12 batches
Epoch 5 of 30 took 47.813s
  training loss:		0.119489
  validation loss:		0.179473
  top 1 accuracy:		93.75 %
0.0706615149974823
0.06108611449599266
Batch of classes 1 out of 12 batches
Epoch 6 of 30 took 49.775s
  training loss:		0.129910
  validation loss:		0.647930
  top 1 accuracy:		43.75 %
0.23865729570388794
0.03754430264234543
Batch of classes 1 out of 12 batches
Epoch 7 of 30 took 47.541s
  training loss:		0.097589
  validation loss:		0.152048
  top 1 accuracy:		93.75 %
0.03646177053451538
0.08763263374567032
Batch of classes 1 out of 12 batches
Epoch 8 of 30 took 46.343s
  training loss:		0.095332
  validation loss:		0.187975
  top 1 accuracy:		81.25 %
0.08067090809345245
0.17218923568725586
Batch of classes 1 out of 12 batches
Epoch 9 of 30 took 47.735s
  training loss:		0.083402
  validation loss:		0.280895
  top 1 accuracy:		100.00 %
0.047905076295137405
0.1208859235048294
Batch of classes 1 out of 12 batches
Epoch 10 of 30 took 49.562s
  training loss:		0.093824
  validation loss:		0.109261
  top 1 accuracy:		100.00 %
0.033569805324077606
0.010455052368342876
Batch of classes 1 out of 12 batches
Epoch 11 of 30 took 47.648s
  training loss:		0.029192
  validation loss:		0.027054
  top 1 accuracy:		100.00 %
0.00395924923941493
0.03357924893498421
Batch of classes 1 out of 12 batches
Epoch 12 of 30 took 47.116s
  training loss:		0.018633
  validation loss:		0.029423
  top 1 accuracy:		100.00 %
0.006018978543579578
0.00871437881141901
Batch of classes 1 out of 12 batches
Epoch 13 of 30 took 47.796s
  training loss:		0.015226
  validation loss:		0.017908
  top 1 accuracy:		100.00 %
0.0024410164915025234
0.00032770592952147126
Batch of classes 1 out of 12 batches
Epoch 14 of 30 took 51.394s
  training loss:		0.018108
  validation loss:		0.027547
  top 1 accuracy:		100.00 %
0.001384642906486988
0.0008185521000996232
Batch of classes 1 out of 12 batches
Epoch 15 of 30 took 47.766s
  training loss:		0.014999
  validation loss:		0.016687
  top 1 accuracy:		100.00 %
0.003140380373224616
0.12128487229347229
Batch of classes 1 out of 12 batches
Epoch 16 of 30 took 47.184s
  training loss:		0.009313
  validation loss:		0.015497
  top 1 accuracy:		100.00 %
0.00032286945497617126
0.0012425375171005726
Batch of classes 1 out of 12 batches
Epoch 17 of 30 took 48.275s
  training loss:		0.024394
  validation loss:		0.021488
  top 1 accuracy:		100.00 %
0.0024450980126857758
0.002979350509122014
Batch of classes 1 out of 12 batches
Epoch 18 of 30 took 50.540s
  training loss:		0.024558
  validation loss:		0.051318
  top 1 accuracy:		100.00 %
0.009535408578813076
0.00017258351726923138
Batch of classes 1 out of 12 batches
Epoch 19 of 30 took 47.715s
  training loss:		0.012665
  validation loss:		0.027466
  top 1 accuracy:		100.00 %
0.0007173743797466159
0.054082147777080536
Batch of classes 1 out of 12 batches
Epoch 20 of 30 took 46.334s
  training loss:		0.016225
  validation loss:		0.062352
  top 1 accuracy:		100.00 %
0.04048377275466919
0.0009452853119000793
Batch of classes 1 out of 12 batches
Epoch 21 of 30 took 48.017s
  training loss:		0.010999
  validation loss:		0.022216
  top 1 accuracy:		100.00 %
0.005049718078225851
0.0018078912980854511
Batch of classes 1 out of 12 batches
Epoch 22 of 30 took 50.820s
  training loss:		0.006353
  validation loss:		0.017789
  top 1 accuracy:		100.00 %
9.681240771897137e-05
0.001737221609801054
Batch of classes 1 out of 12 batches
Epoch 23 of 30 took 47.889s
  training loss:		0.004670
  validation loss:		0.013749
  top 1 accuracy:		100.00 %
3.8358994061127305e-05
0.0047375475987792015
Batch of classes 1 out of 12 batches
Epoch 24 of 30 took 47.254s
  training loss:		0.008593
  validation loss:		0.015376
  top 1 accuracy:		100.00 %
0.0008696987642906606
0.00021071426454000175
Batch of classes 1 out of 12 batches
Epoch 25 of 30 took 47.516s
  training loss:		0.004169
  validation loss:		0.014966
  top 1 accuracy:		100.00 %
0.0013643550919368863
0.0003108927048742771
Batch of classes 1 out of 12 batches
Epoch 26 of 30 took 50.767s
  training loss:		0.005471
  validation loss:		0.013834
  top 1 accuracy:		100.00 %
0.0025890322867780924
0.0004766689380630851
Batch of classes 1 out of 12 batches
Epoch 27 of 30 took 47.922s
  training loss:		0.004046
  validation loss:		0.013480
  top 1 accuracy:		100.00 %
0.0009968348313122988
0.0002057533711194992
Batch of classes 1 out of 12 batches
Epoch 28 of 30 took 46.613s
  training loss:		0.005313
  validation loss:		0.018606
  top 1 accuracy:		100.00 %
0.00014737814490217716
6.0272301197983325e-05
Batch of classes 1 out of 12 batches
Epoch 29 of 30 took 46.778s
  training loss:		0.006715
  validation loss:		0.018952
  top 1 accuracy:		100.00 %
5.6821376347215846e-05
0.0058085722848773
Batch of classes 1 out of 12 batches
Epoch 30 of 30 took 50.213s
  training loss:		0.012619
  validation loss:		0.111612
  top 1 accuracy:		100.00 %
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(500)
tensor(500)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		99.25 %
  top 1 accuracy Hybrid 1       :		99.35 %
  top 1 accuracy NCM            :		99.25 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		99.25 %
  top 1 accuracy Hybrid 1       :		99.35 %
  top 1 accuracy NCM            :		99.25 %
Classes in this batch: tensor([2, 3])
Data Size: 2400


Before first epoch
  validation loss:		0.898471
  top 1 accuracy:		56.25 %
Batch of classes number 2 arrives ...
1.208320140838623
0.09043839573860168
Batch of classes 2 out of 12 batches
Epoch 1 of 30 took 48.246s
  training loss:		0.297331
  validation loss:		0.187821
  top 1 accuracy:		93.75 %
0.15589985251426697
0.2700616121292114
Batch of classes 2 out of 12 batches
Epoch 2 of 30 took 28.126s
  training loss:		0.185437
  validation loss:		0.111348
  top 1 accuracy:		100.00 %
0.14150764048099518
0.09209564328193665
Batch of classes 2 out of 12 batches
Epoch 3 of 30 took 28.502s
  training loss:		0.174334
  validation loss:		0.132936
  top 1 accuracy:		96.88 %
0.11236808449029922
0.1153041422367096
Batch of classes 2 out of 12 batches
Epoch 4 of 30 took 28.494s
  training loss:		0.161570
  validation loss:		0.110736
  top 1 accuracy:		100.00 %
0.08897362649440765
0.19592691957950592
Batch of classes 2 out of 12 batches
Epoch 5 of 30 took 27.897s
  training loss:		0.140289
  validation loss:		0.145086
  top 1 accuracy:		93.75 %
0.15516731142997742
0.1750357449054718
Batch of classes 2 out of 12 batches
Epoch 6 of 30 took 28.412s
  training loss:		0.166695
  validation loss:		0.284556
  top 1 accuracy:		100.00 %
0.09823882579803467
0.2401048243045807
Batch of classes 2 out of 12 batches
Epoch 7 of 30 took 28.162s
  training loss:		0.147537
  validation loss:		0.150643
  top 1 accuracy:		84.38 %
0.058794163167476654
0.1650427281856537
Batch of classes 2 out of 12 batches
Epoch 8 of 30 took 34.417s
  training loss:		0.143408
  validation loss:		0.113895
  top 1 accuracy:		100.00 %
0.17405056953430176
0.09886279702186584
Batch of classes 2 out of 12 batches
Epoch 9 of 30 took 33.891s
  training loss:		0.137253
  validation loss:		0.154182
  top 1 accuracy:		90.62 %
0.1160484328866005
0.15257754921913147
Batch of classes 2 out of 12 batches
Epoch 10 of 30 took 28.127s
  training loss:		0.141054
  validation loss:		0.129007
  top 1 accuracy:		100.00 %
0.08052430301904678
0.03202874958515167
Batch of classes 2 out of 12 batches
Epoch 11 of 30 took 28.496s
  training loss:		0.098082
  validation loss:		0.065591
  top 1 accuracy:		100.00 %
0.0984366238117218
0.06493730843067169
Batch of classes 2 out of 12 batches
Epoch 12 of 30 took 28.493s
  training loss:		0.096831
  validation loss:		0.065090
  top 1 accuracy:		96.88 %
0.07377903908491135
0.11539402604103088
Batch of classes 2 out of 12 batches
Epoch 13 of 30 took 28.351s
  training loss:		0.095930
  validation loss:		0.062521
  top 1 accuracy:		100.00 %
0.04759160801768303
0.13682585954666138
Batch of classes 2 out of 12 batches
Epoch 14 of 30 took 27.857s
  training loss:		0.084079
  validation loss:		0.056290
  top 1 accuracy:		100.00 %
0.07600788027048111
0.10156261920928955
Batch of classes 2 out of 12 batches
Epoch 15 of 30 took 27.685s
  training loss:		0.082333
  validation loss:		0.050949
  top 1 accuracy:		100.00 %
0.0860154777765274
0.11338736116886139
Batch of classes 2 out of 12 batches
Epoch 16 of 30 took 30.108s
  training loss:		0.090740
  validation loss:		0.047823
  top 1 accuracy:		100.00 %
0.11202654242515564
0.05909489467740059
Batch of classes 2 out of 12 batches
Epoch 17 of 30 took 27.951s
  training loss:		0.080893
  validation loss:		0.044093
  top 1 accuracy:		100.00 %
0.09766712784767151
0.1086769700050354
Batch of classes 2 out of 12 batches
Epoch 18 of 30 took 27.678s
  training loss:		0.082684
  validation loss:		0.051502
  top 1 accuracy:		100.00 %
0.12574073672294617
0.08770987391471863
Batch of classes 2 out of 12 batches
Epoch 19 of 30 took 28.183s
  training loss:		0.082927
  validation loss:		0.047303
  top 1 accuracy:		100.00 %
0.06293715536594391
0.0971178188920021
Batch of classes 2 out of 12 batches
Epoch 20 of 30 took 28.135s
  training loss:		0.078933
  validation loss:		0.051059
  top 1 accuracy:		100.00 %
0.04211975634098053
0.08550509810447693
Batch of classes 2 out of 12 batches
Epoch 21 of 30 took 28.158s
  training loss:		0.076423
  validation loss:		0.045920
  top 1 accuracy:		100.00 %
0.02858118526637554
0.09222465753555298
Batch of classes 2 out of 12 batches
Epoch 22 of 30 took 28.129s
  training loss:		0.075153
  validation loss:		0.043224
  top 1 accuracy:		100.00 %
0.05819366127252579
0.10825368016958237
Batch of classes 2 out of 12 batches
Epoch 23 of 30 took 30.724s
  training loss:		0.085865
  validation loss:		0.047616
  top 1 accuracy:		100.00 %
0.06276540458202362
0.057344190776348114
Batch of classes 2 out of 12 batches
Epoch 24 of 30 took 27.756s
  training loss:		0.080674
  validation loss:		0.049699
  top 1 accuracy:		100.00 %
0.07193398475646973
0.06450105458498001
Batch of classes 2 out of 12 batches
Epoch 25 of 30 took 27.906s
  training loss:		0.074268
  validation loss:		0.042967
  top 1 accuracy:		100.00 %
0.06872832030057907
0.06388214975595474
Batch of classes 2 out of 12 batches
Epoch 26 of 30 took 27.706s
  training loss:		0.071137
  validation loss:		0.041879
  top 1 accuracy:		100.00 %
0.07888536155223846
0.086290642619133
Batch of classes 2 out of 12 batches
Epoch 27 of 30 took 28.222s
  training loss:		0.075126
  validation loss:		0.042289
  top 1 accuracy:		100.00 %
0.06489525735378265
0.05973641201853752
Batch of classes 2 out of 12 batches
Epoch 28 of 30 took 28.235s
  training loss:		0.073179
  validation loss:		0.042436
  top 1 accuracy:		100.00 %
0.06566695868968964
0.07858161628246307
Batch of classes 2 out of 12 batches
Epoch 29 of 30 took 27.728s
  training loss:		0.075520
  validation loss:		0.042129
  top 1 accuracy:		100.00 %
0.06577186286449432
0.08450786024332047
Batch of classes 2 out of 12 batches
Epoch 30 of 30 took 27.761s
  training loss:		0.075220
  validation loss:		0.043264
  top 1 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(384)
tensor(384)
tensor(384)
tensor(384)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		98.05 %
  top 1 accuracy Hybrid 1       :		98.55 %
  top 1 accuracy NCM            :		98.10 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		99.25 %
  top 1 accuracy Hybrid 1       :		99.38 %
  top 1 accuracy NCM            :		99.25 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		98.39 %
  top 1 accuracy Hybrid 1       :		98.79 %
  top 1 accuracy NCM            :		98.43 %
Classes in this batch: tensor([4, 5])
Data Size: 1572


Before first epoch
  validation loss:		1.034071
  top 1 accuracy:		50.00 %
Batch of classes number 3 arrives ...
0.15478187799453735
Batch of classes 3 out of 12 batches
Epoch 1 of 30 took 35.418s
  training loss:		0.255884
  validation loss:		0.263293
  top 1 accuracy:		91.67 %
0.11790412664413452
Batch of classes 3 out of 12 batches
Epoch 2 of 30 took 24.553s
  training loss:		0.200584
  validation loss:		0.252066
  top 1 accuracy:		83.33 %
0.23926492035388947
Batch of classes 3 out of 12 batches
Epoch 3 of 30 took 24.576s
  training loss:		0.216318
  validation loss:		0.434364
  top 1 accuracy:		100.00 %
0.17002618312835693
Batch of classes 3 out of 12 batches
Epoch 4 of 30 took 24.622s
  training loss:		0.193978
  validation loss:		0.196711
  top 1 accuracy:		83.33 %
0.17786000669002533
Batch of classes 3 out of 12 batches
Epoch 5 of 30 took 24.345s
  training loss:		0.185802
  validation loss:		0.167645
  top 1 accuracy:		100.00 %
0.14616599678993225
Batch of classes 3 out of 12 batches
Epoch 6 of 30 took 24.506s
  training loss:		0.156587
  validation loss:		0.122111
  top 1 accuracy:		100.00 %
0.08798321336507797
Batch of classes 3 out of 12 batches
Epoch 7 of 30 took 24.219s
  training loss:		0.152276
  validation loss:		0.125228
  top 1 accuracy:		100.00 %
0.17371731996536255
Batch of classes 3 out of 12 batches
Epoch 8 of 30 took 24.936s
  training loss:		0.163038
  validation loss:		0.116619
  top 1 accuracy:		100.00 %
0.10414072871208191
Batch of classes 3 out of 12 batches
Epoch 9 of 30 took 24.708s
  training loss:		0.148370
  validation loss:		0.089966
  top 1 accuracy:		100.00 %
0.11980484426021576
Batch of classes 3 out of 12 batches
Epoch 10 of 30 took 24.320s
  training loss:		0.189709
  validation loss:		0.209777
  top 1 accuracy:		100.00 %
0.19689513742923737
Batch of classes 3 out of 12 batches
Epoch 11 of 30 took 24.384s
  training loss:		0.127709
  validation loss:		0.077693
  top 1 accuracy:		100.00 %
0.133138507604599
Batch of classes 3 out of 12 batches
Epoch 12 of 30 took 24.231s
  training loss:		0.108254
  validation loss:		0.106208
  top 1 accuracy:		100.00 %
0.1011887788772583
Batch of classes 3 out of 12 batches
Epoch 13 of 30 took 24.838s
  training loss:		0.111117
  validation loss:		0.087839
  top 1 accuracy:		100.00 %
0.13490039110183716
Batch of classes 3 out of 12 batches
Epoch 14 of 30 took 24.825s
  training loss:		0.099800
  validation loss:		0.061760
  top 1 accuracy:		100.00 %
0.09368196129798889
Batch of classes 3 out of 12 batches
Epoch 15 of 30 took 24.571s
  training loss:		0.095856
  validation loss:		0.057421
  top 1 accuracy:		100.00 %
0.12031710147857666
Batch of classes 3 out of 12 batches
Epoch 16 of 30 took 24.322s
  training loss:		0.094048
  validation loss:		0.079452
  top 1 accuracy:		100.00 %
0.0732898861169815
Batch of classes 3 out of 12 batches
Epoch 17 of 30 took 24.342s
  training loss:		0.098178
  validation loss:		0.071811
  top 1 accuracy:		100.00 %
0.09968441724777222
Batch of classes 3 out of 12 batches
Epoch 18 of 30 took 24.737s
  training loss:		0.127081
  validation loss:		0.087496
  top 1 accuracy:		100.00 %
0.13743820786476135
Batch of classes 3 out of 12 batches
Epoch 19 of 30 took 24.330s
  training loss:		0.103205
  validation loss:		0.060880
  top 1 accuracy:		100.00 %
0.09191645681858063
Batch of classes 3 out of 12 batches
Epoch 20 of 30 took 24.837s
  training loss:		0.098496
  validation loss:		0.065442
  top 1 accuracy:		100.00 %
0.09819794446229935
Batch of classes 3 out of 12 batches
Epoch 21 of 30 took 24.406s
  training loss:		0.092981
  validation loss:		0.092708
  top 1 accuracy:		100.00 %
0.10308824479579926
Batch of classes 3 out of 12 batches
Epoch 22 of 30 took 24.000s
  training loss:		0.092085
  validation loss:		0.066374
  top 1 accuracy:		100.00 %
0.04532162845134735
Batch of classes 3 out of 12 batches
Epoch 23 of 30 took 24.314s
  training loss:		0.090185
  validation loss:		0.063570
  top 1 accuracy:		100.00 %
0.07218459248542786
Batch of classes 3 out of 12 batches
Epoch 24 of 30 took 24.515s
  training loss:		0.096564
  validation loss:		0.086611
  top 1 accuracy:		100.00 %
0.07813773304224014
Batch of classes 3 out of 12 batches
Epoch 25 of 30 took 24.403s
  training loss:		0.092820
  validation loss:		0.071604
  top 1 accuracy:		100.00 %
0.07892969250679016
Batch of classes 3 out of 12 batches
Epoch 26 of 30 took 24.664s
  training loss:		0.094314
  validation loss:		0.057918
  top 1 accuracy:		100.00 %
0.11476527899503708
Batch of classes 3 out of 12 batches
Epoch 27 of 30 took 24.401s
  training loss:		0.088299
  validation loss:		0.057259
  top 1 accuracy:		100.00 %
0.08232241868972778
Batch of classes 3 out of 12 batches
Epoch 28 of 30 took 24.281s
  training loss:		0.088267
  validation loss:		0.063532
  top 1 accuracy:		100.00 %
0.08132928609848022
Batch of classes 3 out of 12 batches
Epoch 29 of 30 took 24.595s
  training loss:		0.093200
  validation loss:		0.057554
  top 1 accuracy:		100.00 %
0.10557865351438522
Batch of classes 3 out of 12 batches
Epoch 30 of 30 took 24.577s
  training loss:		0.089916
  validation loss:		0.069827
  top 1 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(256)
tensor(256)
tensor(256)
tensor(256)
tensor(256)
tensor(256)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		97.00 %
  top 1 accuracy Hybrid 1       :		97.50 %
  top 1 accuracy NCM            :		97.15 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		96.75 %
  top 1 accuracy Hybrid 1       :		96.75 %
  top 1 accuracy NCM            :		96.75 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		98.28 %
  top 1 accuracy Hybrid 1       :		98.66 %
  top 1 accuracy NCM            :		98.28 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		97.14 %
  top 1 accuracy Hybrid 1       :		97.50 %
  top 1 accuracy NCM            :		97.23 %
Classes in this batch: tensor([6, 7])
Data Size: 7656


Before first epoch
  validation loss:		0.267697
  top 1 accuracy:		91.67 %
Batch of classes number 4 arrives ...
0.13822679221630096
0.18623293936252594
0.30386999249458313
Batch of classes 4 out of 12 batches
Epoch 1 of 30 took 98.831s
  training loss:		0.137655
  validation loss:		0.082445
  top 1 accuracy:		95.83 %
0.0879589095711708
0.08530949056148529
0.07383515685796738
Batch of classes 4 out of 12 batches
Epoch 2 of 30 took 86.013s
  training loss:		0.117726
  validation loss:		0.021069
  top 1 accuracy:		100.00 %
0.10667277872562408
0.12995752692222595
0.07542020082473755
Batch of classes 4 out of 12 batches
Epoch 3 of 30 took 80.378s
  training loss:		0.103565
  validation loss:		0.015966
  top 1 accuracy:		100.00 %
0.07179393619298935
0.10491949319839478
0.09822380542755127
Batch of classes 4 out of 12 batches
Epoch 4 of 30 took 79.154s
  training loss:		0.111341
  validation loss:		0.021157
  top 1 accuracy:		100.00 %
0.10030326247215271
0.19314979016780853
0.08788859844207764
Batch of classes 4 out of 12 batches
Epoch 5 of 30 took 79.735s
  training loss:		0.109666
  validation loss:		0.087104
  top 1 accuracy:		100.00 %
0.15734514594078064
0.1571502983570099
0.07805098593235016
Batch of classes 4 out of 12 batches
Epoch 6 of 30 took 125.986s
  training loss:		0.118097
  validation loss:		0.020913
  top 1 accuracy:		100.00 %
0.07579942792654037
0.0745467022061348
0.13205856084823608
Batch of classes 4 out of 12 batches
Epoch 7 of 30 took 173.099s
  training loss:		0.094336
  validation loss:		0.010727
  top 1 accuracy:		100.00 %
0.0733201652765274
0.10910997539758682
0.09158690273761749
Batch of classes 4 out of 12 batches
Epoch 8 of 30 took 194.060s
  training loss:		0.089568
  validation loss:		0.025717
  top 1 accuracy:		100.00 %
0.08882482349872589
0.11248693615198135
0.08103722333908081
Batch of classes 4 out of 12 batches
Epoch 9 of 30 took 200.305s
  training loss:		0.097374
  validation loss:		0.031698
  top 1 accuracy:		95.83 %
0.0932534784078598
0.09570547938346863
0.07859844714403152
Batch of classes 4 out of 12 batches
Epoch 10 of 30 took 167.179s
  training loss:		0.113135
  validation loss:		0.016829
  top 1 accuracy:		100.00 %
0.09297166019678116
0.07947011291980743
0.06691668927669525
Batch of classes 4 out of 12 batches
Epoch 11 of 30 took 163.570s
  training loss:		0.082765
  validation loss:		0.015697
  top 1 accuracy:		100.00 %
0.06384807080030441
0.11877749860286713
0.09365955740213394
Batch of classes 4 out of 12 batches
Epoch 12 of 30 took 141.549s
  training loss:		0.080401
  validation loss:		0.014529
  top 1 accuracy:		100.00 %
0.08279317617416382
0.09175083041191101
0.07746043056249619
Batch of classes 4 out of 12 batches
Epoch 13 of 30 took 181.014s
  training loss:		0.076104
  validation loss:		0.012257
  top 1 accuracy:		100.00 %
0.06560201942920685
0.07241418957710266
0.0888889953494072
Batch of classes 4 out of 12 batches
Epoch 14 of 30 took 196.983s
  training loss:		0.075382
  validation loss:		0.014755
  top 1 accuracy:		100.00 %
0.05053534358739853
0.07635096460580826
0.0868057981133461
Batch of classes 4 out of 12 batches
Epoch 15 of 30 took 190.200s
  training loss:		0.074238
  validation loss:		0.013976
  top 1 accuracy:		100.00 %
0.08171948045492172
0.07090554386377335
0.054922040551900864
Batch of classes 4 out of 12 batches
Epoch 16 of 30 took 189.427s
  training loss:		0.076764
  validation loss:		0.012849
  top 1 accuracy:		100.00 %
0.08866578340530396
0.06480684876441956
0.06321047991514206
Batch of classes 4 out of 12 batches
Epoch 17 of 30 took 204.537s
  training loss:		0.074596
  validation loss:		0.013581
  top 1 accuracy:		100.00 %
0.09399697929620743
0.09009711444377899
0.046204302459955215
Batch of classes 4 out of 12 batches
Epoch 18 of 30 took 186.106s
  training loss:		0.074126
  validation loss:		0.013814
  top 1 accuracy:		100.00 %
0.0745222270488739
0.04972795397043228
0.08227956295013428
Batch of classes 4 out of 12 batches
Epoch 19 of 30 took 190.133s
  training loss:		0.074318
  validation loss:		0.012931
  top 1 accuracy:		100.00 %
0.09280577301979065
0.0957806259393692
0.05995961278676987
Batch of classes 4 out of 12 batches
Epoch 20 of 30 took 189.839s
  training loss:		0.074324
  validation loss:		0.014879
  top 1 accuracy:		100.00 %
0.05671343952417374
0.05008535087108612
0.07588405162096024
Batch of classes 4 out of 12 batches
Epoch 21 of 30 took 171.373s
  training loss:		0.075182
  validation loss:		0.013097
  top 1 accuracy:		100.00 %
0.06716155260801315
0.08481168746948242
0.09174415469169617
Batch of classes 4 out of 12 batches
Epoch 22 of 30 took 182.979s
  training loss:		0.074329
  validation loss:		0.012968
  top 1 accuracy:		100.00 %
0.07146631926298141
0.08088701963424683
0.06472431868314743
Batch of classes 4 out of 12 batches
Epoch 23 of 30 took 196.017s
  training loss:		0.073562
  validation loss:		0.013313
  top 1 accuracy:		100.00 %
0.03912779316306114
0.07651101797819138
0.09171278029680252
Batch of classes 4 out of 12 batches
Epoch 24 of 30 took 151.975s
  training loss:		0.074058
  validation loss:		0.013616
  top 1 accuracy:		100.00 %
0.06062658876180649
0.061337146908044815
0.08676651120185852
Batch of classes 4 out of 12 batches
Epoch 25 of 30 took 140.063s
  training loss:		0.072302
  validation loss:		0.015275
  top 1 accuracy:		100.00 %
0.07562384754419327
0.06276858597993851
0.051914528012275696
Batch of classes 4 out of 12 batches
Epoch 26 of 30 took 173.746s
  training loss:		0.072940
  validation loss:		0.012820
  top 1 accuracy:		100.00 %
0.06969939917325974
0.07349814474582672
0.10676614195108414
Batch of classes 4 out of 12 batches
Epoch 27 of 30 took 175.753s
  training loss:		0.072413
  validation loss:		0.013432
  top 1 accuracy:		100.00 %
0.061902858316898346
0.06741791218519211
0.06947042047977448
Batch of classes 4 out of 12 batches
Epoch 28 of 30 took 180.457s
  training loss:		0.072713
  validation loss:		0.017299
  top 1 accuracy:		100.00 %
0.06736670434474945
0.07954008132219315
0.057884663343429565
Batch of classes 4 out of 12 batches
Epoch 29 of 30 took 157.602s
  training loss:		0.072240
  validation loss:		0.014462
  top 1 accuracy:		100.00 %
0.060435328632593155
0.08705785125494003
0.06260943412780762
Batch of classes 4 out of 12 batches
Epoch 30 of 30 took 180.103s
  training loss:		0.072693
  validation loss:		0.015657
  top 1 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		95.20 %
  top 1 accuracy Hybrid 1       :		94.35 %
  top 1 accuracy NCM            :		95.30 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		96.25 %
  top 1 accuracy Hybrid 1       :		96.62 %
  top 1 accuracy NCM            :		96.25 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		95.42 %
  top 1 accuracy Hybrid 1       :		95.99 %
  top 1 accuracy NCM            :		95.23 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		100.00 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		97.45 %
  top 1 accuracy Hybrid 1       :		97.26 %
  top 1 accuracy NCM            :		97.46 %
Classes in this batch: tensor([8, 9])
Data Size: 3248


Before first epoch
  validation loss:		1.279352
  top 1 accuracy:		0.00 %
Batch of classes number 5 arrives ...
1.0818555355072021
0.1884731948375702
Batch of classes 5 out of 12 batches
Epoch 1 of 30 took 59.503s
  training loss:		0.317927
  validation loss:		0.149899
  top 1 accuracy:		96.15 %
0.25246578454971313
0.19638213515281677
Batch of classes 5 out of 12 batches
Epoch 2 of 30 took 36.110s
  training loss:		0.252782
  validation loss:		0.194806
  top 1 accuracy:		100.00 %
0.31260693073272705
0.1904737651348114
Batch of classes 5 out of 12 batches
Epoch 3 of 30 took 36.742s
  training loss:		0.223637
  validation loss:		0.168355
  top 1 accuracy:		100.00 %
0.2441333830356598
0.17386531829833984
Batch of classes 5 out of 12 batches
Epoch 4 of 30 took 36.434s
  training loss:		0.212552
  validation loss:		0.185103
  top 1 accuracy:		100.00 %
0.19607195258140564
0.2361242175102234
Batch of classes 5 out of 12 batches
Epoch 5 of 30 took 36.617s
  training loss:		0.210143
  validation loss:		0.149496
  top 1 accuracy:		100.00 %
0.19393357634544373
0.17172518372535706
Batch of classes 5 out of 12 batches
Epoch 6 of 30 took 36.627s
  training loss:		0.194298
  validation loss:		0.136302
  top 1 accuracy:		100.00 %
0.13718660175800323
0.13821707665920258
Batch of classes 5 out of 12 batches
Epoch 7 of 30 took 36.443s
  training loss:		0.187841
  validation loss:		0.172499
  top 1 accuracy:		100.00 %
0.17126312851905823
0.16829407215118408
Batch of classes 5 out of 12 batches
Epoch 8 of 30 took 36.516s
  training loss:		0.181205
  validation loss:		0.148491
  top 1 accuracy:		100.00 %
0.11936583369970322
0.23955094814300537
Batch of classes 5 out of 12 batches
Epoch 9 of 30 took 36.559s
  training loss:		0.177563
  validation loss:		0.143545
  top 1 accuracy:		100.00 %
0.15683051943778992
0.19323712587356567
Batch of classes 5 out of 12 batches
Epoch 10 of 30 took 36.516s
  training loss:		0.180097
  validation loss:		0.136119
  top 1 accuracy:		100.00 %
0.1690279096364975
0.12620139122009277
Batch of classes 5 out of 12 batches
Epoch 11 of 30 took 36.573s
  training loss:		0.152086
  validation loss:		0.143025
  top 1 accuracy:		100.00 %
0.17239701747894287
0.20948681235313416
Batch of classes 5 out of 12 batches
Epoch 12 of 30 took 38.366s
  training loss:		0.147465
  validation loss:		0.148831
  top 1 accuracy:		100.00 %
0.1997610628604889
0.16062894463539124
Batch of classes 5 out of 12 batches
Epoch 13 of 30 took 36.441s
  training loss:		0.143439
  validation loss:		0.133247
  top 1 accuracy:		100.00 %
0.16770848631858826
0.25954943895339966
Batch of classes 5 out of 12 batches
Epoch 14 of 30 took 36.547s
  training loss:		0.140648
  validation loss:		0.145076
  top 1 accuracy:		100.00 %
0.11524266749620438
0.1834842711687088
Batch of classes 5 out of 12 batches
Epoch 15 of 30 took 36.200s
  training loss:		0.137976
  validation loss:		0.133841
  top 1 accuracy:		100.00 %
0.10544449836015701
0.11529290676116943
Batch of classes 5 out of 12 batches
Epoch 16 of 30 took 36.544s
  training loss:		0.138285
  validation loss:		0.123705
  top 1 accuracy:		100.00 %
0.10650575160980225
0.11533939838409424
Batch of classes 5 out of 12 batches
Epoch 17 of 30 took 36.708s
  training loss:		0.138585
  validation loss:		0.133372
  top 1 accuracy:		100.00 %
0.20299391448497772
0.13991428911685944
Batch of classes 5 out of 12 batches
Epoch 18 of 30 took 36.509s
  training loss:		0.137891
  validation loss:		0.145421
  top 1 accuracy:		100.00 %
0.1431812345981598
0.19946664571762085
Batch of classes 5 out of 12 batches
Epoch 19 of 30 took 36.562s
  training loss:		0.137316
  validation loss:		0.134273
  top 1 accuracy:		100.00 %
0.13060696423053741
0.13244089484214783
Batch of classes 5 out of 12 batches
Epoch 20 of 30 took 36.789s
  training loss:		0.137432
  validation loss:		0.128389
  top 1 accuracy:		100.00 %
0.17339462041854858
0.11866369843482971
Batch of classes 5 out of 12 batches
Epoch 21 of 30 took 42.943s
  training loss:		0.135957
  validation loss:		0.132518
  top 1 accuracy:		100.00 %
0.1601564884185791
0.14226427674293518
Batch of classes 5 out of 12 batches
Epoch 22 of 30 took 36.720s
  training loss:		0.133050
  validation loss:		0.137046
  top 1 accuracy:		100.00 %
0.1845380961894989
0.08114993572235107
Batch of classes 5 out of 12 batches
Epoch 23 of 30 took 36.590s
  training loss:		0.133825
  validation loss:		0.143602
  top 1 accuracy:		100.00 %
0.19619017839431763
0.12585411965847015
Batch of classes 5 out of 12 batches
Epoch 24 of 30 took 36.758s
  training loss:		0.133323
  validation loss:		0.145052
  top 1 accuracy:		100.00 %
0.11894945800304413
0.15853926539421082
Batch of classes 5 out of 12 batches
Epoch 25 of 30 took 36.470s
  training loss:		0.134651
  validation loss:		0.123939
  top 1 accuracy:		100.00 %
0.15420271456241608
0.15380597114562988
Batch of classes 5 out of 12 batches
Epoch 26 of 30 took 36.504s
  training loss:		0.132097
  validation loss:		0.127087
  top 1 accuracy:		100.00 %
0.14599677920341492
0.09098794311285019
Batch of classes 5 out of 12 batches
Epoch 27 of 30 took 36.632s
  training loss:		0.134639
  validation loss:		0.132230
  top 1 accuracy:		100.00 %
0.1558416783809662
0.11229750514030457
Batch of classes 5 out of 12 batches
Epoch 28 of 30 took 37.598s
  training loss:		0.134010
  validation loss:		0.139529
  top 1 accuracy:		100.00 %
0.0786847397685051
0.11285395920276642
Batch of classes 5 out of 12 batches
Epoch 29 of 30 took 39.464s
  training loss:		0.131550
  validation loss:		0.146938
  top 1 accuracy:		100.00 %
0.0756782740354538
0.10306081175804138
Batch of classes 5 out of 12 batches
Epoch 30 of 30 took 38.791s
  training loss:		0.134401
  validation loss:		0.141075
  top 1 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		90.80 %
  top 1 accuracy Hybrid 1       :		91.40 %
  top 1 accuracy NCM            :		90.90 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		92.12 %
  top 1 accuracy Hybrid 1       :		93.62 %
  top 1 accuracy NCM            :		92.25 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		89.31 %
  top 1 accuracy Hybrid 1       :		91.98 %
  top 1 accuracy NCM            :		89.50 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		98.51 %
  top 1 accuracy Hybrid 1       :		98.98 %
  top 1 accuracy NCM            :		98.51 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		96.67 %
  top 1 accuracy Hybrid 1       :		96.58 %
  top 1 accuracy NCM            :		96.67 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		94.58 %
  top 1 accuracy Hybrid 1       :		95.29 %
  top 1 accuracy NCM            :		94.64 %
Classes in this batch: tensor([10, 11])
Data Size: 7658


Before first epoch
  validation loss:		0.044219
  top 1 accuracy:		95.83 %
Batch of classes number 6 arrives ...
0.08373457193374634
0.06734700500965118
0.07162245362997055
Batch of classes 6 out of 12 batches
Epoch 1 of 30 took 104.444s
  training loss:		0.072972
  validation loss:		0.018301
  top 1 accuracy:		100.00 %
0.014879314228892326
0.048689283430576324
0.045609250664711
Batch of classes 6 out of 12 batches
Epoch 2 of 30 took 126.200s
  training loss:		0.056406
  validation loss:		0.009426
  top 1 accuracy:		100.00 %
0.022180870175361633
0.08480943739414215
0.03685208782553673
Batch of classes 6 out of 12 batches
Epoch 3 of 30 took 142.602s
  training loss:		0.041472
  validation loss:		0.002493
  top 1 accuracy:		100.00 %
0.01494593732059002
0.02076643332839012
0.0423734150826931
Batch of classes 6 out of 12 batches
Epoch 4 of 30 took 104.146s
  training loss:		0.044990
  validation loss:		0.004562
  top 1 accuracy:		100.00 %
0.01622775010764599
0.021933143958449364
0.04475422948598862
Batch of classes 6 out of 12 batches
Epoch 5 of 30 took 97.887s
  training loss:		0.046496
  validation loss:		0.005643
  top 1 accuracy:		100.00 %
0.12185784429311752
0.026103012263774872
0.038215916603803635
Batch of classes 6 out of 12 batches
Epoch 6 of 30 took 119.824s
  training loss:		0.041348
  validation loss:		0.003913
  top 1 accuracy:		100.00 %
0.01655573584139347
0.02518954500555992
0.025283318012952805
Batch of classes 6 out of 12 batches
Epoch 7 of 30 took 137.499s
  training loss:		0.039807
  validation loss:		0.005265
  top 1 accuracy:		100.00 %
0.03853800147771835
0.02198883332312107
0.04000212997198105
Batch of classes 6 out of 12 batches
Epoch 8 of 30 took 141.310s
  training loss:		0.035866
  validation loss:		0.008999
  top 1 accuracy:		100.00 %
0.02884981967508793
0.03709666058421135
0.010386272333562374
Batch of classes 6 out of 12 batches
Epoch 9 of 30 took 147.923s
  training loss:		0.038695
  validation loss:		0.005113
  top 1 accuracy:		100.00 %
0.026905084028840065
0.03040267340838909
0.024655155837535858
Batch of classes 6 out of 12 batches
Epoch 10 of 30 took 172.283s
  training loss:		0.037482
  validation loss:		0.003655
  top 1 accuracy:		100.00 %
0.040768567472696304
0.02306300960481167
0.020470745861530304
Batch of classes 6 out of 12 batches
Epoch 11 of 30 took 173.508s
  training loss:		0.022727
  validation loss:		0.002577
  top 1 accuracy:		100.00 %
0.014775218442082405
0.012211469933390617
0.01608298532664776
Batch of classes 6 out of 12 batches
Epoch 12 of 30 took 144.886s
  training loss:		0.020904
  validation loss:		0.002860
  top 1 accuracy:		100.00 %
0.025807134807109833
0.01415927242487669
0.00618252856656909
Batch of classes 6 out of 12 batches
Epoch 13 of 30 took 172.725s
  training loss:		0.021287
  validation loss:		0.002481
  top 1 accuracy:		100.00 %
0.012354599311947823
0.02284826710820198
0.018316486850380898
Batch of classes 6 out of 12 batches
Epoch 14 of 30 took 114.037s
  training loss:		0.020783
  validation loss:		0.002679
  top 1 accuracy:		100.00 %
0.02255997247993946
0.02252030558884144
0.010252676904201508
Batch of classes 6 out of 12 batches
Epoch 15 of 30 took 148.059s
  training loss:		0.019603
  validation loss:		0.002716
  top 1 accuracy:		100.00 %
0.015636267140507698
0.02286219596862793
0.02138092927634716
Batch of classes 6 out of 12 batches
Epoch 16 of 30 took 170.920s
  training loss:		0.020053
  validation loss:		0.002929
  top 1 accuracy:		100.00 %
0.027312226593494415
0.010313035920262337
0.02083422988653183
Batch of classes 6 out of 12 batches
Epoch 17 of 30 took 182.952s
  training loss:		0.020146
  validation loss:		0.002557
  top 1 accuracy:		100.00 %
0.009924566373229027
0.015013475902378559
0.010916647501289845
Batch of classes 6 out of 12 batches
Epoch 18 of 30 took 172.722s
  training loss:		0.021252
  validation loss:		0.001627
  top 1 accuracy:		100.00 %
0.01549298595637083
0.026709333062171936
0.03320063650608063
Batch of classes 6 out of 12 batches
Epoch 19 of 30 took 171.863s
  training loss:		0.019902
  validation loss:		0.002682
  top 1 accuracy:		100.00 %
0.021996352821588516
0.012642526999115944
0.04995763301849365
Batch of classes 6 out of 12 batches
Epoch 20 of 30 took 184.930s
  training loss:		0.022073
  validation loss:		0.001878
  top 1 accuracy:		100.00 %
0.013105133548378944
0.03371252864599228
0.009597927331924438
Batch of classes 6 out of 12 batches
Epoch 21 of 30 took 179.138s
  training loss:		0.020189
  validation loss:		0.002348
  top 1 accuracy:		100.00 %
0.017818206921219826
0.020558657124638557
0.008793113753199577
Batch of classes 6 out of 12 batches
Epoch 22 of 30 took 173.280s
  training loss:		0.019553
  validation loss:		0.002608
  top 1 accuracy:		100.00 %
0.027674412354826927
0.02110910974442959
0.015459445305168629
Batch of classes 6 out of 12 batches
Epoch 23 of 30 took 184.590s
  training loss:		0.018769
  validation loss:		0.002613
  top 1 accuracy:		100.00 %
0.0103495167568326
0.027010828256607056
0.015625499188899994
Batch of classes 6 out of 12 batches
Epoch 24 of 30 took 175.785s
  training loss:		0.019331
  validation loss:		0.003602
  top 1 accuracy:		100.00 %
0.024401027709245682
0.04421742632985115
0.012862063944339752
Batch of classes 6 out of 12 batches
Epoch 25 of 30 took 173.370s
  training loss:		0.019189
  validation loss:		0.003026
  top 1 accuracy:		100.00 %
0.013648535124957561
0.01187330111861229
0.008276060223579407
Batch of classes 6 out of 12 batches
Epoch 26 of 30 took 191.467s
  training loss:		0.019479
  validation loss:		0.002806
  top 1 accuracy:		100.00 %
0.016035588458180428
0.01770578883588314
0.030249815434217453
Batch of classes 6 out of 12 batches
Epoch 27 of 30 took 170.455s
  training loss:		0.019136
  validation loss:		0.002882
  top 1 accuracy:		100.00 %
0.01639270782470703
0.021159546449780464
0.014288109727203846
Batch of classes 6 out of 12 batches
Epoch 28 of 30 took 169.569s
  training loss:		0.018868
  validation loss:		0.002352
  top 1 accuracy:		100.00 %
0.010879850015044212
0.028123199939727783
0.013172447681427002
Batch of classes 6 out of 12 batches
Epoch 29 of 30 took 171.713s
  training loss:		0.019193
  validation loss:		0.002926
  top 1 accuracy:		100.00 %
0.02219216711819172
0.029976366087794304
0.04411258548498154
Batch of classes 6 out of 12 batches
Epoch 30 of 30 took 174.379s
  training loss:		0.019153
  validation loss:		0.002883
  top 1 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		90.45 %
  top 1 accuracy Hybrid 1       :		88.95 %
  top 1 accuracy NCM            :		90.70 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		92.25 %
  top 1 accuracy Hybrid 1       :		92.50 %
  top 1 accuracy NCM            :		91.38 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		93.70 %
  top 1 accuracy Hybrid 1       :		94.66 %
  top 1 accuracy NCM            :		93.32 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		99.96 %
  top 1 accuracy NCM            :		100.00 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		96.49 %
  top 1 accuracy Hybrid 1       :		96.40 %
  top 1 accuracy NCM            :		96.40 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		100.00 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		96.59 %
  top 1 accuracy Hybrid 1       :		96.33 %
  top 1 accuracy NCM            :		96.54 %
Classes in this batch: tensor([12, 13])
Data Size: 6208


Before first epoch
  validation loss:		1.720900
  top 1 accuracy:		26.67 %
Batch of classes number 7 arrives ...
0.958227276802063
0.6626181602478027
0.5481581687927246
Batch of classes 7 out of 12 batches
Epoch 1 of 30 took 119.406s
  training loss:		0.623334
  validation loss:		0.688461
  top 1 accuracy:		86.67 %
0.5195501446723938
0.505474328994751
0.49519747495651245
Batch of classes 7 out of 12 batches
Epoch 2 of 30 took 97.203s
  training loss:		0.533672
  validation loss:		0.685220
  top 1 accuracy:		40.00 %
0.5272731184959412
0.5007464289665222
0.45764946937561035
Batch of classes 7 out of 12 batches
Epoch 3 of 30 took 65.263s
  training loss:		0.507643
  validation loss:		0.537234
  top 1 accuracy:		73.33 %
0.3628377616405487
0.4735039174556732
0.5295038819313049
Batch of classes 7 out of 12 batches
Epoch 4 of 30 took 61.021s
  training loss:		0.472387
  validation loss:		0.509819
  top 1 accuracy:		73.33 %
0.38677987456321716
0.3258444666862488
0.4854494333267212
Batch of classes 7 out of 12 batches
Epoch 5 of 30 took 58.627s
  training loss:		0.460006
  validation loss:		0.495765
  top 1 accuracy:		80.00 %
0.37154585123062134
0.5126438736915588
0.2587469220161438
Batch of classes 7 out of 12 batches
Epoch 6 of 30 took 69.571s
  training loss:		0.439785
  validation loss:		0.585380
  top 1 accuracy:		60.00 %
0.517021894454956
0.42216336727142334
0.5049042105674744
Batch of classes 7 out of 12 batches
Epoch 7 of 30 took 59.006s
  training loss:		0.436283
  validation loss:		0.516471
  top 1 accuracy:		80.00 %
0.25956442952156067
0.3740069270133972
0.39281538128852844
Batch of classes 7 out of 12 batches
Epoch 8 of 30 took 58.488s
  training loss:		0.416406
  validation loss:		0.515398
  top 1 accuracy:		86.67 %
0.4059343636035919
0.289070188999176
0.2819823622703552
Batch of classes 7 out of 12 batches
Epoch 9 of 30 took 62.181s
  training loss:		0.406569
  validation loss:		0.501225
  top 1 accuracy:		80.00 %
0.6068235039710999
0.4308857023715973
0.4142901301383972
Batch of classes 7 out of 12 batches
Epoch 10 of 30 took 65.059s
  training loss:		0.393608
  validation loss:		0.468324
  top 1 accuracy:		86.67 %
0.4532063901424408
0.38304710388183594
0.4410665035247803
Batch of classes 7 out of 12 batches
Epoch 11 of 30 took 57.814s
  training loss:		0.348207
  validation loss:		0.482484
  top 1 accuracy:		86.67 %
0.2469007670879364
0.37247174978256226
0.311123788356781
Batch of classes 7 out of 12 batches
Epoch 12 of 30 took 58.004s
  training loss:		0.325829
  validation loss:		0.494384
  top 1 accuracy:		86.67 %
0.4884133040904999
0.27806463837623596
0.3017445206642151
Batch of classes 7 out of 12 batches
Epoch 13 of 30 took 75.509s
  training loss:		0.323828
  validation loss:		0.449909
  top 1 accuracy:		93.33 %
0.22505038976669312
0.3256075382232666
0.3145968019962311
Batch of classes 7 out of 12 batches
Epoch 14 of 30 took 95.921s
  training loss:		0.309490
  validation loss:		0.472031
  top 1 accuracy:		93.33 %
0.33228376507759094
0.33735811710357666
0.20401111245155334
Batch of classes 7 out of 12 batches
Epoch 15 of 30 took 96.569s
  training loss:		0.304431
  validation loss:		0.527719
  top 1 accuracy:		80.00 %
0.2421189844608307
0.307908833026886
0.32310354709625244
Batch of classes 7 out of 12 batches
Epoch 16 of 30 took 58.175s
  training loss:		0.300271
  validation loss:		0.458941
  top 1 accuracy:		86.67 %
0.33316943049430847
0.3067815899848938
0.3575765788555145
Batch of classes 7 out of 12 batches
Epoch 17 of 30 took 60.911s
  training loss:		0.290484
  validation loss:		0.549308
  top 1 accuracy:		80.00 %
0.2570931911468506
0.3177480697631836
0.2288329005241394
Batch of classes 7 out of 12 batches
Epoch 18 of 30 took 58.976s
  training loss:		0.284679
  validation loss:		0.492819
  top 1 accuracy:		86.67 %
0.2935979962348938
0.26247477531433105
0.26025158166885376
Batch of classes 7 out of 12 batches
Epoch 19 of 30 took 72.367s
  training loss:		0.273802
  validation loss:		0.498700
  top 1 accuracy:		86.67 %
0.2114850878715515
0.1943785548210144
0.34790846705436707
Batch of classes 7 out of 12 batches
Epoch 20 of 30 took 63.397s
  training loss:		0.268065
  validation loss:		0.476270
  top 1 accuracy:		80.00 %
0.18781572580337524
0.24699053168296814
0.32911840081214905
Batch of classes 7 out of 12 batches
Epoch 21 of 30 took 89.470s
  training loss:		0.255113
  validation loss:		0.475745
  top 1 accuracy:		86.67 %
0.1934264898300171
0.2711237072944641
0.24566876888275146
Batch of classes 7 out of 12 batches
Epoch 22 of 30 took 98.692s
  training loss:		0.245007
  validation loss:		0.496455
  top 1 accuracy:		86.67 %
0.2859273850917816
0.16657984256744385
0.2394828349351883
Batch of classes 7 out of 12 batches
Epoch 23 of 30 took 90.962s
  training loss:		0.241378
  validation loss:		0.517839
  top 1 accuracy:		80.00 %
0.21379217505455017
0.22963838279247284
0.2175740897655487
Batch of classes 7 out of 12 batches
Epoch 24 of 30 took 56.416s
  training loss:		0.238380
  validation loss:		0.482363
  top 1 accuracy:		86.67 %
0.16437792778015137
0.24649208784103394
0.19613251090049744
Batch of classes 7 out of 12 batches
Epoch 25 of 30 took 58.700s
  training loss:		0.231893
  validation loss:		0.504248
  top 1 accuracy:		86.67 %
0.2060944139957428
0.2267044484615326
0.30709201097488403
Batch of classes 7 out of 12 batches
Epoch 26 of 30 took 58.265s
  training loss:		0.233667
  validation loss:		0.529578
  top 1 accuracy:		86.67 %
0.21907582879066467
0.23942577838897705
0.21149444580078125
Batch of classes 7 out of 12 batches
Epoch 27 of 30 took 58.515s
  training loss:		0.225433
  validation loss:		0.522247
  top 1 accuracy:		86.67 %
0.3643118143081665
0.17323438823223114
0.32983487844467163
Batch of classes 7 out of 12 batches
Epoch 28 of 30 took 69.523s
  training loss:		0.226665
  validation loss:		0.507015
  top 1 accuracy:		80.00 %
0.19118040800094604
0.16484946012496948
0.1561228483915329
Batch of classes 7 out of 12 batches
Epoch 29 of 30 took 84.742s
  training loss:		0.222857
  validation loss:		0.528688
  top 1 accuracy:		86.67 %
0.20496267080307007
0.2562125325202942
0.24293644726276398
Batch of classes 7 out of 12 batches
Epoch 30 of 30 took 58.155s
  training loss:		0.223728
  validation loss:		0.513273
  top 1 accuracy:		86.67 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		81.45 %
  top 1 accuracy Hybrid 1       :		82.25 %
  top 1 accuracy NCM            :		81.45 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		84.25 %
  top 1 accuracy Hybrid 1       :		83.12 %
  top 1 accuracy NCM            :		84.25 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		89.69 %
  top 1 accuracy Hybrid 1       :		88.93 %
  top 1 accuracy NCM            :		89.31 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		98.39 %
  top 1 accuracy Hybrid 1       :		98.32 %
  top 1 accuracy NCM            :		98.16 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		89.74 %
  top 1 accuracy Hybrid 1       :		89.83 %
  top 1 accuracy NCM            :		89.74 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		98.39 %
  top 1 accuracy Hybrid 1       :		98.28 %
  top 1 accuracy NCM            :		98.20 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		79.35 %
  top 1 accuracy Hybrid 1       :		80.08 %
  top 1 accuracy NCM            :		79.35 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		89.89 %
  top 1 accuracy Hybrid 1       :		90.01 %
  top 1 accuracy NCM            :		89.78 %
Classes in this batch: tensor([14, 15])
Data Size: 7200


Before first epoch
  validation loss:		2.346417
  top 1 accuracy:		6.25 %
Batch of classes number 8 arrives ...
0.5262698531150818
0.2754989266395569
0.30693262815475464
Batch of classes 8 out of 12 batches
Epoch 1 of 30 took 206.221s
  training loss:		0.315960
  validation loss:		0.109708
  top 1 accuracy:		100.00 %
0.3161231279373169
0.2265847623348236
0.29670077562332153
Batch of classes 8 out of 12 batches
Epoch 2 of 30 took 182.058s
  training loss:		0.244037
  validation loss:		0.165093
  top 1 accuracy:		90.62 %
0.21264328062534332
0.2091081142425537
0.25594252347946167
Batch of classes 8 out of 12 batches
Epoch 3 of 30 took 190.008s
  training loss:		0.229068
  validation loss:		0.097350
  top 1 accuracy:		96.88 %
0.15327207744121552
0.16683568060398102
0.2376205325126648
Batch of classes 8 out of 12 batches
Epoch 4 of 30 took 201.936s
  training loss:		0.213016
  validation loss:		0.339645
  top 1 accuracy:		75.00 %
0.22640591859817505
0.25959187746047974
0.214670792222023
Batch of classes 8 out of 12 batches
Epoch 5 of 30 took 193.764s
  training loss:		0.223601
  validation loss:		0.095271
  top 1 accuracy:		90.62 %
0.21696269512176514
0.19203269481658936
0.19721755385398865
Batch of classes 8 out of 12 batches
Epoch 6 of 30 took 205.059s
  training loss:		0.198016
  validation loss:		0.083122
  top 1 accuracy:		100.00 %
0.15825200080871582
0.20919856429100037
0.1374794840812683
Batch of classes 8 out of 12 batches
Epoch 7 of 30 took 186.581s
  training loss:		0.202618
  validation loss:		0.204323
  top 1 accuracy:		96.88 %
0.2324683666229248
0.22383850812911987
0.2813072204589844
Batch of classes 8 out of 12 batches
Epoch 8 of 30 took 193.301s
  training loss:		0.218219
  validation loss:		0.098793
  top 1 accuracy:		100.00 %
0.1884102076292038
0.1960071623325348
0.1884140521287918
Batch of classes 8 out of 12 batches
Epoch 9 of 30 took 212.354s
  training loss:		0.200900
  validation loss:		0.129568
  top 1 accuracy:		100.00 %
0.18875116109848022
0.24173516035079956
0.21080023050308228
Batch of classes 8 out of 12 batches
Epoch 10 of 30 took 187.099s
  training loss:		0.193248
  validation loss:		0.093527
  top 1 accuracy:		100.00 %
0.133673295378685
0.15798281133174896
0.1824927031993866
Batch of classes 8 out of 12 batches
Epoch 11 of 30 took 185.321s
  training loss:		0.171190
  validation loss:		0.071081
  top 1 accuracy:		100.00 %
0.17449840903282166
0.190986767411232
0.12273672968149185
Batch of classes 8 out of 12 batches
Epoch 12 of 30 took 188.338s
  training loss:		0.169875
  validation loss:		0.079004
  top 1 accuracy:		100.00 %
0.15299785137176514
0.2403120994567871
0.14929582178592682
Batch of classes 8 out of 12 batches
Epoch 13 of 30 took 200.862s
  training loss:		0.170954
  validation loss:		0.066108
  top 1 accuracy:		100.00 %
0.1550750583410263
0.17865565419197083
0.17033424973487854
Batch of classes 8 out of 12 batches
Epoch 14 of 30 took 184.147s
  training loss:		0.165704
  validation loss:		0.072048
  top 1 accuracy:		100.00 %
0.1797623485326767
0.16539569199085236
0.14571160078048706
Batch of classes 8 out of 12 batches
Epoch 15 of 30 took 187.440s
  training loss:		0.165494
  validation loss:		0.063545
  top 1 accuracy:		100.00 %
0.27230164408683777
0.18016186356544495
0.22144296765327454
Batch of classes 8 out of 12 batches
Epoch 16 of 30 took 203.493s
  training loss:		0.164402
  validation loss:		0.060743
  top 1 accuracy:		100.00 %
0.17833000421524048
0.1796497404575348
0.19723063707351685
Batch of classes 8 out of 12 batches
Epoch 17 of 30 took 180.801s
  training loss:		0.164282
  validation loss:		0.057248
  top 1 accuracy:		100.00 %
0.15850429236888885
0.21975071728229523
0.1316215991973877
Batch of classes 8 out of 12 batches
Epoch 18 of 30 took 193.763s
  training loss:		0.165007
  validation loss:		0.056408
  top 1 accuracy:		100.00 %
0.13731010258197784
0.1765834242105484
0.1887039840221405
Batch of classes 8 out of 12 batches
Epoch 19 of 30 took 184.318s
  training loss:		0.167487
  validation loss:		0.057784
  top 1 accuracy:		100.00 %
0.1950318068265915
0.22578909993171692
0.2031562477350235
Batch of classes 8 out of 12 batches
Epoch 20 of 30 took 183.009s
  training loss:		0.164067
  validation loss:		0.081466
  top 1 accuracy:		100.00 %
Traceback (most recent call last):
  File "main_icarl_CNND.py", line 579, in <module>
    main()
  File "main_icarl_CNND.py", line 324, in main
    for patterns, labels in train_loader:  # Line 151
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 352, in __iter__
    return self._get_iterator()
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 294, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 801, in __init__
    w.start()
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/scratch_net/kringel/chuqli/conda_envs/icarl_pytorch/lib/python3.8/multiprocessing/popen_fork.py", line 70, in _launch
    self.pid = os.fork()
OSError: [Errno 12] Cannot allocate memory
