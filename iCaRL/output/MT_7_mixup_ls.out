----------------- Options ---------------
               add_binary: False                         
               batch_size: 32                            	[default: 64]
                   binary: False                         
            binary_weight: 0.5                           
                blur_prob: 0                             
                 blur_sig: 0.5                           
          checkpoints_dir: /scratch_net/kringel/chuqli/CNNDetection/checkpoints	[default: ./checkpoints]
                class_bal: False                         
           continue_train: False                         
                 cropSize: 224                           
                 data_aug: False                         
                 dataroot: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/test	[default: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL]
          earlystop_epoch: 5                             
                    epoch: latest                        
                 fine_tun: False                         
                    gpuid: [1]                           
                init_gain: 0.02                          
                  init_lr: 0.0005                        
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2                           
                 jpg_prob: 0                             
                 jpg_qual: 75                            
          label_smoothing: False                         
                 loadSize: 256                           
                    mixup: True                          	[default: False]
              mixup_alpha: 0.1                           
                     mode: binary                        
               model_name: resnet18                      
               model_type: resnet                        
            model_weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth	[default: None]
               multiclass: [0, 0, 1, 0, 0, 0, 0]         	[default: [1]]
                     name: icarl_df_7_mixup              	[default: experiment_name]
                  no_flip: False                         
              num_classes: 2                             
               num_epochs: 30                            	[default: 12]
              num_threads: 4                             
                  outfile: temp_0.1.csv                  
            pretrain_name:                               
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 20                            
         save_latest_freq: 2000                          
                 schedule: [10, 20, 30]                  	[default: [10]]
           serial_batches: False                         
          smoothing_alpha: 0.1                           
                   suffix:                               
                task_name: gaugan,biggan,cyclegan,imle,deepfake,crn,wild	[default: ]
              train_split: train                         
                val_split: val                           
----------------- End -------------------
{'All': 14}
Task order: ['gaugan', 'biggan', 'cyclegan', 'imle', 'deepfake', 'crn', 'wild']
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Classes in this batch: tensor([0, 1])
Data Size: 6000


Before first epoch
  validation loss:		1.309705
  top 1 accuracy:		17.05 %
  top 2 accuracy:		17.30 %
Batch of classes number 1 arrives ...
6.4154205322265625
0.4981195330619812
Batch of classes 1 out of 7 batches
Epoch 1 of 30 took 313.891s
  training loss:		0.951806
  validation loss:		0.256866
  top 1 accuracy:		79.80 %
  top 2 accuracy:		100.00 %
0.4711516499519348
0.4741033911705017
Batch of classes 1 out of 7 batches
Epoch 2 of 30 took 319.892s
  training loss:		0.463311
  validation loss:		0.267172
  top 1 accuracy:		86.95 %
  top 2 accuracy:		100.00 %
0.4084510803222656
0.22583337128162384
Batch of classes 1 out of 7 batches
Epoch 3 of 30 took 323.815s
  training loss:		0.358257
  validation loss:		0.236853
  top 1 accuracy:		89.90 %
  top 2 accuracy:		100.00 %
0.3110423684120178
0.24275676906108856
Batch of classes 1 out of 7 batches
Epoch 4 of 30 took 380.426s
  training loss:		0.315662
  validation loss:		0.188611
  top 1 accuracy:		89.15 %
  top 2 accuracy:		100.00 %
0.14996366202831268
0.22654758393764496
Batch of classes 1 out of 7 batches
Epoch 5 of 30 took 353.377s
  training loss:		0.294779
  validation loss:		0.277034
  top 1 accuracy:		90.00 %
  top 2 accuracy:		100.00 %
0.15907175838947296
0.19537939131259918
Batch of classes 1 out of 7 batches
Epoch 6 of 30 took 331.191s
  training loss:		0.260272
  validation loss:		0.247973
  top 1 accuracy:		93.55 %
  top 2 accuracy:		100.00 %
0.23424170911312103
0.11366761475801468
Batch of classes 1 out of 7 batches
Epoch 7 of 30 took 362.317s
  training loss:		0.230282
  validation loss:		0.334109
  top 1 accuracy:		81.35 %
  top 2 accuracy:		100.00 %
0.13358955085277557
0.03187396377325058
Batch of classes 1 out of 7 batches
Epoch 8 of 30 took 318.260s
  training loss:		0.227764
  validation loss:		0.216404
  top 1 accuracy:		96.90 %
  top 2 accuracy:		100.00 %
0.1068306714296341
0.43697917461395264
Batch of classes 1 out of 7 batches
Epoch 9 of 30 took 328.186s
  training loss:		0.231736
  validation loss:		0.235131
  top 1 accuracy:		95.25 %
  top 2 accuracy:		100.00 %
0.12010698765516281
0.11098603904247284
Batch of classes 1 out of 7 batches
Epoch 10 of 30 took 365.324s
  training loss:		0.254280
  validation loss:		0.200511
  top 1 accuracy:		95.10 %
  top 2 accuracy:		100.00 %
0.18950803577899933
0.017272748053073883
Batch of classes 1 out of 7 batches
Epoch 11 of 30 took 291.959s
  training loss:		0.155596
  validation loss:		0.240057
  top 1 accuracy:		98.65 %
  top 2 accuracy:		100.00 %
0.2546606957912445
0.2516479790210724
Batch of classes 1 out of 7 batches
Epoch 12 of 30 took 168.981s
  training loss:		0.143945
  validation loss:		0.265022
  top 1 accuracy:		98.45 %
  top 2 accuracy:		100.00 %
0.013745108619332314
0.48895713686943054
Batch of classes 1 out of 7 batches
Epoch 13 of 30 took 93.747s
  training loss:		0.161130
  validation loss:		0.240974
  top 1 accuracy:		98.60 %
  top 2 accuracy:		100.00 %
0.030284319072961807
0.020835401490330696
Batch of classes 1 out of 7 batches
Epoch 14 of 30 took 77.966s
  training loss:		0.141583
  validation loss:		0.240994
  top 1 accuracy:		99.05 %
  top 2 accuracy:		100.00 %
0.056482210755348206
0.2683252990245819
Batch of classes 1 out of 7 batches
Epoch 15 of 30 took 71.264s
  training loss:		0.152703
  validation loss:		0.231668
  top 1 accuracy:		98.75 %
  top 2 accuracy:		100.00 %
0.013635152019560337
0.007087886333465576
Batch of classes 1 out of 7 batches
Epoch 16 of 30 took 121.334s
  training loss:		0.129700
  validation loss:		0.243292
  top 1 accuracy:		98.70 %
  top 2 accuracy:		100.00 %
0.10496427118778229
0.388483464717865
Batch of classes 1 out of 7 batches
Epoch 17 of 30 took 97.542s
  training loss:		0.123956
  validation loss:		0.308683
  top 1 accuracy:		98.85 %
  top 2 accuracy:		100.00 %
0.020816385746002197
0.04661264270544052
Batch of classes 1 out of 7 batches
Epoch 18 of 30 took 149.974s
  training loss:		0.109551
  validation loss:		0.248575
  top 1 accuracy:		98.85 %
  top 2 accuracy:		100.00 %
0.03710323944687843
0.24795526266098022
Batch of classes 1 out of 7 batches
Epoch 19 of 30 took 102.495s
  training loss:		0.119342
  validation loss:		0.232301
  top 1 accuracy:		98.30 %
  top 2 accuracy:		100.00 %
0.023488279432058334
0.01034978125244379
Batch of classes 1 out of 7 batches
Epoch 20 of 30 took 97.906s
  training loss:		0.132978
  validation loss:		0.255246
  top 1 accuracy:		98.55 %
  top 2 accuracy:		100.00 %
0.06278438121080399
0.46792393922805786
Batch of classes 1 out of 7 batches
Epoch 21 of 30 took 145.680s
  training loss:		0.109021
  validation loss:		0.231152
  top 1 accuracy:		99.05 %
  top 2 accuracy:		100.00 %
0.008780296891927719
0.054917462170124054
Batch of classes 1 out of 7 batches
Epoch 22 of 30 took 82.127s
  training loss:		0.126954
  validation loss:		0.250912
  top 1 accuracy:		99.30 %
  top 2 accuracy:		100.00 %
0.02100362628698349
0.020062493160367012
Batch of classes 1 out of 7 batches
Epoch 23 of 30 took 69.946s
  training loss:		0.112462
  validation loss:		0.245643
  top 1 accuracy:		99.25 %
  top 2 accuracy:		100.00 %
0.03519636392593384
0.2114710658788681
Batch of classes 1 out of 7 batches
Epoch 24 of 30 took 71.190s
  training loss:		0.095034
  validation loss:		0.254539
  top 1 accuracy:		99.45 %
  top 2 accuracy:		100.00 %
0.02411389723420143
0.2894795536994934
Batch of classes 1 out of 7 batches
Epoch 25 of 30 took 76.112s
  training loss:		0.112722
  validation loss:		0.251757
  top 1 accuracy:		99.30 %
  top 2 accuracy:		100.00 %
0.005559026729315519
0.010170985013246536
Batch of classes 1 out of 7 batches
Epoch 26 of 30 took 73.758s
  training loss:		0.107489
  validation loss:		0.242535
  top 1 accuracy:		99.65 %
  top 2 accuracy:		100.00 %
0.5040357112884521
0.22120539844036102
Batch of classes 1 out of 7 batches
Epoch 27 of 30 took 90.868s
  training loss:		0.110588
  validation loss:		0.255168
  top 1 accuracy:		99.35 %
  top 2 accuracy:		100.00 %
0.025242075324058533
0.10174556821584702
Batch of classes 1 out of 7 batches
Epoch 28 of 30 took 87.052s
  training loss:		0.105618
  validation loss:		0.269843
  top 1 accuracy:		99.40 %
  top 2 accuracy:		100.00 %
0.09755019843578339
0.005836531985551119
Batch of classes 1 out of 7 batches
Epoch 29 of 30 took 74.621s
  training loss:		0.111122
  validation loss:		0.238598
  top 1 accuracy:		99.55 %
  top 2 accuracy:		100.00 %
0.02836586907505989
0.13627482950687408
Batch of classes 1 out of 7 batches
Epoch 30 of 30 took 73.467s
  training loss:		0.106076
  validation loss:		0.238934
  top 1 accuracy:		99.30 %
  top 2 accuracy:		100.00 %
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		99.45 %
  top 1 accuracy Hybrid 1       :		99.30 %
  top 1 accuracy NCM            :		99.45 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		99.50 %
  top 1 accuracy Hybrid 1       :		99.30 %
  top 1 accuracy NCM            :		99.50 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		99.45 %
  top 1 accuracy Hybrid 1       :		99.30 %
  top 1 accuracy NCM            :		99.45 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		99.50 %
  top 1 accuracy Hybrid 1       :		99.30 %
  top 1 accuracy NCM            :		99.50 %
Classes in this batch: tensor([2, 3])
Data Size: 2400


Before first epoch
  validation loss:		1.558018
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 2 arrives ...
8.545841217041016
1.3509148359298706
Batch of classes 2 out of 7 batches
Epoch 1 of 30 took 56.299s
  training loss:		2.066489
  validation loss:		0.158737
  top 1 accuracy:		56.50 %
  top 2 accuracy:		92.25 %
1.4456593990325928
1.0223846435546875
Batch of classes 2 out of 7 batches
Epoch 2 of 30 took 46.374s
  training loss:		1.184267
  validation loss:		0.130506
  top 1 accuracy:		82.38 %
  top 2 accuracy:		96.50 %
0.9893802404403687
0.7766482830047607
Batch of classes 2 out of 7 batches
Epoch 3 of 30 took 37.603s
  training loss:		1.037769
  validation loss:		0.156265
  top 1 accuracy:		73.62 %
  top 2 accuracy:		91.37 %
0.7489013075828552
0.8733108043670654
Batch of classes 2 out of 7 batches
Epoch 4 of 30 took 39.066s
  training loss:		0.949189
  validation loss:		0.130923
  top 1 accuracy:		87.88 %
  top 2 accuracy:		97.37 %
0.7456701397895813
0.5872769951820374
Batch of classes 2 out of 7 batches
Epoch 5 of 30 took 56.622s
  training loss:		0.894072
  validation loss:		0.115533
  top 1 accuracy:		87.37 %
  top 2 accuracy:		95.00 %
0.7001216411590576
0.7021457552909851
Batch of classes 2 out of 7 batches
Epoch 6 of 30 took 45.357s
  training loss:		0.893144
  validation loss:		0.121849
  top 1 accuracy:		88.88 %
  top 2 accuracy:		97.37 %
0.6491039991378784
0.7165720462799072
Batch of classes 2 out of 7 batches
Epoch 7 of 30 took 38.380s
  training loss:		0.841952
  validation loss:		0.118853
  top 1 accuracy:		92.37 %
  top 2 accuracy:		98.37 %
1.3066518306732178
0.6402735114097595
Batch of classes 2 out of 7 batches
Epoch 8 of 30 took 37.870s
  training loss:		0.804637
  validation loss:		0.102941
  top 1 accuracy:		91.62 %
  top 2 accuracy:		97.75 %
0.5691362619400024
1.7290339469909668
Batch of classes 2 out of 7 batches
Epoch 9 of 30 took 38.529s
  training loss:		0.774648
  validation loss:		0.106310
  top 1 accuracy:		91.75 %
  top 2 accuracy:		98.25 %
1.4362989664077759
0.5149401426315308
Batch of classes 2 out of 7 batches
Epoch 10 of 30 took 37.756s
  training loss:		0.764161
  validation loss:		0.105663
  top 1 accuracy:		95.38 %
  top 2 accuracy:		99.25 %
1.018239140510559
0.4721493124961853
Batch of classes 2 out of 7 batches
Epoch 11 of 30 took 38.038s
  training loss:		0.716704
  validation loss:		0.114496
  top 1 accuracy:		89.13 %
  top 2 accuracy:		97.87 %
0.5102964043617249
0.5179583430290222
Batch of classes 2 out of 7 batches
Epoch 12 of 30 took 38.047s
  training loss:		0.639345
  validation loss:		0.116661
  top 1 accuracy:		91.37 %
  top 2 accuracy:		98.50 %
1.5291380882263184
0.39900749921798706
Batch of classes 2 out of 7 batches
Epoch 13 of 30 took 38.849s
  training loss:		0.631205
  validation loss:		0.092234
  top 1 accuracy:		96.25 %
  top 2 accuracy:		99.25 %
0.5968835353851318
0.6524542570114136
Batch of classes 2 out of 7 batches
Epoch 14 of 30 took 38.096s
  training loss:		0.588941
  validation loss:		0.106644
  top 1 accuracy:		95.00 %
  top 2 accuracy:		99.12 %
0.42149725556373596
0.5033926367759705
Batch of classes 2 out of 7 batches
Epoch 15 of 30 took 39.092s
  training loss:		0.543096
  validation loss:		0.097496
  top 1 accuracy:		96.38 %
  top 2 accuracy:		98.87 %
0.41561341285705566
0.35563021898269653
Batch of classes 2 out of 7 batches
Epoch 16 of 30 took 37.872s
  training loss:		0.625668
  validation loss:		0.108342
  top 1 accuracy:		93.88 %
  top 2 accuracy:		98.62 %
0.3744439482688904
0.38369110226631165
Batch of classes 2 out of 7 batches
Epoch 17 of 30 took 39.946s
  training loss:		0.546640
  validation loss:		0.096428
  top 1 accuracy:		96.88 %
  top 2 accuracy:		98.75 %
0.48357340693473816
0.8329274654388428
Batch of classes 2 out of 7 batches
Epoch 18 of 30 took 37.855s
  training loss:		0.590007
  validation loss:		0.093974
  top 1 accuracy:		96.13 %
  top 2 accuracy:		99.12 %
0.4499989449977875
0.41650158166885376
Batch of classes 2 out of 7 batches
Epoch 19 of 30 took 39.534s
  training loss:		0.545501
  validation loss:		0.101256
  top 1 accuracy:		96.88 %
  top 2 accuracy:		98.87 %
0.4068804383277893
0.7753310799598694
Batch of classes 2 out of 7 batches
Epoch 20 of 30 took 38.725s
  training loss:		0.548123
  validation loss:		0.104134
  top 1 accuracy:		93.88 %
  top 2 accuracy:		98.50 %
0.40607956051826477
1.4397597312927246
Batch of classes 2 out of 7 batches
Epoch 21 of 30 took 37.961s
  training loss:		0.499738
  validation loss:		0.108538
  top 1 accuracy:		95.75 %
  top 2 accuracy:		99.00 %
0.38980749249458313
0.9143093824386597
Batch of classes 2 out of 7 batches
Epoch 22 of 30 took 38.935s
  training loss:		0.498244
  validation loss:		0.102881
  top 1 accuracy:		97.62 %
  top 2 accuracy:		99.50 %
0.31195858120918274
0.40582960844039917
Batch of classes 2 out of 7 batches
Epoch 23 of 30 took 38.937s
  training loss:		0.535370
  validation loss:		0.106041
  top 1 accuracy:		96.75 %
  top 2 accuracy:		99.00 %
0.3089238405227661
0.44590458273887634
Batch of classes 2 out of 7 batches
Epoch 24 of 30 took 38.872s
  training loss:		0.544617
  validation loss:		0.100127
  top 1 accuracy:		97.37 %
  top 2 accuracy:		98.87 %
0.35944440960884094
0.4089445471763611
Batch of classes 2 out of 7 batches
Epoch 25 of 30 took 38.510s
  training loss:		0.488530
  validation loss:		0.105935
  top 1 accuracy:		97.50 %
  top 2 accuracy:		99.25 %
0.3392961025238037
0.31542861461639404
Batch of classes 2 out of 7 batches
Epoch 26 of 30 took 38.591s
  training loss:		0.474538
  validation loss:		0.103853
  top 1 accuracy:		97.37 %
  top 2 accuracy:		99.50 %
0.42421776056289673
0.3281113803386688
Batch of classes 2 out of 7 batches
Epoch 27 of 30 took 38.601s
  training loss:		0.542648
  validation loss:		0.106973
  top 1 accuracy:		96.75 %
  top 2 accuracy:		99.50 %
0.37495124340057373
0.35460537672042847
Batch of classes 2 out of 7 batches
Epoch 28 of 30 took 38.111s
  training loss:		0.500473
  validation loss:		0.108153
  top 1 accuracy:		97.00 %
  top 2 accuracy:		99.00 %
0.35907280445098877
0.361555814743042
Batch of classes 2 out of 7 batches
Epoch 29 of 30 took 38.162s
  training loss:		0.506554
  validation loss:		0.100520
  top 1 accuracy:		97.25 %
  top 2 accuracy:		99.37 %
0.3484874665737152
0.30367007851600647
Batch of classes 2 out of 7 batches
Epoch 30 of 30 took 38.235s
  training loss:		0.511525
  validation loss:		0.108083
  top 1 accuracy:		96.38 %
  top 2 accuracy:		99.12 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		73.50 %
  top 1 accuracy Hybrid 1       :		58.35 %
  top 1 accuracy NCM            :		75.05 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		95.40 %
  top 1 accuracy Hybrid 1       :		95.10 %
  top 1 accuracy NCM            :		94.50 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		86.62 %
  top 1 accuracy Hybrid 1       :		96.38 %
  top 1 accuracy NCM            :		85.50 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		98.50 %
  top 1 accuracy Hybrid 1       :		98.75 %
  top 1 accuracy NCM            :		98.38 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		77.25 %
  top 1 accuracy Hybrid 1       :		69.21 %
  top 1 accuracy NCM            :		78.04 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		96.29 %
  top 1 accuracy Hybrid 1       :		96.14 %
  top 1 accuracy NCM            :		95.61 %
Classes in this batch: tensor([4, 5])
Data Size: 1572


Before first epoch
  validation loss:		0.982015
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 3 arrives ...
5.072512149810791
1.5542373657226562
Batch of classes 3 out of 7 batches
Epoch 1 of 30 took 89.063s
  training loss:		1.856978
  validation loss:		0.155934
  top 1 accuracy:		65.27 %
  top 2 accuracy:		94.27 %
1.0750459432601929
0.970897376537323
Batch of classes 3 out of 7 batches
Epoch 2 of 30 took 57.908s
  training loss:		1.192244
  validation loss:		0.131158
  top 1 accuracy:		85.31 %
  top 2 accuracy:		94.66 %
0.701124370098114
0.7245231866836548
Batch of classes 3 out of 7 batches
Epoch 3 of 30 took 42.743s
  training loss:		1.001332
  validation loss:		0.114025
  top 1 accuracy:		87.60 %
  top 2 accuracy:		95.23 %
0.7596471905708313
0.6533217430114746
Batch of classes 3 out of 7 batches
Epoch 4 of 30 took 40.840s
  training loss:		0.909465
  validation loss:		0.117641
  top 1 accuracy:		91.79 %
  top 2 accuracy:		96.76 %
0.8181583881378174
0.7995155453681946
Batch of classes 3 out of 7 batches
Epoch 5 of 30 took 36.927s
  training loss:		0.914374
  validation loss:		0.114279
  top 1 accuracy:		89.69 %
  top 2 accuracy:		97.14 %
0.7064017057418823
1.861572504043579
Batch of classes 3 out of 7 batches
Epoch 6 of 30 took 35.674s
  training loss:		0.887593
  validation loss:		0.120244
  top 1 accuracy:		91.98 %
  top 2 accuracy:		97.71 %
0.6790332794189453
0.7591238021850586
Batch of classes 3 out of 7 batches
Epoch 7 of 30 took 35.759s
  training loss:		0.818634
  validation loss:		0.134143
  top 1 accuracy:		83.97 %
  top 2 accuracy:		93.70 %
0.5059396028518677
0.6266207695007324
Batch of classes 3 out of 7 batches
Epoch 8 of 30 took 35.775s
  training loss:		0.740050
  validation loss:		0.116382
  top 1 accuracy:		90.27 %
  top 2 accuracy:		96.56 %
0.5335474610328674
0.6776288151741028
Batch of classes 3 out of 7 batches
Epoch 9 of 30 took 35.853s
  training loss:		0.727629
  validation loss:		0.105869
  top 1 accuracy:		94.27 %
  top 2 accuracy:		98.28 %
0.8269346952438354
0.6600226759910583
Batch of classes 3 out of 7 batches
Epoch 10 of 30 took 35.854s
  training loss:		0.793848
  validation loss:		0.107981
  top 1 accuracy:		96.18 %
  top 2 accuracy:		99.43 %
0.4843202531337738
0.5140014290809631
Batch of classes 3 out of 7 batches
Epoch 11 of 30 took 35.718s
  training loss:		0.633426
  validation loss:		0.103637
  top 1 accuracy:		95.23 %
  top 2 accuracy:		98.28 %
0.42607760429382324
0.48560309410095215
Batch of classes 3 out of 7 batches
Epoch 12 of 30 took 35.868s
  training loss:		0.630248
  validation loss:		0.098585
  top 1 accuracy:		96.95 %
  top 2 accuracy:		98.85 %
0.5526260137557983
0.9774177074432373
Batch of classes 3 out of 7 batches
Epoch 13 of 30 took 35.880s
  training loss:		0.659645
  validation loss:		0.107396
  top 1 accuracy:		95.61 %
  top 2 accuracy:		99.05 %
0.41587403416633606
0.3809686303138733
Batch of classes 3 out of 7 batches
Epoch 14 of 30 took 35.720s
  training loss:		0.675992
  validation loss:		0.100337
  top 1 accuracy:		96.76 %
  top 2 accuracy:		99.43 %
0.5349786877632141
0.4726400375366211
Batch of classes 3 out of 7 batches
Epoch 15 of 30 took 35.822s
  training loss:		0.684025
  validation loss:		0.103252
  top 1 accuracy:		95.42 %
  top 2 accuracy:		98.85 %
0.36899226903915405
0.4602763056755066
Batch of classes 3 out of 7 batches
Epoch 16 of 30 took 35.734s
  training loss:		0.591944
  validation loss:		0.107587
  top 1 accuracy:		93.70 %
  top 2 accuracy:		97.52 %
0.38398754596710205
0.4053645133972168
Batch of classes 3 out of 7 batches
Epoch 17 of 30 took 35.895s
  training loss:		0.618616
  validation loss:		0.101875
  top 1 accuracy:		96.56 %
  top 2 accuracy:		99.05 %
0.40318816900253296
0.40908384323120117
Batch of classes 3 out of 7 batches
Epoch 18 of 30 took 35.607s
  training loss:		0.647350
  validation loss:		0.100597
  top 1 accuracy:		96.95 %
  top 2 accuracy:		99.05 %
0.3991822898387909
0.5591106414794922
Batch of classes 3 out of 7 batches
Epoch 19 of 30 took 35.748s
  training loss:		0.589549
  validation loss:		0.105185
  top 1 accuracy:		97.14 %
  top 2 accuracy:		99.05 %
0.42377936840057373
0.39852091670036316
Batch of classes 3 out of 7 batches
Epoch 20 of 30 took 35.482s
  training loss:		0.618682
  validation loss:		0.099803
  top 1 accuracy:		96.76 %
  top 2 accuracy:		99.62 %
1.0459778308868408
1.2802382707595825
Batch of classes 3 out of 7 batches
Epoch 21 of 30 took 35.793s
  training loss:		0.641165
  validation loss:		0.102050
  top 1 accuracy:		96.76 %
  top 2 accuracy:		99.24 %
0.3730199337005615
0.4007475674152374
Batch of classes 3 out of 7 batches
Epoch 22 of 30 took 35.799s
  training loss:		0.545945
  validation loss:		0.094643
  top 1 accuracy:		96.95 %
  top 2 accuracy:		99.05 %
0.43126875162124634
0.3144720196723938
Batch of classes 3 out of 7 batches
Epoch 23 of 30 took 35.708s
  training loss:		0.594158
  validation loss:		0.104477
  top 1 accuracy:		95.42 %
  top 2 accuracy:		98.47 %
0.4451749920845032
0.46408939361572266
Batch of classes 3 out of 7 batches
Epoch 24 of 30 took 35.785s
  training loss:		0.580219
  validation loss:		0.100854
  top 1 accuracy:		97.71 %
  top 2 accuracy:		99.24 %
0.4096068739891052
0.3860706686973572
Batch of classes 3 out of 7 batches
Epoch 25 of 30 took 35.565s
  training loss:		0.520733
  validation loss:		0.096512
  top 1 accuracy:		97.71 %
  top 2 accuracy:		99.24 %
0.45343148708343506
0.3578943908214569
Batch of classes 3 out of 7 batches
Epoch 26 of 30 took 35.871s
  training loss:		0.611546
  validation loss:		0.092554
  top 1 accuracy:		97.52 %
  top 2 accuracy:		98.85 %
0.39231446385383606
0.3433361053466797
Batch of classes 3 out of 7 batches
Epoch 27 of 30 took 35.414s
  training loss:		0.582376
  validation loss:		0.102734
  top 1 accuracy:		97.33 %
  top 2 accuracy:		98.66 %
0.731998860836029
1.0514551401138306
Batch of classes 3 out of 7 batches
Epoch 28 of 30 took 35.642s
  training loss:		0.576154
  validation loss:		0.094294
  top 1 accuracy:		98.28 %
  top 2 accuracy:		99.62 %
0.6100766658782959
0.35912635922431946
Batch of classes 3 out of 7 batches
Epoch 29 of 30 took 35.563s
  training loss:		0.566710
  validation loss:		0.097179
  top 1 accuracy:		97.14 %
  top 2 accuracy:		99.24 %
0.31618258357048035
1.5466783046722412
Batch of classes 3 out of 7 batches
Epoch 30 of 30 took 35.622s
  training loss:		0.605619
  validation loss:		0.105657
  top 1 accuracy:		96.76 %
  top 2 accuracy:		98.47 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		77.40 %
  top 1 accuracy Hybrid 1       :		67.20 %
  top 1 accuracy NCM            :		77.50 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		95.00 %
  top 1 accuracy Hybrid 1       :		95.10 %
  top 1 accuracy NCM            :		95.00 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		70.75 %
  top 1 accuracy Hybrid 1       :		74.50 %
  top 1 accuracy NCM            :		71.25 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		97.38 %
  top 1 accuracy Hybrid 1       :		95.88 %
  top 1 accuracy NCM            :		97.38 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		96.18 %
  top 1 accuracy Hybrid 1       :		96.76 %
  top 1 accuracy NCM            :		94.85 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		98.09 %
  top 1 accuracy Hybrid 1       :		97.90 %
  top 1 accuracy NCM            :		97.90 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		78.76 %
  top 1 accuracy Hybrid 1       :		73.62 %
  top 1 accuracy NCM            :		78.73 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		96.06 %
  top 1 accuracy Hybrid 1       :		95.73 %
  top 1 accuracy NCM            :		96.03 %
Classes in this batch: tensor([6, 7])
Data Size: 7656


Before first epoch
  validation loss:		1.006248
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 4 arrives ...
8.803990364074707
1.0633437633514404
0.6647405028343201
Batch of classes 4 out of 7 batches
Epoch 1 of 30 took 118.687s
  training loss:		1.277490
  validation loss:		0.077909
  top 1 accuracy:		99.73 %
  top 2 accuracy:		100.00 %
0.7119449377059937
0.8780166506767273
0.7834211587905884
Batch of classes 4 out of 7 batches
Epoch 2 of 30 took 114.231s
  training loss:		0.823943
  validation loss:		0.105550
  top 1 accuracy:		99.80 %
  top 2 accuracy:		100.00 %
0.641905665397644
0.9204446077346802
1.199194073677063
Batch of classes 4 out of 7 batches
Epoch 3 of 30 took 121.466s
  training loss:		0.753525
  validation loss:		0.117182
  top 1 accuracy:		99.37 %
  top 2 accuracy:		99.92 %
0.6684927940368652
0.5154368877410889
0.6099613904953003
Batch of classes 4 out of 7 batches
Epoch 4 of 30 took 116.478s
  training loss:		0.744196
  validation loss:		0.107122
  top 1 accuracy:		99.88 %
  top 2 accuracy:		100.00 %
0.5577895641326904
0.641262412071228
0.5626736879348755
Batch of classes 4 out of 7 batches
Epoch 5 of 30 took 116.370s
  training loss:		0.718519
  validation loss:		0.106602
  top 1 accuracy:		99.45 %
  top 2 accuracy:		100.00 %
0.6074703931808472
0.567110002040863
0.6030693054199219
Batch of classes 4 out of 7 batches
Epoch 6 of 30 took 117.940s
  training loss:		0.717434
  validation loss:		0.096204
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.5642304420471191
0.7128719091415405
0.6239688396453857
Batch of classes 4 out of 7 batches
Epoch 7 of 30 took 112.551s
  training loss:		0.705134
  validation loss:		0.099905
  top 1 accuracy:		99.57 %
  top 2 accuracy:		99.84 %
0.524699866771698
0.5765933990478516
0.55698561668396
Batch of classes 4 out of 7 batches
Epoch 8 of 30 took 114.406s
  training loss:		0.697281
  validation loss:		0.100802
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.5356433391571045
0.7552738785743713
0.5601189732551575
Batch of classes 4 out of 7 batches
Epoch 9 of 30 took 112.507s
  training loss:		0.665806
  validation loss:		0.090358
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.834627628326416
0.5673214197158813
0.7016476392745972
Batch of classes 4 out of 7 batches
Epoch 10 of 30 took 113.241s
  training loss:		0.672134
  validation loss:		0.104504
  top 1 accuracy:		99.88 %
  top 2 accuracy:		99.96 %
1.2938270568847656
0.5470597147941589
0.6356649994850159
Batch of classes 4 out of 7 batches
Epoch 11 of 30 took 111.567s
  training loss:		0.636706
  validation loss:		0.088625
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.5154297947883606
1.0709949731826782
0.737120509147644
Batch of classes 4 out of 7 batches
Epoch 12 of 30 took 123.169s
  training loss:		0.622729
  validation loss:		0.083584
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.754450798034668
0.4922139644622803
0.5193458795547485
Batch of classes 4 out of 7 batches
Epoch 13 of 30 took 141.734s
  training loss:		0.623147
  validation loss:		0.088270
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.47095194458961487
0.4946630597114563
0.7405128479003906
Batch of classes 4 out of 7 batches
Epoch 14 of 30 took 244.657s
  training loss:		0.634318
  validation loss:		0.091367
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.5557515025138855
0.6145724654197693
0.6460225582122803
Batch of classes 4 out of 7 batches
Epoch 15 of 30 took 393.488s
  training loss:		0.621692
  validation loss:		0.087780
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.5130885243415833
0.5305312871932983
0.4971485435962677
Batch of classes 4 out of 7 batches
Epoch 16 of 30 took 450.200s
  training loss:		0.617186
  validation loss:		0.082117
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.8914943933486938
0.9271631240844727
0.49998003244400024
Batch of classes 4 out of 7 batches
Epoch 17 of 30 took 548.940s
  training loss:		0.638354
  validation loss:		0.085480
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.505490779876709
0.5240577459335327
0.4673975706100464
Batch of classes 4 out of 7 batches
Epoch 18 of 30 took 576.763s
  training loss:		0.617308
  validation loss:		0.089331
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.5230008363723755
0.6551045179367065
1.0765998363494873
Batch of classes 4 out of 7 batches
Epoch 19 of 30 took 538.039s
  training loss:		0.581538
  validation loss:		0.079628
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.5068427920341492
0.9346641898155212
0.478366494178772
Batch of classes 4 out of 7 batches
Epoch 20 of 30 took 534.098s
  training loss:		0.629613
  validation loss:		0.083688
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.522672176361084
0.547254204750061
0.4970720708370209
Batch of classes 4 out of 7 batches
Epoch 21 of 30 took 542.849s
  training loss:		0.603429
  validation loss:		0.087461
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.534325361251831
0.5413206815719604
0.598846435546875
Batch of classes 4 out of 7 batches
Epoch 22 of 30 took 539.092s
  training loss:		0.593343
  validation loss:		0.075004
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.492456316947937
1.0690064430236816
0.51246178150177
Batch of classes 4 out of 7 batches
Epoch 23 of 30 took 524.178s
  training loss:		0.614545
  validation loss:		0.083248
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.503585934638977
0.9621551632881165
0.48293399810791016
Batch of classes 4 out of 7 batches
Epoch 24 of 30 took 528.572s
  training loss:		0.597231
  validation loss:		0.086249
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.5076560974121094
0.9534018039703369
0.5156074166297913
Batch of classes 4 out of 7 batches
Epoch 25 of 30 took 532.019s
  training loss:		0.623497
  validation loss:		0.082251
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.5314573645591736
0.4923498034477234
0.980603814125061
Batch of classes 4 out of 7 batches
Epoch 26 of 30 took 534.151s
  training loss:		0.594596
  validation loss:		0.080021
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.0386912822723389
0.4745566248893738
0.5009021162986755
Batch of classes 4 out of 7 batches
Epoch 27 of 30 took 573.856s
  training loss:		0.611409
  validation loss:		0.081439
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.4734703302383423
0.5136660933494568
0.7335019111633301
Batch of classes 4 out of 7 batches
Epoch 28 of 30 took 561.066s
  training loss:		0.613566
  validation loss:		0.088394
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.5078845620155334
0.5245655179023743
0.48649001121520996
Batch of classes 4 out of 7 batches
Epoch 29 of 30 took 557.551s
  training loss:		0.607011
  validation loss:		0.081278
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.48316192626953125
0.7326077222824097
0.46120625734329224
Batch of classes 4 out of 7 batches
Epoch 30 of 30 took 484.620s
  training loss:		0.588083
  validation loss:		0.082095
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		81.20 %
  top 1 accuracy Hybrid 1       :		73.20 %
  top 1 accuracy NCM            :		81.70 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		94.80 %
  top 1 accuracy Hybrid 1       :		93.05 %
  top 1 accuracy NCM            :		94.85 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		72.25 %
  top 1 accuracy Hybrid 1       :		70.75 %
  top 1 accuracy NCM            :		73.50 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		96.25 %
  top 1 accuracy Hybrid 1       :		93.62 %
  top 1 accuracy NCM            :		96.38 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		92.94 %
  top 1 accuracy Hybrid 1       :		94.27 %
  top 1 accuracy NCM            :		92.94 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		96.56 %
  top 1 accuracy Hybrid 1       :		95.42 %
  top 1 accuracy NCM            :		96.56 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.92 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		99.92 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		100.00 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		89.16 %
  top 1 accuracy Hybrid 1       :		86.39 %
  top 1 accuracy NCM            :		89.50 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		97.41 %
  top 1 accuracy Hybrid 1       :		96.36 %
  top 1 accuracy NCM            :		97.45 %
Classes in this batch: tensor([8, 9])
Data Size: 3248


Before first epoch
  validation loss:		0.858929
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 5 arrives ...
6.683073997497559
1.636182427406311
Batch of classes 5 out of 7 batches
Epoch 1 of 30 took 189.264s
  training loss:		1.760208
  validation loss:		0.204040
  top 1 accuracy:		50.55 %
  top 2 accuracy:		99.54 %
1.4886448383331299
1.4725621938705444
Batch of classes 5 out of 7 batches
Epoch 2 of 30 took 176.188s
  training loss:		1.175719
  validation loss:		0.131070
  top 1 accuracy:		93.99 %
  top 2 accuracy:		98.98 %
0.7721015810966492
0.6511247754096985
Batch of classes 5 out of 7 batches
Epoch 3 of 30 took 172.889s
  training loss:		0.926375
  validation loss:		0.129024
  top 1 accuracy:		95.93 %
  top 2 accuracy:		98.34 %
1.8977992534637451
0.9545083045959473
Batch of classes 5 out of 7 batches
Epoch 4 of 30 took 166.512s
  training loss:		0.904165
  validation loss:		0.133133
  top 1 accuracy:		96.21 %
  top 2 accuracy:		98.52 %
0.639971911907196
0.6216295957565308
Batch of classes 5 out of 7 batches
Epoch 5 of 30 took 163.400s
  training loss:		0.858780
  validation loss:		0.137967
  top 1 accuracy:		96.40 %
  top 2 accuracy:		98.71 %
1.6610215902328491
0.6053718328475952
Batch of classes 5 out of 7 batches
Epoch 6 of 30 took 162.502s
  training loss:		0.828939
  validation loss:		0.128984
  top 1 accuracy:		95.75 %
  top 2 accuracy:		98.98 %
0.6870990991592407
0.7864124774932861
Batch of classes 5 out of 7 batches
Epoch 7 of 30 took 172.544s
  training loss:		0.800156
  validation loss:		0.141478
  top 1 accuracy:		95.93 %
  top 2 accuracy:		98.80 %
0.6077046990394592
0.6025391817092896
Batch of classes 5 out of 7 batches
Epoch 8 of 30 took 167.478s
  training loss:		0.777116
  validation loss:		0.126551
  top 1 accuracy:		96.21 %
  top 2 accuracy:		98.61 %
0.7727199792861938
0.5889930129051208
Batch of classes 5 out of 7 batches
Epoch 9 of 30 took 186.956s
  training loss:		0.796792
  validation loss:		0.141039
  top 1 accuracy:		93.81 %
  top 2 accuracy:		97.50 %
0.808874249458313
0.6125355958938599
Batch of classes 5 out of 7 batches
Epoch 10 of 30 took 172.348s
  training loss:		0.758678
  validation loss:		0.124185
  top 1 accuracy:		93.35 %
  top 2 accuracy:		98.15 %
0.5398203134536743
0.9979503154754639
Batch of classes 5 out of 7 batches
Epoch 11 of 30 took 162.537s
  training loss:		0.719552
  validation loss:		0.127468
  top 1 accuracy:		96.67 %
  top 2 accuracy:		98.80 %
0.7244291305541992
0.6573158502578735
Batch of classes 5 out of 7 batches
Epoch 12 of 30 took 161.602s
  training loss:		0.723546
  validation loss:		0.119018
  top 1 accuracy:		96.21 %
  top 2 accuracy:		98.80 %
0.46772047877311707
0.5501139760017395
Batch of classes 5 out of 7 batches
Epoch 13 of 30 took 170.028s
  training loss:		0.711589
  validation loss:		0.123263
  top 1 accuracy:		96.40 %
  top 2 accuracy:		98.61 %
0.5939246416091919
0.52227383852005
Batch of classes 5 out of 7 batches
Epoch 14 of 30 took 163.798s
  training loss:		0.702377
  validation loss:		0.138969
  top 1 accuracy:		96.40 %
  top 2 accuracy:		98.61 %
0.5227861404418945
1.1413826942443848
Batch of classes 5 out of 7 batches
Epoch 15 of 30 took 197.243s
  training loss:		0.745167
  validation loss:		0.119785
  top 1 accuracy:		96.49 %
  top 2 accuracy:		98.61 %
0.5259974002838135
0.48177844285964966
Batch of classes 5 out of 7 batches
Epoch 16 of 30 took 146.633s
  training loss:		0.677924
  validation loss:		0.129493
  top 1 accuracy:		96.30 %
  top 2 accuracy:		98.61 %
1.3109749555587769
0.9693830013275146
Batch of classes 5 out of 7 batches
Epoch 17 of 30 took 112.960s
  training loss:		0.667005
  validation loss:		0.134260
  top 1 accuracy:		96.77 %
  top 2 accuracy:		99.26 %
0.5279806852340698
0.5123134851455688
Batch of classes 5 out of 7 batches
Epoch 18 of 30 took 71.571s
  training loss:		0.674636
  validation loss:		0.127345
  top 1 accuracy:		96.77 %
  top 2 accuracy:		98.61 %
0.652687132358551
1.3853191137313843
Batch of classes 5 out of 7 batches
Epoch 19 of 30 took 68.880s
  training loss:		0.687154
  validation loss:		0.136171
  top 1 accuracy:		96.49 %
  top 2 accuracy:		98.89 %
0.715886116027832
0.5868241786956787
Batch of classes 5 out of 7 batches
Epoch 20 of 30 took 66.696s
  training loss:		0.704607
  validation loss:		0.123679
  top 1 accuracy:		96.40 %
  top 2 accuracy:		99.54 %
0.49611178040504456
0.5155232548713684
Batch of classes 5 out of 7 batches
Epoch 21 of 30 took 56.104s
  training loss:		0.649387
  validation loss:		0.125439
  top 1 accuracy:		96.58 %
  top 2 accuracy:		98.71 %
1.4167730808258057
0.47901612520217896
Batch of classes 5 out of 7 batches
Epoch 22 of 30 took 56.283s
  training loss:		0.718088
  validation loss:		0.127489
  top 1 accuracy:		96.77 %
  top 2 accuracy:		98.61 %
0.6768429279327393
0.5968869924545288
Batch of classes 5 out of 7 batches
Epoch 23 of 30 took 54.424s
  training loss:		0.629785
  validation loss:		0.127873
  top 1 accuracy:		96.67 %
  top 2 accuracy:		98.52 %
0.5077170729637146
1.3926002979278564
Batch of classes 5 out of 7 batches
Epoch 24 of 30 took 71.856s
  training loss:		0.686579
  validation loss:		0.127375
  top 1 accuracy:		96.67 %
  top 2 accuracy:		98.61 %
0.48935627937316895
0.6000245809555054
Batch of classes 5 out of 7 batches
Epoch 25 of 30 took 53.448s
  training loss:		0.656662
  validation loss:		0.127063
  top 1 accuracy:		96.77 %
  top 2 accuracy:		98.89 %
0.5607911348342896
0.4718726575374603
Batch of classes 5 out of 7 batches
Epoch 26 of 30 took 53.821s
  training loss:		0.700096
  validation loss:		0.130397
  top 1 accuracy:		96.86 %
  top 2 accuracy:		98.80 %
0.5726640820503235
0.6086781024932861
Batch of classes 5 out of 7 batches
Epoch 27 of 30 took 53.480s
  training loss:		0.660977
  validation loss:		0.125419
  top 1 accuracy:		96.86 %
  top 2 accuracy:		98.98 %
0.5049737095832825
0.4907340407371521
Batch of classes 5 out of 7 batches
Epoch 28 of 30 took 54.615s
  training loss:		0.628853
  validation loss:		0.123801
  top 1 accuracy:		96.49 %
  top 2 accuracy:		99.26 %
0.5420136451721191
0.526711642742157
Batch of classes 5 out of 7 batches
Epoch 29 of 30 took 53.657s
  training loss:		0.669275
  validation loss:		0.128975
  top 1 accuracy:		96.77 %
  top 2 accuracy:		98.43 %
0.969022810459137
0.59256511926651
Batch of classes 5 out of 7 batches
Epoch 30 of 30 took 53.773s
  training loss:		0.639887
  validation loss:		0.127353
  top 1 accuracy:		96.30 %
  top 2 accuracy:		98.61 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		77.75 %
  top 1 accuracy Hybrid 1       :		70.85 %
  top 1 accuracy NCM            :		77.50 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		90.60 %
  top 1 accuracy Hybrid 1       :		89.75 %
  top 1 accuracy NCM            :		90.60 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		71.12 %
  top 1 accuracy Hybrid 1       :		70.12 %
  top 1 accuracy NCM            :		72.25 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		94.38 %
  top 1 accuracy Hybrid 1       :		90.50 %
  top 1 accuracy NCM            :		94.75 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		91.98 %
  top 1 accuracy Hybrid 1       :		92.94 %
  top 1 accuracy NCM            :		91.79 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		95.80 %
  top 1 accuracy Hybrid 1       :		94.66 %
  top 1 accuracy NCM            :		95.42 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.73 %
  top 1 accuracy Hybrid 1       :		99.92 %
  top 1 accuracy NCM            :		99.65 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.84 %
  top 1 accuracy Hybrid 1       :		99.92 %
  top 1 accuracy NCM            :		99.84 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		95.56 %
  top 1 accuracy Hybrid 1       :		96.30 %
  top 1 accuracy NCM            :		95.56 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		96.30 %
  top 1 accuracy Hybrid 1       :		96.30 %
  top 1 accuracy NCM            :		96.30 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		88.89 %
  top 1 accuracy Hybrid 1       :		87.05 %
  top 1 accuracy NCM            :		88.90 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		95.70 %
  top 1 accuracy Hybrid 1       :		94.96 %
  top 1 accuracy NCM            :		95.72 %
Classes in this batch: tensor([10, 11])
Data Size: 7658


Before first epoch
  validation loss:		1.043080
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 6 arrives ...
7.48735237121582
0.657034695148468
1.4908018112182617
Batch of classes 6 out of 7 batches
Epoch 1 of 30 took 470.913s
  training loss:		1.171634
  validation loss:		0.105758
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.5528609752655029
0.6840166449546814
0.8856801986694336
Batch of classes 6 out of 7 batches
Epoch 2 of 30 took 458.017s
  training loss:		0.830014
  validation loss:		0.099948
  top 1 accuracy:		99.88 %
  top 2 accuracy:		100.00 %
1.6409786939620972
0.635155200958252
0.6200041770935059
Batch of classes 6 out of 7 batches
Epoch 3 of 30 took 488.077s
  training loss:		0.772624
  validation loss:		0.098855
  top 1 accuracy:		99.88 %
  top 2 accuracy:		100.00 %
0.5650791525840759
0.5782063007354736
0.5352196097373962
Batch of classes 6 out of 7 batches
Epoch 4 of 30 took 491.757s
  training loss:		0.764502
  validation loss:		0.100494
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.5939404368400574
0.7077601552009583
0.6620638370513916
Batch of classes 6 out of 7 batches
Epoch 5 of 30 took 492.886s
  training loss:		0.734574
  validation loss:		0.092774
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.8075611591339111
0.9832396507263184
0.5830549597740173
Batch of classes 6 out of 7 batches
Epoch 6 of 30 took 496.009s
  training loss:		0.751475
  validation loss:		0.095475
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.6232154369354248
0.6648101210594177
1.3445978164672852
Batch of classes 6 out of 7 batches
Epoch 7 of 30 took 512.377s
  training loss:		0.735328
  validation loss:		0.086083
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.758154034614563
0.6013309955596924
0.5098562836647034
Batch of classes 6 out of 7 batches
Epoch 8 of 30 took 506.930s
  training loss:		0.720685
  validation loss:		0.094046
  top 1 accuracy:		99.92 %
  top 2 accuracy:		99.96 %
0.5417481064796448
0.6684777736663818
0.7898672819137573
Batch of classes 6 out of 7 batches
Epoch 9 of 30 took 539.925s
  training loss:		0.695864
  validation loss:		0.087436
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
0.5861995220184326
0.5680325031280518
0.590826153755188
Batch of classes 6 out of 7 batches
Epoch 10 of 30 took 587.911s
  training loss:		0.715262
  validation loss:		0.099212
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.6519414186477661
0.5327399969100952
0.5746790766716003
Batch of classes 6 out of 7 batches
Epoch 11 of 30 took 557.716s
  training loss:		0.637203
  validation loss:		0.088922
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.5330822467803955
0.5905981063842773
0.6137394905090332
Batch of classes 6 out of 7 batches
Epoch 12 of 30 took 555.470s
  training loss:		0.655829
  validation loss:		0.086212
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.756097137928009
0.4886853098869324
0.5769607424736023
Batch of classes 6 out of 7 batches
Epoch 13 of 30 took 518.940s
  training loss:		0.625695
  validation loss:		0.086221
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.7267827987670898
0.5318909883499146
0.49381399154663086
Batch of classes 6 out of 7 batches
Epoch 14 of 30 took 546.156s
  training loss:		0.619850
  validation loss:		0.082203
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
0.5083436965942383
0.5279042720794678
0.5302146077156067
Batch of classes 6 out of 7 batches
Epoch 15 of 30 took 566.211s
  training loss:		0.633750
  validation loss:		0.082124
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.5144331455230713
0.5322076678276062
0.542364239692688
Batch of classes 6 out of 7 batches
Epoch 16 of 30 took 592.454s
  training loss:		0.628279
  validation loss:		0.082303
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.5458179712295532
0.6827406287193298
0.5184162259101868
Batch of classes 6 out of 7 batches
Epoch 17 of 30 took 557.297s
  training loss:		0.630686
  validation loss:		0.081266
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.5225431323051453
0.904090404510498
0.5071887373924255
Batch of classes 6 out of 7 batches
Epoch 18 of 30 took 580.827s
  training loss:		0.618871
  validation loss:		0.080822
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.553226113319397
1.0695114135742188
0.5357298254966736
Batch of classes 6 out of 7 batches
Epoch 19 of 30 took 559.033s
  training loss:		0.626975
  validation loss:		0.077380
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.5482168793678284
0.5177945494651794
0.5285012125968933
Batch of classes 6 out of 7 batches
Epoch 20 of 30 took 540.029s
  training loss:		0.650534
  validation loss:		0.087953
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1552109718322754
0.9074358344078064
0.5308831334114075
Batch of classes 6 out of 7 batches
Epoch 21 of 30 took 556.592s
  training loss:		0.609741
  validation loss:		0.083151
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.917040228843689
0.5236436724662781
0.5489503741264343
Batch of classes 6 out of 7 batches
Epoch 22 of 30 took 574.644s
  training loss:		0.595601
  validation loss:		0.081235
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.4965859353542328
0.5557166337966919
0.5133050680160522
Batch of classes 6 out of 7 batches
Epoch 23 of 30 took 610.561s
  training loss:		0.629240
  validation loss:		0.080181
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.5027437210083008
1.1006754636764526
0.5281450748443604
Batch of classes 6 out of 7 batches
Epoch 24 of 30 took 549.886s
  training loss:		0.625101
  validation loss:		0.077821
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.717107355594635
0.5002965927124023
0.5191928744316101
Batch of classes 6 out of 7 batches
Epoch 25 of 30 took 480.657s
  training loss:		0.622280
  validation loss:		0.079883
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.0334900617599487
0.5190374851226807
1.0899492502212524
Batch of classes 6 out of 7 batches
Epoch 26 of 30 took 474.850s
  training loss:		0.625737
  validation loss:		0.076158
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.5284719467163086
0.5419332385063171
0.49793845415115356
Batch of classes 6 out of 7 batches
Epoch 27 of 30 took 486.218s
  training loss:		0.622701
  validation loss:		0.077548
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1836832761764526
0.5361692905426025
0.4953478276729584
Batch of classes 6 out of 7 batches
Epoch 28 of 30 took 506.966s
  training loss:		0.609737
  validation loss:		0.087007
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.5397306680679321
0.5375332832336426
0.5265543460845947
Batch of classes 6 out of 7 batches
Epoch 29 of 30 took 539.674s
  training loss:		0.615212
  validation loss:		0.076429
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.0941340923309326
0.6249820590019226
0.5052688121795654
Batch of classes 6 out of 7 batches
Epoch 30 of 30 took 539.806s
  training loss:		0.602898
  validation loss:		0.080838
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		75.85 %
  top 1 accuracy Hybrid 1       :		67.00 %
  top 1 accuracy NCM            :		76.25 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		88.70 %
  top 1 accuracy Hybrid 1       :		88.85 %
  top 1 accuracy NCM            :		89.15 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		69.38 %
  top 1 accuracy Hybrid 1       :		60.12 %
  top 1 accuracy NCM            :		69.38 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		94.38 %
  top 1 accuracy Hybrid 1       :		91.50 %
  top 1 accuracy NCM            :		93.75 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		91.41 %
  top 1 accuracy Hybrid 1       :		95.42 %
  top 1 accuracy NCM            :		91.22 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		96.56 %
  top 1 accuracy Hybrid 1       :		96.37 %
  top 1 accuracy NCM            :		96.56 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		68.53 %
  top 1 accuracy Hybrid 1       :		49.96 %
  top 1 accuracy NCM            :		78.45 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		100.00 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		95.84 %
  top 1 accuracy Hybrid 1       :		96.12 %
  top 1 accuracy NCM            :		96.03 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		95.84 %
  top 1 accuracy Hybrid 1       :		96.12 %
  top 1 accuracy NCM            :		96.03 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		81.47 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		71.51 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		100.00 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		77.98 %
  top 1 accuracy Hybrid 1       :		75.58 %
  top 1 accuracy NCM            :		78.07 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		96.49 %
  top 1 accuracy Hybrid 1       :		96.30 %
  top 1 accuracy NCM            :		96.55 %
Classes in this batch: tensor([12, 13])
Data Size: 6208


Before first epoch
  validation loss:		0.874148
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 7 arrives ...
5.620434761047363
1.7301626205444336
1.4050034284591675
Batch of classes 7 out of 7 batches
Epoch 1 of 30 took 311.455s
  training loss:		1.686377
  validation loss:		0.191583
  top 1 accuracy:		66.12 %
  top 2 accuracy:		97.87 %
1.5440030097961426
1.6993805170059204
1.2022637128829956
Batch of classes 7 out of 7 batches
Epoch 2 of 30 took 281.487s
  training loss:		1.344830
  validation loss:		0.188989
  top 1 accuracy:		75.04 %
  top 2 accuracy:		99.27 %
1.2485030889511108
1.3822826147079468
1.4934048652648926
Batch of classes 7 out of 7 batches
Epoch 3 of 30 took 281.634s
  training loss:		1.273725
  validation loss:		0.180054
  top 1 accuracy:		74.79 %
  top 2 accuracy:		97.19 %
1.0395809412002563
1.1073799133300781
1.1609338521957397
Batch of classes 7 out of 7 batches
Epoch 4 of 30 took 260.562s
  training loss:		1.207208
  validation loss:		0.188525
  top 1 accuracy:		73.53 %
  top 2 accuracy:		98.79 %
1.017896056175232
1.6548845767974854
1.761003017425537
Batch of classes 7 out of 7 batches
Epoch 5 of 30 took 260.685s
  training loss:		1.179576
  validation loss:		0.191207
  top 1 accuracy:		72.08 %
  top 2 accuracy:		95.59 %
1.030666708946228
1.6048529148101807
1.1228179931640625
Batch of classes 7 out of 7 batches
Epoch 6 of 30 took 269.869s
  training loss:		1.146817
  validation loss:		0.180626
  top 1 accuracy:		78.14 %
  top 2 accuracy:		98.45 %
1.19596266746521
1.1247062683105469
1.0398963689804077
Batch of classes 7 out of 7 batches
Epoch 7 of 30 took 265.991s
  training loss:		1.122805
  validation loss:		0.205968
  top 1 accuracy:		68.25 %
  top 2 accuracy:		95.59 %
0.9825208187103271
0.9969809055328369
1.1976922750473022
Batch of classes 7 out of 7 batches
Epoch 8 of 30 took 261.738s
  training loss:		1.126886
  validation loss:		0.182357
  top 1 accuracy:		66.65 %
  top 2 accuracy:		94.43 %
1.0702533721923828
1.0279734134674072
0.9492570161819458
Batch of classes 7 out of 7 batches
Epoch 9 of 30 took 269.765s
  training loss:		1.095946
  validation loss:		0.161445
  top 1 accuracy:		78.67 %
  top 2 accuracy:		98.01 %
1.0150398015975952
1.4461584091186523
1.0508008003234863
Batch of classes 7 out of 7 batches
Epoch 10 of 30 took 270.479s
  training loss:		1.050048
  validation loss:		0.165762
  top 1 accuracy:		75.96 %
  top 2 accuracy:		97.82 %
0.8132642507553101
0.7296540141105652
0.7267376184463501
Batch of classes 7 out of 7 batches
Epoch 11 of 30 took 275.666s
  training loss:		0.988100
  validation loss:		0.172777
  top 1 accuracy:		80.51 %
  top 2 accuracy:		97.96 %
0.7602987289428711
0.7528176307678223
0.7993943691253662
Batch of classes 7 out of 7 batches
Epoch 12 of 30 took 275.493s
  training loss:		0.983007
  validation loss:		0.169911
  top 1 accuracy:		81.48 %
  top 2 accuracy:		97.77 %
0.8310725688934326
0.7965365648269653
0.6586655378341675
Batch of classes 7 out of 7 batches
Epoch 13 of 30 took 276.825s
  training loss:		0.959753
  validation loss:		0.168190
  top 1 accuracy:		80.56 %
  top 2 accuracy:		97.38 %
1.0554355382919312
0.8583618998527527
1.3274848461151123
Batch of classes 7 out of 7 batches
Epoch 14 of 30 took 283.019s
  training loss:		0.939521
  validation loss:		0.171893
  top 1 accuracy:		79.50 %
  top 2 accuracy:		96.90 %
1.5515904426574707
0.7401487827301025
0.8714049458503723
Batch of classes 7 out of 7 batches
Epoch 15 of 30 took 282.386s
  training loss:		0.937181
  validation loss:		0.180896
  top 1 accuracy:		79.69 %
  top 2 accuracy:		96.56 %
0.8707612752914429
1.0952060222625732
0.9056198596954346
Batch of classes 7 out of 7 batches
Epoch 16 of 30 took 280.410s
  training loss:		0.906954
  validation loss:		0.186334
  top 1 accuracy:		79.30 %
  top 2 accuracy:		98.16 %
0.7098420262336731
0.8535439372062683
1.3174548149108887
Batch of classes 7 out of 7 batches
Epoch 17 of 30 took 280.153s
  training loss:		0.904603
  validation loss:		0.174398
  top 1 accuracy:		80.90 %
  top 2 accuracy:		96.90 %
0.7327364683151245
0.7104660868644714
0.7378861904144287
Batch of classes 7 out of 7 batches
Epoch 18 of 30 took 282.872s
  training loss:		0.902297
  validation loss:		0.176761
  top 1 accuracy:		79.06 %
  top 2 accuracy:		95.40 %
0.7614309787750244
0.8438534736633301
1.600447654724121
Batch of classes 7 out of 7 batches
Epoch 19 of 30 took 282.381s
  training loss:		0.881549
  validation loss:		0.168848
  top 1 accuracy:		79.45 %
  top 2 accuracy:		97.29 %
1.3444550037384033
0.8062806129455566
0.7682151794433594
Batch of classes 7 out of 7 batches
Epoch 20 of 30 took 287.170s
  training loss:		0.870506
  validation loss:		0.179096
  top 1 accuracy:		79.84 %
  top 2 accuracy:		94.04 %
0.6045330166816711
1.5281715393066406
0.6982330083847046
Batch of classes 7 out of 7 batches
Epoch 21 of 30 took 283.353s
  training loss:		0.855048
  validation loss:		0.175852
  top 1 accuracy:		79.93 %
  top 2 accuracy:		96.22 %
0.6361713409423828
1.2138898372650146
0.9165255427360535
Batch of classes 7 out of 7 batches
Epoch 22 of 30 took 278.795s
  training loss:		0.842382
  validation loss:		0.173080
  top 1 accuracy:		80.95 %
  top 2 accuracy:		93.50 %
1.1342554092407227
0.6347734928131104
0.9532392024993896
Batch of classes 7 out of 7 batches
Epoch 23 of 30 took 282.312s
  training loss:		0.850461
  validation loss:		0.177144
  top 1 accuracy:		81.39 %
  top 2 accuracy:		95.25 %
0.7734313607215881
0.5745102167129517
1.392216682434082
Batch of classes 7 out of 7 batches
Epoch 24 of 30 took 286.042s
  training loss:		0.827783
  validation loss:		0.175266
  top 1 accuracy:		80.90 %
  top 2 accuracy:		93.41 %
0.8251517415046692
1.0245020389556885
0.7920715808868408
Batch of classes 7 out of 7 batches
Epoch 25 of 30 took 279.200s
  training loss:		0.842722
  validation loss:		0.181211
  top 1 accuracy:		80.03 %
  top 2 accuracy:		95.40 %
0.6820521354675293
0.6808972358703613
1.3587660789489746
Batch of classes 7 out of 7 batches
Epoch 26 of 30 took 285.536s
  training loss:		0.819495
  validation loss:		0.179715
  top 1 accuracy:		80.80 %
  top 2 accuracy:		93.12 %
0.675644040107727
0.6603963971138
0.6473075151443481
Batch of classes 7 out of 7 batches
Epoch 27 of 30 took 290.037s
  training loss:		0.810552
  validation loss:		0.173732
  top 1 accuracy:		81.24 %
  top 2 accuracy:		96.56 %
0.7610704302787781
1.0264191627502441
0.5540169477462769
Batch of classes 7 out of 7 batches
Epoch 28 of 30 took 285.830s
  training loss:		0.838456
  validation loss:		0.176601
  top 1 accuracy:		81.14 %
  top 2 accuracy:		92.54 %
0.7493539452552795
0.6709813475608826
0.8877483010292053
Batch of classes 7 out of 7 batches
Epoch 29 of 30 took 288.738s
  training loss:		0.811857
  validation loss:		0.174869
  top 1 accuracy:		80.27 %
  top 2 accuracy:		95.44 %
0.7220525741577148
1.201028823852539
1.6065974235534668
Batch of classes 7 out of 7 batches
Epoch 30 of 30 took 286.333s
  training loss:		0.818126
  validation loss:		0.176461
  top 1 accuracy:		80.76 %
  top 2 accuracy:		92.73 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		67.30 %
  top 1 accuracy Hybrid 1       :		60.85 %
  top 1 accuracy NCM            :		66.75 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		79.85 %
  top 1 accuracy Hybrid 1       :		79.15 %
  top 1 accuracy NCM            :		79.75 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		60.75 %
  top 1 accuracy Hybrid 1       :		59.38 %
  top 1 accuracy NCM            :		62.25 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		88.25 %
  top 1 accuracy Hybrid 1       :		86.38 %
  top 1 accuracy NCM            :		88.62 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		87.02 %
  top 1 accuracy Hybrid 1       :		88.17 %
  top 1 accuracy NCM            :		87.60 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		94.47 %
  top 1 accuracy Hybrid 1       :		93.51 %
  top 1 accuracy NCM            :		94.27 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		72.92 %
  top 1 accuracy Hybrid 1       :		57.41 %
  top 1 accuracy NCM            :		73.43 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.92 %
  top 1 accuracy Hybrid 1       :		99.92 %
  top 1 accuracy NCM            :		99.88 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		85.95 %
  top 1 accuracy Hybrid 1       :		85.86 %
  top 1 accuracy NCM            :		86.14 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		93.99 %
  top 1 accuracy Hybrid 1       :		93.72 %
  top 1 accuracy NCM            :		94.18 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		76.84 %
  top 1 accuracy Hybrid 1       :		92.48 %
  top 1 accuracy NCM            :		76.21 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.96 %
  top 1 accuracy Hybrid 1       :		99.92 %
  top 1 accuracy NCM            :		99.96 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		81.14 %
  top 1 accuracy Hybrid 1       :		80.76 %
  top 1 accuracy NCM            :		81.00 %
Binary accuracy:
Final results on wild classes:
  top 1 accuracy iCaRL          :		81.34 %
  top 1 accuracy Hybrid 1       :		80.76 %
  top 1 accuracy NCM            :		81.39 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		75.30 %
  top 1 accuracy Hybrid 1       :		74.09 %
  top 1 accuracy NCM            :		75.30 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		91.54 %
  top 1 accuracy Hybrid 1       :		91.11 %
  top 1 accuracy NCM            :		91.56 %
----------------- Options ---------------
               add_binary: False                         
               batch_size: 32                            	[default: 64]
                   binary: False                         
            binary_weight: 0.5                           
                blur_prob: 0                             
                 blur_sig: 0.5                           
          checkpoints_dir: /scratch_net/kringel/chuqli/CNNDetection/checkpoints	[default: ./checkpoints]
                class_bal: False                         
           continue_train: False                         
                 cropSize: 224                           
                 data_aug: False                         
                 dataroot: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/test	[default: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL]
          earlystop_epoch: 5                             
                    epoch: latest                        
                 fine_tun: False                         
                    gpuid: [1]                           
                init_gain: 0.02                          
                  init_lr: 0.0005                        
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2                           
                 jpg_prob: 0                             
                 jpg_qual: 75                            
          label_smoothing: True                          	[default: False]
                 loadSize: 256                           
                    mixup: False                         
              mixup_alpha: 0.1                           
                     mode: binary                        
               model_name: resnet18                      
               model_type: resnet                        
            model_weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth	[default: None]
               multiclass: [0, 0, 1, 0, 0, 0, 0]         	[default: [1]]
                     name: icarl_df_7_ls                 	[default: experiment_name]
                  no_flip: False                         
              num_classes: 2                             
               num_epochs: 30                            	[default: 12]
              num_threads: 4                             
                  outfile: temp_0.1.csv                  
            pretrain_name:                               
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 20                            
         save_latest_freq: 2000                          
                 schedule: [10, 20, 30]                  	[default: [10]]
           serial_batches: False                         
          smoothing_alpha: 0.1                           
                   suffix:                               
                task_name: gaugan,biggan,cyclegan,imle,deepfake,crn,wild	[default: ]
              train_split: train                         
                val_split: val                           
----------------- End -------------------
{'All': 14}
Task order: ['gaugan', 'biggan', 'cyclegan', 'imle', 'deepfake', 'crn', 'wild']
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Classes in this batch: tensor([0, 1])
Data Size: 6000


Before first epoch
  validation loss:		1.309705
  top 1 accuracy:		17.05 %
  top 2 accuracy:		17.30 %
Batch of classes number 1 arrives ...
7.8953399658203125
1.0719375610351562
Batch of classes 1 out of 7 batches
Epoch 1 of 30 took 196.213s
  training loss:		1.342928
  validation loss:		0.518688
  top 1 accuracy:		78.55 %
  top 2 accuracy:		99.95 %
1.2010798454284668
0.7717440128326416
Batch of classes 1 out of 7 batches
Epoch 2 of 30 took 188.100s
  training loss:		0.863324
  validation loss:		0.723392
  top 1 accuracy:		88.50 %
  top 2 accuracy:		99.90 %
0.70719975233078
0.7001117467880249
Batch of classes 1 out of 7 batches
Epoch 3 of 30 took 149.448s
  training loss:		0.770102
  validation loss:		0.715268
  top 1 accuracy:		92.35 %
  top 2 accuracy:		100.00 %
0.7473626732826233
0.6881684064865112
Batch of classes 1 out of 7 batches
Epoch 4 of 30 took 175.311s
  training loss:		0.715568
  validation loss:		0.811816
  top 1 accuracy:		91.70 %
  top 2 accuracy:		99.95 %
0.6407235264778137
0.6893199682235718
Batch of classes 1 out of 7 batches
Epoch 5 of 30 took 191.290s
  training loss:		0.698112
  validation loss:		0.627870
  top 1 accuracy:		92.55 %
  top 2 accuracy:		99.90 %
0.6818494200706482
0.6309308409690857
Batch of classes 1 out of 7 batches
Epoch 6 of 30 took 175.387s
  training loss:		0.683789
  validation loss:		0.869946
  top 1 accuracy:		93.40 %
  top 2 accuracy:		99.95 %
0.8689697980880737
0.5993889570236206
Batch of classes 1 out of 7 batches
Epoch 7 of 30 took 196.038s
  training loss:		0.675907
  validation loss:		0.868755
  top 1 accuracy:		93.30 %
  top 2 accuracy:		99.95 %
0.8168440461158752
0.7441737651824951
Batch of classes 1 out of 7 batches
Epoch 8 of 30 took 177.116s
  training loss:		0.672609
  validation loss:		1.238394
  top 1 accuracy:		95.70 %
  top 2 accuracy:		99.95 %
0.6337342858314514
0.6362088918685913
Batch of classes 1 out of 7 batches
Epoch 9 of 30 took 200.295s
  training loss:		0.639855
  validation loss:		0.860551
  top 1 accuracy:		96.60 %
  top 2 accuracy:		100.00 %
0.7005592584609985
0.5903928279876709
Batch of classes 1 out of 7 batches
Epoch 10 of 30 took 148.765s
  training loss:		0.626528
  validation loss:		0.804898
  top 1 accuracy:		96.70 %
  top 2 accuracy:		100.00 %
0.6099772453308105
0.5641232132911682
Batch of classes 1 out of 7 batches
Epoch 11 of 30 took 142.127s
  training loss:		0.594690
  validation loss:		0.946256
  top 1 accuracy:		98.45 %
  top 2 accuracy:		100.00 %
0.5617976188659668
0.5981548428535461
Batch of classes 1 out of 7 batches
Epoch 12 of 30 took 157.082s
  training loss:		0.579097
  validation loss:		1.143456
  top 1 accuracy:		99.00 %
  top 2 accuracy:		100.00 %
0.5651282072067261
0.565173864364624
Batch of classes 1 out of 7 batches
Epoch 13 of 30 took 115.210s
  training loss:		0.572754
  validation loss:		1.292558
  top 1 accuracy:		99.15 %
  top 2 accuracy:		100.00 %
0.5686085820198059
0.558854877948761
Batch of classes 1 out of 7 batches
Epoch 14 of 30 took 60.124s
  training loss:		0.570793
  validation loss:		1.066166
  top 1 accuracy:		99.60 %
  top 2 accuracy:		100.00 %
0.5689122676849365
0.5679275989532471
Batch of classes 1 out of 7 batches
Epoch 15 of 30 took 47.922s
  training loss:		0.575551
  validation loss:		1.194566
  top 1 accuracy:		99.30 %
  top 2 accuracy:		100.00 %
0.5584194660186768
0.5564334392547607
Batch of classes 1 out of 7 batches
Epoch 16 of 30 took 56.029s
  training loss:		0.567499
  validation loss:		1.053001
  top 1 accuracy:		99.20 %
  top 2 accuracy:		100.00 %
0.5617042183876038
0.5596529245376587
Batch of classes 1 out of 7 batches
Epoch 17 of 30 took 52.902s
  training loss:		0.569107
  validation loss:		1.179941
  top 1 accuracy:		99.20 %
  top 2 accuracy:		100.00 %
0.5654948353767395
0.5559319257736206
Batch of classes 1 out of 7 batches
Epoch 18 of 30 took 48.508s
  training loss:		0.571569
  validation loss:		1.168974
  top 1 accuracy:		98.30 %
  top 2 accuracy:		100.00 %
0.5536315441131592
0.5613439083099365
Batch of classes 1 out of 7 batches
Epoch 19 of 30 took 60.314s
  training loss:		0.563174
  validation loss:		1.365655
  top 1 accuracy:		99.05 %
  top 2 accuracy:		100.00 %
0.5534497499465942
0.5605799555778503
Batch of classes 1 out of 7 batches
Epoch 20 of 30 took 83.363s
  training loss:		0.562085
  validation loss:		1.268874
  top 1 accuracy:		98.95 %
  top 2 accuracy:		100.00 %
0.5538017153739929
0.5529110431671143
Batch of classes 1 out of 7 batches
Epoch 21 of 30 took 132.000s
  training loss:		0.558918
  validation loss:		1.152984
  top 1 accuracy:		99.30 %
  top 2 accuracy:		100.00 %
0.5733078122138977
0.5529587864875793
Batch of classes 1 out of 7 batches
Epoch 22 of 30 took 182.600s
  training loss:		0.558407
  validation loss:		1.175802
  top 1 accuracy:		99.50 %
  top 2 accuracy:		100.00 %
0.6329662203788757
0.5589059591293335
Batch of classes 1 out of 7 batches
Epoch 23 of 30 took 187.570s
  training loss:		0.555070
  validation loss:		1.177794
  top 1 accuracy:		99.30 %
  top 2 accuracy:		100.00 %
0.549546480178833
0.5523520708084106
Batch of classes 1 out of 7 batches
Epoch 24 of 30 took 144.282s
  training loss:		0.554331
  validation loss:		1.180781
  top 1 accuracy:		99.45 %
  top 2 accuracy:		100.00 %
0.5690433979034424
0.5562492609024048
Batch of classes 1 out of 7 batches
Epoch 25 of 30 took 180.867s
  training loss:		0.553796
  validation loss:		1.269883
  top 1 accuracy:		99.40 %
  top 2 accuracy:		100.00 %
0.5508121252059937
0.549569308757782
Batch of classes 1 out of 7 batches
Epoch 26 of 30 took 189.717s
  training loss:		0.554587
  validation loss:		1.238538
  top 1 accuracy:		99.25 %
  top 2 accuracy:		100.00 %
0.5528744459152222
0.5499887466430664
Batch of classes 1 out of 7 batches
Epoch 27 of 30 took 198.798s
  training loss:		0.553835
  validation loss:		1.049093
  top 1 accuracy:		99.10 %
  top 2 accuracy:		100.00 %
0.5485783815383911
0.55180424451828
Batch of classes 1 out of 7 batches
Epoch 28 of 30 took 157.288s
  training loss:		0.554427
  validation loss:		1.137275
  top 1 accuracy:		99.25 %
  top 2 accuracy:		100.00 %
0.5612382888793945
0.5524559020996094
Batch of classes 1 out of 7 batches
Epoch 29 of 30 took 179.374s
  training loss:		0.553418
  validation loss:		1.265318
  top 1 accuracy:		99.50 %
  top 2 accuracy:		100.00 %
0.5490028262138367
0.5485380291938782
Batch of classes 1 out of 7 batches
Epoch 30 of 30 took 182.884s
  training loss:		0.551445
  validation loss:		1.149929
  top 1 accuracy:		99.35 %
  top 2 accuracy:		100.00 %
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		99.55 %
  top 1 accuracy Hybrid 1       :		99.35 %
  top 1 accuracy NCM            :		99.55 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		99.55 %
  top 1 accuracy Hybrid 1       :		99.35 %
  top 1 accuracy NCM            :		99.55 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		99.55 %
  top 1 accuracy Hybrid 1       :		99.35 %
  top 1 accuracy NCM            :		99.55 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		99.55 %
  top 1 accuracy Hybrid 1       :		99.35 %
  top 1 accuracy NCM            :		99.55 %
Classes in this batch: tensor([2, 3])
Data Size: 2400


Before first epoch
  validation loss:		1.642786
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.25 %
Batch of classes number 2 arrives ...
2.90372633934021
1.581735372543335
Batch of classes 2 out of 7 batches
Epoch 1 of 30 took 54.157s
  training loss:		1.896063
  validation loss:		1.413780
  top 1 accuracy:		86.50 %
  top 2 accuracy:		98.50 %
1.8048138618469238
1.4572608470916748
Batch of classes 2 out of 7 batches
Epoch 2 of 30 took 39.990s
  training loss:		1.609450
  validation loss:		1.111301
  top 1 accuracy:		89.25 %
  top 2 accuracy:		98.12 %
1.6498847007751465
1.3914036750793457
Batch of classes 2 out of 7 batches
Epoch 3 of 30 took 38.795s
  training loss:		1.491389
  validation loss:		1.319974
  top 1 accuracy:		90.50 %
  top 2 accuracy:		97.75 %
1.3554139137268066
1.2784786224365234
Batch of classes 2 out of 7 batches
Epoch 4 of 30 took 38.626s
  training loss:		1.418261
  validation loss:		1.310934
  top 1 accuracy:		78.50 %
  top 2 accuracy:		94.00 %
1.4417699575424194
1.379631757736206
Batch of classes 2 out of 7 batches
Epoch 5 of 30 took 41.219s
  training loss:		1.446010
  validation loss:		1.313833
  top 1 accuracy:		80.62 %
  top 2 accuracy:		98.87 %
1.389792561531067
1.241853952407837
Batch of classes 2 out of 7 batches
Epoch 6 of 30 took 38.731s
  training loss:		1.351171
  validation loss:		1.232635
  top 1 accuracy:		90.00 %
  top 2 accuracy:		97.87 %
1.3470054864883423
1.2235729694366455
Batch of classes 2 out of 7 batches
Epoch 7 of 30 took 38.754s
  training loss:		1.318973
  validation loss:		1.319837
  top 1 accuracy:		91.75 %
  top 2 accuracy:		98.75 %
1.3751237392425537
1.1041597127914429
Batch of classes 2 out of 7 batches
Epoch 8 of 30 took 38.511s
  training loss:		1.281206
  validation loss:		1.057310
  top 1 accuracy:		90.13 %
  top 2 accuracy:		98.25 %
1.194885015487671
1.3091576099395752
Batch of classes 2 out of 7 batches
Epoch 9 of 30 took 38.999s
  training loss:		1.223453
  validation loss:		1.322835
  top 1 accuracy:		93.12 %
  top 2 accuracy:		98.37 %
1.3146989345550537
1.1579258441925049
Batch of classes 2 out of 7 batches
Epoch 10 of 30 took 39.605s
  training loss:		1.231218
  validation loss:		1.114713
  top 1 accuracy:		87.12 %
  top 2 accuracy:		96.13 %
1.1291732788085938
1.2162206172943115
Batch of classes 2 out of 7 batches
Epoch 11 of 30 took 38.923s
  training loss:		1.156619
  validation loss:		1.195132
  top 1 accuracy:		96.25 %
  top 2 accuracy:		99.62 %
1.2419965267181396
1.0622354745864868
Batch of classes 2 out of 7 batches
Epoch 12 of 30 took 39.012s
  training loss:		1.112415
  validation loss:		1.100228
  top 1 accuracy:		96.00 %
  top 2 accuracy:		99.00 %
1.0474246740341187
1.0548033714294434
Batch of classes 2 out of 7 batches
Epoch 13 of 30 took 39.483s
  training loss:		1.103780
  validation loss:		1.257863
  top 1 accuracy:		97.75 %
  top 2 accuracy:		99.50 %
1.0228638648986816
1.0186668634414673
Batch of classes 2 out of 7 batches
Epoch 14 of 30 took 39.301s
  training loss:		1.098065
  validation loss:		1.186496
  top 1 accuracy:		97.12 %
  top 2 accuracy:		99.37 %
1.0336767435073853
1.1572704315185547
Batch of classes 2 out of 7 batches
Epoch 15 of 30 took 38.841s
  training loss:		1.094147
  validation loss:		1.362155
  top 1 accuracy:		96.50 %
  top 2 accuracy:		99.75 %
0.9834696054458618
0.9807776808738708
Batch of classes 2 out of 7 batches
Epoch 16 of 30 took 39.172s
  training loss:		1.087268
  validation loss:		1.066483
  top 1 accuracy:		96.13 %
  top 2 accuracy:		99.12 %
1.0623681545257568
1.097442865371704
Batch of classes 2 out of 7 batches
Epoch 17 of 30 took 38.890s
  training loss:		1.075977
  validation loss:		1.201696
  top 1 accuracy:		96.50 %
  top 2 accuracy:		99.00 %
1.1963558197021484
1.0253236293792725
Batch of classes 2 out of 7 batches
Epoch 18 of 30 took 39.465s
  training loss:		1.072517
  validation loss:		1.210199
  top 1 accuracy:		97.50 %
  top 2 accuracy:		99.37 %
1.0359454154968262
1.0610663890838623
Batch of classes 2 out of 7 batches
Epoch 19 of 30 took 46.065s
  training loss:		1.069755
  validation loss:		1.282639
  top 1 accuracy:		95.63 %
  top 2 accuracy:		99.25 %
1.092052698135376
1.0178844928741455
Batch of classes 2 out of 7 batches
Epoch 20 of 30 took 38.746s
  training loss:		1.061666
  validation loss:		0.991741
  top 1 accuracy:		96.88 %
  top 2 accuracy:		99.00 %
1.0376136302947998
1.0990087985992432
Batch of classes 2 out of 7 batches
Epoch 21 of 30 took 38.956s
  training loss:		1.053411
  validation loss:		1.301799
  top 1 accuracy:		97.00 %
  top 2 accuracy:		99.50 %
0.9805786609649658
1.0301597118377686
Batch of classes 2 out of 7 batches
Epoch 22 of 30 took 38.574s
  training loss:		1.050568
  validation loss:		1.252717
  top 1 accuracy:		97.75 %
  top 2 accuracy:		99.62 %
1.0742182731628418
1.0815601348876953
Batch of classes 2 out of 7 batches
Epoch 23 of 30 took 38.874s
  training loss:		1.045786
  validation loss:		1.200884
  top 1 accuracy:		97.50 %
  top 2 accuracy:		99.62 %
1.051108717918396
1.0783894062042236
Batch of classes 2 out of 7 batches
Epoch 24 of 30 took 38.944s
  training loss:		1.048559
  validation loss:		1.124366
  top 1 accuracy:		98.12 %
  top 2 accuracy:		99.37 %
1.0257289409637451
1.0907766819000244
Batch of classes 2 out of 7 batches
Epoch 25 of 30 took 38.757s
  training loss:		1.047223
  validation loss:		1.297248
  top 1 accuracy:		97.00 %
  top 2 accuracy:		98.87 %
0.9576757550239563
1.0626481771469116
Batch of classes 2 out of 7 batches
Epoch 26 of 30 took 38.737s
  training loss:		1.046613
  validation loss:		1.173237
  top 1 accuracy:		97.75 %
  top 2 accuracy:		99.50 %
1.0781629085540771
1.1352856159210205
Batch of classes 2 out of 7 batches
Epoch 27 of 30 took 38.740s
  training loss:		1.046152
  validation loss:		1.175895
  top 1 accuracy:		98.25 %
  top 2 accuracy:		99.37 %
1.0075446367263794
1.079674482345581
Batch of classes 2 out of 7 batches
Epoch 28 of 30 took 38.811s
  training loss:		1.041202
  validation loss:		1.260400
  top 1 accuracy:		98.37 %
  top 2 accuracy:		99.87 %
0.996626615524292
1.2600629329681396
Batch of classes 2 out of 7 batches
Epoch 29 of 30 took 38.895s
  training loss:		1.039594
  validation loss:		1.260061
  top 1 accuracy:		97.62 %
  top 2 accuracy:		99.62 %
1.0192279815673828
1.0728548765182495
Batch of classes 2 out of 7 batches
Epoch 30 of 30 took 39.163s
  training loss:		1.044336
  validation loss:		1.272691
  top 1 accuracy:		97.62 %
  top 2 accuracy:		99.37 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		77.80 %
  top 1 accuracy Hybrid 1       :		54.45 %
  top 1 accuracy NCM            :		79.70 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		98.05 %
  top 1 accuracy Hybrid 1       :		96.30 %
  top 1 accuracy NCM            :		98.05 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		87.00 %
  top 1 accuracy Hybrid 1       :		97.62 %
  top 1 accuracy NCM            :		85.12 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		98.38 %
  top 1 accuracy Hybrid 1       :		98.62 %
  top 1 accuracy NCM            :		98.38 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		80.43 %
  top 1 accuracy Hybrid 1       :		66.79 %
  top 1 accuracy NCM            :		81.25 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		98.14 %
  top 1 accuracy Hybrid 1       :		96.96 %
  top 1 accuracy NCM            :		98.14 %
Classes in this batch: tensor([4, 5])
Data Size: 1572


Before first epoch
  validation loss:		1.423630
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 3 arrives ...
2.313135862350464
1.9856349229812622
Batch of classes 3 out of 7 batches
Epoch 1 of 30 took 48.439s
  training loss:		1.901272
  validation loss:		1.341520
  top 1 accuracy:		75.76 %
  top 2 accuracy:		90.27 %
1.545243740081787
1.6401535272598267
Batch of classes 3 out of 7 batches
Epoch 2 of 30 took 36.071s
  training loss:		1.561995
  validation loss:		1.383634
  top 1 accuracy:		87.98 %
  top 2 accuracy:		95.61 %
1.4636826515197754
1.48480224609375
Batch of classes 3 out of 7 batches
Epoch 3 of 30 took 36.341s
  training loss:		1.431376
  validation loss:		1.027870
  top 1 accuracy:		90.27 %
  top 2 accuracy:		96.56 %
1.235640287399292
1.4245948791503906
Batch of classes 3 out of 7 batches
Epoch 4 of 30 took 36.252s
  training loss:		1.338919
  validation loss:		1.046874
  top 1 accuracy:		94.47 %
  top 2 accuracy:		98.47 %
1.443293809890747
1.2972350120544434
Batch of classes 3 out of 7 batches
Epoch 5 of 30 took 36.386s
  training loss:		1.322946
  validation loss:		0.873906
  top 1 accuracy:		91.79 %
  top 2 accuracy:		97.90 %
1.2403768301010132
1.5107347965240479
Batch of classes 3 out of 7 batches
Epoch 6 of 30 took 36.316s
  training loss:		1.297255
  validation loss:		1.052000
  top 1 accuracy:		90.27 %
  top 2 accuracy:		96.95 %
1.321162462234497
1.3736965656280518
Batch of classes 3 out of 7 batches
Epoch 7 of 30 took 36.375s
  training loss:		1.337515
  validation loss:		1.318239
  top 1 accuracy:		92.18 %
  top 2 accuracy:		98.47 %
1.22084641456604
1.265612244606018
Batch of classes 3 out of 7 batches
Epoch 8 of 30 took 36.161s
  training loss:		1.234297
  validation loss:		1.106601
  top 1 accuracy:		94.27 %
  top 2 accuracy:		98.47 %
1.1373018026351929
1.2024013996124268
Batch of classes 3 out of 7 batches
Epoch 9 of 30 took 36.175s
  training loss:		1.212217
  validation loss:		1.029343
  top 1 accuracy:		95.23 %
  top 2 accuracy:		99.24 %
1.2580618858337402
1.1309199333190918
Batch of classes 3 out of 7 batches
Epoch 10 of 30 took 36.075s
  training loss:		1.235131
  validation loss:		1.096398
  top 1 accuracy:		95.99 %
  top 2 accuracy:		98.28 %
1.15321683883667
1.1230353116989136
Batch of classes 3 out of 7 batches
Epoch 11 of 30 took 35.861s
  training loss:		1.144757
  validation loss:		1.157086
  top 1 accuracy:		96.37 %
  top 2 accuracy:		98.09 %
1.1871150732040405
1.0349982976913452
Batch of classes 3 out of 7 batches
Epoch 12 of 30 took 41.027s
  training loss:		1.125325
  validation loss:		1.056158
  top 1 accuracy:		96.95 %
  top 2 accuracy:		99.24 %
1.164724349975586
1.0544824600219727
Batch of classes 3 out of 7 batches
Epoch 13 of 30 took 36.132s
  training loss:		1.132170
  validation loss:		1.065183
  top 1 accuracy:		96.37 %
  top 2 accuracy:		98.47 %
1.0368601083755493
1.1325554847717285
Batch of classes 3 out of 7 batches
Epoch 14 of 30 took 36.467s
  training loss:		1.124527
  validation loss:		1.035154
  top 1 accuracy:		95.80 %
  top 2 accuracy:		98.47 %
1.1498254537582397
1.093214511871338
Batch of classes 3 out of 7 batches
Epoch 15 of 30 took 36.047s
  training loss:		1.122193
  validation loss:		1.074348
  top 1 accuracy:		96.95 %
  top 2 accuracy:		99.24 %
1.087998628616333
1.1052758693695068
Batch of classes 3 out of 7 batches
Epoch 16 of 30 took 36.213s
  training loss:		1.114990
  validation loss:		1.087319
  top 1 accuracy:		97.52 %
  top 2 accuracy:		99.81 %
1.0837907791137695
1.141066074371338
Batch of classes 3 out of 7 batches
Epoch 17 of 30 took 36.221s
  training loss:		1.110200
  validation loss:		1.273986
  top 1 accuracy:		96.37 %
  top 2 accuracy:		99.24 %
1.1156888008117676
1.1951637268066406
Batch of classes 3 out of 7 batches
Epoch 18 of 30 took 36.706s
  training loss:		1.114693
  validation loss:		1.000762
  top 1 accuracy:		96.18 %
  top 2 accuracy:		98.28 %
1.1251537799835205
1.1480283737182617
Batch of classes 3 out of 7 batches
Epoch 19 of 30 took 46.318s
  training loss:		1.116446
  validation loss:		1.156204
  top 1 accuracy:		97.14 %
  top 2 accuracy:		99.43 %
1.1129062175750732
1.09358811378479
Batch of classes 3 out of 7 batches
Epoch 20 of 30 took 35.982s
  training loss:		1.108126
  validation loss:		0.972810
  top 1 accuracy:		97.14 %
  top 2 accuracy:		99.43 %
1.063538908958435
1.0701358318328857
Batch of classes 3 out of 7 batches
Epoch 21 of 30 took 36.542s
  training loss:		1.092487
  validation loss:		1.170892
  top 1 accuracy:		96.76 %
  top 2 accuracy:		99.43 %
1.0491695404052734
1.081960678100586
Batch of classes 3 out of 7 batches
Epoch 22 of 30 took 36.232s
  training loss:		1.090735
  validation loss:		1.210205
  top 1 accuracy:		97.33 %
  top 2 accuracy:		99.81 %
1.1021840572357178
1.089317798614502
Batch of classes 3 out of 7 batches
Epoch 23 of 30 took 36.460s
  training loss:		1.087102
  validation loss:		1.273285
  top 1 accuracy:		96.95 %
  top 2 accuracy:		99.62 %
1.0426838397979736
1.0114023685455322
Batch of classes 3 out of 7 batches
Epoch 24 of 30 took 36.505s
  training loss:		1.089076
  validation loss:		1.183290
  top 1 accuracy:		97.90 %
  top 2 accuracy:		99.81 %
0.9522989988327026
1.0268205404281616
Batch of classes 3 out of 7 batches
Epoch 25 of 30 took 36.242s
  training loss:		1.096014
  validation loss:		1.151504
  top 1 accuracy:		96.37 %
  top 2 accuracy:		99.62 %
1.0085166692733765
1.1143957376480103
Batch of classes 3 out of 7 batches
Epoch 26 of 30 took 36.417s
  training loss:		1.095084
  validation loss:		1.145216
  top 1 accuracy:		97.14 %
  top 2 accuracy:		99.81 %
1.1005293130874634
1.0675197839736938
Batch of classes 3 out of 7 batches
Epoch 27 of 30 took 36.583s
  training loss:		1.091440
  validation loss:		1.094696
  top 1 accuracy:		98.28 %
  top 2 accuracy:		99.81 %
1.1089863777160645
1.265637755393982
Batch of classes 3 out of 7 batches
Epoch 28 of 30 took 36.241s
  training loss:		1.086376
  validation loss:		1.136407
  top 1 accuracy:		97.90 %
  top 2 accuracy:		99.81 %
1.035853624343872
1.0455960035324097
Batch of classes 3 out of 7 batches
Epoch 29 of 30 took 44.698s
  training loss:		1.086596
  validation loss:		1.076095
  top 1 accuracy:		97.71 %
  top 2 accuracy:		99.43 %
1.064863681793213
1.0618573427200317
Batch of classes 3 out of 7 batches
Epoch 30 of 30 took 35.825s
  training loss:		1.085983
  validation loss:		1.144516
  top 1 accuracy:		96.56 %
  top 2 accuracy:		99.05 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		83.15 %
  top 1 accuracy Hybrid 1       :		65.55 %
  top 1 accuracy NCM            :		82.55 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		97.70 %
  top 1 accuracy Hybrid 1       :		95.20 %
  top 1 accuracy NCM            :		97.75 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		71.12 %
  top 1 accuracy Hybrid 1       :		75.00 %
  top 1 accuracy NCM            :		73.25 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		97.38 %
  top 1 accuracy Hybrid 1       :		95.75 %
  top 1 accuracy NCM            :		97.12 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		95.80 %
  top 1 accuracy Hybrid 1       :		96.56 %
  top 1 accuracy NCM            :		95.80 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		98.66 %
  top 1 accuracy Hybrid 1       :		98.09 %
  top 1 accuracy NCM            :		98.66 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		82.25 %
  top 1 accuracy Hybrid 1       :		72.71 %
  top 1 accuracy NCM            :		82.40 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		97.77 %
  top 1 accuracy Hybrid 1       :		95.79 %
  top 1 accuracy NCM            :		97.74 %
Classes in this batch: tensor([6, 7])
Data Size: 7656


Before first epoch
  validation loss:		1.486869
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 4 arrives ...
3.3407249450683594
1.432631492614746
1.3643718957901
Batch of classes 4 out of 7 batches
Epoch 1 of 30 took 370.600s
  training loss:		1.441277
  validation loss:		1.369128
  top 1 accuracy:		99.26 %
  top 2 accuracy:		100.00 %
1.303159475326538
1.3108887672424316
1.292397379875183
Batch of classes 4 out of 7 batches
Epoch 2 of 30 took 343.707s
  training loss:		1.281768
  validation loss:		1.135164
  top 1 accuracy:		99.84 %
  top 2 accuracy:		100.00 %
1.2865583896636963
1.2076492309570312
1.3040300607681274
Batch of classes 4 out of 7 batches
Epoch 3 of 30 took 345.865s
  training loss:		1.260967
  validation loss:		0.989747
  top 1 accuracy:		99.61 %
  top 2 accuracy:		99.96 %
1.248221516609192
1.2198317050933838
1.3265302181243896
Batch of classes 4 out of 7 batches
Epoch 4 of 30 took 341.011s
  training loss:		1.224502
  validation loss:		1.168019
  top 1 accuracy:		98.71 %
  top 2 accuracy:		99.80 %
1.1764321327209473
1.3285897970199585
1.2581719160079956
Batch of classes 4 out of 7 batches
Epoch 5 of 30 took 330.292s
  training loss:		1.223779
  validation loss:		1.202268
  top 1 accuracy:		99.65 %
  top 2 accuracy:		99.92 %
1.2679952383041382
1.1925288438796997
1.1974549293518066
Batch of classes 4 out of 7 batches
Epoch 6 of 30 took 299.407s
  training loss:		1.205840
  validation loss:		0.967616
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.201905369758606
1.2432589530944824
1.189113736152649
Batch of classes 4 out of 7 batches
Epoch 7 of 30 took 296.539s
  training loss:		1.202525
  validation loss:		1.277223
  top 1 accuracy:		98.67 %
  top 2 accuracy:		99.84 %
1.1968514919281006
1.0892575979232788
1.181054711341858
Batch of classes 4 out of 7 batches
Epoch 8 of 30 took 291.033s
  training loss:		1.198766
  validation loss:		1.205863
  top 1 accuracy:		99.06 %
  top 2 accuracy:		99.57 %
1.2567068338394165
1.2503199577331543
1.2089779376983643
Batch of classes 4 out of 7 batches
Epoch 9 of 30 took 304.693s
  training loss:		1.221717
  validation loss:		1.121726
  top 1 accuracy:		97.02 %
  top 2 accuracy:		98.39 %
1.2002462148666382
1.2163147926330566
1.1575433015823364
Batch of classes 4 out of 7 batches
Epoch 10 of 30 took 311.055s
  training loss:		1.196288
  validation loss:		1.162490
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
1.2211534976959229
1.1777576208114624
1.122511863708496
Batch of classes 4 out of 7 batches
Epoch 11 of 30 took 229.129s
  training loss:		1.166868
  validation loss:		1.144881
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.0930780172348022
1.1707069873809814
1.1301213502883911
Batch of classes 4 out of 7 batches
Epoch 12 of 30 took 305.368s
  training loss:		1.161795
  validation loss:		1.170484
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1706366539001465
1.1263790130615234
1.1863484382629395
Batch of classes 4 out of 7 batches
Epoch 13 of 30 took 281.379s
  training loss:		1.160062
  validation loss:		1.108541
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1323084831237793
1.1506367921829224
1.2087113857269287
Batch of classes 4 out of 7 batches
Epoch 14 of 30 took 263.573s
  training loss:		1.161531
  validation loss:		1.247316
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.182023286819458
1.1310920715332031
1.1363813877105713
Batch of classes 4 out of 7 batches
Epoch 15 of 30 took 251.611s
  training loss:		1.159910
  validation loss:		0.965889
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1502056121826172
1.1433122158050537
1.2089345455169678
Batch of classes 4 out of 7 batches
Epoch 16 of 30 took 275.368s
  training loss:		1.159442
  validation loss:		1.079373
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1293798685073853
1.1773844957351685
1.197525143623352
Batch of classes 4 out of 7 batches
Epoch 17 of 30 took 111.091s
  training loss:		1.158348
  validation loss:		1.256807
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.200075387954712
1.159781575202942
1.1532044410705566
Batch of classes 4 out of 7 batches
Epoch 18 of 30 took 109.834s
  training loss:		1.160231
  validation loss:		1.108726
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.162827730178833
1.1374629735946655
1.159716010093689
Batch of classes 4 out of 7 batches
Epoch 19 of 30 took 110.754s
  training loss:		1.156951
  validation loss:		1.166411
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1411049365997314
1.1876089572906494
1.1993675231933594
Batch of classes 4 out of 7 batches
Epoch 20 of 30 took 111.085s
  training loss:		1.157306
  validation loss:		1.221824
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1508551836013794
1.1494125127792358
1.1668202877044678
Batch of classes 4 out of 7 batches
Epoch 21 of 30 took 110.454s
  training loss:		1.152879
  validation loss:		1.193674
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.177799105644226
1.1690725088119507
1.191382884979248
Batch of classes 4 out of 7 batches
Epoch 22 of 30 took 109.891s
  training loss:		1.152010
  validation loss:		1.221723
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1687309741973877
1.1403462886810303
1.1523479223251343
Batch of classes 4 out of 7 batches
Epoch 23 of 30 took 110.374s
  training loss:		1.150838
  validation loss:		1.115385
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1784021854400635
1.1765596866607666
1.1763617992401123
Batch of classes 4 out of 7 batches
Epoch 24 of 30 took 110.425s
  training loss:		1.153023
  validation loss:		1.149593
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.0784368515014648
1.1900136470794678
1.1384676694869995
Batch of classes 4 out of 7 batches
Epoch 25 of 30 took 110.540s
  training loss:		1.152904
  validation loss:		1.201012
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1517601013183594
1.1161184310913086
1.1930782794952393
Batch of classes 4 out of 7 batches
Epoch 26 of 30 took 110.974s
  training loss:		1.150375
  validation loss:		1.090808
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1334543228149414
1.1865284442901611
1.1109257936477661
Batch of classes 4 out of 7 batches
Epoch 27 of 30 took 110.538s
  training loss:		1.149668
  validation loss:		1.227202
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.179589867591858
1.1584632396697998
1.137209415435791
Batch of classes 4 out of 7 batches
Epoch 28 of 30 took 109.349s
  training loss:		1.148753
  validation loss:		1.132952
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1889293193817139
1.1786577701568604
1.1019155979156494
Batch of classes 4 out of 7 batches
Epoch 29 of 30 took 110.238s
  training loss:		1.150752
  validation loss:		1.100747
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1287713050842285
1.1188421249389648
1.099290370941162
Batch of classes 4 out of 7 batches
Epoch 30 of 30 took 110.415s
  training loss:		1.151317
  validation loss:		1.239645
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		84.15 %
  top 1 accuracy Hybrid 1       :		74.80 %
  top 1 accuracy NCM            :		83.50 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		96.35 %
  top 1 accuracy Hybrid 1       :		94.40 %
  top 1 accuracy NCM            :		96.30 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		69.50 %
  top 1 accuracy Hybrid 1       :		70.25 %
  top 1 accuracy NCM            :		70.12 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		97.62 %
  top 1 accuracy Hybrid 1       :		96.62 %
  top 1 accuracy NCM            :		97.75 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		93.70 %
  top 1 accuracy Hybrid 1       :		94.85 %
  top 1 accuracy NCM            :		93.32 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		97.90 %
  top 1 accuracy Hybrid 1       :		97.90 %
  top 1 accuracy NCM            :		97.71 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		100.00 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		100.00 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		89.89 %
  top 1 accuracy Hybrid 1       :		86.91 %
  top 1 accuracy NCM            :		89.72 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		98.25 %
  top 1 accuracy Hybrid 1       :		97.45 %
  top 1 accuracy NCM            :		98.23 %
Classes in this batch: tensor([8, 9])
Data Size: 3248


Before first epoch
  validation loss:		0.719102
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 5 arrives ...
3.5820746421813965
1.5178422927856445
Batch of classes 5 out of 7 batches
Epoch 1 of 30 took 62.889s
  training loss:		1.648987
  validation loss:		0.465632
  top 1 accuracy:		95.01 %
  top 2 accuracy:		98.52 %
1.2778699398040771
1.3711564540863037
Batch of classes 5 out of 7 batches
Epoch 2 of 30 took 54.109s
  training loss:		1.386513
  validation loss:		0.468918
  top 1 accuracy:		95.38 %
  top 2 accuracy:		97.87 %
1.3840512037277222
1.3192118406295776
Batch of classes 5 out of 7 batches
Epoch 3 of 30 took 54.181s
  training loss:		1.329312
  validation loss:		0.391445
  top 1 accuracy:		95.47 %
  top 2 accuracy:		98.80 %
1.3258429765701294
1.2663695812225342
Batch of classes 5 out of 7 batches
Epoch 4 of 30 took 54.167s
  training loss:		1.307165
  validation loss:		0.415491
  top 1 accuracy:		95.47 %
  top 2 accuracy:		98.61 %
1.2890732288360596
1.2853105068206787
Batch of classes 5 out of 7 batches
Epoch 5 of 30 took 54.166s
  training loss:		1.280289
  validation loss:		0.532800
  top 1 accuracy:		96.30 %
  top 2 accuracy:		99.17 %
1.3244332075119019
1.273829460144043
Batch of classes 5 out of 7 batches
Epoch 6 of 30 took 54.208s
  training loss:		1.288617
  validation loss:		0.528186
  top 1 accuracy:		96.21 %
  top 2 accuracy:		98.80 %
1.2895534038543701
1.2160511016845703
Batch of classes 5 out of 7 batches
Epoch 7 of 30 took 54.103s
  training loss:		1.272294
  validation loss:		0.393723
  top 1 accuracy:		95.47 %
  top 2 accuracy:		98.80 %
1.2519636154174805
1.2196475267410278
Batch of classes 5 out of 7 batches
Epoch 8 of 30 took 54.109s
  training loss:		1.265617
  validation loss:		0.399493
  top 1 accuracy:		95.84 %
  top 2 accuracy:		98.61 %
1.255537509918213
1.3086469173431396
Batch of classes 5 out of 7 batches
Epoch 9 of 30 took 54.177s
  training loss:		1.255972
  validation loss:		0.355968
  top 1 accuracy:		95.47 %
  top 2 accuracy:		98.06 %
1.2178013324737549
1.2279651165008545
Batch of classes 5 out of 7 batches
Epoch 10 of 30 took 54.109s
  training loss:		1.244897
  validation loss:		0.514472
  top 1 accuracy:		95.75 %
  top 2 accuracy:		99.26 %
1.171334981918335
1.1859585046768188
Batch of classes 5 out of 7 batches
Epoch 11 of 30 took 54.359s
  training loss:		1.211770
  validation loss:		0.442292
  top 1 accuracy:		96.30 %
  top 2 accuracy:		98.80 %
1.1650058031082153
1.2124009132385254
Batch of classes 5 out of 7 batches
Epoch 12 of 30 took 54.118s
  training loss:		1.202751
  validation loss:		0.411628
  top 1 accuracy:		96.21 %
  top 2 accuracy:		97.97 %
1.1811376810073853
1.2271968126296997
Batch of classes 5 out of 7 batches
Epoch 13 of 30 took 54.196s
  training loss:		1.202686
  validation loss:		0.438771
  top 1 accuracy:		96.12 %
  top 2 accuracy:		98.34 %
1.227168321609497
1.1129131317138672
Batch of classes 5 out of 7 batches
Epoch 14 of 30 took 54.225s
  training loss:		1.200509
  validation loss:		0.406231
  top 1 accuracy:		96.30 %
  top 2 accuracy:		98.52 %
1.1416046619415283
1.181723713874817
Batch of classes 5 out of 7 batches
Epoch 15 of 30 took 54.129s
  training loss:		1.202541
  validation loss:		0.373681
  top 1 accuracy:		96.30 %
  top 2 accuracy:		98.43 %
1.2548518180847168
1.1376752853393555
Batch of classes 5 out of 7 batches
Epoch 16 of 30 took 54.240s
  training loss:		1.202955
  validation loss:		0.433017
  top 1 accuracy:		96.30 %
  top 2 accuracy:		99.35 %
1.193682312965393
1.2322874069213867
Batch of classes 5 out of 7 batches
Epoch 17 of 30 took 54.249s
  training loss:		1.199947
  validation loss:		0.396738
  top 1 accuracy:		95.38 %
  top 2 accuracy:		99.08 %
1.2323784828186035
1.2949682474136353
Batch of classes 5 out of 7 batches
Epoch 18 of 30 took 54.744s
  training loss:		1.198092
  validation loss:		0.406057
  top 1 accuracy:		96.12 %
  top 2 accuracy:		98.89 %
1.2684268951416016
1.5927170515060425
Batch of classes 5 out of 7 batches
Epoch 19 of 30 took 54.308s
  training loss:		1.201224
  validation loss:		0.410607
  top 1 accuracy:		96.21 %
  top 2 accuracy:		98.89 %
1.266463041305542
1.2843960523605347
Batch of classes 5 out of 7 batches
Epoch 20 of 30 took 54.132s
  training loss:		1.198824
  validation loss:		0.367236
  top 1 accuracy:		96.30 %
  top 2 accuracy:		99.26 %
1.1391022205352783
1.220459222793579
Batch of classes 5 out of 7 batches
Epoch 21 of 30 took 54.210s
  training loss:		1.193089
  validation loss:		0.369550
  top 1 accuracy:		96.30 %
  top 2 accuracy:		99.08 %
1.160947561264038
1.1361048221588135
Batch of classes 5 out of 7 batches
Epoch 22 of 30 took 54.040s
  training loss:		1.189703
  validation loss:		0.398196
  top 1 accuracy:		95.93 %
  top 2 accuracy:		98.98 %
1.1512542963027954
1.201249599456787
Batch of classes 5 out of 7 batches
Epoch 23 of 30 took 54.237s
  training loss:		1.189268
  validation loss:		0.393440
  top 1 accuracy:		96.12 %
  top 2 accuracy:		98.89 %
1.2364635467529297
1.1936213970184326
Batch of classes 5 out of 7 batches
Epoch 24 of 30 took 54.129s
  training loss:		1.188603
  validation loss:		0.384642
  top 1 accuracy:		96.30 %
  top 2 accuracy:		98.52 %
1.192404866218567
1.1633284091949463
Batch of classes 5 out of 7 batches
Epoch 25 of 30 took 54.202s
  training loss:		1.189676
  validation loss:		0.412465
  top 1 accuracy:		96.12 %
  top 2 accuracy:		97.97 %
1.186835765838623
1.2016798257827759
Batch of classes 5 out of 7 batches
Epoch 26 of 30 took 54.291s
  training loss:		1.188416
  validation loss:		0.392434
  top 1 accuracy:		96.21 %
  top 2 accuracy:		98.61 %
1.1834720373153687
1.1919118165969849
Batch of classes 5 out of 7 batches
Epoch 27 of 30 took 54.099s
  training loss:		1.188738
  validation loss:		0.397460
  top 1 accuracy:		96.30 %
  top 2 accuracy:		98.80 %
1.1702871322631836
1.2692534923553467
Batch of classes 5 out of 7 batches
Epoch 28 of 30 took 54.275s
  training loss:		1.189542
  validation loss:		0.387266
  top 1 accuracy:		96.30 %
  top 2 accuracy:		98.80 %
1.2434608936309814
1.1971967220306396
Batch of classes 5 out of 7 batches
Epoch 29 of 30 took 54.055s
  training loss:		1.190323
  validation loss:		0.380949
  top 1 accuracy:		96.21 %
  top 2 accuracy:		98.52 %
1.19284987449646
1.1587574481964111
Batch of classes 5 out of 7 batches
Epoch 30 of 30 took 54.146s
  training loss:		1.189783
  validation loss:		0.417715
  top 1 accuracy:		96.12 %
  top 2 accuracy:		98.61 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		84.30 %
  top 1 accuracy Hybrid 1       :		81.00 %
  top 1 accuracy NCM            :		84.10 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		94.50 %
  top 1 accuracy Hybrid 1       :		92.70 %
  top 1 accuracy NCM            :		94.70 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		67.38 %
  top 1 accuracy Hybrid 1       :		65.62 %
  top 1 accuracy NCM            :		68.50 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		95.00 %
  top 1 accuracy Hybrid 1       :		92.25 %
  top 1 accuracy NCM            :		95.00 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		88.93 %
  top 1 accuracy Hybrid 1       :		87.21 %
  top 1 accuracy NCM            :		88.74 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		96.37 %
  top 1 accuracy Hybrid 1       :		94.08 %
  top 1 accuracy NCM            :		96.37 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.92 %
  top 1 accuracy Hybrid 1       :		99.92 %
  top 1 accuracy NCM            :		99.92 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.92 %
  top 1 accuracy Hybrid 1       :		99.92 %
  top 1 accuracy NCM            :		99.92 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		96.21 %
  top 1 accuracy Hybrid 1       :		96.12 %
  top 1 accuracy NCM            :		96.21 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		96.30 %
  top 1 accuracy Hybrid 1       :		96.21 %
  top 1 accuracy NCM            :		96.30 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		90.28 %
  top 1 accuracy Hybrid 1       :		88.99 %
  top 1 accuracy NCM            :		90.34 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		96.97 %
  top 1 accuracy Hybrid 1       :		95.95 %
  top 1 accuracy NCM            :		97.03 %
Classes in this batch: tensor([10, 11])
Data Size: 7658


Before first epoch
  validation loss:		1.604970
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 6 arrives ...
3.136047840118408
1.6776936054229736
1.3421471118927002
Batch of classes 6 out of 7 batches
Epoch 1 of 30 took 188.142s
  training loss:		1.386307
  validation loss:		1.296898
  top 1 accuracy:		99.84 %
  top 2 accuracy:		100.00 %
1.2642033100128174
1.1502768993377686
1.1842923164367676
Batch of classes 6 out of 7 batches
Epoch 2 of 30 took 110.363s
  training loss:		1.262743
  validation loss:		1.254565
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
1.1890430450439453
1.314975380897522
1.1768385171890259
Batch of classes 6 out of 7 batches
Epoch 3 of 30 took 110.157s
  training loss:		1.247766
  validation loss:		1.270643
  top 1 accuracy:		99.76 %
  top 2 accuracy:		100.00 %
1.1992816925048828
1.2665822505950928
1.3101696968078613
Batch of classes 6 out of 7 batches
Epoch 4 of 30 took 110.118s
  training loss:		1.239577
  validation loss:		1.372114
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
1.2545149326324463
1.3668709993362427
1.2068238258361816
Batch of classes 6 out of 7 batches
Epoch 5 of 30 took 110.076s
  training loss:		1.245752
  validation loss:		1.225910
  top 1 accuracy:		99.80 %
  top 2 accuracy:		99.96 %
1.272026538848877
1.186690330505371
1.2070612907409668
Batch of classes 6 out of 7 batches
Epoch 6 of 30 took 109.814s
  training loss:		1.234072
  validation loss:		1.212429
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
1.2914146184921265
1.3573002815246582
1.2302665710449219
Batch of classes 6 out of 7 batches
Epoch 7 of 30 took 109.836s
  training loss:		1.215831
  validation loss:		1.253476
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
1.2123868465423584
1.2605175971984863
1.1775511503219604
Batch of classes 6 out of 7 batches
Epoch 8 of 30 took 110.793s
  training loss:		1.192833
  validation loss:		1.312955
  top 1 accuracy:		99.88 %
  top 2 accuracy:		99.96 %
1.1871148347854614
1.15574312210083
1.1796672344207764
Batch of classes 6 out of 7 batches
Epoch 9 of 30 took 110.030s
  training loss:		1.195248
  validation loss:		1.219370
  top 1 accuracy:		99.41 %
  top 2 accuracy:		99.96 %
1.1767529249191284
1.2084846496582031
1.2100064754486084
Batch of classes 6 out of 7 batches
Epoch 10 of 30 took 110.152s
  training loss:		1.177742
  validation loss:		1.180303
  top 1 accuracy:		97.61 %
  top 2 accuracy:		100.00 %
1.1958601474761963
1.1546440124511719
1.2126253843307495
Batch of classes 6 out of 7 batches
Epoch 11 of 30 took 110.115s
  training loss:		1.152637
  validation loss:		1.297412
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.0963833332061768
1.1420549154281616
1.1422622203826904
Batch of classes 6 out of 7 batches
Epoch 12 of 30 took 110.400s
  training loss:		1.145329
  validation loss:		1.254706
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1857534646987915
1.1611440181732178
1.2016905546188354
Batch of classes 6 out of 7 batches
Epoch 13 of 30 took 109.912s
  training loss:		1.141631
  validation loss:		1.263416
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1703529357910156
1.1509695053100586
1.1444389820098877
Batch of classes 6 out of 7 batches
Epoch 14 of 30 took 121.234s
  training loss:		1.141533
  validation loss:		1.229638
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1759424209594727
1.1315584182739258
1.1224405765533447
Batch of classes 6 out of 7 batches
Epoch 15 of 30 took 111.216s
  training loss:		1.140100
  validation loss:		1.250865
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1312360763549805
1.1209733486175537
1.1746351718902588
Batch of classes 6 out of 7 batches
Epoch 16 of 30 took 110.654s
  training loss:		1.140061
  validation loss:		1.265446
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.0820996761322021
1.09988272190094
1.152883768081665
Batch of classes 6 out of 7 batches
Epoch 17 of 30 took 109.564s
  training loss:		1.140863
  validation loss:		1.236721
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1221024990081787
1.1858947277069092
1.13350510597229
Batch of classes 6 out of 7 batches
Epoch 18 of 30 took 110.043s
  training loss:		1.139979
  validation loss:		1.216305
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1762555837631226
1.1368165016174316
1.1376540660858154
Batch of classes 6 out of 7 batches
Epoch 19 of 30 took 110.383s
  training loss:		1.139379
  validation loss:		1.242541
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1238842010498047
1.1103475093841553
1.1310458183288574
Batch of classes 6 out of 7 batches
Epoch 20 of 30 took 110.327s
  training loss:		1.137737
  validation loss:		1.281062
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1627110242843628
1.2199840545654297
1.0973265171051025
Batch of classes 6 out of 7 batches
Epoch 21 of 30 took 148.857s
  training loss:		1.136185
  validation loss:		1.285785
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1830453872680664
1.1859947443008423
1.1899210214614868
Batch of classes 6 out of 7 batches
Epoch 22 of 30 took 145.236s
  training loss:		1.134309
  validation loss:		1.255708
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.139593482017517
1.1571238040924072
1.1063728332519531
Batch of classes 6 out of 7 batches
Epoch 23 of 30 took 112.434s
  training loss:		1.136147
  validation loss:		1.247467
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.087820053100586
1.1203385591506958
1.1984050273895264
Batch of classes 6 out of 7 batches
Epoch 24 of 30 took 110.242s
  training loss:		1.135302
  validation loss:		1.226548
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1469941139221191
1.1447731256484985
1.1346938610076904
Batch of classes 6 out of 7 batches
Epoch 25 of 30 took 110.455s
  training loss:		1.134128
  validation loss:		1.221540
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1808096170425415
1.1187951564788818
1.0948667526245117
Batch of classes 6 out of 7 batches
Epoch 26 of 30 took 110.037s
  training loss:		1.134571
  validation loss:		1.282955
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1648168563842773
1.1744928359985352
1.1851307153701782
Batch of classes 6 out of 7 batches
Epoch 27 of 30 took 110.809s
  training loss:		1.134870
  validation loss:		1.260030
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.0878407955169678
1.1193777322769165
1.0989398956298828
Batch of classes 6 out of 7 batches
Epoch 28 of 30 took 119.299s
  training loss:		1.134820
  validation loss:		1.293391
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.0718880891799927
1.1683471202850342
1.1589186191558838
Batch of classes 6 out of 7 batches
Epoch 29 of 30 took 113.578s
  training loss:		1.136372
  validation loss:		1.194138
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
1.1638174057006836
1.118464469909668
1.132362961769104
Batch of classes 6 out of 7 batches
Epoch 30 of 30 took 110.434s
  training loss:		1.135988
  validation loss:		1.209780
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		77.50 %
  top 1 accuracy Hybrid 1       :		68.65 %
  top 1 accuracy NCM            :		76.90 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		91.85 %
  top 1 accuracy Hybrid 1       :		89.45 %
  top 1 accuracy NCM            :		91.90 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		66.38 %
  top 1 accuracy Hybrid 1       :		62.63 %
  top 1 accuracy NCM            :		67.38 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		93.50 %
  top 1 accuracy Hybrid 1       :		91.00 %
  top 1 accuracy NCM            :		93.12 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		89.12 %
  top 1 accuracy Hybrid 1       :		89.89 %
  top 1 accuracy NCM            :		89.50 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		96.18 %
  top 1 accuracy Hybrid 1       :		95.04 %
  top 1 accuracy NCM            :		96.18 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		71.83 %
  top 1 accuracy Hybrid 1       :		50.00 %
  top 1 accuracy NCM            :		73.71 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.96 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		99.96 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		95.84 %
  top 1 accuracy Hybrid 1       :		96.03 %
  top 1 accuracy NCM            :		95.84 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		96.03 %
  top 1 accuracy Hybrid 1       :		96.03 %
  top 1 accuracy NCM            :		96.03 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		78.06 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		76.29 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		100.00 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		77.92 %
  top 1 accuracy Hybrid 1       :		75.84 %
  top 1 accuracy NCM            :		77.93 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		97.07 %
  top 1 accuracy Hybrid 1       :		96.30 %
  top 1 accuracy NCM            :		97.05 %
Classes in this batch: tensor([12, 13])
Data Size: 6208


Before first epoch
  validation loss:		0.896140
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 7 arrives ...
3.8545775413513184
1.8351590633392334
1.9378268718719482
Batch of classes 7 out of 7 batches
Epoch 1 of 30 took 118.304s
  training loss:		1.930329
  validation loss:		0.629192
  top 1 accuracy:		67.18 %
  top 2 accuracy:		99.47 %
1.773190975189209
1.6918851137161255
1.7978839874267578
Batch of classes 7 out of 7 batches
Epoch 2 of 30 took 86.621s
  training loss:		1.777252
  validation loss:		0.574301
  top 1 accuracy:		70.96 %
  top 2 accuracy:		96.61 %
1.5876576900482178
1.6486880779266357
1.5890653133392334
Batch of classes 7 out of 7 batches
Epoch 3 of 30 took 86.566s
  training loss:		1.714568
  validation loss:		0.494611
  top 1 accuracy:		74.16 %
  top 2 accuracy:		98.21 %
1.5723823308944702
1.605880856513977
1.6778409481048584
Batch of classes 7 out of 7 batches
Epoch 4 of 30 took 87.903s
  training loss:		1.681009
  validation loss:		0.609625
  top 1 accuracy:		68.64 %
  top 2 accuracy:		95.93 %
1.7123161554336548
1.9363644123077393
1.7372026443481445
Batch of classes 7 out of 7 batches
Epoch 5 of 30 took 86.820s
  training loss:		1.644169
  validation loss:		0.553244
  top 1 accuracy:		71.30 %
  top 2 accuracy:		96.32 %
1.593616247177124
1.7132230997085571
1.594645380973816
Batch of classes 7 out of 7 batches
Epoch 6 of 30 took 86.579s
  training loss:		1.619748
  validation loss:		0.570422
  top 1 accuracy:		75.57 %
  top 2 accuracy:		98.25 %
1.6879713535308838
1.4196770191192627
1.608827829360962
Batch of classes 7 out of 7 batches
Epoch 7 of 30 took 86.637s
  training loss:		1.598852
  validation loss:		0.512046
  top 1 accuracy:		75.08 %
  top 2 accuracy:		94.76 %
1.6212656497955322
1.5358946323394775
1.4256027936935425
Batch of classes 7 out of 7 batches
Epoch 8 of 30 took 86.699s
  training loss:		1.581207
  validation loss:		0.621319
  top 1 accuracy:		76.73 %
  top 2 accuracy:		97.72 %
1.5966036319732666
1.567281723022461
1.4683754444122314
Batch of classes 7 out of 7 batches
Epoch 9 of 30 took 87.208s
  training loss:		1.552201
  validation loss:		0.548701
  top 1 accuracy:		76.59 %
  top 2 accuracy:		96.56 %
1.6858041286468506
1.4115064144134521
1.5330442190170288
Batch of classes 7 out of 7 batches
Epoch 10 of 30 took 86.515s
  training loss:		1.536252
  validation loss:		0.536661
  top 1 accuracy:		77.31 %
  top 2 accuracy:		97.14 %
1.4440977573394775
1.4032143354415894
1.5361931324005127
Batch of classes 7 out of 7 batches
Epoch 11 of 30 took 86.751s
  training loss:		1.458699
  validation loss:		0.581087
  top 1 accuracy:		77.65 %
  top 2 accuracy:		96.56 %
1.4124817848205566
1.214514970779419
1.3466062545776367
Batch of classes 7 out of 7 batches
Epoch 12 of 30 took 86.519s
  training loss:		1.431278
  validation loss:		0.583668
  top 1 accuracy:		78.19 %
  top 2 accuracy:		96.41 %
1.3447070121765137
1.385751485824585
1.3684604167938232
Batch of classes 7 out of 7 batches
Epoch 13 of 30 took 90.063s
  training loss:		1.416645
  validation loss:		0.604994
  top 1 accuracy:		79.93 %
  top 2 accuracy:		97.24 %
1.3258626461029053
1.4948997497558594
1.366081714630127
Batch of classes 7 out of 7 batches
Epoch 14 of 30 took 88.557s
  training loss:		1.402316
  validation loss:		0.617807
  top 1 accuracy:		78.33 %
  top 2 accuracy:		96.07 %
1.4732470512390137
1.3019764423370361
1.3687748908996582
Batch of classes 7 out of 7 batches
Epoch 15 of 30 took 87.093s
  training loss:		1.396571
  validation loss:		0.564944
  top 1 accuracy:		79.30 %
  top 2 accuracy:		96.61 %
1.3697810173034668
1.3332405090332031
1.3256158828735352
Batch of classes 7 out of 7 batches
Epoch 16 of 30 took 87.134s
  training loss:		1.390255
  validation loss:		0.561934
  top 1 accuracy:		80.42 %
  top 2 accuracy:		95.78 %
1.3551521301269531
1.4976139068603516
1.423452377319336
Batch of classes 7 out of 7 batches
Epoch 17 of 30 took 87.029s
  training loss:		1.376739
  validation loss:		0.562820
  top 1 accuracy:		79.01 %
  top 2 accuracy:		95.64 %
1.2978980541229248
1.376286268234253
1.378801941871643
Batch of classes 7 out of 7 batches
Epoch 18 of 30 took 86.781s
  training loss:		1.369972
  validation loss:		0.566288
  top 1 accuracy:		79.45 %
  top 2 accuracy:		95.30 %
1.3244128227233887
1.3021602630615234
1.2646703720092773
Batch of classes 7 out of 7 batches
Epoch 19 of 30 took 86.655s
  training loss:		1.366317
  validation loss:		0.546400
  top 1 accuracy:		77.90 %
  top 2 accuracy:		96.46 %
1.2779783010482788
1.2190852165222168
1.2932708263397217
Batch of classes 7 out of 7 batches
Epoch 20 of 30 took 117.114s
  training loss:		1.360841
  validation loss:		0.542772
  top 1 accuracy:		77.85 %
  top 2 accuracy:		95.64 %
1.3015259504318237
1.3376572132110596
1.2967925071716309
Batch of classes 7 out of 7 batches
Epoch 21 of 30 took 143.748s
  training loss:		1.332202
  validation loss:		0.540129
  top 1 accuracy:		81.39 %
  top 2 accuracy:		95.25 %
1.245306372642517
1.265098214149475
1.2676606178283691
Batch of classes 7 out of 7 batches
Epoch 22 of 30 took 138.493s
  training loss:		1.321561
  validation loss:		0.526238
  top 1 accuracy:		81.58 %
  top 2 accuracy:		94.62 %
1.3101136684417725
1.418816328048706
1.2895605564117432
Batch of classes 7 out of 7 batches
Epoch 23 of 30 took 117.218s
  training loss:		1.314521
  validation loss:		0.538324
  top 1 accuracy:		81.43 %
  top 2 accuracy:		94.04 %
1.2653106451034546
1.2404606342315674
1.2389307022094727
Batch of classes 7 out of 7 batches
Epoch 24 of 30 took 97.558s
  training loss:		1.314819
  validation loss:		0.553334
  top 1 accuracy:		80.22 %
  top 2 accuracy:		94.38 %
1.289097785949707
1.3873929977416992
1.338647723197937
Batch of classes 7 out of 7 batches
Epoch 25 of 30 took 87.518s
  training loss:		1.307087
  validation loss:		0.555372
  top 1 accuracy:		80.51 %
  top 2 accuracy:		94.43 %
1.3193464279174805
1.314107894897461
1.214972734451294
Batch of classes 7 out of 7 batches
Epoch 26 of 30 took 86.131s
  training loss:		1.305271
  validation loss:		0.536950
  top 1 accuracy:		80.76 %
  top 2 accuracy:		92.97 %
1.3497719764709473
1.2650361061096191
1.2902767658233643
Batch of classes 7 out of 7 batches
Epoch 27 of 30 took 91.915s
  training loss:		1.300944
  validation loss:		0.538406
  top 1 accuracy:		80.17 %
  top 2 accuracy:		93.12 %
1.2407186031341553
1.2434170246124268
1.3629345893859863
Batch of classes 7 out of 7 batches
Epoch 28 of 30 took 93.616s
  training loss:		1.294648
  validation loss:		0.483503
  top 1 accuracy:		80.22 %
  top 2 accuracy:		92.58 %
1.2292771339416504
1.3075531721115112
1.34438157081604
Batch of classes 7 out of 7 batches
Epoch 29 of 30 took 112.473s
  training loss:		1.285385
  validation loss:		0.602992
  top 1 accuracy:		80.85 %
  top 2 accuracy:		92.87 %
1.4174447059631348
1.2904486656188965
1.3198151588439941
Batch of classes 7 out of 7 batches
Epoch 30 of 30 took 117.625s
  training loss:		1.287003
  validation loss:		0.554133
  top 1 accuracy:		80.47 %
  top 2 accuracy:		93.07 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		70.35 %
  top 1 accuracy Hybrid 1       :		66.10 %
  top 1 accuracy NCM            :		69.20 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		84.15 %
  top 1 accuracy Hybrid 1       :		83.00 %
  top 1 accuracy NCM            :		84.05 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		56.00 %
  top 1 accuracy Hybrid 1       :		52.00 %
  top 1 accuracy NCM            :		58.12 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		87.12 %
  top 1 accuracy Hybrid 1       :		85.00 %
  top 1 accuracy NCM            :		87.50 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		84.16 %
  top 1 accuracy Hybrid 1       :		87.02 %
  top 1 accuracy NCM            :		85.11 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		92.75 %
  top 1 accuracy Hybrid 1       :		92.37 %
  top 1 accuracy NCM            :		92.94 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		74.10 %
  top 1 accuracy Hybrid 1       :		64.34 %
  top 1 accuracy NCM            :		74.18 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.61 %
  top 1 accuracy Hybrid 1       :		99.76 %
  top 1 accuracy NCM            :		99.61 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		82.53 %
  top 1 accuracy Hybrid 1       :		81.15 %
  top 1 accuracy NCM            :		83.64 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		93.90 %
  top 1 accuracy Hybrid 1       :		93.35 %
  top 1 accuracy NCM            :		93.72 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		75.12 %
  top 1 accuracy Hybrid 1       :		85.19 %
  top 1 accuracy NCM            :		75.00 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.88 %
  top 1 accuracy Hybrid 1       :		99.84 %
  top 1 accuracy NCM            :		99.88 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		80.32 %
  top 1 accuracy Hybrid 1       :		80.47 %
  top 1 accuracy NCM            :		80.42 %
Binary accuracy:
Final results on wild classes:
  top 1 accuracy iCaRL          :		80.61 %
  top 1 accuracy Hybrid 1       :		80.56 %
  top 1 accuracy NCM            :		80.85 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		74.78 %
  top 1 accuracy Hybrid 1       :		73.86 %
  top 1 accuracy NCM            :		74.88 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		91.90 %
  top 1 accuracy Hybrid 1       :		91.51 %
  top 1 accuracy NCM            :		91.95 %
