----------------- Options ---------------
               add_binary: False                         
               batch_size: 32                            	[default: 64]
                   binary: True                          	[default: False]
              binary_loss: sum_b_sig                     
            binary_weight: 0.5                           
                blur_prob: 0                             
                 blur_sig: 0.5                           
          checkpoints_dir: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL/checkpoints	[default: ./checkpoints]
                class_bal: False                         
           continue_train: False                         
                 cropSize: 224                           
                 data_aug: False                         
                 dataroot: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/test	[default: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL]
          earlystop_epoch: 5                             
                    epoch: latest                        
                 fine_tun: False                         
                    gpuid: [1]                           
                init_gain: 0.02                          
                  init_lr: 0.0005                        
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2                           
                 jpg_prob: 0                             
                 jpg_qual: 75                            
          label_smoothing: False                         
                 loadSize: 256                           
                    mixup: False                         
              mixup_alpha: 0.1                           
                     mode: binary                        
               model_name: resnet18                      
               model_type: resnet                        
            model_weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth	[default: None]
               multiclass: [0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0]	[default: [1]]
                     name: icarl_df_12_binary            	[default: experiment_name]
                  no_flip: False                         
              num_classes: 2                             
               num_epochs: 30                            	[default: 12]
              num_threads: 4                             
                  outfile: temp_0.1.csv                  
            pretrain_name:                               
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 20                            
         save_latest_freq: 2000                          
                 schedule: [10, 20, 30]                  	[default: [10]]
           serial_batches: False                         
          smoothing_alpha: 0.1                           
                   suffix:                               
                task_name: gaugan,biggan,cyclegan,imle,deepfake,crn,wild,glow,stargan_gf,stylegan,whichfaceisreal,san	[default: ]
              train_split: train                         
                val_split: val                           
----------------- End -------------------
{'All': 24}
Task order: ['gaugan', 'biggan', 'cyclegan', 'imle', 'deepfake', 'crn', 'wild', 'glow', 'stargan_gf', 'stylegan', 'whichfaceisreal', 'san']
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Classes in this batch: tensor([0, 1])
Data Size: 6000


Before first epoch
  validation loss:		4.725966
  top 1 accuracy:		75.00 %
Batch of classes number 1 arrives ...
4.998220920562744
0.3064613342285156
Batch of classes 1 out of 12 batches
Epoch 1 of 30 took 158.199s
  training loss:		1.046642
  validation loss:		0.287214
  top 1 accuracy:		93.75 %
0.39450496435165405
0.1777438223361969
Batch of classes 1 out of 12 batches
Epoch 2 of 30 took 143.392s
  training loss:		0.254619
  validation loss:		0.284471
  top 1 accuracy:		62.50 %
0.20206698775291443
0.14821648597717285
Batch of classes 1 out of 12 batches
Epoch 3 of 30 took 112.727s
  training loss:		0.176791
  validation loss:		0.338457
  top 1 accuracy:		68.75 %
0.060407526791095734
0.10675596445798874
Batch of classes 1 out of 12 batches
Epoch 4 of 30 took 137.036s
  training loss:		0.160669
  validation loss:		0.120143
  top 1 accuracy:		93.75 %
0.25487521290779114
0.2879522442817688
Batch of classes 1 out of 12 batches
Epoch 5 of 30 took 80.920s
  training loss:		0.125901
  validation loss:		0.140869
  top 1 accuracy:		93.75 %
0.07948726415634155
0.04537436366081238
Batch of classes 1 out of 12 batches
Epoch 6 of 30 took 50.364s
  training loss:		0.111863
  validation loss:		0.115168
  top 1 accuracy:		100.00 %
0.048577822744846344
0.05727429315447807
Batch of classes 1 out of 12 batches
Epoch 7 of 30 took 43.301s
  training loss:		0.113349
  validation loss:		0.414273
  top 1 accuracy:		87.50 %
0.07306420803070068
0.026379475370049477
Batch of classes 1 out of 12 batches
Epoch 8 of 30 took 92.017s
  training loss:		0.081284
  validation loss:		0.147433
  top 1 accuracy:		93.75 %
0.017068076878786087
0.1283293217420578
Batch of classes 1 out of 12 batches
Epoch 9 of 30 took 137.390s
  training loss:		0.089770
  validation loss:		0.094457
  top 1 accuracy:		100.00 %
0.32934823632240295
0.07817353308200836
Batch of classes 1 out of 12 batches
Epoch 10 of 30 took 133.794s
  training loss:		0.115534
  validation loss:		0.115407
  top 1 accuracy:		100.00 %
0.26642754673957825
0.021488532423973083
Batch of classes 1 out of 12 batches
Epoch 11 of 30 took 112.802s
  training loss:		0.039981
  validation loss:		0.026669
  top 1 accuracy:		100.00 %
0.004442065022885799
0.013048199005424976
Batch of classes 1 out of 12 batches
Epoch 12 of 30 took 125.589s
  training loss:		0.017361
  validation loss:		0.027407
  top 1 accuracy:		100.00 %
0.003677237778902054
0.017437636852264404
Batch of classes 1 out of 12 batches
Epoch 13 of 30 took 127.991s
  training loss:		0.014198
  validation loss:		0.015657
  top 1 accuracy:		100.00 %
0.007653058506548405
0.0004980633384548128
Batch of classes 1 out of 12 batches
Epoch 14 of 30 took 88.754s
  training loss:		0.011989
  validation loss:		0.019865
  top 1 accuracy:		100.00 %
0.009459901601076126
0.012773629277944565
Batch of classes 1 out of 12 batches
Epoch 15 of 30 took 41.365s
  training loss:		0.019848
  validation loss:		0.017164
  top 1 accuracy:		100.00 %
0.0005653059342876077
0.0780172199010849
Batch of classes 1 out of 12 batches
Epoch 16 of 30 took 42.528s
  training loss:		0.023246
  validation loss:		0.043836
  top 1 accuracy:		100.00 %
0.002529267920181155
0.00819477066397667
Batch of classes 1 out of 12 batches
Epoch 17 of 30 took 41.113s
  training loss:		0.025187
  validation loss:		0.018190
  top 1 accuracy:		100.00 %
0.004171282052993774
0.028001796454191208
Batch of classes 1 out of 12 batches
Epoch 18 of 30 took 41.348s
  training loss:		0.023848
  validation loss:		0.038006
  top 1 accuracy:		100.00 %
0.01065509021282196
0.009515556506812572
Batch of classes 1 out of 12 batches
Epoch 19 of 30 took 41.277s
  training loss:		0.017256
  validation loss:		0.019384
  top 1 accuracy:		100.00 %
0.0001654277730267495
0.00022043648641556501
Batch of classes 1 out of 12 batches
Epoch 20 of 30 took 41.528s
  training loss:		0.018291
  validation loss:		0.031066
  top 1 accuracy:		100.00 %
0.011134704574942589
0.07401009649038315
Batch of classes 1 out of 12 batches
Epoch 21 of 30 took 42.942s
  training loss:		0.010705
  validation loss:		0.016558
  top 1 accuracy:		100.00 %
0.01085621863603592
0.00042560792644508183
Batch of classes 1 out of 12 batches
Epoch 22 of 30 took 47.184s
  training loss:		0.007298
  validation loss:		0.015785
  top 1 accuracy:		100.00 %
0.0010414165444672108
0.0029999513644725084
Batch of classes 1 out of 12 batches
Epoch 23 of 30 took 41.275s
  training loss:		0.003346
  validation loss:		0.010780
  top 1 accuracy:		100.00 %
0.00047415352310054004
0.000508216442540288
Batch of classes 1 out of 12 batches
Epoch 24 of 30 took 40.983s
  training loss:		0.005692
  validation loss:		0.013196
  top 1 accuracy:		100.00 %
0.0016882129712030292
0.006504627410322428
Batch of classes 1 out of 12 batches
Epoch 25 of 30 took 41.490s
  training loss:		0.004412
  validation loss:		0.013552
  top 1 accuracy:		100.00 %
0.002675562398508191
0.000228693155804649
Batch of classes 1 out of 12 batches
Epoch 26 of 30 took 41.512s
  training loss:		0.005179
  validation loss:		0.013656
  top 1 accuracy:		100.00 %
7.494440069422126e-05
0.001559038762934506
Batch of classes 1 out of 12 batches
Epoch 27 of 30 took 42.439s
  training loss:		0.003827
  validation loss:		0.007181
  top 1 accuracy:		100.00 %
4.172146145720035e-05
2.129802669514902e-05
Batch of classes 1 out of 12 batches
Epoch 28 of 30 took 47.710s
  training loss:		0.005014
  validation loss:		0.009993
  top 1 accuracy:		100.00 %
0.00027073020464740694
4.067136978846975e-05
Batch of classes 1 out of 12 batches
Epoch 29 of 30 took 52.016s
  training loss:		0.002155
  validation loss:		0.006984
  top 1 accuracy:		100.00 %
0.0028708958998322487
0.0006400058045983315
Batch of classes 1 out of 12 batches
Epoch 30 of 30 took 46.079s
  training loss:		0.002654
  validation loss:		0.009668
  top 1 accuracy:		100.00 %
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(500)
tensor(500)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		99.70 %
  top 1 accuracy Hybrid 1       :		99.85 %
  top 1 accuracy NCM            :		99.70 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		99.70 %
  top 1 accuracy Hybrid 1       :		99.85 %
  top 1 accuracy NCM            :		99.70 %
Classes in this batch: tensor([2, 3])
Data Size: 2400


Before first epoch
  validation loss:		1.289923
  top 1 accuracy:		34.38 %
Batch of classes number 2 arrives ...
0.5467977523803711
0.16472069919109344
Batch of classes 2 out of 12 batches
Epoch 1 of 30 took 46.682s
  training loss:		0.305169
  validation loss:		0.184947
  top 1 accuracy:		87.50 %
0.17144745588302612
0.20599161088466644
Batch of classes 2 out of 12 batches
Epoch 2 of 30 took 26.489s
  training loss:		0.211664
  validation loss:		0.161871
  top 1 accuracy:		100.00 %
0.1660960465669632
0.21342365443706512
Batch of classes 2 out of 12 batches
Epoch 3 of 30 took 26.588s
  training loss:		0.175219
  validation loss:		0.096503
  top 1 accuracy:		100.00 %
0.10640569776296616
0.09285598248243332
Batch of classes 2 out of 12 batches
Epoch 4 of 30 took 26.494s
  training loss:		0.171035
  validation loss:		0.135257
  top 1 accuracy:		96.88 %
0.1613297462463379
0.13156282901763916
Batch of classes 2 out of 12 batches
Epoch 5 of 30 took 26.545s
  training loss:		0.184958
  validation loss:		0.132940
  top 1 accuracy:		100.00 %
0.1602717936038971
0.2948131561279297
Batch of classes 2 out of 12 batches
Epoch 6 of 30 took 26.679s
  training loss:		0.153773
  validation loss:		0.118985
  top 1 accuracy:		100.00 %
0.054414425045251846
0.19490766525268555
Batch of classes 2 out of 12 batches
Epoch 7 of 30 took 26.759s
  training loss:		0.175194
  validation loss:		0.116897
  top 1 accuracy:		100.00 %
0.17371781170368195
0.2466692477464676
Batch of classes 2 out of 12 batches
Epoch 8 of 30 took 26.752s
  training loss:		0.161334
  validation loss:		0.117821
  top 1 accuracy:		100.00 %
0.1546289175748825
0.10140945762395859
Batch of classes 2 out of 12 batches
Epoch 9 of 30 took 26.405s
  training loss:		0.164787
  validation loss:		0.099929
  top 1 accuracy:		96.88 %
0.16530801355838776
0.18865634500980377
Batch of classes 2 out of 12 batches
Epoch 10 of 30 took 26.745s
  training loss:		0.159299
  validation loss:		0.104211
  top 1 accuracy:		100.00 %
0.12396208941936493
0.059656962752342224
Batch of classes 2 out of 12 batches
Epoch 11 of 30 took 26.716s
  training loss:		0.105042
  validation loss:		0.049206
  top 1 accuracy:		100.00 %
0.09620335698127747
0.06352076679468155
Batch of classes 2 out of 12 batches
Epoch 12 of 30 took 26.507s
  training loss:		0.099406
  validation loss:		0.046577
  top 1 accuracy:		100.00 %
0.08266837149858475
0.10460670292377472
Batch of classes 2 out of 12 batches
Epoch 13 of 30 took 26.613s
  training loss:		0.092786
  validation loss:		0.043970
  top 1 accuracy:		100.00 %
0.12033338844776154
0.11400819569826126
Batch of classes 2 out of 12 batches
Epoch 14 of 30 took 26.419s
  training loss:		0.093404
  validation loss:		0.050608
  top 1 accuracy:		100.00 %
0.07361511886119843
0.07684988528490067
Batch of classes 2 out of 12 batches
Epoch 15 of 30 took 26.814s
  training loss:		0.091281
  validation loss:		0.048193
  top 1 accuracy:		100.00 %
0.054628707468509674
0.09235117584466934
Batch of classes 2 out of 12 batches
Epoch 16 of 30 took 26.762s
  training loss:		0.087740
  validation loss:		0.039564
  top 1 accuracy:		100.00 %
0.0734742134809494
0.05615008994936943
Batch of classes 2 out of 12 batches
Epoch 17 of 30 took 26.237s
  training loss:		0.087238
  validation loss:		0.041143
  top 1 accuracy:		100.00 %
0.0923776924610138
0.0809047669172287
Batch of classes 2 out of 12 batches
Epoch 18 of 30 took 26.933s
  training loss:		0.089861
  validation loss:		0.047376
  top 1 accuracy:		100.00 %
0.06945773959159851
0.06678063422441483
Batch of classes 2 out of 12 batches
Epoch 19 of 30 took 26.838s
  training loss:		0.091779
  validation loss:		0.047906
  top 1 accuracy:		100.00 %
0.08861006796360016
0.09617989510297775
Batch of classes 2 out of 12 batches
Epoch 20 of 30 took 26.810s
  training loss:		0.124483
  validation loss:		0.043944
  top 1 accuracy:		100.00 %
0.0753994882106781
0.0774882435798645
Batch of classes 2 out of 12 batches
Epoch 21 of 30 took 26.492s
  training loss:		0.088236
  validation loss:		0.041576
  top 1 accuracy:		100.00 %
0.09419992566108704
0.08313128352165222
Batch of classes 2 out of 12 batches
Epoch 22 of 30 took 26.890s
  training loss:		0.087243
  validation loss:		0.038589
  top 1 accuracy:		100.00 %
0.05145344138145447
0.09345154464244843
Batch of classes 2 out of 12 batches
Epoch 23 of 30 took 26.474s
  training loss:		0.083802
  validation loss:		0.038263
  top 1 accuracy:		100.00 %
0.09523118287324905
0.11508115381002426
Batch of classes 2 out of 12 batches
Epoch 24 of 30 took 26.804s
  training loss:		0.083682
  validation loss:		0.038356
  top 1 accuracy:		100.00 %
0.08969821035861969
0.10011325776576996
Batch of classes 2 out of 12 batches
Epoch 25 of 30 took 26.103s
  training loss:		0.084629
  validation loss:		0.038739
  top 1 accuracy:		100.00 %
0.13708031177520752
0.10765446722507477
Batch of classes 2 out of 12 batches
Epoch 26 of 30 took 26.127s
  training loss:		0.083853
  validation loss:		0.039456
  top 1 accuracy:		100.00 %
0.04411165043711662
0.05111566558480263
Batch of classes 2 out of 12 batches
Epoch 27 of 30 took 26.545s
  training loss:		0.094674
  validation loss:		0.036375
  top 1 accuracy:		100.00 %
0.08309493213891983
0.06630276143550873
Batch of classes 2 out of 12 batches
Epoch 28 of 30 took 26.551s
  training loss:		0.085003
  validation loss:		0.043866
  top 1 accuracy:		100.00 %
0.11775491386651993
0.09328165650367737
Batch of classes 2 out of 12 batches
Epoch 29 of 30 took 26.291s
  training loss:		0.084375
  validation loss:		0.039530
  top 1 accuracy:		100.00 %
0.09331607818603516
0.07317213714122772
Batch of classes 2 out of 12 batches
Epoch 30 of 30 took 26.355s
  training loss:		0.082978
  validation loss:		0.036413
  top 1 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(384)
tensor(384)
tensor(384)
tensor(384)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		97.90 %
  top 1 accuracy Hybrid 1       :		97.85 %
  top 1 accuracy NCM            :		97.90 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		98.62 %
  top 1 accuracy Hybrid 1       :		98.75 %
  top 1 accuracy NCM            :		98.62 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		98.11 %
  top 1 accuracy Hybrid 1       :		98.11 %
  top 1 accuracy NCM            :		98.11 %
Classes in this batch: tensor([4, 5])
Data Size: 1572


Before first epoch
  validation loss:		1.234346
  top 1 accuracy:		16.67 %
Batch of classes number 3 arrives ...
0.20020996034145355
Batch of classes 3 out of 12 batches
Epoch 1 of 30 took 34.812s
  training loss:		0.254940
  validation loss:		0.243758
  top 1 accuracy:		100.00 %
0.1697520613670349
Batch of classes 3 out of 12 batches
Epoch 2 of 30 took 23.418s
  training loss:		0.186224
  validation loss:		0.229098
  top 1 accuracy:		83.33 %
0.12097737938165665
Batch of classes 3 out of 12 batches
Epoch 3 of 30 took 23.513s
  training loss:		0.198692
  validation loss:		0.182512
  top 1 accuracy:		83.33 %
0.23076029121875763
Batch of classes 3 out of 12 batches
Epoch 4 of 30 took 23.289s
  training loss:		0.202484
  validation loss:		0.523547
  top 1 accuracy:		100.00 %
0.23045584559440613
Batch of classes 3 out of 12 batches
Epoch 5 of 30 took 23.463s
  training loss:		0.191192
  validation loss:		0.165461
  top 1 accuracy:		100.00 %
0.21348273754119873
Batch of classes 3 out of 12 batches
Epoch 6 of 30 took 23.291s
  training loss:		0.177779
  validation loss:		0.195987
  top 1 accuracy:		100.00 %
0.1779855191707611
Batch of classes 3 out of 12 batches
Epoch 7 of 30 took 23.580s
  training loss:		0.175451
  validation loss:		0.155308
  top 1 accuracy:		100.00 %
0.10454665869474411
Batch of classes 3 out of 12 batches
Epoch 8 of 30 took 23.351s
  training loss:		0.161585
  validation loss:		0.246540
  top 1 accuracy:		100.00 %
0.10085529834032059
Batch of classes 3 out of 12 batches
Epoch 9 of 30 took 23.520s
  training loss:		0.203781
  validation loss:		0.137100
  top 1 accuracy:		100.00 %
0.17119276523590088
Batch of classes 3 out of 12 batches
Epoch 10 of 30 took 23.507s
  training loss:		0.147313
  validation loss:		0.195779
  top 1 accuracy:		100.00 %
0.10145331174135208
Batch of classes 3 out of 12 batches
Epoch 11 of 30 took 23.412s
  training loss:		0.137484
  validation loss:		0.122011
  top 1 accuracy:		100.00 %
0.04258022457361221
Batch of classes 3 out of 12 batches
Epoch 12 of 30 took 23.586s
  training loss:		0.109269
  validation loss:		0.081266
  top 1 accuracy:		100.00 %
0.10099364817142487
Batch of classes 3 out of 12 batches
Epoch 13 of 30 took 23.156s
  training loss:		0.101461
  validation loss:		0.095025
  top 1 accuracy:		100.00 %
0.07247461378574371
Batch of classes 3 out of 12 batches
Epoch 14 of 30 took 23.417s
  training loss:		0.099662
  validation loss:		0.088002
  top 1 accuracy:		100.00 %
0.08620401471853256
Batch of classes 3 out of 12 batches
Epoch 15 of 30 took 23.501s
  training loss:		0.113042
  validation loss:		0.095005
  top 1 accuracy:		100.00 %
0.05645723640918732
Batch of classes 3 out of 12 batches
Epoch 16 of 30 took 23.516s
  training loss:		0.106560
  validation loss:		0.072213
  top 1 accuracy:		100.00 %
0.05875721573829651
Batch of classes 3 out of 12 batches
Epoch 17 of 30 took 23.397s
  training loss:		0.113195
  validation loss:		0.086116
  top 1 accuracy:		100.00 %
0.08463388681411743
Batch of classes 3 out of 12 batches
Epoch 18 of 30 took 23.305s
  training loss:		0.096266
  validation loss:		0.088601
  top 1 accuracy:		100.00 %
0.06577441096305847
Batch of classes 3 out of 12 batches
Epoch 19 of 30 took 23.532s
  training loss:		0.098631
  validation loss:		0.081892
  top 1 accuracy:		100.00 %
0.08408913016319275
Batch of classes 3 out of 12 batches
Epoch 20 of 30 took 26.613s
  training loss:		0.095159
  validation loss:		0.087603
  top 1 accuracy:		100.00 %
0.04578111320734024
Batch of classes 3 out of 12 batches
Epoch 21 of 30 took 23.411s
  training loss:		0.090618
  validation loss:		0.077172
  top 1 accuracy:		100.00 %
0.1513473093509674
Batch of classes 3 out of 12 batches
Epoch 22 of 30 took 23.547s
  training loss:		0.090825
  validation loss:		0.072980
  top 1 accuracy:		100.00 %
0.12163634598255157
Batch of classes 3 out of 12 batches
Epoch 23 of 30 took 23.249s
  training loss:		0.092645
  validation loss:		0.075187
  top 1 accuracy:		100.00 %
0.10297863185405731
Batch of classes 3 out of 12 batches
Epoch 24 of 30 took 23.250s
  training loss:		0.102381
  validation loss:		0.081181
  top 1 accuracy:		100.00 %
0.07077237963676453
Batch of classes 3 out of 12 batches
Epoch 25 of 30 took 23.471s
  training loss:		0.102764
  validation loss:		0.061124
  top 1 accuracy:		100.00 %
0.04697046056389809
Batch of classes 3 out of 12 batches
Epoch 26 of 30 took 23.240s
  training loss:		0.095302
  validation loss:		0.069163
  top 1 accuracy:		100.00 %
0.1195959821343422
Batch of classes 3 out of 12 batches
Epoch 27 of 30 took 23.534s
  training loss:		0.097006
  validation loss:		0.081229
  top 1 accuracy:		100.00 %
0.09670665860176086
Batch of classes 3 out of 12 batches
Epoch 28 of 30 took 23.416s
  training loss:		0.099232
  validation loss:		0.086773
  top 1 accuracy:		100.00 %
0.08788196742534637
Batch of classes 3 out of 12 batches
Epoch 29 of 30 took 23.573s
  training loss:		0.091005
  validation loss:		0.062818
  top 1 accuracy:		100.00 %
0.12853580713272095
Batch of classes 3 out of 12 batches
Epoch 30 of 30 took 23.782s
  training loss:		0.095195
  validation loss:		0.093470
  top 1 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(256)
tensor(256)
tensor(256)
tensor(256)
tensor(256)
tensor(256)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		96.00 %
  top 1 accuracy Hybrid 1       :		96.45 %
  top 1 accuracy NCM            :		96.05 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		96.00 %
  top 1 accuracy Hybrid 1       :		96.50 %
  top 1 accuracy NCM            :		96.00 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		96.95 %
  top 1 accuracy Hybrid 1       :		97.52 %
  top 1 accuracy NCM            :		96.95 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		96.15 %
  top 1 accuracy Hybrid 1       :		96.63 %
  top 1 accuracy NCM            :		96.18 %
Classes in this batch: tensor([6, 7])
Data Size: 7656


Before first epoch
  validation loss:		0.261107
  top 1 accuracy:		87.50 %
Batch of classes number 4 arrives ...
0.4346143305301666
0.08745967596769333
0.1257563680410385
Batch of classes 4 out of 12 batches
Epoch 1 of 30 took 201.187s
  training loss:		0.132622
  validation loss:		0.019407
  top 1 accuracy:		100.00 %
0.10406075417995453
0.13939735293388367
0.10651381313800812
Batch of classes 4 out of 12 batches
Epoch 2 of 30 took 178.629s
  training loss:		0.115820
  validation loss:		0.028958
  top 1 accuracy:		100.00 %
0.0688539445400238
0.08296015858650208
0.10143057256937027
Batch of classes 4 out of 12 batches
Epoch 3 of 30 took 173.401s
  training loss:		0.117528
  validation loss:		0.018369
  top 1 accuracy:		100.00 %
0.15732774138450623
0.09889478236436844
0.11578316986560822
Batch of classes 4 out of 12 batches
Epoch 4 of 30 took 148.411s
  training loss:		0.105448
  validation loss:		0.016022
  top 1 accuracy:		100.00 %
0.055717505514621735
0.1038827896118164
0.08852845430374146
Batch of classes 4 out of 12 batches
Epoch 5 of 30 took 178.237s
  training loss:		0.103651
  validation loss:		0.034047
  top 1 accuracy:		100.00 %
0.06556679308414459
0.06999489665031433
0.07796920835971832
Batch of classes 4 out of 12 batches
Epoch 6 of 30 took 177.074s
  training loss:		0.084400
  validation loss:		0.028387
  top 1 accuracy:		100.00 %
0.25691646337509155
0.1744423359632492
0.1007801815867424
Batch of classes 4 out of 12 batches
Epoch 7 of 30 took 185.771s
  training loss:		0.132167
  validation loss:		0.024155
  top 1 accuracy:		100.00 %
0.16391126811504364
0.09561576694250107
0.05885203555226326
Batch of classes 4 out of 12 batches
Epoch 8 of 30 took 130.921s
  training loss:		0.089169
  validation loss:		0.049420
  top 1 accuracy:		100.00 %
0.37578675150871277
0.05471713840961456
0.07475079596042633
Batch of classes 4 out of 12 batches
Epoch 9 of 30 took 73.903s
  training loss:		0.099695
  validation loss:		0.012481
  top 1 accuracy:		100.00 %
0.12920506298542023
0.05221990495920181
0.0802321657538414
Batch of classes 4 out of 12 batches
Epoch 10 of 30 took 73.193s
  training loss:		0.093359
  validation loss:		0.014173
  top 1 accuracy:		100.00 %
0.041502680629491806
0.07802194356918335
0.04592626169323921
Batch of classes 4 out of 12 batches
Epoch 11 of 30 took 73.247s
  training loss:		0.077666
  validation loss:		0.016737
  top 1 accuracy:		100.00 %
0.06516358256340027
0.06722463667392731
0.07909256964921951
Batch of classes 4 out of 12 batches
Epoch 12 of 30 took 73.109s
  training loss:		0.071614
  validation loss:		0.013577
  top 1 accuracy:		100.00 %
0.09690459072589874
0.08674008399248123
0.06549292802810669
Batch of classes 4 out of 12 batches
Epoch 13 of 30 took 73.556s
  training loss:		0.070022
  validation loss:		0.011997
  top 1 accuracy:		100.00 %
0.055578362196683884
0.05885061249136925
0.09334300458431244
Batch of classes 4 out of 12 batches
Epoch 14 of 30 took 72.457s
  training loss:		0.070088
  validation loss:		0.013292
  top 1 accuracy:		100.00 %
0.09408961981534958
0.06438000500202179
0.08231090009212494
Batch of classes 4 out of 12 batches
Epoch 15 of 30 took 72.404s
  training loss:		0.071174
  validation loss:		0.013108
  top 1 accuracy:		100.00 %
0.04197292402386665
0.07637772709131241
0.08546587079763412
Batch of classes 4 out of 12 batches
Epoch 16 of 30 took 72.760s
  training loss:		0.072008
  validation loss:		0.012991
  top 1 accuracy:		100.00 %
0.05617950111627579
0.09076979756355286
0.08157595247030258
Batch of classes 4 out of 12 batches
Epoch 17 of 30 took 72.507s
  training loss:		0.072188
  validation loss:		0.018101
  top 1 accuracy:		100.00 %
0.07943394780158997
0.09409815073013306
0.07034116983413696
Batch of classes 4 out of 12 batches
Epoch 18 of 30 took 72.875s
  training loss:		0.079890
  validation loss:		0.012461
  top 1 accuracy:		100.00 %
0.07192670553922653
0.07735052704811096
0.074024498462677
Batch of classes 4 out of 12 batches
Epoch 19 of 30 took 72.735s
  training loss:		0.076988
  validation loss:		0.011934
  top 1 accuracy:		100.00 %
0.04148061200976372
0.09742722660303116
0.050543203949928284
Batch of classes 4 out of 12 batches
Epoch 20 of 30 took 72.576s
  training loss:		0.071533
  validation loss:		0.013684
  top 1 accuracy:		100.00 %
0.06763258576393127
0.04078874737024307
0.08713075518608093
Batch of classes 4 out of 12 batches
Epoch 21 of 30 took 73.092s
  training loss:		0.069506
  validation loss:		0.013281
  top 1 accuracy:		100.00 %
0.07821859419345856
0.05163073167204857
0.061195388436317444
Batch of classes 4 out of 12 batches
Epoch 22 of 30 took 72.759s
  training loss:		0.069114
  validation loss:		0.014335
  top 1 accuracy:		100.00 %
0.07722080498933792
0.06211850792169571
0.07760530710220337
Batch of classes 4 out of 12 batches
Epoch 23 of 30 took 72.777s
  training loss:		0.069489
  validation loss:		0.014026
  top 1 accuracy:		100.00 %
0.08265390247106552
0.06028412654995918
0.052868254482746124
Batch of classes 4 out of 12 batches
Epoch 24 of 30 took 72.674s
  training loss:		0.069902
  validation loss:		0.013647
  top 1 accuracy:		100.00 %
0.06798283010721207
0.05738023295998573
0.05578327551484108
Batch of classes 4 out of 12 batches
Epoch 25 of 30 took 73.031s
  training loss:		0.070242
  validation loss:		0.013494
  top 1 accuracy:		100.00 %
0.06672751903533936
0.0604204386472702
0.06463036686182022
Batch of classes 4 out of 12 batches
Epoch 26 of 30 took 72.785s
  training loss:		0.072105
  validation loss:		0.014550
  top 1 accuracy:		100.00 %
0.08790133148431778
0.06886444240808487
0.11023595184087753
Batch of classes 4 out of 12 batches
Epoch 27 of 30 took 72.852s
  training loss:		0.070142
  validation loss:		0.015936
  top 1 accuracy:		100.00 %
0.07234132289886475
0.08182596415281296
0.04086186736822128
Batch of classes 4 out of 12 batches
Epoch 28 of 30 took 73.061s
  training loss:		0.070022
  validation loss:		0.017522
  top 1 accuracy:		100.00 %
0.07445333898067474
0.06303158402442932
0.07902835309505463
Batch of classes 4 out of 12 batches
Epoch 29 of 30 took 72.767s
  training loss:		0.070666
  validation loss:		0.012235
  top 1 accuracy:		100.00 %
0.0920891985297203
0.07598503679037094
0.0747707262635231
Batch of classes 4 out of 12 batches
Epoch 30 of 30 took 72.318s
  training loss:		0.070032
  validation loss:		0.016105
  top 1 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		94.00 %
  top 1 accuracy Hybrid 1       :		94.35 %
  top 1 accuracy NCM            :		93.80 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		95.62 %
  top 1 accuracy Hybrid 1       :		96.38 %
  top 1 accuracy NCM            :		95.62 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		94.66 %
  top 1 accuracy Hybrid 1       :		95.23 %
  top 1 accuracy NCM            :		94.66 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		100.00 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		96.89 %
  top 1 accuracy Hybrid 1       :		97.16 %
  top 1 accuracy NCM            :		96.82 %
Classes in this batch: tensor([8, 9])
Data Size: 3248


Before first epoch
  validation loss:		1.259341
  top 1 accuracy:		0.00 %
Batch of classes number 5 arrives ...
0.6039032340049744
0.3880237340927124
Batch of classes 5 out of 12 batches
Epoch 1 of 30 took 43.611s
  training loss:		0.332867
  validation loss:		0.200738
  top 1 accuracy:		100.00 %
0.23314428329467773
0.4159756898880005
Batch of classes 5 out of 12 batches
Epoch 2 of 30 took 34.501s
  training loss:		0.251339
  validation loss:		0.179452
  top 1 accuracy:		100.00 %
0.2968235909938812
0.19636498391628265
Batch of classes 5 out of 12 batches
Epoch 3 of 30 took 34.939s
  training loss:		0.221420
  validation loss:		0.203839
  top 1 accuracy:		100.00 %
0.2436426281929016
0.1934433877468109
Batch of classes 5 out of 12 batches
Epoch 4 of 30 took 34.588s
  training loss:		0.213509
  validation loss:		0.170735
  top 1 accuracy:		100.00 %
0.14991065859794617
0.17393988370895386
Batch of classes 5 out of 12 batches
Epoch 5 of 30 took 34.628s
  training loss:		0.195261
  validation loss:		0.158500
  top 1 accuracy:		100.00 %
0.1463923454284668
0.14315181970596313
Batch of classes 5 out of 12 batches
Epoch 6 of 30 took 34.748s
  training loss:		0.214601
  validation loss:		0.124548
  top 1 accuracy:		100.00 %
0.1617242842912674
0.1746746301651001
Batch of classes 5 out of 12 batches
Epoch 7 of 30 took 34.647s
  training loss:		0.172432
  validation loss:		0.139099
  top 1 accuracy:		100.00 %
0.16136214137077332
0.19907240569591522
Batch of classes 5 out of 12 batches
Epoch 8 of 30 took 34.522s
  training loss:		0.182053
  validation loss:		0.153719
  top 1 accuracy:		100.00 %
0.2193763256072998
0.38678744435310364
Batch of classes 5 out of 12 batches
Epoch 9 of 30 took 34.656s
  training loss:		0.207745
  validation loss:		0.147247
  top 1 accuracy:		100.00 %
0.19768038392066956
0.20098167657852173
Batch of classes 5 out of 12 batches
Epoch 10 of 30 took 34.295s
  training loss:		0.182632
  validation loss:		0.135279
  top 1 accuracy:		100.00 %
0.15154114365577698
0.18518996238708496
Batch of classes 5 out of 12 batches
Epoch 11 of 30 took 34.795s
  training loss:		0.155596
  validation loss:		0.123480
  top 1 accuracy:		100.00 %
0.15530824661254883
0.16455230116844177
Batch of classes 5 out of 12 batches
Epoch 12 of 30 took 34.719s
  training loss:		0.147302
  validation loss:		0.131293
  top 1 accuracy:		100.00 %
0.16685278713703156
0.14259397983551025
Batch of classes 5 out of 12 batches
Epoch 13 of 30 took 34.543s
  training loss:		0.143405
  validation loss:		0.128318
  top 1 accuracy:		100.00 %
0.17129743099212646
0.1973666250705719
Batch of classes 5 out of 12 batches
Epoch 14 of 30 took 34.634s
  training loss:		0.142300
  validation loss:		0.115113
  top 1 accuracy:		100.00 %
0.19182339310646057
0.130977064371109
Batch of classes 5 out of 12 batches
Epoch 15 of 30 took 34.710s
  training loss:		0.141572
  validation loss:		0.116826
  top 1 accuracy:		100.00 %
0.13433726131916046
0.12378917634487152
Batch of classes 5 out of 12 batches
Epoch 16 of 30 took 34.584s
  training loss:		0.142164
  validation loss:		0.129464
  top 1 accuracy:		100.00 %
0.14759112894535065
0.13316883146762848
Batch of classes 5 out of 12 batches
Epoch 17 of 30 took 34.769s
  training loss:		0.139372
  validation loss:		0.151514
  top 1 accuracy:		100.00 %
0.16528207063674927
0.10760782659053802
Batch of classes 5 out of 12 batches
Epoch 18 of 30 took 34.686s
  training loss:		0.141102
  validation loss:		0.122538
  top 1 accuracy:		100.00 %
0.11455707252025604
0.1327257752418518
Batch of classes 5 out of 12 batches
Epoch 19 of 30 took 34.665s
  training loss:		0.138819
  validation loss:		0.118507
  top 1 accuracy:		100.00 %
0.16844379901885986
0.13828971982002258
Batch of classes 5 out of 12 batches
Epoch 20 of 30 took 34.621s
  training loss:		0.140573
  validation loss:		0.116117
  top 1 accuracy:		100.00 %
0.10904764384031296
0.1144346296787262
Batch of classes 5 out of 12 batches
Epoch 21 of 30 took 34.617s
  training loss:		0.138907
  validation loss:		0.121350
  top 1 accuracy:		100.00 %
0.1163560077548027
0.1181921735405922
Batch of classes 5 out of 12 batches
Epoch 22 of 30 took 34.873s
  training loss:		0.138847
  validation loss:		0.120964
  top 1 accuracy:		100.00 %
0.10499883443117142
0.10560708492994308
Batch of classes 5 out of 12 batches
Epoch 23 of 30 took 34.471s
  training loss:		0.137105
  validation loss:		0.121971
  top 1 accuracy:		100.00 %
0.11743220686912537
0.11833663284778595
Batch of classes 5 out of 12 batches
Epoch 24 of 30 took 34.666s
  training loss:		0.136825
  validation loss:		0.131488
  top 1 accuracy:		100.00 %
0.16379404067993164
0.15515616536140442
Batch of classes 5 out of 12 batches
Epoch 25 of 30 took 34.305s
  training loss:		0.137115
  validation loss:		0.132334
  top 1 accuracy:		100.00 %
0.18251147866249084
0.08226516842842102
Batch of classes 5 out of 12 batches
Epoch 26 of 30 took 34.305s
  training loss:		0.135324
  validation loss:		0.130479
  top 1 accuracy:		100.00 %
0.16564618051052094
0.14252644777297974
Batch of classes 5 out of 12 batches
Epoch 27 of 30 took 34.766s
  training loss:		0.134156
  validation loss:		0.124595
  top 1 accuracy:		100.00 %
0.11180184036493301
0.11050022393465042
Batch of classes 5 out of 12 batches
Epoch 28 of 30 took 34.650s
  training loss:		0.136939
  validation loss:		0.115492
  top 1 accuracy:		100.00 %
0.12816858291625977
0.18563306331634521
Batch of classes 5 out of 12 batches
Epoch 29 of 30 took 34.727s
  training loss:		0.135235
  validation loss:		0.119076
  top 1 accuracy:		100.00 %
0.14903219044208527
0.10257001966238022
Batch of classes 5 out of 12 batches
Epoch 30 of 30 took 34.547s
  training loss:		0.135671
  validation loss:		0.110730
  top 1 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		90.25 %
  top 1 accuracy Hybrid 1       :		90.15 %
  top 1 accuracy NCM            :		90.25 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		91.50 %
  top 1 accuracy Hybrid 1       :		92.12 %
  top 1 accuracy NCM            :		91.25 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		90.84 %
  top 1 accuracy Hybrid 1       :		91.60 %
  top 1 accuracy NCM            :		90.27 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.33 %
  top 1 accuracy Hybrid 1       :		99.45 %
  top 1 accuracy NCM            :		99.29 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		96.58 %
  top 1 accuracy Hybrid 1       :		96.77 %
  top 1 accuracy NCM            :		96.58 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		94.75 %
  top 1 accuracy Hybrid 1       :		94.93 %
  top 1 accuracy NCM            :		94.67 %
Classes in this batch: tensor([10, 11])
Data Size: 7658


Before first epoch
  validation loss:		0.062726
  top 1 accuracy:		95.83 %
Batch of classes number 6 arrives ...
0.189004048705101
0.04060713201761246
0.062180500477552414
Batch of classes 6 out of 12 batches
Epoch 1 of 30 took 86.824s
  training loss:		0.085215
  validation loss:		0.016364
  top 1 accuracy:		100.00 %
0.046585679054260254
0.02539384923875332
0.02871180884540081
Batch of classes 6 out of 12 batches
Epoch 2 of 30 took 73.080s
  training loss:		0.057602
  validation loss:		0.007691
  top 1 accuracy:		100.00 %
0.14480996131896973
0.012850268743932247
0.1043766587972641
Batch of classes 6 out of 12 batches
Epoch 3 of 30 took 72.700s
  training loss:		0.059573
  validation loss:		0.005292
  top 1 accuracy:		100.00 %
0.02230379357933998
0.016834570094943047
0.0667727142572403
Batch of classes 6 out of 12 batches
Epoch 4 of 30 took 73.604s
  training loss:		0.064526
  validation loss:		0.010944
  top 1 accuracy:		100.00 %
0.12881731986999512
0.03535153716802597
0.01711769588291645
Batch of classes 6 out of 12 batches
Epoch 5 of 30 took 72.872s
  training loss:		0.058219
  validation loss:		0.018389
  top 1 accuracy:		100.00 %
0.026042301207780838
0.016170715913176537
0.03076961636543274
Batch of classes 6 out of 12 batches
Epoch 6 of 30 took 73.143s
  training loss:		0.042103
  validation loss:		0.010068
  top 1 accuracy:		100.00 %
0.04362795501947403
0.019862128421664238
0.015025111846625805
Batch of classes 6 out of 12 batches
Epoch 7 of 30 took 73.048s
  training loss:		0.041603
  validation loss:		0.013841
  top 1 accuracy:		100.00 %
0.02909361571073532
0.04024510458111763
0.1290636956691742
Batch of classes 6 out of 12 batches
Epoch 8 of 30 took 73.350s
  training loss:		0.047317
  validation loss:		0.006086
  top 1 accuracy:		100.00 %
0.06603693962097168
0.02035706117749214
0.0626184269785881
Batch of classes 6 out of 12 batches
Epoch 9 of 30 took 72.827s
  training loss:		0.049560
  validation loss:		0.014395
  top 1 accuracy:		95.83 %
0.0779782235622406
0.05029134824872017
0.1758897602558136
Batch of classes 6 out of 12 batches
Epoch 10 of 30 took 72.492s
  training loss:		0.053820
  validation loss:		0.005541
  top 1 accuracy:		100.00 %
0.022064555436372757
0.05807773396372795
0.03378232568502426
Batch of classes 6 out of 12 batches
Epoch 11 of 30 took 72.917s
  training loss:		0.031561
  validation loss:		0.003835
  top 1 accuracy:		100.00 %
0.016013070940971375
0.014185063540935516
0.03870774433016777
Batch of classes 6 out of 12 batches
Epoch 12 of 30 took 73.131s
  training loss:		0.030044
  validation loss:		0.004660
  top 1 accuracy:		100.00 %
0.037527669221162796
0.018555499613285065
0.017078343778848648
Batch of classes 6 out of 12 batches
Epoch 13 of 30 took 72.733s
  training loss:		0.026513
  validation loss:		0.003001
  top 1 accuracy:		100.00 %
0.046634286642074585
0.026012921705842018
0.01541975699365139
Batch of classes 6 out of 12 batches
Epoch 14 of 30 took 72.729s
  training loss:		0.026815
  validation loss:		0.003091
  top 1 accuracy:		100.00 %
0.051577307283878326
0.03266013413667679
0.026864763349294662
Batch of classes 6 out of 12 batches
Epoch 15 of 30 took 72.855s
  training loss:		0.026941
  validation loss:		0.003350
  top 1 accuracy:		100.00 %
0.027476955205202103
0.029002724215388298
0.06369825452566147
Batch of classes 6 out of 12 batches
Epoch 16 of 30 took 73.192s
  training loss:		0.027911
  validation loss:		0.004248
  top 1 accuracy:		100.00 %
0.014621930196881294
0.02112877182662487
0.023512795567512512
Batch of classes 6 out of 12 batches
Epoch 17 of 30 took 73.431s
  training loss:		0.025903
  validation loss:		0.003534
  top 1 accuracy:		100.00 %
0.021564923226833344
0.03423341363668442
0.027712417766451836
Batch of classes 6 out of 12 batches
Epoch 18 of 30 took 73.492s
  training loss:		0.030866
  validation loss:		0.004395
  top 1 accuracy:		100.00 %
0.0569041445851326
0.027234984561800957
0.01897488720715046
Batch of classes 6 out of 12 batches
Epoch 19 of 30 took 72.822s
  training loss:		0.029526
  validation loss:		0.004129
  top 1 accuracy:		100.00 %
0.03718046098947525
0.03327002376317978
0.03662122040987015
Batch of classes 6 out of 12 batches
Epoch 20 of 30 took 72.567s
  training loss:		0.026694
  validation loss:		0.003868
  top 1 accuracy:		100.00 %
0.021180639043450356
0.0166816096752882
0.01937326043844223
Batch of classes 6 out of 12 batches
Epoch 21 of 30 took 72.979s
  training loss:		0.026957
  validation loss:		0.004210
  top 1 accuracy:		100.00 %
0.015732815489172935
0.030299315229058266
0.02240191586315632
Batch of classes 6 out of 12 batches
Epoch 22 of 30 took 73.012s
  training loss:		0.027110
  validation loss:		0.004172
  top 1 accuracy:		100.00 %
0.06605027616024017
0.033116664737463
0.01190506387501955
Batch of classes 6 out of 12 batches
Epoch 23 of 30 took 72.477s
  training loss:		0.026049
  validation loss:		0.003943
  top 1 accuracy:		100.00 %
0.029358956962823868
0.009837964549660683
0.024470921605825424
Batch of classes 6 out of 12 batches
Epoch 24 of 30 took 73.080s
  training loss:		0.025225
  validation loss:		0.003718
  top 1 accuracy:		100.00 %
0.021055404096841812
0.017744556069374084
0.01667454093694687
Batch of classes 6 out of 12 batches
Epoch 25 of 30 took 73.244s
  training loss:		0.025015
  validation loss:		0.003509
  top 1 accuracy:		100.00 %
0.022400079295039177
0.020192846655845642
0.01778271608054638
Batch of classes 6 out of 12 batches
Epoch 26 of 30 took 72.661s
  training loss:		0.025827
  validation loss:		0.003653
  top 1 accuracy:		100.00 %
0.028455790132284164
0.03172813355922699
0.03376578912138939
Batch of classes 6 out of 12 batches
Epoch 27 of 30 took 72.652s
  training loss:		0.025776
  validation loss:		0.003661
  top 1 accuracy:		100.00 %
0.032490018755197525
0.025081221014261246
0.031117886304855347
Batch of classes 6 out of 12 batches
Epoch 28 of 30 took 73.080s
  training loss:		0.026692
  validation loss:		0.003858
  top 1 accuracy:		100.00 %
0.048684459179639816
0.0213894285261631
0.024692080914974213
Batch of classes 6 out of 12 batches
Epoch 29 of 30 took 72.624s
  training loss:		0.025513
  validation loss:		0.003597
  top 1 accuracy:		100.00 %
0.018432937562465668
0.009507308714091778
0.04083867371082306
Batch of classes 6 out of 12 batches
Epoch 30 of 30 took 72.936s
  training loss:		0.025599
  validation loss:		0.003629
  top 1 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		86.30 %
  top 1 accuracy Hybrid 1       :		79.55 %
  top 1 accuracy NCM            :		87.15 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		93.50 %
  top 1 accuracy Hybrid 1       :		89.88 %
  top 1 accuracy NCM            :		92.88 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		93.89 %
  top 1 accuracy Hybrid 1       :		95.04 %
  top 1 accuracy NCM            :		93.51 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.92 %
  top 1 accuracy Hybrid 1       :		99.92 %
  top 1 accuracy NCM            :		99.88 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		95.84 %
  top 1 accuracy Hybrid 1       :		96.21 %
  top 1 accuracy NCM            :		95.75 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.96 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		99.92 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		95.73 %
  top 1 accuracy Hybrid 1       :		94.12 %
  top 1 accuracy NCM            :		95.80 %
Classes in this batch: tensor([12, 13])
Data Size: 6208


Before first epoch
  validation loss:		1.503295
  top 1 accuracy:		6.67 %
Batch of classes number 7 arrives ...
0.7833119034767151
0.5605236887931824
0.4381234645843506
Batch of classes 7 out of 12 batches
Epoch 1 of 30 took 73.641s
  training loss:		0.616840
  validation loss:		0.569046
  top 1 accuracy:		60.00 %
0.48736482858657837
0.48253899812698364
0.46656325459480286
Batch of classes 7 out of 12 batches
Epoch 2 of 30 took 54.162s
  training loss:		0.528709
  validation loss:		0.612395
  top 1 accuracy:		86.67 %
0.5960384607315063
0.4728650450706482
0.5277836322784424
Batch of classes 7 out of 12 batches
Epoch 3 of 30 took 54.127s
  training loss:		0.499457
  validation loss:		0.531428
  top 1 accuracy:		73.33 %
0.4957243502140045
0.4800916910171509
0.4197796881198883
Batch of classes 7 out of 12 batches
Epoch 4 of 30 took 54.404s
  training loss:		0.479441
  validation loss:		0.543544
  top 1 accuracy:		73.33 %
0.45376914739608765
0.36376065015792847
0.43325740098953247
Batch of classes 7 out of 12 batches
Epoch 5 of 30 took 54.153s
  training loss:		0.461374
  validation loss:		0.542702
  top 1 accuracy:		100.00 %
0.449069619178772
0.5759921073913574
0.5571126937866211
Batch of classes 7 out of 12 batches
Epoch 6 of 30 took 54.339s
  training loss:		0.454813
  validation loss:		0.512100
  top 1 accuracy:		80.00 %
0.5178198218345642
0.4365064203739166
0.2972840666770935
Batch of classes 7 out of 12 batches
Epoch 7 of 30 took 54.343s
  training loss:		0.440084
  validation loss:		0.516636
  top 1 accuracy:		66.67 %
0.4283677339553833
0.35184380412101746
0.3920595645904541
Batch of classes 7 out of 12 batches
Epoch 8 of 30 took 53.935s
  training loss:		0.433581
  validation loss:		0.534578
  top 1 accuracy:		53.33 %
0.5451049208641052
0.3911014497280121
0.4104565382003784
Batch of classes 7 out of 12 batches
Epoch 9 of 30 took 54.262s
  training loss:		0.418709
  validation loss:		0.588562
  top 1 accuracy:		66.67 %
0.4451252818107605
0.47004982829093933
0.3702622354030609
Batch of classes 7 out of 12 batches
Epoch 10 of 30 took 54.220s
  training loss:		0.401701
  validation loss:		0.573931
  top 1 accuracy:		80.00 %
0.3269360363483429
0.4021294116973877
0.46596068143844604
Batch of classes 7 out of 12 batches
Epoch 11 of 30 took 54.442s
  training loss:		0.354651
  validation loss:		0.491908
  top 1 accuracy:		80.00 %
0.31463220715522766
0.3802773952484131
0.4221494197845459
Batch of classes 7 out of 12 batches
Epoch 12 of 30 took 54.370s
  training loss:		0.337330
  validation loss:		0.467827
  top 1 accuracy:		86.67 %
0.2855793833732605
0.32378730177879333
0.4084867238998413
Batch of classes 7 out of 12 batches
Epoch 13 of 30 took 54.184s
  training loss:		0.328628
  validation loss:		0.474567
  top 1 accuracy:		80.00 %
0.3194406032562256
0.39498648047447205
0.27303412556648254
Batch of classes 7 out of 12 batches
Epoch 14 of 30 took 54.292s
  training loss:		0.320185
  validation loss:		0.489986
  top 1 accuracy:		73.33 %
0.33896446228027344
0.31125587224960327
0.42386889457702637
Batch of classes 7 out of 12 batches
Epoch 15 of 30 took 54.556s
  training loss:		0.320084
  validation loss:		0.468628
  top 1 accuracy:		73.33 %
0.28393426537513733
0.3386823832988739
0.258254736661911
Batch of classes 7 out of 12 batches
Epoch 16 of 30 took 54.454s
  training loss:		0.305973
  validation loss:		0.493304
  top 1 accuracy:		80.00 %
0.3231266140937805
0.21446681022644043
0.2569199502468109
Batch of classes 7 out of 12 batches
Epoch 17 of 30 took 54.274s
  training loss:		0.306170
  validation loss:		0.497977
  top 1 accuracy:		100.00 %
0.2817028760910034
0.26496589183807373
0.2778417468070984
Batch of classes 7 out of 12 batches
Epoch 18 of 30 took 55.418s
  training loss:		0.292751
  validation loss:		0.497951
  top 1 accuracy:		73.33 %
0.2704596221446991
0.3704597055912018
0.41622185707092285
Batch of classes 7 out of 12 batches
Epoch 19 of 30 took 54.148s
  training loss:		0.291310
  validation loss:		0.466457
  top 1 accuracy:		86.67 %
0.32021334767341614
0.2846313714981079
0.21576184034347534
Batch of classes 7 out of 12 batches
Epoch 20 of 30 took 54.422s
  training loss:		0.285308
  validation loss:		0.520794
  top 1 accuracy:		73.33 %
0.2749350965023041
0.4019232392311096
0.2719200551509857
Batch of classes 7 out of 12 batches
Epoch 21 of 30 took 54.813s
  training loss:		0.267501
  validation loss:		0.466255
  top 1 accuracy:		73.33 %
0.20867976546287537
0.29710716009140015
0.19358794391155243
Batch of classes 7 out of 12 batches
Epoch 22 of 30 took 54.657s
  training loss:		0.256708
  validation loss:		0.491423
  top 1 accuracy:		73.33 %
0.2532167434692383
0.19823282957077026
0.2331283688545227
Batch of classes 7 out of 12 batches
Epoch 23 of 30 took 54.306s
  training loss:		0.252894
  validation loss:		0.493767
  top 1 accuracy:		80.00 %
0.22525709867477417
0.21952921152114868
0.24276474118232727
Batch of classes 7 out of 12 batches
Epoch 24 of 30 took 53.906s
  training loss:		0.251695
  validation loss:		0.484127
  top 1 accuracy:		80.00 %
0.2452353835105896
0.2571970224380493
0.2778117060661316
Batch of classes 7 out of 12 batches
Epoch 25 of 30 took 54.333s
  training loss:		0.251280
  validation loss:		0.494013
  top 1 accuracy:		80.00 %
0.2647598385810852
0.3595738112926483
0.267887145280838
Batch of classes 7 out of 12 batches
Epoch 26 of 30 took 54.422s
  training loss:		0.244262
  validation loss:		0.505541
  top 1 accuracy:		80.00 %
0.24474966526031494
0.3175155222415924
0.26327335834503174
Batch of classes 7 out of 12 batches
Epoch 27 of 30 took 54.444s
  training loss:		0.245346
  validation loss:		0.522723
  top 1 accuracy:		73.33 %
0.22690370678901672
0.18410755693912506
0.2060326635837555
Batch of classes 7 out of 12 batches
Epoch 28 of 30 took 54.412s
  training loss:		0.239442
  validation loss:		0.498064
  top 1 accuracy:		80.00 %
0.233878031373024
0.22735601663589478
0.23183083534240723
Batch of classes 7 out of 12 batches
Epoch 29 of 30 took 53.725s
  training loss:		0.235160
  validation loss:		0.490674
  top 1 accuracy:		73.33 %
0.16725167632102966
0.26964253187179565
0.23939058184623718
Batch of classes 7 out of 12 batches
Epoch 30 of 30 took 54.266s
  training loss:		0.236465
  validation loss:		0.498312
  top 1 accuracy:		86.67 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		79.40 %
  top 1 accuracy Hybrid 1       :		79.00 %
  top 1 accuracy NCM            :		79.45 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		76.88 %
  top 1 accuracy Hybrid 1       :		78.12 %
  top 1 accuracy NCM            :		77.12 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		88.17 %
  top 1 accuracy Hybrid 1       :		87.98 %
  top 1 accuracy NCM            :		88.36 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		98.75 %
  top 1 accuracy Hybrid 1       :		99.53 %
  top 1 accuracy NCM            :		98.63 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		86.32 %
  top 1 accuracy Hybrid 1       :		84.84 %
  top 1 accuracy NCM            :		85.77 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		98.71 %
  top 1 accuracy Hybrid 1       :		99.45 %
  top 1 accuracy NCM            :		98.59 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		79.25 %
  top 1 accuracy Hybrid 1       :		80.13 %
  top 1 accuracy NCM            :		79.11 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		88.77 %
  top 1 accuracy Hybrid 1       :		89.13 %
  top 1 accuracy NCM            :		88.67 %
Classes in this batch: tensor([14, 15])
Data Size: 7200


Before first epoch
  validation loss:		2.854892
  top 1 accuracy:		6.25 %
Batch of classes number 8 arrives ...
0.6939823031425476
0.29216092824935913
0.2321213185787201
Batch of classes 8 out of 12 batches
Epoch 1 of 30 took 75.975s
  training loss:		0.291880
  validation loss:		0.206877
  top 1 accuracy:		96.88 %
0.24483144283294678
0.31146425008773804
0.29351139068603516
Batch of classes 8 out of 12 batches
Epoch 2 of 30 took 75.544s
  training loss:		0.240947
  validation loss:		0.212241
  top 1 accuracy:		100.00 %
0.16623416543006897
0.31241241097450256
0.19773384928703308
Batch of classes 8 out of 12 batches
Epoch 3 of 30 took 75.199s
  training loss:		0.215708
  validation loss:		0.282318
  top 1 accuracy:		78.12 %
0.17162829637527466
0.23120062053203583
0.1991269588470459
Batch of classes 8 out of 12 batches
Epoch 4 of 30 took 76.814s
  training loss:		0.219094
  validation loss:		0.160925
  top 1 accuracy:		100.00 %
0.3592635989189148
0.22577141225337982
0.23455481231212616
Batch of classes 8 out of 12 batches
Epoch 5 of 30 took 75.623s
  training loss:		0.203559
  validation loss:		0.062774
  top 1 accuracy:		100.00 %
0.23490720987319946
0.17862671613693237
0.18312302231788635
Batch of classes 8 out of 12 batches
Epoch 6 of 30 took 75.444s
  training loss:		0.192470
  validation loss:		0.635943
  top 1 accuracy:		56.25 %
0.19014547765254974
0.16650909185409546
0.1718299686908722
Batch of classes 8 out of 12 batches
Epoch 7 of 30 took 75.575s
  training loss:		0.204717
  validation loss:		0.165190
  top 1 accuracy:		100.00 %
0.18908365070819855
0.19761084020137787
0.16999655961990356
Batch of classes 8 out of 12 batches
Epoch 8 of 30 took 75.276s
  training loss:		0.193097
  validation loss:		0.097650
  top 1 accuracy:		100.00 %
0.23418186604976654
0.14301615953445435
0.21242010593414307
Batch of classes 8 out of 12 batches
Epoch 9 of 30 took 77.074s
  training loss:		0.195141
  validation loss:		0.229506
  top 1 accuracy:		100.00 %
0.3291272521018982
0.15475817024707794
0.1685115098953247
Batch of classes 8 out of 12 batches
Epoch 10 of 30 took 77.231s
  training loss:		0.191253
  validation loss:		0.104255
  top 1 accuracy:		100.00 %
0.18460211157798767
0.15938830375671387
0.20453894138336182
Batch of classes 8 out of 12 batches
Epoch 11 of 30 took 77.382s
  training loss:		0.167109
  validation loss:		0.078647
  top 1 accuracy:		100.00 %
0.10354863107204437
0.15225714445114136
0.17302477359771729
Batch of classes 8 out of 12 batches
Epoch 12 of 30 took 76.833s
  training loss:		0.162423
  validation loss:		0.058309
  top 1 accuracy:		100.00 %
0.1565195918083191
0.2230861485004425
0.14206096529960632
Batch of classes 8 out of 12 batches
Epoch 13 of 30 took 78.446s
  training loss:		0.159542
  validation loss:		0.052255
  top 1 accuracy:		100.00 %
0.18260027468204498
0.16544528305530548
0.2286907434463501
Batch of classes 8 out of 12 batches
Epoch 14 of 30 took 76.864s
  training loss:		0.158557
  validation loss:		0.053870
  top 1 accuracy:		100.00 %
0.17640650272369385
0.15057401359081268
0.16443748772144318
Batch of classes 8 out of 12 batches
Epoch 15 of 30 took 78.883s
  training loss:		0.159178
  validation loss:		0.071100
  top 1 accuracy:		100.00 %
0.20269151031970978
0.20399831235408783
0.17235039174556732
Batch of classes 8 out of 12 batches
Epoch 16 of 30 took 77.446s
  training loss:		0.158520
  validation loss:		0.049683
  top 1 accuracy:		100.00 %
0.18631267547607422
0.1385805308818817
0.14454354345798492
Batch of classes 8 out of 12 batches
Epoch 17 of 30 took 76.839s
  training loss:		0.158675
  validation loss:		0.049075
  top 1 accuracy:		100.00 %
0.12619169056415558
0.17045870423316956
0.13434967398643494
Batch of classes 8 out of 12 batches
Epoch 18 of 30 took 77.131s
  training loss:		0.159557
  validation loss:		0.063100
  top 1 accuracy:		100.00 %
0.1795472353696823
0.1598200649023056
0.1847105771303177
Batch of classes 8 out of 12 batches
Epoch 19 of 30 took 77.463s
  training loss:		0.160445
  validation loss:		0.056959
  top 1 accuracy:		100.00 %
0.143072247505188
0.1549220085144043
0.18347883224487305
Batch of classes 8 out of 12 batches
Epoch 20 of 30 took 76.753s
  training loss:		0.157866
  validation loss:		0.056299
  top 1 accuracy:		100.00 %
0.14399835467338562
0.21884065866470337
0.15791276097297668
Batch of classes 8 out of 12 batches
Epoch 21 of 30 took 76.891s
  training loss:		0.158766
  validation loss:		0.047257
  top 1 accuracy:		100.00 %
0.1617548018693924
0.1942022144794464
0.10423322021961212
Batch of classes 8 out of 12 batches
Epoch 22 of 30 took 77.245s
  training loss:		0.156692
  validation loss:		0.048922
  top 1 accuracy:		100.00 %
0.1618834137916565
0.16178816556930542
0.18608838319778442
Batch of classes 8 out of 12 batches
Epoch 23 of 30 took 77.237s
  training loss:		0.156002
  validation loss:		0.050207
  top 1 accuracy:		100.00 %
0.14446301758289337
0.1313852220773697
0.17834843695163727
Batch of classes 8 out of 12 batches
Epoch 24 of 30 took 77.889s
  training loss:		0.155572
  validation loss:		0.046533
  top 1 accuracy:		100.00 %
0.1731242835521698
0.19215133786201477
0.16219653189182281
Batch of classes 8 out of 12 batches
Epoch 25 of 30 took 77.696s
  training loss:		0.155456
  validation loss:		0.048638
  top 1 accuracy:		100.00 %
0.13960246741771698
0.19829849898815155
0.1505468338727951
Batch of classes 8 out of 12 batches
Epoch 26 of 30 took 78.322s
  training loss:		0.155130
  validation loss:		0.050313
  top 1 accuracy:		100.00 %
0.14757968485355377
0.11096179485321045
0.130355104804039
Batch of classes 8 out of 12 batches
Epoch 27 of 30 took 76.788s
  training loss:		0.156084
  validation loss:		0.054756
  top 1 accuracy:		100.00 %
0.15526698529720306
0.1547614187002182
0.12719197571277618
Batch of classes 8 out of 12 batches
Epoch 28 of 30 took 77.275s
  training loss:		0.155303
  validation loss:		0.044565
  top 1 accuracy:		100.00 %
0.17166189849376678
0.1439860761165619
0.10996003448963165
Batch of classes 8 out of 12 batches
Epoch 29 of 30 took 77.244s
  training loss:		0.154228
  validation loss:		0.046375
  top 1 accuracy:		100.00 %
0.13959971070289612
0.16001689434051514
0.11405394971370697
Batch of classes 8 out of 12 batches
Epoch 30 of 30 took 76.920s
  training loss:		0.155912
  validation loss:		0.054666
  top 1 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		74.60 %
  top 1 accuracy Hybrid 1       :		75.65 %
  top 1 accuracy NCM            :		75.40 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		77.38 %
  top 1 accuracy Hybrid 1       :		77.38 %
  top 1 accuracy NCM            :		77.62 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		88.93 %
  top 1 accuracy Hybrid 1       :		88.55 %
  top 1 accuracy NCM            :		88.17 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		98.90 %
  top 1 accuracy Hybrid 1       :		98.94 %
  top 1 accuracy NCM            :		98.67 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		90.48 %
  top 1 accuracy Hybrid 1       :		91.59 %
  top 1 accuracy NCM            :		90.30 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		98.86 %
  top 1 accuracy Hybrid 1       :		98.90 %
  top 1 accuracy NCM            :		98.63 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		72.42 %
  top 1 accuracy Hybrid 1       :		72.27 %
  top 1 accuracy NCM            :		73.00 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		99.35 %
  top 1 accuracy Hybrid 1       :		99.42 %
  top 1 accuracy NCM            :		99.25 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		90.80 %
  top 1 accuracy Hybrid 1       :		91.00 %
  top 1 accuracy NCM            :		90.84 %
Classes in this batch: tensor([16, 17])
Data Size: 7200


Before first epoch
  validation loss:		1.440271
  top 1 accuracy:		6.25 %
Batch of classes number 9 arrives ...
0.46710988879203796
0.1506030559539795
0.1418658047914505
Batch of classes 9 out of 12 batches
Epoch 1 of 30 took 130.462s
  training loss:		0.209910
  validation loss:		0.068707
  top 1 accuracy:		100.00 %
0.23225528001785278
0.1761399805545807
0.24535560607910156
Batch of classes 9 out of 12 batches
Epoch 2 of 30 took 80.150s
  training loss:		0.184322
  validation loss:		0.068311
  top 1 accuracy:		96.88 %
0.15222133696079254
0.1454204022884369
0.17581139504909515
Batch of classes 9 out of 12 batches
Epoch 3 of 30 took 80.607s
  training loss:		0.170260
  validation loss:		0.039185
  top 1 accuracy:		100.00 %
0.14939811825752258
0.1140751838684082
0.11777669191360474
Batch of classes 9 out of 12 batches
Epoch 4 of 30 took 79.609s
  training loss:		0.168523
  validation loss:		0.044461
  top 1 accuracy:		100.00 %
0.23725613951683044
0.21626310050487518
0.14912629127502441
Batch of classes 9 out of 12 batches
Epoch 5 of 30 took 80.509s
  training loss:		0.164759
  validation loss:		0.055843
  top 1 accuracy:		100.00 %
0.13016295433044434
0.20073184370994568
0.14834043383598328
Batch of classes 9 out of 12 batches
Epoch 6 of 30 took 80.506s
  training loss:		0.162425
  validation loss:		0.055023
  top 1 accuracy:		100.00 %
0.17138250172138214
0.1573410928249359
0.15535974502563477
Batch of classes 9 out of 12 batches
Epoch 7 of 30 took 80.074s
  training loss:		0.159777
  validation loss:		0.040404
  top 1 accuracy:		100.00 %
0.154578298330307
0.15433557331562042
0.13884778320789337
Batch of classes 9 out of 12 batches
Epoch 8 of 30 took 79.980s
  training loss:		0.157938
  validation loss:		0.039163
  top 1 accuracy:		100.00 %
0.16545280814170837
0.17901703715324402
0.20632755756378174
Batch of classes 9 out of 12 batches
Epoch 9 of 30 took 80.534s
  training loss:		0.156980
  validation loss:		0.048705
  top 1 accuracy:		100.00 %
0.17340125143527985
0.18582665920257568
0.1465928852558136
Batch of classes 9 out of 12 batches
Epoch 10 of 30 took 81.542s
  training loss:		0.159616
  validation loss:		0.061099
  top 1 accuracy:		100.00 %
0.1701025366783142
0.14755752682685852
0.1497029960155487
Batch of classes 9 out of 12 batches
Epoch 11 of 30 took 80.414s
  training loss:		0.142282
  validation loss:		0.038576
  top 1 accuracy:		100.00 %
0.09738080948591232
0.14068666100502014
0.13802874088287354
Batch of classes 9 out of 12 batches
Epoch 12 of 30 took 81.118s
  training loss:		0.138861
  validation loss:		0.030642
  top 1 accuracy:		100.00 %
0.1666797548532486
0.08372528851032257
0.1832505613565445
Batch of classes 9 out of 12 batches
Epoch 13 of 30 took 80.270s
  training loss:		0.138224
  validation loss:		0.039711
  top 1 accuracy:		100.00 %
0.12145762145519257
0.15771999955177307
0.1088576540350914
Batch of classes 9 out of 12 batches
Epoch 14 of 30 took 80.807s
  training loss:		0.136527
  validation loss:		0.033841
  top 1 accuracy:		100.00 %
0.13596810400485992
0.13302414119243622
0.1457286924123764
Batch of classes 9 out of 12 batches
Epoch 15 of 30 took 79.951s
  training loss:		0.137269
  validation loss:		0.034843
  top 1 accuracy:		100.00 %
0.153469055891037
0.13440555334091187
0.1503448188304901
Batch of classes 9 out of 12 batches
Epoch 16 of 30 took 80.191s
  training loss:		0.136484
  validation loss:		0.025322
  top 1 accuracy:		100.00 %
0.11366266012191772
0.13035860657691956
0.12897709012031555
Batch of classes 9 out of 12 batches
Epoch 17 of 30 took 80.541s
  training loss:		0.135659
  validation loss:		0.028208
  top 1 accuracy:		100.00 %
0.1583060473203659
0.1258554905653
0.12245218455791473
Batch of classes 9 out of 12 batches
Epoch 18 of 30 took 80.338s
  training loss:		0.136130
  validation loss:		0.036126
  top 1 accuracy:		100.00 %
0.11737798154354095
0.1460123062133789
0.15695740282535553
Batch of classes 9 out of 12 batches
Epoch 19 of 30 took 80.488s
  training loss:		0.137344
  validation loss:		0.039175
  top 1 accuracy:		100.00 %
0.11464191973209381
0.1178390234708786
0.18403775990009308
Batch of classes 9 out of 12 batches
Epoch 20 of 30 took 80.378s
  training loss:		0.136142
  validation loss:		0.027718
  top 1 accuracy:		100.00 %
0.15412816405296326
0.11871948838233948
0.1409636288881302
Batch of classes 9 out of 12 batches
Epoch 21 of 30 took 80.256s
  training loss:		0.135747
  validation loss:		0.031153
  top 1 accuracy:		100.00 %
0.12291522324085236
0.08662387728691101
0.1147976666688919
Batch of classes 9 out of 12 batches
Epoch 22 of 30 took 80.317s
  training loss:		0.134775
  validation loss:		0.035617
  top 1 accuracy:		100.00 %
0.13716283440589905
0.13038133084774017
0.09917071461677551
Batch of classes 9 out of 12 batches
Epoch 23 of 30 took 80.195s
  training loss:		0.134671
  validation loss:		0.034265
  top 1 accuracy:		100.00 %
0.12934790551662445
0.13337363302707672
0.12492482364177704
Batch of classes 9 out of 12 batches
Epoch 24 of 30 took 79.797s
  training loss:		0.134888
  validation loss:		0.033802
  top 1 accuracy:		100.00 %
0.14777010679244995
0.14355571568012238
0.11777828633785248
Batch of classes 9 out of 12 batches
Epoch 25 of 30 took 80.627s
  training loss:		0.134500
  validation loss:		0.032281
  top 1 accuracy:		100.00 %
0.17742115259170532
0.1667608618736267
0.1333926022052765
Batch of classes 9 out of 12 batches
Epoch 26 of 30 took 80.280s
  training loss:		0.134415
  validation loss:		0.035861
  top 1 accuracy:		100.00 %
0.09624926745891571
0.1299605816602707
0.14324736595153809
Batch of classes 9 out of 12 batches
Epoch 27 of 30 took 80.845s
  training loss:		0.133997
  validation loss:		0.036603
  top 1 accuracy:		100.00 %
0.15576674044132233
0.11570461094379425
0.16910426318645477
Batch of classes 9 out of 12 batches
Epoch 28 of 30 took 80.153s
  training loss:		0.134327
  validation loss:		0.035748
  top 1 accuracy:		100.00 %
0.14312304556369781
0.12353132665157318
0.1315258890390396
Batch of classes 9 out of 12 batches
Epoch 29 of 30 took 81.160s
  training loss:		0.134146
  validation loss:		0.030419
  top 1 accuracy:		100.00 %
0.14246749877929688
0.13934314250946045
0.16163712739944458
Batch of classes 9 out of 12 batches
Epoch 30 of 30 took 79.879s
  training loss:		0.134464
  validation loss:		0.040080
  top 1 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		74.55 %
  top 1 accuracy Hybrid 1       :		74.95 %
  top 1 accuracy NCM            :		76.90 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		77.50 %
  top 1 accuracy Hybrid 1       :		78.00 %
  top 1 accuracy NCM            :		79.25 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		91.79 %
  top 1 accuracy Hybrid 1       :		90.84 %
  top 1 accuracy NCM            :		89.89 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.69 %
  top 1 accuracy Hybrid 1       :		99.61 %
  top 1 accuracy NCM            :		99.49 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		89.46 %
  top 1 accuracy Hybrid 1       :		89.00 %
  top 1 accuracy NCM            :		89.19 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.69 %
  top 1 accuracy Hybrid 1       :		99.61 %
  top 1 accuracy NCM            :		99.45 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		66.89 %
  top 1 accuracy Hybrid 1       :		68.25 %
  top 1 accuracy NCM            :		66.65 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		91.69 %
  top 1 accuracy Hybrid 1       :		92.31 %
  top 1 accuracy NCM            :		92.81 %
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		99.98 %
  top 1 accuracy Hybrid 1       :		99.98 %
  top 1 accuracy NCM            :		99.92 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		90.81 %
  top 1 accuracy Hybrid 1       :		91.08 %
  top 1 accuracy NCM            :		91.21 %
Classes in this batch: tensor([18, 19])
Data Size: 7188


Before first epoch
  validation loss:		2.190597
  top 1 accuracy:		11.54 %
Batch of classes number 10 arrives ...
0.7317383885383606
0.47807633876800537
0.23074986040592194
Batch of classes 10 out of 12 batches
Epoch 1 of 30 took 152.044s
  training loss:		0.422024
  validation loss:		0.521340
  top 1 accuracy:		76.92 %
0.3741269111633301
0.24040350317955017
0.2235652208328247
Batch of classes 10 out of 12 batches
Epoch 2 of 30 took 70.421s
  training loss:		0.286983
  validation loss:		0.288525
  top 1 accuracy:		73.08 %
0.21915946900844574
0.3055025339126587
0.1915440559387207
Batch of classes 10 out of 12 batches
Epoch 3 of 30 took 70.590s
  training loss:		0.250025
  validation loss:		0.257562
  top 1 accuracy:		69.23 %
0.16886679828166962
0.24558652937412262
0.16580809652805328
Batch of classes 10 out of 12 batches
Epoch 4 of 30 took 70.595s
  training loss:		0.236797
  validation loss:		0.258033
  top 1 accuracy:		100.00 %
0.21950694918632507
0.31937694549560547
0.22656092047691345
Batch of classes 10 out of 12 batches
Epoch 5 of 30 took 70.488s
  training loss:		0.209895
  validation loss:		0.143349
  top 1 accuracy:		88.46 %
0.20043176412582397
0.1476878523826599
0.1725149154663086
Batch of classes 10 out of 12 batches
Epoch 6 of 30 took 70.780s
  training loss:		0.210099
  validation loss:		0.100931
  top 1 accuracy:		100.00 %
0.15912756323814392
0.17419081926345825
0.1922466903924942
Batch of classes 10 out of 12 batches
Epoch 7 of 30 took 70.407s
  training loss:		0.210875
  validation loss:		0.925609
  top 1 accuracy:		42.31 %
0.32009050250053406
0.2131272852420807
0.2665758728981018
Batch of classes 10 out of 12 batches
Epoch 8 of 30 took 70.724s
  training loss:		0.200563
  validation loss:		0.167202
  top 1 accuracy:		84.62 %
0.1512538492679596
0.13214011490345
0.26144686341285706
Batch of classes 10 out of 12 batches
Epoch 9 of 30 took 69.973s
  training loss:		0.206723
  validation loss:		0.213166
  top 1 accuracy:		76.92 %
0.14211958646774292
0.24958032369613647
0.20813456177711487
Batch of classes 10 out of 12 batches
Epoch 10 of 30 took 70.884s
  training loss:		0.199125
  validation loss:		0.088178
  top 1 accuracy:		92.31 %
0.10085384547710419
0.1649583876132965
0.17264874279499054
Batch of classes 10 out of 12 batches
Epoch 11 of 30 took 70.711s
  training loss:		0.164027
  validation loss:		0.053191
  top 1 accuracy:		100.00 %
0.1539534628391266
0.11697400361299515
0.16333122551441193
Batch of classes 10 out of 12 batches
Epoch 12 of 30 took 70.535s
  training loss:		0.159981
  validation loss:		0.048473
  top 1 accuracy:		100.00 %
0.1956661194562912
0.09649618715047836
0.14520329236984253
Batch of classes 10 out of 12 batches
Epoch 13 of 30 took 70.427s
  training loss:		0.157768
  validation loss:		0.056682
  top 1 accuracy:		100.00 %
0.16481663286685944
0.14288340508937836
0.21303126215934753
Batch of classes 10 out of 12 batches
Epoch 14 of 30 took 70.353s
  training loss:		0.155364
  validation loss:		0.045531
  top 1 accuracy:		100.00 %
0.17458650469779968
0.14125409722328186
0.15535442531108856
Batch of classes 10 out of 12 batches
Epoch 15 of 30 took 70.831s
  training loss:		0.157324
  validation loss:		0.048747
  top 1 accuracy:		100.00 %
0.12752693891525269
0.16072575747966766
0.17806267738342285
Batch of classes 10 out of 12 batches
Epoch 16 of 30 took 70.258s
  training loss:		0.155251
  validation loss:		0.047258
  top 1 accuracy:		100.00 %
0.1637333184480667
0.16598199307918549
0.13953660428524017
Batch of classes 10 out of 12 batches
Epoch 17 of 30 took 71.081s
  training loss:		0.156167
  validation loss:		0.047117
  top 1 accuracy:		100.00 %
0.146224707365036
0.1264944076538086
0.14417773485183716
Batch of classes 10 out of 12 batches
Epoch 18 of 30 took 70.716s
  training loss:		0.153692
  validation loss:		0.042541
  top 1 accuracy:		100.00 %
0.13565459847450256
0.18944934010505676
0.17759276926517487
Batch of classes 10 out of 12 batches
Epoch 19 of 30 took 70.827s
  training loss:		0.153635
  validation loss:		0.046184
  top 1 accuracy:		100.00 %
0.15132564306259155
0.1809212863445282
0.1729390025138855
Batch of classes 10 out of 12 batches
Epoch 20 of 30 took 70.305s
  training loss:		0.154544
  validation loss:		0.064151
  top 1 accuracy:		100.00 %
0.12594474852085114
0.18613991141319275
0.18404829502105713
Batch of classes 10 out of 12 batches
Epoch 21 of 30 took 70.256s
  training loss:		0.152605
  validation loss:		0.043011
  top 1 accuracy:		100.00 %
0.12928654253482819
0.1777149736881256
0.13617759943008423
Batch of classes 10 out of 12 batches
Epoch 22 of 30 took 70.997s
  training loss:		0.149066
  validation loss:		0.044435
  top 1 accuracy:		100.00 %
0.1458098292350769
0.14478972554206848
0.1317024976015091
Batch of classes 10 out of 12 batches
Epoch 23 of 30 took 70.777s
  training loss:		0.149711
  validation loss:		0.037198
  top 1 accuracy:		100.00 %
0.14479786157608032
0.19467413425445557
0.14711400866508484
Batch of classes 10 out of 12 batches
Epoch 24 of 30 took 70.317s
  training loss:		0.148888
  validation loss:		0.036751
  top 1 accuracy:		100.00 %
0.1386299431324005
0.16251781582832336
0.19727666676044464
Batch of classes 10 out of 12 batches
Epoch 25 of 30 took 70.455s
  training loss:		0.147655
  validation loss:		0.042591
  top 1 accuracy:		100.00 %
0.11429393291473389
0.11649474501609802
0.14823471009731293
Batch of classes 10 out of 12 batches
Epoch 26 of 30 took 70.347s
  training loss:		0.148477
  validation loss:		0.039176
  top 1 accuracy:		100.00 %
0.12431736290454865
0.14994488656520844
0.1745339334011078
Batch of classes 10 out of 12 batches
Epoch 27 of 30 took 70.502s
  training loss:		0.148893
  validation loss:		0.035470
  top 1 accuracy:		100.00 %
0.1392160952091217
0.13944227993488312
0.134666308760643
Batch of classes 10 out of 12 batches
Epoch 28 of 30 took 70.304s
  training loss:		0.147148
  validation loss:		0.040653
  top 1 accuracy:		100.00 %
0.1553615778684616
0.14381760358810425
0.1484876126050949
Batch of classes 10 out of 12 batches
Epoch 29 of 30 took 70.462s
  training loss:		0.148674
  validation loss:		0.037636
  top 1 accuracy:		100.00 %
0.16668300330638885
0.15854395925998688
0.1169772669672966
Batch of classes 10 out of 12 batches
Epoch 30 of 30 took 70.924s
  training loss:		0.148927
  validation loss:		0.040586
  top 1 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		81.50 %
  top 1 accuracy Hybrid 1       :		81.50 %
  top 1 accuracy NCM            :		81.70 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		84.25 %
  top 1 accuracy Hybrid 1       :		83.88 %
  top 1 accuracy NCM            :		84.88 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		90.27 %
  top 1 accuracy Hybrid 1       :		91.79 %
  top 1 accuracy NCM            :		90.08 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		98.12 %
  top 1 accuracy Hybrid 1       :		98.90 %
  top 1 accuracy NCM            :		98.12 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		92.24 %
  top 1 accuracy Hybrid 1       :		90.94 %
  top 1 accuracy NCM            :		91.77 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		98.16 %
  top 1 accuracy Hybrid 1       :		98.90 %
  top 1 accuracy NCM            :		98.16 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		69.95 %
  top 1 accuracy Hybrid 1       :		70.82 %
  top 1 accuracy NCM            :		69.85 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		97.46 %
  top 1 accuracy Hybrid 1       :		97.69 %
  top 1 accuracy NCM            :		97.40 %
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		97.98 %
  top 1 accuracy Hybrid 1       :		98.27 %
  top 1 accuracy NCM            :		97.92 %
Final results on stylegan classes:
  top 1 accuracy iCaRL          :		99.79 %
  top 1 accuracy Hybrid 1       :		99.71 %
  top 1 accuracy NCM            :		99.79 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		93.34 %
  top 1 accuracy Hybrid 1       :		93.64 %
  top 1 accuracy NCM            :		93.32 %
Classes in this batch: tensor([20, 21])
Data Size: 1200


Before first epoch
  validation loss:		0.991769
  top 1 accuracy:		75.00 %
Batch of classes number 11 arrives ...
0.49086838960647583
Batch of classes 11 out of 12 batches
Epoch 1 of 30 took 75.584s
  training loss:		0.376109
  validation loss:		0.411290
  top 1 accuracy:		100.00 %
0.2683049440383911
Batch of classes 11 out of 12 batches
Epoch 2 of 30 took 50.898s
  training loss:		0.290757
  validation loss:		0.437467
  top 1 accuracy:		100.00 %
0.2304544448852539
Batch of classes 11 out of 12 batches
Epoch 3 of 30 took 51.070s
  training loss:		0.274455
  validation loss:		0.313929
  top 1 accuracy:		93.75 %
0.1291137933731079
Batch of classes 11 out of 12 batches
Epoch 4 of 30 took 51.329s
  training loss:		0.207994
  validation loss:		0.428637
  top 1 accuracy:		87.50 %
0.24844861030578613
Batch of classes 11 out of 12 batches
Epoch 5 of 30 took 51.707s
  training loss:		0.211201
  validation loss:		0.465463
  top 1 accuracy:		75.00 %
0.10692356526851654
Batch of classes 11 out of 12 batches
Epoch 6 of 30 took 50.746s
  training loss:		0.199073
  validation loss:		0.610989
  top 1 accuracy:		56.25 %
0.19916245341300964
Batch of classes 11 out of 12 batches
Epoch 7 of 30 took 51.230s
  training loss:		0.179986
  validation loss:		0.377105
  top 1 accuracy:		100.00 %
0.24540705978870392
Batch of classes 11 out of 12 batches
Epoch 8 of 30 took 50.882s
  training loss:		0.198028
  validation loss:		1.924452
  top 1 accuracy:		6.25 %
0.09705986827611923
Batch of classes 11 out of 12 batches
Epoch 9 of 30 took 51.130s
  training loss:		0.182709
  validation loss:		0.526771
  top 1 accuracy:		56.25 %
0.1308758407831192
Batch of classes 11 out of 12 batches
Epoch 10 of 30 took 50.653s
  training loss:		0.189240
  validation loss:		0.264551
  top 1 accuracy:		100.00 %
0.10387735813856125
Batch of classes 11 out of 12 batches
Epoch 11 of 30 took 50.642s
  training loss:		0.139853
  validation loss:		0.198295
  top 1 accuracy:		100.00 %
0.12609922885894775
Batch of classes 11 out of 12 batches
Epoch 12 of 30 took 50.826s
  training loss:		0.125827
  validation loss:		0.215008
  top 1 accuracy:		93.75 %
0.15539084374904633
Batch of classes 11 out of 12 batches
Epoch 13 of 30 took 50.449s
  training loss:		0.122341
  validation loss:		0.229992
  top 1 accuracy:		100.00 %
0.0630621612071991
Batch of classes 11 out of 12 batches
Epoch 14 of 30 took 50.076s
  training loss:		0.117440
  validation loss:		0.198393
  top 1 accuracy:		100.00 %
0.1024802029132843
Batch of classes 11 out of 12 batches
Epoch 15 of 30 took 50.544s
  training loss:		0.117940
  validation loss:		0.188033
  top 1 accuracy:		100.00 %
0.10966991633176804
Batch of classes 11 out of 12 batches
Epoch 16 of 30 took 50.414s
  training loss:		0.116565
  validation loss:		0.205164
  top 1 accuracy:		100.00 %
0.10959015041589737
Batch of classes 11 out of 12 batches
Epoch 17 of 30 took 50.762s
  training loss:		0.115950
  validation loss:		0.199546
  top 1 accuracy:		100.00 %
0.08744925260543823
Batch of classes 11 out of 12 batches
Epoch 18 of 30 took 51.778s
  training loss:		0.116997
  validation loss:		0.200986
  top 1 accuracy:		100.00 %
0.09716490656137466
Batch of classes 11 out of 12 batches
Epoch 19 of 30 took 50.157s
  training loss:		0.106753
  validation loss:		0.179185
  top 1 accuracy:		100.00 %
0.09829874336719513
Batch of classes 11 out of 12 batches
Epoch 20 of 30 took 50.779s
  training loss:		0.111309
  validation loss:		0.172221
  top 1 accuracy:		100.00 %
0.13293036818504333
Batch of classes 11 out of 12 batches
Epoch 21 of 30 took 50.456s
  training loss:		0.110527
  validation loss:		0.176658
  top 1 accuracy:		100.00 %
0.11330798268318176
Batch of classes 11 out of 12 batches
Epoch 22 of 30 took 50.318s
  training loss:		0.107159
  validation loss:		0.169733
  top 1 accuracy:		100.00 %
0.13148117065429688
Batch of classes 11 out of 12 batches
Epoch 23 of 30 took 51.716s
  training loss:		0.105437
  validation loss:		0.173830
  top 1 accuracy:		100.00 %
0.12467682361602783
Batch of classes 11 out of 12 batches
Epoch 24 of 30 took 51.071s
  training loss:		0.106351
  validation loss:		0.174742
  top 1 accuracy:		100.00 %
0.09969376027584076
Batch of classes 11 out of 12 batches
Epoch 25 of 30 took 50.853s
  training loss:		0.103970
  validation loss:		0.175414
  top 1 accuracy:		100.00 %
0.11671082675457001
Batch of classes 11 out of 12 batches
Epoch 26 of 30 took 50.065s
  training loss:		0.104658
  validation loss:		0.165423
  top 1 accuracy:		100.00 %
0.10419844090938568
Batch of classes 11 out of 12 batches
Epoch 27 of 30 took 50.417s
  training loss:		0.099873
  validation loss:		0.172413
  top 1 accuracy:		100.00 %
0.10233911871910095
Batch of classes 11 out of 12 batches
Epoch 28 of 30 took 50.251s
  training loss:		0.101856
  validation loss:		0.176961
  top 1 accuracy:		100.00 %
0.07850329577922821
Batch of classes 11 out of 12 batches
Epoch 29 of 30 took 50.384s
  training loss:		0.102259
  validation loss:		0.171941
  top 1 accuracy:		93.75 %
0.1162133514881134
Batch of classes 11 out of 12 batches
Epoch 30 of 30 took 51.253s
  training loss:		0.102636
  validation loss:		0.163383
  top 1 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		81.45 %
  top 1 accuracy Hybrid 1       :		82.00 %
  top 1 accuracy NCM            :		81.90 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		82.75 %
  top 1 accuracy Hybrid 1       :		82.38 %
  top 1 accuracy NCM            :		82.88 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		90.84 %
  top 1 accuracy Hybrid 1       :		92.18 %
  top 1 accuracy NCM            :		90.46 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.57 %
  top 1 accuracy Hybrid 1       :		99.49 %
  top 1 accuracy NCM            :		99.49 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		91.87 %
  top 1 accuracy Hybrid 1       :		91.87 %
  top 1 accuracy NCM            :		91.68 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.49 %
  top 1 accuracy Hybrid 1       :		99.41 %
  top 1 accuracy NCM            :		99.45 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		70.04 %
  top 1 accuracy Hybrid 1       :		70.29 %
  top 1 accuracy NCM            :		70.04 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		98.21 %
  top 1 accuracy Hybrid 1       :		98.17 %
  top 1 accuracy NCM            :		98.15 %
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		98.50 %
  top 1 accuracy Hybrid 1       :		98.50 %
  top 1 accuracy NCM            :		98.46 %
Final results on stylegan classes:
  top 1 accuracy iCaRL          :		93.40 %
  top 1 accuracy Hybrid 1       :		93.36 %
  top 1 accuracy NCM            :		93.78 %
Final results on whichfaceisreal classes:
  top 1 accuracy iCaRL          :		94.25 %
  top 1 accuracy Hybrid 1       :		94.00 %
  top 1 accuracy NCM            :		94.00 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		93.22 %
  top 1 accuracy Hybrid 1       :		93.27 %
  top 1 accuracy NCM            :		93.24 %
Classes in this batch: tensor([22, 23])
Data Size: 260


Before first epoch
  validation loss:		2.531343
  top 1 accuracy:		11.54 %
Batch of classes number 12 arrives ...
0.4900568127632141
Batch of classes 12 out of 12 batches
Epoch 1 of 30 took 18.062s
  training loss:		0.292203
  validation loss:		1.390578
  top 1 accuracy:		30.77 %
0.4129883050918579
Batch of classes 12 out of 12 batches
Epoch 2 of 30 took 17.151s
  training loss:		0.236796
  validation loss:		1.291022
  top 1 accuracy:		34.62 %
0.0984027311205864
Batch of classes 12 out of 12 batches
Epoch 3 of 30 took 17.198s
  training loss:		0.173499
  validation loss:		1.076932
  top 1 accuracy:		46.15 %
0.06811147928237915
Batch of classes 12 out of 12 batches
Epoch 4 of 30 took 17.161s
  training loss:		0.160156
  validation loss:		1.104562
  top 1 accuracy:		50.00 %
0.14892056584358215
Batch of classes 12 out of 12 batches
Epoch 5 of 30 took 17.734s
  training loss:		0.157054
  validation loss:		1.172735
  top 1 accuracy:		42.31 %
0.15957015752792358
Batch of classes 12 out of 12 batches
Epoch 6 of 30 took 17.029s
  training loss:		0.141141
  validation loss:		0.984714
  top 1 accuracy:		57.69 %
0.08085624873638153
Batch of classes 12 out of 12 batches
Epoch 7 of 30 took 17.550s
  training loss:		0.123599
  validation loss:		0.913295
  top 1 accuracy:		73.08 %
0.06906071305274963
Batch of classes 12 out of 12 batches
Epoch 8 of 30 took 17.734s
  training loss:		0.128802
  validation loss:		1.200590
  top 1 accuracy:		38.46 %
0.12054644525051117
Batch of classes 12 out of 12 batches
Epoch 9 of 30 took 17.223s
  training loss:		0.128253
  validation loss:		0.899318
  top 1 accuracy:		61.54 %
0.058972422033548355
Batch of classes 12 out of 12 batches
Epoch 10 of 30 took 17.345s
  training loss:		0.122710
  validation loss:		1.010167
  top 1 accuracy:		73.08 %
0.06271863728761673
Batch of classes 12 out of 12 batches
Epoch 11 of 30 took 17.139s
  training loss:		0.094580
  validation loss:		1.052825
  top 1 accuracy:		42.31 %
0.040897831320762634
Batch of classes 12 out of 12 batches
Epoch 12 of 30 took 17.544s
  training loss:		0.102179
  validation loss:		0.901038
  top 1 accuracy:		53.85 %
0.10378139466047287
Batch of classes 12 out of 12 batches
Epoch 13 of 30 took 17.279s
  training loss:		0.077121
  validation loss:		0.867020
  top 1 accuracy:		76.92 %
0.07761820405721664
Batch of classes 12 out of 12 batches
Epoch 14 of 30 took 17.205s
  training loss:		0.072917
  validation loss:		0.941911
  top 1 accuracy:		57.69 %
0.08720698952674866
Batch of classes 12 out of 12 batches
Epoch 15 of 30 took 17.694s
  training loss:		0.088617
  validation loss:		0.954225
  top 1 accuracy:		57.69 %
0.09881502389907837
Batch of classes 12 out of 12 batches
Epoch 16 of 30 took 17.393s
  training loss:		0.087592
  validation loss:		1.039003
  top 1 accuracy:		50.00 %
0.042832646518945694
Batch of classes 12 out of 12 batches
Epoch 17 of 30 took 17.617s
  training loss:		0.099248
  validation loss:		0.917440
  top 1 accuracy:		61.54 %
0.03881183639168739
Batch of classes 12 out of 12 batches
Epoch 18 of 30 took 17.746s
  training loss:		0.087450
  validation loss:		0.901757
  top 1 accuracy:		61.54 %
0.06726305931806564
Batch of classes 12 out of 12 batches
Epoch 19 of 30 took 17.078s
  training loss:		0.089602
  validation loss:		0.932184
  top 1 accuracy:		61.54 %
0.14817240834236145
Batch of classes 12 out of 12 batches
Epoch 20 of 30 took 17.104s
  training loss:		0.069674
  validation loss:		0.947741
  top 1 accuracy:		65.38 %
0.13089901208877563
Batch of classes 12 out of 12 batches
Epoch 21 of 30 took 17.448s
  training loss:		0.064730
  validation loss:		0.928931
  top 1 accuracy:		61.54 %
0.03713726997375488
Batch of classes 12 out of 12 batches
Epoch 22 of 30 took 17.224s
  training loss:		0.066174
  validation loss:		0.947630
  top 1 accuracy:		61.54 %
0.05153660476207733
Batch of classes 12 out of 12 batches
Epoch 23 of 30 took 17.708s
  training loss:		0.066672
  validation loss:		0.955084
  top 1 accuracy:		65.38 %
0.04456100985407829
Batch of classes 12 out of 12 batches
Epoch 24 of 30 took 17.173s
  training loss:		0.063910
  validation loss:		0.999282
  top 1 accuracy:		53.85 %
0.06282656639814377
Batch of classes 12 out of 12 batches
Epoch 25 of 30 took 17.171s
  training loss:		0.068439
  validation loss:		0.954588
  top 1 accuracy:		65.38 %
0.113723024725914
Batch of classes 12 out of 12 batches
Epoch 26 of 30 took 17.420s
  training loss:		0.065903
  validation loss:		0.972875
  top 1 accuracy:		57.69 %
0.06644250452518463
Batch of classes 12 out of 12 batches
Epoch 27 of 30 took 17.213s
  training loss:		0.062107
  validation loss:		0.949257
  top 1 accuracy:		57.69 %
0.04725165665149689
Batch of classes 12 out of 12 batches
Epoch 28 of 30 took 17.047s
  training loss:		0.065799
  validation loss:		1.038884
  top 1 accuracy:		53.85 %
0.11675629764795303
Batch of classes 12 out of 12 batches
Epoch 29 of 30 took 17.253s
  training loss:		0.067407
  validation loss:		0.994681
  top 1 accuracy:		53.85 %
0.0295714121311903
Batch of classes 12 out of 12 batches
Epoch 30 of 30 took 17.243s
  training loss:		0.068829
  validation loss:		0.987161
  top 1 accuracy:		53.85 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		82.75 %
  top 1 accuracy Hybrid 1       :		82.85 %
  top 1 accuracy NCM            :		82.10 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		81.88 %
  top 1 accuracy Hybrid 1       :		82.50 %
  top 1 accuracy NCM            :		81.62 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		93.70 %
  top 1 accuracy Hybrid 1       :		93.13 %
  top 1 accuracy NCM            :		93.32 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.02 %
  top 1 accuracy Hybrid 1       :		99.37 %
  top 1 accuracy NCM            :		99.06 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		92.14 %
  top 1 accuracy Hybrid 1       :		92.33 %
  top 1 accuracy NCM            :		92.05 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.22 %
  top 1 accuracy Hybrid 1       :		99.41 %
  top 1 accuracy NCM            :		99.22 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		68.01 %
  top 1 accuracy Hybrid 1       :		68.69 %
  top 1 accuracy NCM            :		68.01 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		97.46 %
  top 1 accuracy Hybrid 1       :		97.71 %
  top 1 accuracy NCM            :		97.40 %
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		98.62 %
  top 1 accuracy Hybrid 1       :		98.50 %
  top 1 accuracy NCM            :		98.65 %
Final results on stylegan classes:
  top 1 accuracy iCaRL          :		89.97 %
  top 1 accuracy Hybrid 1       :		90.43 %
  top 1 accuracy NCM            :		90.18 %
Final results on whichfaceisreal classes:
  top 1 accuracy iCaRL          :		83.50 %
  top 1 accuracy Hybrid 1       :		85.00 %
  top 1 accuracy NCM            :		83.25 %
Final results on san classes:
  top 1 accuracy iCaRL          :		57.78 %
  top 1 accuracy Hybrid 1       :		55.56 %
  top 1 accuracy NCM            :		57.78 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		92.33 %
  top 1 accuracy Hybrid 1       :		92.56 %
  top 1 accuracy NCM            :		92.27 %
tensor([[[ 99.7000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 99.8500,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 99.7000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 97.9000,  98.6250,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 97.8500,  98.7500,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 97.9000,  98.6250,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 96.0000,  96.0000,  96.9466,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 96.4500,  96.5000,  97.5191,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 96.0500,  96.0000,  96.9466,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 94.0000,  95.6250,  94.6565, 100.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 94.3500,  96.3750,  95.2290, 100.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 93.8000,  95.6250,  94.6565, 100.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 90.2500,  91.5000,  90.8397,  99.3339,  96.5804,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 90.1500,  92.1250,  91.6031,  99.4514,  96.7653,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 90.2500,  91.2500,  90.2672,  99.2947,  96.5804,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 86.3000,  93.5000,  93.8931,  99.9216,  95.8410,  99.9608,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 79.5500,  89.8750,  95.0382,  99.9216,  96.2107, 100.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 87.1500,  92.8750,  93.5115,  99.8824,  95.7486,  99.9216,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 79.4000,  76.8750,  88.1679,  98.7461,  86.3216,  98.7069,  79.2535,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 79.0000,  78.1250,  87.9771,  99.5298,  84.8429,  99.4514,  80.1260,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 79.4500,  77.1250,  88.3588,  98.6285,  85.7671,  98.5893,  79.1081,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 74.6000,  77.3750,  88.9313,  98.9028,  90.4806,  98.8636,  72.4188,
           99.3542,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 75.6500,  77.3750,  88.5496,  98.9420,  91.5896,  98.9028,  72.2734,
           99.4167,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 75.4000,  77.6250,  88.1679,  98.6677,  90.2958,  98.6285,  73.0005,
           99.2500,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 74.5500,  77.5000,  91.7939,  99.6865,  89.4640,  99.6865,  66.8929,
           91.6875,  99.9792,   0.0000,   0.0000,   0.0000],
         [ 74.9500,  78.0000,  90.8397,  99.6082,  89.0018,  99.6082,  68.2501,
           92.3125,  99.9792,   0.0000,   0.0000,   0.0000],
         [ 76.9000,  79.2500,  89.8855,  99.4906,  89.1867,  99.4514,  66.6505,
           92.8125,  99.9167,   0.0000,   0.0000,   0.0000]],

        [[ 81.5000,  84.2500,  90.2672,  98.1191,  92.2366,  98.1583,  69.9467,
           97.4583,  97.9792,  99.7911,   0.0000,   0.0000],
         [ 81.5000,  83.8750,  91.7939,  98.9028,  90.9427,  98.9028,  70.8192,
           97.6875,  98.2708,  99.7076,   0.0000,   0.0000],
         [ 81.7000,  84.8750,  90.0763,  98.1191,  91.7745,  98.1583,  69.8497,
           97.3958,  97.9167,  99.7911,   0.0000,   0.0000]],

        [[ 81.4500,  82.7500,  90.8397,  99.5690,  91.8669,  99.4906,  70.0436,
           98.2083,  98.5000,  93.4002,  94.2500,   0.0000],
         [ 82.0000,  82.3750,  92.1756,  99.4906,  91.8669,  99.4122,  70.2860,
           98.1667,  98.5000,  93.3584,  94.0000,   0.0000],
         [ 81.9000,  82.8750,  90.4580,  99.4906,  91.6821,  99.4514,  70.0436,
           98.1458,  98.4583,  93.7761,  94.0000,   0.0000]],

        [[ 82.7500,  81.8750,  93.7023,  99.0204,  92.1442,  99.2163,  68.0078,
           97.4583,  98.6250,  89.9749,  83.5000,  57.7778],
         [ 82.8500,  82.5000,  93.1298,  99.3730,  92.3290,  99.4122,  68.6864,
           97.7083,  98.5000,  90.4344,  85.0000,  55.5556],
         [ 82.1000,  81.6250,  93.3206,  99.0596,  92.0518,  99.2163,  68.0078,
           97.3958,  98.6458,  90.1838,  83.2500,  57.7778]]])
tensor([87.0043, 87.1232, 86.8862])
----------------- Options ---------------
               add_binary: True                          	[default: False]
               batch_size: 32                            	[default: 64]
                   binary: False                         
              binary_loss: sum_a_sig                     	[default: sum_b_sig]
            binary_weight: 0.3                           	[default: 0.5]
                blur_prob: 0                             
                 blur_sig: 0.5                           
          checkpoints_dir: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL/checkpoints	[default: ./checkpoints]
                class_bal: False                         
           continue_train: False                         
                 cropSize: 224                           
                 data_aug: False                         
                 dataroot: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/test	[default: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL]
          earlystop_epoch: 5                             
                    epoch: latest                        
                 fine_tun: False                         
                    gpuid: [1]                           
                init_gain: 0.02                          
                  init_lr: 0.0005                        
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2                           
                 jpg_prob: 0                             
                 jpg_qual: 75                            
          label_smoothing: False                         
                 loadSize: 256                           
                    mixup: False                         
              mixup_alpha: 0.1                           
                     mode: binary                        
               model_name: resnet18                      
               model_type: resnet                        
            model_weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth	[default: None]
               multiclass: [0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0]	[default: [1]]
                     name: icarl_df_12_sum_a_sig03       	[default: experiment_name]
                  no_flip: False                         
              num_classes: 2                             
               num_epochs: 30                            	[default: 12]
              num_threads: 4                             
                  outfile: temp_0.1.csv                  
            pretrain_name:                               
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 20                            
         save_latest_freq: 2000                          
                 schedule: [10, 20, 30]                  	[default: [10]]
           serial_batches: False                         
          smoothing_alpha: 0.1                           
                   suffix:                               
                task_name: gaugan,biggan,cyclegan,imle,deepfake,crn,wild,glow,stargan_gf,stylegan,whichfaceisreal,san	[default: ]
              train_split: train                         
                val_split: val                           
----------------- End -------------------
{'All': 24}
Task order: ['gaugan', 'biggan', 'cyclegan', 'imle', 'deepfake', 'crn', 'wild', 'glow', 'stargan_gf', 'stylegan', 'whichfaceisreal', 'san']
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Classes in this batch: tensor([0, 1])
Data Size: 6000


Before first epoch
  validation loss:		1.021936
  top 1 accuracy:		17.25 %
  top 2 accuracy:		17.35 %
Batch of classes number 1 arrives ...
0.9570852518081665
0.1490282267332077
Batch of classes 1 out of 12 batches
Epoch 1 of 30 took 90.725s
  training loss:		0.203641
  validation loss:		0.033009
  top 1 accuracy:		83.90 %
  top 2 accuracy:		99.95 %
0.11071237921714783
0.16875387728214264
Batch of classes 1 out of 12 batches
Epoch 2 of 30 took 51.847s
  training loss:		0.117628
  validation loss:		0.020907
  top 1 accuracy:		90.10 %
  top 2 accuracy:		99.95 %
0.08437944948673248
0.06206812709569931
Batch of classes 1 out of 12 batches
Epoch 3 of 30 took 51.550s
  training loss:		0.091541
  validation loss:		0.022057
  top 1 accuracy:		90.75 %
  top 2 accuracy:		99.60 %
0.0987146869301796
0.0474516786634922
Batch of classes 1 out of 12 batches
Epoch 4 of 30 took 51.224s
  training loss:		0.075596
  validation loss:		0.014674
  top 1 accuracy:		93.10 %
  top 2 accuracy:		100.00 %
0.1523076593875885
0.05037722736597061
Batch of classes 1 out of 12 batches
Epoch 5 of 30 took 51.852s
  training loss:		0.071354
  validation loss:		0.031225
  top 1 accuracy:		84.45 %
  top 2 accuracy:		100.00 %
0.05694953352212906
0.05476560816168785
Batch of classes 1 out of 12 batches
Epoch 6 of 30 took 51.704s
  training loss:		0.065842
  validation loss:		0.011480
  top 1 accuracy:		94.95 %
  top 2 accuracy:		100.00 %
0.07666303217411041
0.039161600172519684
Batch of classes 1 out of 12 batches
Epoch 7 of 30 took 51.429s
  training loss:		0.058455
  validation loss:		0.012635
  top 1 accuracy:		94.15 %
  top 2 accuracy:		99.95 %
0.042688965797424316
0.047342557460069656
Batch of classes 1 out of 12 batches
Epoch 8 of 30 took 51.480s
  training loss:		0.048694
  validation loss:		0.011290
  top 1 accuracy:		95.10 %
  top 2 accuracy:		100.00 %
0.048174936324357986
0.1308867484331131
Batch of classes 1 out of 12 batches
Epoch 9 of 30 took 51.544s
  training loss:		0.051533
  validation loss:		0.011199
  top 1 accuracy:		94.75 %
  top 2 accuracy:		100.00 %
0.02490878850221634
0.0307301115244627
Batch of classes 1 out of 12 batches
Epoch 10 of 30 took 51.427s
  training loss:		0.043951
  validation loss:		0.010485
  top 1 accuracy:		95.65 %
  top 2 accuracy:		100.00 %
0.04368298500776291
0.0019357216078788042
Batch of classes 1 out of 12 batches
Epoch 11 of 30 took 51.485s
  training loss:		0.024236
  validation loss:		0.003804
  top 1 accuracy:		98.55 %
  top 2 accuracy:		100.00 %
0.012329788878560066
0.006777889560908079
Batch of classes 1 out of 12 batches
Epoch 12 of 30 took 51.656s
  training loss:		0.016765
  validation loss:		0.002898
  top 1 accuracy:		98.80 %
  top 2 accuracy:		100.00 %
0.007830744609236717
0.02793709561228752
Batch of classes 1 out of 12 batches
Epoch 13 of 30 took 51.226s
  training loss:		0.015912
  validation loss:		0.005623
  top 1 accuracy:		97.40 %
  top 2 accuracy:		100.00 %
0.008760079741477966
0.027882102876901627
Batch of classes 1 out of 12 batches
Epoch 14 of 30 took 51.524s
  training loss:		0.015124
  validation loss:		0.003218
  top 1 accuracy:		98.55 %
  top 2 accuracy:		100.00 %
0.0021028416231274605
0.033911313861608505
Batch of classes 1 out of 12 batches
Epoch 15 of 30 took 51.504s
  training loss:		0.017714
  validation loss:		0.004080
  top 1 accuracy:		98.50 %
  top 2 accuracy:		100.00 %
0.01033785194158554
0.005255180411040783
Batch of classes 1 out of 12 batches
Epoch 16 of 30 took 52.160s
  training loss:		0.009168
  validation loss:		0.002650
  top 1 accuracy:		99.05 %
  top 2 accuracy:		100.00 %
0.01822451502084732
0.0006590893026441336
Batch of classes 1 out of 12 batches
Epoch 17 of 30 took 51.564s
  training loss:		0.009269
  validation loss:		0.003440
  top 1 accuracy:		98.70 %
  top 2 accuracy:		100.00 %
0.004653453826904297
0.0008354120654985309
Batch of classes 1 out of 12 batches
Epoch 18 of 30 took 51.259s
  training loss:		0.009572
  validation loss:		0.003426
  top 1 accuracy:		98.75 %
  top 2 accuracy:		100.00 %
0.0007811679970473051
0.03102533146739006
Batch of classes 1 out of 12 batches
Epoch 19 of 30 took 51.466s
  training loss:		0.011407
  validation loss:		0.003348
  top 1 accuracy:		98.55 %
  top 2 accuracy:		100.00 %
0.008691733703017235
0.003122975118458271
Batch of classes 1 out of 12 batches
Epoch 20 of 30 took 51.466s
  training loss:		0.009016
  validation loss:		0.003633
  top 1 accuracy:		98.30 %
  top 2 accuracy:		100.00 %
0.0026839233469218016
0.0017979794647544622
Batch of classes 1 out of 12 batches
Epoch 21 of 30 took 51.449s
  training loss:		0.007022
  validation loss:		0.002094
  top 1 accuracy:		99.40 %
  top 2 accuracy:		100.00 %
0.0008326646639034152
0.00020067396690137684
Batch of classes 1 out of 12 batches
Epoch 22 of 30 took 51.288s
  training loss:		0.006674
  validation loss:		0.001948
  top 1 accuracy:		99.30 %
  top 2 accuracy:		100.00 %
0.003975319676101208
0.0027667777612805367
Batch of classes 1 out of 12 batches
Epoch 23 of 30 took 51.381s
  training loss:		0.003545
  validation loss:		0.001508
  top 1 accuracy:		99.80 %
  top 2 accuracy:		100.00 %
0.0005577448173426092
0.0006826489698141813
Batch of classes 1 out of 12 batches
Epoch 24 of 30 took 51.079s
  training loss:		0.004342
  validation loss:		0.002203
  top 1 accuracy:		99.25 %
  top 2 accuracy:		100.00 %
0.006747841369360685
0.008039853535592556
Batch of classes 1 out of 12 batches
Epoch 25 of 30 took 50.827s
  training loss:		0.003607
  validation loss:		0.001926
  top 1 accuracy:		99.40 %
  top 2 accuracy:		100.00 %
0.008007388561964035
0.0017961710691452026
Batch of classes 1 out of 12 batches
Epoch 26 of 30 took 51.264s
  training loss:		0.003129
  validation loss:		0.001392
  top 1 accuracy:		99.65 %
  top 2 accuracy:		100.00 %
0.00027040584245696664
0.0003804729785770178
Batch of classes 1 out of 12 batches
Epoch 27 of 30 took 51.436s
  training loss:		0.004213
  validation loss:		0.002061
  top 1 accuracy:		99.15 %
  top 2 accuracy:		100.00 %
0.0018965966301038861
0.0021957100834697485
Batch of classes 1 out of 12 batches
Epoch 28 of 30 took 51.290s
  training loss:		0.003382
  validation loss:		0.001314
  top 1 accuracy:		99.60 %
  top 2 accuracy:		100.00 %
0.0003685711417347193
0.0004440816701389849
Batch of classes 1 out of 12 batches
Epoch 29 of 30 took 50.727s
  training loss:		0.002736
  validation loss:		0.001591
  top 1 accuracy:		99.35 %
  top 2 accuracy:		100.00 %
0.001112725818529725
0.0033154364209622145
Batch of classes 1 out of 12 batches
Epoch 30 of 30 took 50.837s
  training loss:		0.002826
  validation loss:		0.004121
  top 1 accuracy:		99.10 %
  top 2 accuracy:		100.00 %
=> Load model weights: /home/chuqli/scratch/CNNDetection/checkpoints/no_aug/model_epoch_best.pth
=> Load Done
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(500)
tensor(500)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		99.70 %
  top 1 accuracy Hybrid 1       :		99.10 %
  top 1 accuracy NCM            :		99.70 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		99.70 %
  top 1 accuracy Hybrid 1       :		99.10 %
  top 1 accuracy NCM            :		99.70 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		99.70 %
  top 1 accuracy Hybrid 1       :		99.10 %
  top 1 accuracy NCM            :		99.70 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		99.70 %
  top 1 accuracy Hybrid 1       :		99.10 %
  top 1 accuracy NCM            :		99.70 %
Classes in this batch: tensor([2, 3])
Data Size: 2400


Before first epoch
  validation loss:		1.182278
  top 1 accuracy:		0.00 %
  top 2 accuracy:		6.62 %
Batch of classes number 2 arrives ...
1.2665292024612427
0.09484615921974182
Batch of classes 2 out of 12 batches
Epoch 1 of 30 took 40.891s
  training loss:		0.209463
  validation loss:		0.043692
  top 1 accuracy:		88.75 %
  top 2 accuracy:		96.75 %
0.12586486339569092
0.07221746444702148
Batch of classes 2 out of 12 batches
Epoch 2 of 30 took 32.916s
  training loss:		0.114242
  validation loss:		0.036236
  top 1 accuracy:		90.75 %
  top 2 accuracy:		98.25 %
0.09535732865333557
0.06860066205263138
Batch of classes 2 out of 12 batches
Epoch 3 of 30 took 33.083s
  training loss:		0.099119
  validation loss:		0.042821
  top 1 accuracy:		82.25 %
  top 2 accuracy:		95.88 %
0.05796185880899429
0.06650212407112122
Batch of classes 2 out of 12 batches
Epoch 4 of 30 took 32.862s
  training loss:		0.085048
  validation loss:		0.034546
  top 1 accuracy:		89.25 %
  top 2 accuracy:		97.87 %
0.038949258625507355
0.04687894880771637
Batch of classes 2 out of 12 batches
Epoch 5 of 30 took 32.902s
  training loss:		0.080028
  validation loss:		0.042613
  top 1 accuracy:		80.25 %
  top 2 accuracy:		96.25 %
0.09225773811340332
0.06042216718196869
Batch of classes 2 out of 12 batches
Epoch 6 of 30 took 32.834s
  training loss:		0.070138
  validation loss:		0.038308
  top 1 accuracy:		84.13 %
  top 2 accuracy:		95.25 %
0.0814276933670044
0.048889629542827606
Batch of classes 2 out of 12 batches
Epoch 7 of 30 took 32.532s
  training loss:		0.070172
  validation loss:		0.039194
  top 1 accuracy:		82.75 %
  top 2 accuracy:		96.63 %
0.11594325304031372
0.03546636924147606
Batch of classes 2 out of 12 batches
Epoch 8 of 30 took 32.695s
  training loss:		0.059018
  validation loss:		0.047270
  top 1 accuracy:		79.75 %
  top 2 accuracy:		92.12 %
0.05712737888097763
0.14654934406280518
Batch of classes 2 out of 12 batches
Epoch 9 of 30 took 33.006s
  training loss:		0.072269
  validation loss:		0.044991
  top 1 accuracy:		77.38 %
  top 2 accuracy:		95.75 %
0.04248325154185295
0.25000616908073425
Batch of classes 2 out of 12 batches
Epoch 10 of 30 took 32.490s
  training loss:		0.063713
  validation loss:		0.046449
  top 1 accuracy:		77.50 %
  top 2 accuracy:		95.88 %
0.083121657371521
0.0249456986784935
Batch of classes 2 out of 12 batches
Epoch 11 of 30 took 32.857s
  training loss:		0.042365
  validation loss:		0.022473
  top 1 accuracy:		92.37 %
  top 2 accuracy:		98.62 %
0.03665061667561531
0.05407142639160156
Batch of classes 2 out of 12 batches
Epoch 12 of 30 took 32.947s
  training loss:		0.034738
  validation loss:		0.035207
  top 1 accuracy:		84.50 %
  top 2 accuracy:		99.12 %
0.03335694968700409
0.023586060851812363
Batch of classes 2 out of 12 batches
Epoch 13 of 30 took 32.887s
  training loss:		0.033532
  validation loss:		0.018573
  top 1 accuracy:		93.75 %
  top 2 accuracy:		99.50 %
0.02712925337255001
0.019909333437681198
Batch of classes 2 out of 12 batches
Epoch 14 of 30 took 32.871s
  training loss:		0.023101
  validation loss:		0.023377
  top 1 accuracy:		90.13 %
  top 2 accuracy:		99.50 %
0.030712075531482697
0.01798192225396633
Batch of classes 2 out of 12 batches
Epoch 15 of 30 took 32.485s
  training loss:		0.026918
  validation loss:		0.024381
  top 1 accuracy:		89.63 %
  top 2 accuracy:		99.00 %
0.016995668411254883
0.038210198283195496
Batch of classes 2 out of 12 batches
Epoch 16 of 30 took 32.832s
  training loss:		0.027435
  validation loss:		0.015954
  top 1 accuracy:		94.88 %
  top 2 accuracy:		99.75 %
0.01720079779624939
0.027422083541750908
Batch of classes 2 out of 12 batches
Epoch 17 of 30 took 32.939s
  training loss:		0.028507
  validation loss:		0.017205
  top 1 accuracy:		94.25 %
  top 2 accuracy:		99.50 %
0.03542851284146309
0.022301966324448586
Batch of classes 2 out of 12 batches
Epoch 18 of 30 took 32.398s
  training loss:		0.032432
  validation loss:		0.014696
  top 1 accuracy:		95.63 %
  top 2 accuracy:		99.62 %
0.02599455788731575
0.028109312057495117
Batch of classes 2 out of 12 batches
Epoch 19 of 30 took 32.973s
  training loss:		0.028810
  validation loss:		0.025801
  top 1 accuracy:		89.50 %
  top 2 accuracy:		98.62 %
0.02060133032500744
0.02223791740834713
Batch of classes 2 out of 12 batches
Epoch 20 of 30 took 32.949s
  training loss:		0.022272
  validation loss:		0.015700
  top 1 accuracy:		94.63 %
  top 2 accuracy:		99.50 %
0.013223430141806602
0.011791770346462727
Batch of classes 2 out of 12 batches
Epoch 21 of 30 took 32.901s
  training loss:		0.016328
  validation loss:		0.012753
  top 1 accuracy:		96.00 %
  top 2 accuracy:		99.75 %
0.042994461953639984
0.005982103291898966
Batch of classes 2 out of 12 batches
Epoch 22 of 30 took 32.985s
  training loss:		0.014752
  validation loss:		0.015861
  top 1 accuracy:		94.00 %
  top 2 accuracy:		99.37 %
0.019849149510264397
0.017012685537338257
Batch of classes 2 out of 12 batches
Epoch 23 of 30 took 33.148s
  training loss:		0.013635
  validation loss:		0.013066
  top 1 accuracy:		95.25 %
  top 2 accuracy:		99.75 %
0.01731782965362072
0.008868970908224583
Batch of classes 2 out of 12 batches
Epoch 24 of 30 took 33.033s
  training loss:		0.012744
  validation loss:		0.016275
  top 1 accuracy:		94.25 %
  top 2 accuracy:		99.87 %
0.007863047532737255
0.002844479400664568
Batch of classes 2 out of 12 batches
Epoch 25 of 30 took 32.697s
  training loss:		0.012543
  validation loss:		0.011629
  top 1 accuracy:		95.63 %
  top 2 accuracy:		99.75 %
0.013110090978443623
0.00653039151802659
Batch of classes 2 out of 12 batches
Epoch 26 of 30 took 33.077s
  training loss:		0.010065
  validation loss:		0.015395
  top 1 accuracy:		94.13 %
  top 2 accuracy:		99.12 %
0.007804499007761478
0.00789736956357956
Batch of classes 2 out of 12 batches
Epoch 27 of 30 took 32.852s
  training loss:		0.009366
  validation loss:		0.015133
  top 1 accuracy:		93.88 %
  top 2 accuracy:		99.37 %
0.014380702748894691
0.012221522629261017
Batch of classes 2 out of 12 batches
Epoch 28 of 30 took 33.108s
  training loss:		0.010745
  validation loss:		0.023717
  top 1 accuracy:		91.12 %
  top 2 accuracy:		99.25 %
0.010437600314617157
0.01369879487901926
Batch of classes 2 out of 12 batches
Epoch 29 of 30 took 33.122s
  training loss:		0.009938
  validation loss:		0.011558
  top 1 accuracy:		96.00 %
  top 2 accuracy:		99.37 %
0.030161280184984207
0.042261771857738495
Batch of classes 2 out of 12 batches
Epoch 30 of 30 took 33.012s
  training loss:		0.009704
  validation loss:		0.007574
  top 1 accuracy:		97.75 %
  top 2 accuracy:		99.62 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(384)
tensor(384)
tensor(384)
tensor(384)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		73.90 %
  top 1 accuracy Hybrid 1       :		47.85 %
  top 1 accuracy NCM            :		75.80 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		96.90 %
  top 1 accuracy Hybrid 1       :		95.55 %
  top 1 accuracy NCM            :		97.15 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		86.62 %
  top 1 accuracy Hybrid 1       :		97.75 %
  top 1 accuracy NCM            :		85.62 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		99.00 %
  top 1 accuracy Hybrid 1       :		99.12 %
  top 1 accuracy NCM            :		98.88 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		77.54 %
  top 1 accuracy Hybrid 1       :		62.11 %
  top 1 accuracy NCM            :		78.61 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		97.50 %
  top 1 accuracy Hybrid 1       :		96.57 %
  top 1 accuracy NCM            :		97.64 %
Classes in this batch: tensor([4, 5])
Data Size: 1572


Before first epoch
  validation loss:		0.593539
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 3 arrives ...
0.2662082612514496
Batch of classes 3 out of 12 batches
Epoch 1 of 30 took 32.997s
  training loss:		0.165453
  validation loss:		0.072845
  top 1 accuracy:		66.79 %
  top 2 accuracy:		92.94 %
0.13798567652702332
Batch of classes 3 out of 12 batches
Epoch 2 of 30 took 29.230s
  training loss:		0.105835
  validation loss:		0.060569
  top 1 accuracy:		76.15 %
  top 2 accuracy:		90.65 %
0.08725496381521225
Batch of classes 3 out of 12 batches
Epoch 3 of 30 took 28.999s
  training loss:		0.097325
  validation loss:		0.028182
  top 1 accuracy:		91.22 %
  top 2 accuracy:		97.14 %
0.05420560762286186
Batch of classes 3 out of 12 batches
Epoch 4 of 30 took 28.864s
  training loss:		0.078184
  validation loss:		0.035298
  top 1 accuracy:		87.02 %
  top 2 accuracy:		94.66 %
0.060204796493053436
Batch of classes 3 out of 12 batches
Epoch 5 of 30 took 28.735s
  training loss:		0.086595
  validation loss:		0.044817
  top 1 accuracy:		83.02 %
  top 2 accuracy:		91.22 %
0.09594932943582535
Batch of classes 3 out of 12 batches
Epoch 6 of 30 took 28.780s
  training loss:		0.121033
  validation loss:		0.029450
  top 1 accuracy:		90.84 %
  top 2 accuracy:		95.23 %
0.0540848970413208
Batch of classes 3 out of 12 batches
Epoch 7 of 30 took 28.801s
  training loss:		0.067940
  validation loss:		0.029961
  top 1 accuracy:		90.84 %
  top 2 accuracy:		94.85 %
0.051232777535915375
Batch of classes 3 out of 12 batches
Epoch 8 of 30 took 28.683s
  training loss:		0.078293
  validation loss:		0.026808
  top 1 accuracy:		89.69 %
  top 2 accuracy:		95.23 %
0.041719261556863785
Batch of classes 3 out of 12 batches
Epoch 9 of 30 took 28.744s
  training loss:		0.069962
  validation loss:		0.022096
  top 1 accuracy:		91.98 %
  top 2 accuracy:		95.80 %
0.028319502249360085
Batch of classes 3 out of 12 batches
Epoch 10 of 30 took 28.823s
  training loss:		0.048042
  validation loss:		0.015021
  top 1 accuracy:		93.51 %
  top 2 accuracy:		98.28 %
0.024047691375017166
Batch of classes 3 out of 12 batches
Epoch 11 of 30 took 28.721s
  training loss:		0.035279
  validation loss:		0.011713
  top 1 accuracy:		95.99 %
  top 2 accuracy:		98.66 %
0.029503867030143738
Batch of classes 3 out of 12 batches
Epoch 12 of 30 took 28.884s
  training loss:		0.029800
  validation loss:		0.014077
  top 1 accuracy:		94.66 %
  top 2 accuracy:		98.47 %
0.02537674643099308
Batch of classes 3 out of 12 batches
Epoch 13 of 30 took 28.814s
  training loss:		0.025246
  validation loss:		0.016791
  top 1 accuracy:		93.13 %
  top 2 accuracy:		97.33 %
0.018371084704995155
Batch of classes 3 out of 12 batches
Epoch 14 of 30 took 28.912s
  training loss:		0.026704
  validation loss:		0.014157
  top 1 accuracy:		94.47 %
  top 2 accuracy:		98.66 %
0.01891748234629631
Batch of classes 3 out of 12 batches
Epoch 15 of 30 took 28.801s
  training loss:		0.021913
  validation loss:		0.015164
  top 1 accuracy:		94.27 %
  top 2 accuracy:		98.47 %
0.019716517999768257
Batch of classes 3 out of 12 batches
Epoch 16 of 30 took 28.814s
  training loss:		0.034282
  validation loss:		0.018383
  top 1 accuracy:		93.89 %
  top 2 accuracy:		98.09 %
0.011973435059189796
Batch of classes 3 out of 12 batches
Epoch 17 of 30 took 29.043s
  training loss:		0.029568
  validation loss:		0.010750
  top 1 accuracy:		95.99 %
  top 2 accuracy:		99.24 %
0.017342207953333855
Batch of classes 3 out of 12 batches
Epoch 18 of 30 took 29.108s
  training loss:		0.026773
  validation loss:		0.017017
  top 1 accuracy:		93.32 %
  top 2 accuracy:		97.90 %
0.019602632150053978
Batch of classes 3 out of 12 batches
Epoch 19 of 30 took 28.979s
  training loss:		0.023998
  validation loss:		0.011664
  top 1 accuracy:		96.56 %
  top 2 accuracy:		98.47 %
0.00947257224470377
Batch of classes 3 out of 12 batches
Epoch 20 of 30 took 28.843s
  training loss:		0.030777
  validation loss:		0.009622
  top 1 accuracy:		96.37 %
  top 2 accuracy:		98.85 %
0.009880187921226025
Batch of classes 3 out of 12 batches
Epoch 21 of 30 took 28.953s
  training loss:		0.017022
  validation loss:		0.008631
  top 1 accuracy:		96.76 %
  top 2 accuracy:		98.85 %
0.008528536185622215
Batch of classes 3 out of 12 batches
Epoch 22 of 30 took 29.054s
  training loss:		0.022016
  validation loss:		0.010123
  top 1 accuracy:		96.76 %
  top 2 accuracy:		99.24 %
0.009218593128025532
Batch of classes 3 out of 12 batches
Epoch 23 of 30 took 29.269s
  training loss:		0.015993
  validation loss:		0.009302
  top 1 accuracy:		95.99 %
  top 2 accuracy:		99.05 %
0.010251934640109539
Batch of classes 3 out of 12 batches
Epoch 24 of 30 took 29.082s
  training loss:		0.013339
  validation loss:		0.010133
  top 1 accuracy:		96.37 %
  top 2 accuracy:		99.24 %
0.010385559871792793
Batch of classes 3 out of 12 batches
Epoch 25 of 30 took 28.831s
  training loss:		0.021858
  validation loss:		0.013575
  top 1 accuracy:		95.23 %
  top 2 accuracy:		98.47 %
0.006642813794314861
Batch of classes 3 out of 12 batches
Epoch 26 of 30 took 28.930s
  training loss:		0.016474
  validation loss:		0.009453
  top 1 accuracy:		96.95 %
  top 2 accuracy:		99.05 %
0.010299665853381157
Batch of classes 3 out of 12 batches
Epoch 27 of 30 took 29.141s
  training loss:		0.013886
  validation loss:		0.010492
  top 1 accuracy:		95.99 %
  top 2 accuracy:		99.43 %
0.005473505239933729
Batch of classes 3 out of 12 batches
Epoch 28 of 30 took 28.550s
  training loss:		0.017956
  validation loss:		0.016613
  top 1 accuracy:		94.66 %
  top 2 accuracy:		98.66 %
0.006053091958165169
Batch of classes 3 out of 12 batches
Epoch 29 of 30 took 29.423s
  training loss:		0.012438
  validation loss:		0.010723
  top 1 accuracy:		95.42 %
  top 2 accuracy:		98.66 %
0.013649634085595608
Batch of classes 3 out of 12 batches
Epoch 30 of 30 took 28.944s
  training loss:		0.015357
  validation loss:		0.011985
  top 1 accuracy:		95.42 %
  top 2 accuracy:		99.05 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(256)
tensor(256)
tensor(256)
tensor(256)
tensor(256)
tensor(256)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		73.80 %
  top 1 accuracy Hybrid 1       :		73.05 %
  top 1 accuracy NCM            :		75.45 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		96.15 %
  top 1 accuracy Hybrid 1       :		95.90 %
  top 1 accuracy NCM            :		96.25 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		71.00 %
  top 1 accuracy Hybrid 1       :		61.38 %
  top 1 accuracy NCM            :		72.62 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		95.25 %
  top 1 accuracy Hybrid 1       :		94.12 %
  top 1 accuracy NCM            :		95.62 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		93.89 %
  top 1 accuracy Hybrid 1       :		95.42 %
  top 1 accuracy NCM            :		93.51 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		97.14 %
  top 1 accuracy Hybrid 1       :		97.14 %
  top 1 accuracy NCM            :		97.14 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		76.29 %
  top 1 accuracy Hybrid 1       :		73.77 %
  top 1 accuracy NCM            :		77.62 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		96.09 %
  top 1 accuracy Hybrid 1       :		95.67 %
  top 1 accuracy NCM            :		96.24 %
Classes in this batch: tensor([6, 7])
Data Size: 7656


Before first epoch
  validation loss:		0.514187
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 4 arrives ...
0.37035316228866577
0.018326155841350555
0.010077846236526966
Batch of classes 4 out of 12 batches
Epoch 1 of 30 took 149.102s
  training loss:		0.069144
  validation loss:		0.002378
  top 1 accuracy:		99.41 %
  top 2 accuracy:		99.96 %
0.019615598022937775
0.03516998514533043
0.009547372348606586
Batch of classes 4 out of 12 batches
Epoch 2 of 30 took 89.739s
  training loss:		0.034482
  validation loss:		0.007150
  top 1 accuracy:		98.12 %
  top 2 accuracy:		99.80 %
0.01852787472307682
0.10151980817317963
0.00932782981544733
Batch of classes 4 out of 12 batches
Epoch 3 of 30 took 89.165s
  training loss:		0.030866
  validation loss:		0.008814
  top 1 accuracy:		97.37 %
  top 2 accuracy:		99.69 %
0.0107253547757864
0.03687452897429466
0.01446354016661644
Batch of classes 4 out of 12 batches
Epoch 4 of 30 took 89.428s
  training loss:		0.026838
  validation loss:		0.001012
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.008782392367720604
0.030365128070116043
0.009836607612669468
Batch of classes 4 out of 12 batches
Epoch 5 of 30 took 89.077s
  training loss:		0.018751
  validation loss:		0.049351
  top 1 accuracy:		76.18 %
  top 2 accuracy:		89.54 %
0.014306380413472652
0.028636733070015907
0.025666719302535057
Batch of classes 4 out of 12 batches
Epoch 6 of 30 took 89.107s
  training loss:		0.020837
  validation loss:		0.002955
  top 1 accuracy:		99.69 %
  top 2 accuracy:		99.92 %
0.024990294128656387
0.030906299129128456
0.037930455058813095
Batch of classes 4 out of 12 batches
Epoch 7 of 30 took 89.957s
  training loss:		0.031937
  validation loss:		0.001631
  top 1 accuracy:		99.61 %
  top 2 accuracy:		99.88 %
0.03354530781507492
0.012625894509255886
0.06071755290031433
Batch of classes 4 out of 12 batches
Epoch 8 of 30 took 88.687s
  training loss:		0.022046
  validation loss:		0.000897
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
0.010721934959292412
0.006566651631146669
0.00492109265178442
Batch of classes 4 out of 12 batches
Epoch 9 of 30 took 88.978s
  training loss:		0.013955
  validation loss:		0.000528
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.0031824251636862755
0.009174319915473461
0.0043503534980118275
Batch of classes 4 out of 12 batches
Epoch 10 of 30 took 88.970s
  training loss:		0.015663
  validation loss:		0.004536
  top 1 accuracy:		98.55 %
  top 2 accuracy:		99.37 %
0.02847430855035782
0.006622704677283764
0.005228583235293627
Batch of classes 4 out of 12 batches
Epoch 11 of 30 took 89.852s
  training loss:		0.009681
  validation loss:		0.000355
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
0.0061524189077317715
0.00488734245300293
0.0024203078355640173
Batch of classes 4 out of 12 batches
Epoch 12 of 30 took 89.347s
  training loss:		0.009116
  validation loss:		0.000553
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.004824331030249596
0.005187273491173983
0.006189947947859764
Batch of classes 4 out of 12 batches
Epoch 13 of 30 took 89.584s
  training loss:		0.007001
  validation loss:		0.000201
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.00424293102696538
0.0011986186727881432
0.009000909514725208
Batch of classes 4 out of 12 batches
Epoch 14 of 30 took 88.726s
  training loss:		0.005382
  validation loss:		0.000566
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.004105699248611927
0.007269685156643391
0.002161772223189473
Batch of classes 4 out of 12 batches
Epoch 15 of 30 took 88.872s
  training loss:		0.005938
  validation loss:		0.000203
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.002813837258145213
0.00665696244686842
0.004088814370334148
Batch of classes 4 out of 12 batches
Epoch 16 of 30 took 88.543s
  training loss:		0.005969
  validation loss:		0.002485
  top 1 accuracy:		99.29 %
  top 2 accuracy:		99.92 %
0.015165156684815884
0.0020526095759123564
0.002994165290147066
Batch of classes 4 out of 12 batches
Epoch 17 of 30 took 88.964s
  training loss:		0.008686
  validation loss:		0.000098
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.0034912119153887033
0.004335496574640274
0.0016332698287442327
Batch of classes 4 out of 12 batches
Epoch 18 of 30 took 89.160s
  training loss:		0.005340
  validation loss:		0.000329
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.011021806858479977
0.006720711477100849
0.0044354405254125595
Batch of classes 4 out of 12 batches
Epoch 19 of 30 took 89.118s
  training loss:		0.004730
  validation loss:		0.000811
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
0.006189320236444473
0.003932639956474304
0.006677054334431887
Batch of classes 4 out of 12 batches
Epoch 20 of 30 took 89.201s
  training loss:		0.006262
  validation loss:		0.000192
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.0013584289699792862
0.0028516140300780535
0.0005023481789976358
Batch of classes 4 out of 12 batches
Epoch 21 of 30 took 88.798s
  training loss:		0.002914
  validation loss:		0.000363
  top 1 accuracy:		99.88 %
  top 2 accuracy:		100.00 %
0.0001865784579422325
0.000823246082291007
0.0005160723230801523
Batch of classes 4 out of 12 batches
Epoch 22 of 30 took 89.514s
  training loss:		0.003186
  validation loss:		0.000230
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.0066637201234698296
0.002312819240614772
0.0007350132218562067
Batch of classes 4 out of 12 batches
Epoch 23 of 30 took 89.278s
  training loss:		0.004093
  validation loss:		0.000138
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.0016822637990117073
0.0012807814637199044
0.0017222824972122908
Batch of classes 4 out of 12 batches
Epoch 24 of 30 took 89.291s
  training loss:		0.002762
  validation loss:		0.000043
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.002772565232589841
0.001300940988585353
0.00047366367653012276
Batch of classes 4 out of 12 batches
Epoch 25 of 30 took 89.221s
  training loss:		0.001834
  validation loss:		0.000233
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.0009463505120947957
0.00043439280125312507
0.0023510060273110867
Batch of classes 4 out of 12 batches
Epoch 26 of 30 took 88.789s
  training loss:		0.003525
  validation loss:		0.000290
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.00018732284661382437
0.003313776571303606
0.0009633026202209294
Batch of classes 4 out of 12 batches
Epoch 27 of 30 took 89.154s
  training loss:		0.003057
  validation loss:		0.000043
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.0018209235277026892
0.0008775974856689572
0.0008303771028295159
Batch of classes 4 out of 12 batches
Epoch 28 of 30 took 88.287s
  training loss:		0.001615
  validation loss:		0.000076
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.0008188920328393579
0.00041777617298066616
0.0009051237720996141
Batch of classes 4 out of 12 batches
Epoch 29 of 30 took 88.315s
  training loss:		0.001305
  validation loss:		0.000132
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.00032936586649157107
0.0007584847044199705
0.00027288112323731184
Batch of classes 4 out of 12 batches
Epoch 30 of 30 took 89.353s
  training loss:		0.001121
  validation loss:		0.000107
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
tensor(192)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		68.90 %
  top 1 accuracy Hybrid 1       :		67.95 %
  top 1 accuracy NCM            :		68.60 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		91.40 %
  top 1 accuracy Hybrid 1       :		91.00 %
  top 1 accuracy NCM            :		91.70 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		73.62 %
  top 1 accuracy Hybrid 1       :		69.75 %
  top 1 accuracy NCM            :		73.88 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		94.12 %
  top 1 accuracy Hybrid 1       :		94.38 %
  top 1 accuracy NCM            :		94.12 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		86.45 %
  top 1 accuracy Hybrid 1       :		88.93 %
  top 1 accuracy NCM            :		86.64 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		94.08 %
  top 1 accuracy Hybrid 1       :		95.23 %
  top 1 accuracy NCM            :		94.27 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.69 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		99.73 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		100.00 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		100.00 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		84.48 %
  top 1 accuracy Hybrid 1       :		83.99 %
  top 1 accuracy NCM            :		84.45 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		95.75 %
  top 1 accuracy Hybrid 1       :		95.75 %
  top 1 accuracy NCM            :		95.86 %
Classes in this batch: tensor([8, 9])
Data Size: 3248


Before first epoch
  validation loss:		0.524804
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 5 arrives ...
0.769496500492096
0.14167644083499908
Batch of classes 5 out of 12 batches
Epoch 1 of 30 took 49.685s
  training loss:		0.162529
  validation loss:		0.026154
  top 1 accuracy:		95.56 %
  top 2 accuracy:		96.86 %
0.06238964945077896
0.07333443313837051
Batch of classes 5 out of 12 batches
Epoch 2 of 30 took 43.471s
  training loss:		0.072255
  validation loss:		0.013916
  top 1 accuracy:		94.36 %
  top 2 accuracy:		98.34 %
0.13372769951820374
0.025717202574014664
Batch of classes 5 out of 12 batches
Epoch 3 of 30 took 43.620s
  training loss:		0.060167
  validation loss:		0.011785
  top 1 accuracy:		95.56 %
  top 2 accuracy:		98.43 %
0.04079277813434601
0.04540616273880005
Batch of classes 5 out of 12 batches
Epoch 4 of 30 took 43.370s
  training loss:		0.055227
  validation loss:		0.012249
  top 1 accuracy:		95.38 %
  top 2 accuracy:		99.08 %
0.07450889050960541
0.05062412470579147
Batch of classes 5 out of 12 batches
Epoch 5 of 30 took 43.512s
  training loss:		0.044015
  validation loss:		0.011033
  top 1 accuracy:		95.84 %
  top 2 accuracy:		98.71 %
0.0243394635617733
0.030179746448993683
Batch of classes 5 out of 12 batches
Epoch 6 of 30 took 43.721s
  training loss:		0.046241
  validation loss:		0.011874
  top 1 accuracy:		95.19 %
  top 2 accuracy:		98.34 %
0.08773007988929749
0.012048200704157352
Batch of classes 5 out of 12 batches
Epoch 7 of 30 took 43.555s
  training loss:		0.040581
  validation loss:		0.012333
  top 1 accuracy:		95.47 %
  top 2 accuracy:		98.98 %
0.05264410749077797
0.03848990425467491
Batch of classes 5 out of 12 batches
Epoch 8 of 30 took 43.496s
  training loss:		0.127831
  validation loss:		0.161829
  top 1 accuracy:		19.22 %
  top 2 accuracy:		55.55 %
0.3570449948310852
0.2855292558670044
Batch of classes 5 out of 12 batches
Epoch 9 of 30 took 43.391s
  training loss:		0.268821
  validation loss:		0.054758
  top 1 accuracy:		69.13 %
  top 2 accuracy:		98.34 %
0.23608459532260895
0.26192641258239746
Batch of classes 5 out of 12 batches
Epoch 10 of 30 took 43.702s
  training loss:		0.227939
  validation loss:		0.048086
  top 1 accuracy:		76.25 %
  top 2 accuracy:		99.26 %
0.2561095952987671
0.16963446140289307
Batch of classes 5 out of 12 batches
Epoch 11 of 30 took 43.597s
  training loss:		0.196898
  validation loss:		0.037890
  top 1 accuracy:		81.70 %
  top 2 accuracy:		99.63 %
0.129055917263031
0.1639142632484436
Batch of classes 5 out of 12 batches
Epoch 12 of 30 took 43.406s
  training loss:		0.186668
  validation loss:		0.034995
  top 1 accuracy:		85.30 %
  top 2 accuracy:		97.60 %
0.21285897493362427
0.1426583230495453
Batch of classes 5 out of 12 batches
Epoch 13 of 30 took 43.314s
  training loss:		0.174720
  validation loss:		0.032416
  top 1 accuracy:		84.94 %
  top 2 accuracy:		98.34 %
0.17945528030395508
0.13110175728797913
Batch of classes 5 out of 12 batches
Epoch 14 of 30 took 43.832s
  training loss:		0.162868
  validation loss:		0.034680
  top 1 accuracy:		84.10 %
  top 2 accuracy:		98.61 %
0.1224653497338295
0.17264916002750397
Batch of classes 5 out of 12 batches
Epoch 15 of 30 took 43.395s
  training loss:		0.155742
  validation loss:		0.028409
  top 1 accuracy:		86.41 %
  top 2 accuracy:		98.52 %
0.1107122078537941
0.1884741336107254
Batch of classes 5 out of 12 batches
Epoch 16 of 30 took 43.610s
  training loss:		0.147818
  validation loss:		0.030757
  top 1 accuracy:		85.58 %
  top 2 accuracy:		98.52 %
0.156758651137352
0.1288662552833557
Batch of classes 5 out of 12 batches
Epoch 17 of 30 took 43.065s
  training loss:		0.140938
  validation loss:		0.025793
  top 1 accuracy:		87.71 %
  top 2 accuracy:		98.80 %
0.14157888293266296
0.1494646519422531
Batch of classes 5 out of 12 batches
Epoch 18 of 30 took 43.332s
  training loss:		0.135269
  validation loss:		0.025496
  top 1 accuracy:		88.17 %
  top 2 accuracy:		98.06 %
0.15351130068302155
0.0976153090596199
Batch of classes 5 out of 12 batches
Epoch 19 of 30 took 43.239s
  training loss:		0.119840
  validation loss:		0.031494
  top 1 accuracy:		87.15 %
  top 2 accuracy:		98.43 %
0.11951535195112228
0.1677594929933548
Batch of classes 5 out of 12 batches
Epoch 20 of 30 took 43.148s
  training loss:		0.114246
  validation loss:		0.026999
  top 1 accuracy:		86.78 %
  top 2 accuracy:		98.71 %
0.0877227932214737
0.08719038218259811
Batch of classes 5 out of 12 batches
Epoch 21 of 30 took 43.461s
  training loss:		0.108172
  validation loss:		0.025274
  top 1 accuracy:		88.45 %
  top 2 accuracy:		98.34 %
0.1042066439986229
0.09601622819900513
Batch of classes 5 out of 12 batches
Epoch 22 of 30 took 43.643s
  training loss:		0.106562
  validation loss:		0.023225
  top 1 accuracy:		89.19 %
  top 2 accuracy:		98.24 %
0.06896466016769409
0.09050941467285156
Batch of classes 5 out of 12 batches
Epoch 23 of 30 took 43.675s
  training loss:		0.101524
  validation loss:		0.023811
  top 1 accuracy:		88.54 %
  top 2 accuracy:		97.78 %
0.08268488943576813
0.06685753166675568
Batch of classes 5 out of 12 batches
Epoch 24 of 30 took 43.658s
  training loss:		0.096671
  validation loss:		0.028930
  top 1 accuracy:		87.34 %
  top 2 accuracy:		97.87 %
0.07570900022983551
0.07327494025230408
Batch of classes 5 out of 12 batches
Epoch 25 of 30 took 43.817s
  training loss:		0.100573
  validation loss:		0.026968
  top 1 accuracy:		87.71 %
  top 2 accuracy:		97.87 %
0.0604359470307827
0.11882880330085754
Batch of classes 5 out of 12 batches
Epoch 26 of 30 took 43.806s
  training loss:		0.099671
  validation loss:		0.022037
  top 1 accuracy:		89.28 %
  top 2 accuracy:		97.87 %
0.11079463362693787
0.11631922423839569
Batch of classes 5 out of 12 batches
Epoch 27 of 30 took 43.841s
  training loss:		0.088198
  validation loss:		0.025939
  top 1 accuracy:		87.99 %
  top 2 accuracy:		98.24 %
0.056609708815813065
0.053192898631095886
Batch of classes 5 out of 12 batches
Epoch 28 of 30 took 43.525s
  training loss:		0.091698
  validation loss:		0.021126
  top 1 accuracy:		91.31 %
  top 2 accuracy:		98.15 %
0.07357177883386612
0.05815201252698898
Batch of classes 5 out of 12 batches
Epoch 29 of 30 took 43.807s
  training loss:		0.089276
  validation loss:		0.025446
  top 1 accuracy:		88.63 %
  top 2 accuracy:		97.69 %
0.0764738991856575
0.14751935005187988
Batch of classes 5 out of 12 batches
Epoch 30 of 30 took 43.817s
  training loss:		0.085656
  validation loss:		0.022059
  top 1 accuracy:		90.11 %
  top 2 accuracy:		97.87 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
tensor(154)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		44.40 %
  top 1 accuracy Hybrid 1       :		30.25 %
  top 1 accuracy NCM            :		44.15 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		66.00 %
  top 1 accuracy Hybrid 1       :		64.60 %
  top 1 accuracy NCM            :		66.35 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		34.75 %
  top 1 accuracy Hybrid 1       :		46.88 %
  top 1 accuracy NCM            :		34.75 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		69.38 %
  top 1 accuracy Hybrid 1       :		71.88 %
  top 1 accuracy NCM            :		70.25 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		62.79 %
  top 1 accuracy Hybrid 1       :		63.93 %
  top 1 accuracy NCM            :		63.17 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		78.24 %
  top 1 accuracy Hybrid 1       :		77.86 %
  top 1 accuracy NCM            :		79.58 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		95.65 %
  top 1 accuracy Hybrid 1       :		97.65 %
  top 1 accuracy NCM            :		96.08 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		97.10 %
  top 1 accuracy Hybrid 1       :		98.00 %
  top 1 accuracy NCM            :		97.30 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		89.28 %
  top 1 accuracy Hybrid 1       :		90.11 %
  top 1 accuracy NCM            :		89.19 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		89.56 %
  top 1 accuracy Hybrid 1       :		90.11 %
  top 1 accuracy NCM            :		89.46 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		70.45 %
  top 1 accuracy Hybrid 1       :		68.73 %
  top 1 accuracy NCM            :		70.55 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		82.38 %
  top 1 accuracy Hybrid 1       :		82.65 %
  top 1 accuracy NCM            :		82.74 %
Classes in this batch: tensor([10, 11])
Data Size: 7658


Before first epoch
  validation loss:		0.941665
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 6 arrives ...
0.45459213852882385
0.07697289437055588
0.06315377354621887
Batch of classes 6 out of 12 batches
Epoch 1 of 30 took 148.572s
  training loss:		0.106610
  validation loss:		0.003816
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.037037670612335205
0.04798520356416702
0.03835853934288025
Batch of classes 6 out of 12 batches
Epoch 2 of 30 took 89.414s
  training loss:		0.044630
  validation loss:		0.003140
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.02625204622745514
0.04661340266466141
0.027127742767333984
Batch of classes 6 out of 12 batches
Epoch 3 of 30 took 88.857s
  training loss:		0.036382
  validation loss:		0.001986
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.02948283962905407
0.01781991310417652
0.014899790287017822
Batch of classes 6 out of 12 batches
Epoch 4 of 30 took 89.368s
  training loss:		0.029941
  validation loss:		0.005090
  top 1 accuracy:		99.61 %
  top 2 accuracy:		99.88 %
0.024615434929728508
0.06049793213605881
0.007532897405326366
Batch of classes 6 out of 12 batches
Epoch 5 of 30 took 89.197s
  training loss:		0.030022
  validation loss:		0.004061
  top 1 accuracy:		99.88 %
  top 2 accuracy:		100.00 %
0.025481561198830605
0.018712980672717094
0.01750951074063778
Batch of classes 6 out of 12 batches
Epoch 6 of 30 took 89.540s
  training loss:		0.025375
  validation loss:		0.005930
  top 1 accuracy:		98.51 %
  top 2 accuracy:		99.76 %
0.025243423879146576
0.028960518538951874
0.05207101255655289
Batch of classes 6 out of 12 batches
Epoch 7 of 30 took 89.242s
  training loss:		0.075700
  validation loss:		0.007619
  top 1 accuracy:		98.86 %
  top 2 accuracy:		100.00 %
0.03332650661468506
0.09645304083824158
0.05126409977674484
Batch of classes 6 out of 12 batches
Epoch 8 of 30 took 89.670s
  training loss:		0.060457
  validation loss:		0.002825
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.04509330540895462
0.021624034270644188
0.0270596444606781
Batch of classes 6 out of 12 batches
Epoch 9 of 30 took 89.602s
  training loss:		0.049527
  validation loss:		0.002178
  top 1 accuracy:		99.88 %
  top 2 accuracy:		100.00 %
0.05828820914030075
0.05899525433778763
0.03309151530265808
Batch of classes 6 out of 12 batches
Epoch 10 of 30 took 88.793s
  training loss:		0.043406
  validation loss:		0.003566
  top 1 accuracy:		99.96 %
  top 2 accuracy:		99.96 %
0.04738079383969307
0.02123253419995308
0.05696868151426315
Batch of classes 6 out of 12 batches
Epoch 11 of 30 took 88.729s
  training loss:		0.033844
  validation loss:		0.002276
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
0.04011645168066025
0.025417227298021317
0.03160908445715904
Batch of classes 6 out of 12 batches
Epoch 12 of 30 took 89.640s
  training loss:		0.031200
  validation loss:		0.002465
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
0.02944376692175865
0.01483074203133583
0.0398155152797699
Batch of classes 6 out of 12 batches
Epoch 13 of 30 took 89.490s
  training loss:		0.028713
  validation loss:		0.001726
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.014644129201769829
0.02474450320005417
0.04120221734046936
Batch of classes 6 out of 12 batches
Epoch 14 of 30 took 89.227s
  training loss:		0.026740
  validation loss:		0.001551
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.031450796872377396
0.04689367488026619
0.02631031721830368
Batch of classes 6 out of 12 batches
Epoch 15 of 30 took 89.359s
  training loss:		0.025749
  validation loss:		0.002370
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.030610408633947372
0.009558219462633133
0.014782078564167023
Batch of classes 6 out of 12 batches
Epoch 16 of 30 took 88.979s
  training loss:		0.026447
  validation loss:		0.001815
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.033365681767463684
0.011143052950501442
0.040802568197250366
Batch of classes 6 out of 12 batches
Epoch 17 of 30 took 89.555s
  training loss:		0.024346
  validation loss:		0.002270
  top 1 accuracy:		99.92 %
  top 2 accuracy:		99.96 %
0.014980260282754898
0.017565807327628136
0.02465132623910904
Batch of classes 6 out of 12 batches
Epoch 18 of 30 took 89.289s
  training loss:		0.021247
  validation loss:		0.002448
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.003315524896606803
0.0578882098197937
0.02549099177122116
Batch of classes 6 out of 12 batches
Epoch 19 of 30 took 89.233s
  training loss:		0.019532
  validation loss:		0.001822
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
0.013489644974470139
0.030146684497594833
0.025982992723584175
Batch of classes 6 out of 12 batches
Epoch 20 of 30 took 89.250s
  training loss:		0.027492
  validation loss:		0.001727
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.014434725977480412
0.016849994659423828
0.014432894997298717
Batch of classes 6 out of 12 batches
Epoch 21 of 30 took 89.141s
  training loss:		0.017339
  validation loss:		0.002020
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
0.018989328294992447
0.013093393296003342
0.017165975645184517
Batch of classes 6 out of 12 batches
Epoch 22 of 30 took 89.072s
  training loss:		0.018261
  validation loss:		0.002113
  top 1 accuracy:		99.80 %
  top 2 accuracy:		100.00 %
0.02273249626159668
0.0718853771686554
0.021100535988807678
Batch of classes 6 out of 12 batches
Epoch 23 of 30 took 89.705s
  training loss:		0.016126
  validation loss:		0.001698
  top 1 accuracy:		100.00 %
  top 2 accuracy:		100.00 %
0.008364933542907238
0.004727058112621307
0.039947040379047394
Batch of classes 6 out of 12 batches
Epoch 24 of 30 took 89.444s
  training loss:		0.015834
  validation loss:		0.001947
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
0.02511277236044407
0.01640745811164379
0.01460982859134674
Batch of classes 6 out of 12 batches
Epoch 25 of 30 took 89.336s
  training loss:		0.015530
  validation loss:		0.001810
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
0.022865552455186844
0.007137868087738752
0.008878795430064201
Batch of classes 6 out of 12 batches
Epoch 26 of 30 took 89.276s
  training loss:		0.015184
  validation loss:		0.001818
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.020688463002443314
0.10538788139820099
0.006760646589100361
Batch of classes 6 out of 12 batches
Epoch 27 of 30 took 88.861s
  training loss:		0.015152
  validation loss:		0.001970
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
0.013486328534781933
0.0038991360925137997
0.011042619124054909
Batch of classes 6 out of 12 batches
Epoch 28 of 30 took 89.689s
  training loss:		0.014319
  validation loss:		0.002670
  top 1 accuracy:		99.92 %
  top 2 accuracy:		99.96 %
0.021854549646377563
0.007780222687870264
0.014916397631168365
Batch of classes 6 out of 12 batches
Epoch 29 of 30 took 89.745s
  training loss:		0.013299
  validation loss:		0.002156
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.012141512706875801
0.009104994125664234
0.0058866944164037704
Batch of classes 6 out of 12 batches
Epoch 30 of 30 took 89.345s
  training loss:		0.013094
  validation loss:		0.001875
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
tensor(128)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		44.70 %
  top 1 accuracy Hybrid 1       :		34.70 %
  top 1 accuracy NCM            :		41.60 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		70.55 %
  top 1 accuracy Hybrid 1       :		65.50 %
  top 1 accuracy NCM            :		71.10 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		41.88 %
  top 1 accuracy Hybrid 1       :		41.62 %
  top 1 accuracy NCM            :		44.50 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		76.50 %
  top 1 accuracy Hybrid 1       :		75.25 %
  top 1 accuracy NCM            :		76.88 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		71.37 %
  top 1 accuracy Hybrid 1       :		78.82 %
  top 1 accuracy NCM            :		72.71 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		84.54 %
  top 1 accuracy Hybrid 1       :		87.21 %
  top 1 accuracy NCM            :		84.92 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		73.79 %
  top 1 accuracy Hybrid 1       :		49.29 %
  top 1 accuracy NCM            :		76.02 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.80 %
  top 1 accuracy Hybrid 1       :		99.73 %
  top 1 accuracy NCM            :		99.80 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		76.06 %
  top 1 accuracy Hybrid 1       :		75.14 %
  top 1 accuracy NCM            :		76.06 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		76.16 %
  top 1 accuracy Hybrid 1       :		75.42 %
  top 1 accuracy NCM            :		76.16 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		75.51 %
  top 1 accuracy Hybrid 1       :		99.96 %
  top 1 accuracy NCM            :		73.39 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.88 %
  top 1 accuracy Hybrid 1       :		100.00 %
  top 1 accuracy NCM            :		99.88 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		65.57 %
  top 1 accuracy Hybrid 1       :		63.74 %
  top 1 accuracy NCM            :		65.25 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		88.18 %
  top 1 accuracy Hybrid 1       :		87.09 %
  top 1 accuracy NCM            :		88.35 %
Classes in this batch: tensor([12, 13])
Data Size: 6208


Before first epoch
  validation loss:		0.420532
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 7 arrives ...
0.7285158634185791
0.2716955542564392
0.2383110523223877
Batch of classes 7 out of 12 batches
Epoch 1 of 30 took 75.771s
  training loss:		0.293655
  validation loss:		0.068510
  top 1 accuracy:		58.36 %
  top 2 accuracy:		99.08 %
0.24805352091789246
0.23709607124328613
0.21444056928157806
Batch of classes 7 out of 12 batches
Epoch 2 of 30 took 69.572s
  training loss:		0.232356
  validation loss:		0.056377
  top 1 accuracy:		66.46 %
  top 2 accuracy:		98.50 %
0.20510393381118774
0.22170837223529816
0.20532813668251038
Batch of classes 7 out of 12 batches
Epoch 3 of 30 took 69.444s
  training loss:		0.212740
  validation loss:		0.057018
  top 1 accuracy:		67.43 %
  top 2 accuracy:		97.67 %
0.2436360865831375
0.25309765338897705
0.21179929375648499
Batch of classes 7 out of 12 batches
Epoch 4 of 30 took 69.686s
  training loss:		0.200558
  validation loss:		0.055372
  top 1 accuracy:		69.12 %
  top 2 accuracy:		96.99 %
0.22606094181537628
0.17810629308223724
0.18875432014465332
Batch of classes 7 out of 12 batches
Epoch 5 of 30 took 69.629s
  training loss:		0.193645
  validation loss:		0.050991
  top 1 accuracy:		70.77 %
  top 2 accuracy:		98.98 %
0.21251660585403442
0.19901663064956665
0.17908814549446106
Batch of classes 7 out of 12 batches
Epoch 6 of 30 took 68.487s
  training loss:		0.187684
  validation loss:		0.055369
  top 1 accuracy:		68.64 %
  top 2 accuracy:		96.32 %
0.23713348805904388
0.170673206448555
0.21059949696063995
Batch of classes 7 out of 12 batches
Epoch 7 of 30 took 68.821s
  training loss:		0.180148
  validation loss:		0.051511
  top 1 accuracy:		73.05 %
  top 2 accuracy:		96.61 %
0.18383288383483887
0.20022481679916382
0.18337704241275787
Batch of classes 7 out of 12 batches
Epoch 8 of 30 took 69.458s
  training loss:		0.173527
  validation loss:		0.051096
  top 1 accuracy:		70.58 %
  top 2 accuracy:		98.55 %
0.15213562548160553
0.15480129420757294
0.19160667061805725
Batch of classes 7 out of 12 batches
Epoch 9 of 30 took 69.620s
  training loss:		0.164510
  validation loss:		0.052381
  top 1 accuracy:		72.42 %
  top 2 accuracy:		96.90 %
0.20004582405090332
0.14119412004947662
0.19813603162765503
Batch of classes 7 out of 12 batches
Epoch 10 of 30 took 69.335s
  training loss:		0.160658
  validation loss:		0.046468
  top 1 accuracy:		74.31 %
  top 2 accuracy:		98.11 %
0.20605286955833435
0.1470712125301361
0.1170726791024208
Batch of classes 7 out of 12 batches
Epoch 11 of 30 took 69.210s
  training loss:		0.138548
  validation loss:		0.044408
  top 1 accuracy:		77.85 %
  top 2 accuracy:		97.77 %
0.13446380198001862
0.10149461030960083
0.09690234810113907
Batch of classes 7 out of 12 batches
Epoch 12 of 30 took 69.311s
  training loss:		0.126168
  validation loss:		0.046152
  top 1 accuracy:		77.41 %
  top 2 accuracy:		98.25 %
0.1942678689956665
0.08724450320005417
0.10265792906284332
Batch of classes 7 out of 12 batches
Epoch 13 of 30 took 69.497s
  training loss:		0.123587
  validation loss:		0.043679
  top 1 accuracy:		77.65 %
  top 2 accuracy:		97.87 %
0.14916351437568665
0.12937617301940918
0.12863704562187195
Batch of classes 7 out of 12 batches
Epoch 14 of 30 took 69.565s
  training loss:		0.115151
  validation loss:		0.045444
  top 1 accuracy:		77.46 %
  top 2 accuracy:		97.67 %
0.06827189028263092
0.14046530425548553
0.12300918996334076
Batch of classes 7 out of 12 batches
Epoch 15 of 30 took 69.271s
  training loss:		0.115853
  validation loss:		0.046067
  top 1 accuracy:		76.01 %
  top 2 accuracy:		97.58 %
0.12435224652290344
0.11686687171459198
0.12332374602556229
Batch of classes 7 out of 12 batches
Epoch 16 of 30 took 69.494s
  training loss:		0.111186
  validation loss:		0.049322
  top 1 accuracy:		76.25 %
  top 2 accuracy:		97.19 %
0.11483067274093628
0.10287906229496002
0.12933653593063354
Batch of classes 7 out of 12 batches
Epoch 17 of 30 took 69.601s
  training loss:		0.108509
  validation loss:		0.045478
  top 1 accuracy:		77.65 %
  top 2 accuracy:		97.77 %
0.09105321764945984
0.10295063257217407
0.15529319643974304
Batch of classes 7 out of 12 batches
Epoch 18 of 30 took 69.333s
  training loss:		0.105536
  validation loss:		0.046062
  top 1 accuracy:		77.36 %
  top 2 accuracy:		97.04 %
0.17952460050582886
0.1081765666604042
0.061386384069919586
Batch of classes 7 out of 12 batches
Epoch 19 of 30 took 69.174s
  training loss:		0.104241
  validation loss:		0.051423
  top 1 accuracy:		76.73 %
  top 2 accuracy:		96.22 %
0.09065213799476624
0.06365054845809937
0.110725998878479
Batch of classes 7 out of 12 batches
Epoch 20 of 30 took 69.833s
  training loss:		0.101139
  validation loss:		0.049310
  top 1 accuracy:		76.30 %
  top 2 accuracy:		97.92 %
0.08071444928646088
0.05750356987118721
0.11497393995523453
Batch of classes 7 out of 12 batches
Epoch 21 of 30 took 69.554s
  training loss:		0.089283
  validation loss:		0.049172
  top 1 accuracy:		76.15 %
  top 2 accuracy:		96.22 %
0.08152105659246445
0.05728113651275635
0.0639483854174614
Batch of classes 7 out of 12 batches
Epoch 22 of 30 took 69.222s
  training loss:		0.085231
  validation loss:		0.049555
  top 1 accuracy:		76.88 %
  top 2 accuracy:		96.51 %
0.05194369703531265
0.06639039516448975
0.08577084541320801
Batch of classes 7 out of 12 batches
Epoch 23 of 30 took 69.381s
  training loss:		0.082474
  validation loss:		0.049110
  top 1 accuracy:		77.36 %
  top 2 accuracy:		97.09 %
0.05083765089511871
0.04352486878633499
0.051915738731622696
Batch of classes 7 out of 12 batches
Epoch 24 of 30 took 69.447s
  training loss:		0.079796
  validation loss:		0.051417
  top 1 accuracy:		76.35 %
  top 2 accuracy:		96.07 %
0.09433093667030334
0.11191485822200775
0.08655136078596115
Batch of classes 7 out of 12 batches
Epoch 25 of 30 took 69.139s
  training loss:		0.077844
  validation loss:		0.049749
  top 1 accuracy:		76.20 %
  top 2 accuracy:		96.95 %
0.06953410804271698
0.04660413786768913
0.1054716408252716
Batch of classes 7 out of 12 batches
Epoch 26 of 30 took 69.563s
  training loss:		0.080371
  validation loss:		0.051367
  top 1 accuracy:		74.75 %
  top 2 accuracy:		96.17 %
0.09032246470451355
0.10073696076869965
0.09766104817390442
Batch of classes 7 out of 12 batches
Epoch 27 of 30 took 69.142s
  training loss:		0.075985
  validation loss:		0.049484
  top 1 accuracy:		77.02 %
  top 2 accuracy:		97.09 %
0.11921169608831406
0.0367293655872345
0.1598673164844513
Batch of classes 7 out of 12 batches
Epoch 28 of 30 took 69.934s
  training loss:		0.074703
  validation loss:		0.050871
  top 1 accuracy:		76.20 %
  top 2 accuracy:		97.19 %
0.04069488123059273
0.09531736373901367
0.05898815393447876
Batch of classes 7 out of 12 batches
Epoch 29 of 30 took 69.388s
  training loss:		0.069721
  validation loss:		0.054905
  top 1 accuracy:		76.25 %
  top 2 accuracy:		95.78 %
0.07097697257995605
0.05597233027219772
0.05061645433306694
Batch of classes 7 out of 12 batches
Epoch 30 of 30 took 69.043s
  training loss:		0.071692
  validation loss:		0.052349
  top 1 accuracy:		76.54 %
  top 2 accuracy:		96.95 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
tensor(110)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		54.10 %
  top 1 accuracy Hybrid 1       :		50.70 %
  top 1 accuracy NCM            :		52.55 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		74.10 %
  top 1 accuracy Hybrid 1       :		73.85 %
  top 1 accuracy NCM            :		74.35 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		45.25 %
  top 1 accuracy Hybrid 1       :		44.62 %
  top 1 accuracy NCM            :		46.25 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		78.25 %
  top 1 accuracy Hybrid 1       :		78.50 %
  top 1 accuracy NCM            :		79.25 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		73.66 %
  top 1 accuracy Hybrid 1       :		75.38 %
  top 1 accuracy NCM            :		74.24 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		86.45 %
  top 1 accuracy Hybrid 1       :		86.64 %
  top 1 accuracy NCM            :		86.45 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		71.51 %
  top 1 accuracy Hybrid 1       :		80.76 %
  top 1 accuracy NCM            :		72.81 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.57 %
  top 1 accuracy Hybrid 1       :		99.76 %
  top 1 accuracy NCM            :		99.57 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		80.31 %
  top 1 accuracy Hybrid 1       :		65.34 %
  top 1 accuracy NCM            :		80.68 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		88.08 %
  top 1 accuracy Hybrid 1       :		85.67 %
  top 1 accuracy NCM            :		88.35 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		76.92 %
  top 1 accuracy Hybrid 1       :		68.18 %
  top 1 accuracy NCM            :		75.31 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.41 %
  top 1 accuracy Hybrid 1       :		99.73 %
  top 1 accuracy NCM            :		99.37 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		73.15 %
  top 1 accuracy Hybrid 1       :		76.54 %
  top 1 accuracy NCM            :		73.10 %
Binary accuracy:
Final results on wild classes:
  top 1 accuracy iCaRL          :		77.46 %
  top 1 accuracy Hybrid 1       :		77.22 %
  top 1 accuracy NCM            :		77.51 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		69.09 %
  top 1 accuracy Hybrid 1       :		67.86 %
  top 1 accuracy NCM            :		68.88 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		88.05 %
  top 1 accuracy Hybrid 1       :		87.88 %
  top 1 accuracy NCM            :		88.19 %
Classes in this batch: tensor([14, 15])
Data Size: 7200


Before first epoch
  validation loss:		0.604637
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 8 arrives ...
0.8731245994567871
0.09599579870700836
0.0460331030189991
Batch of classes 8 out of 12 batches
Epoch 1 of 30 took 1473.747s
  training loss:		0.125486
  validation loss:		0.010034
  top 1 accuracy:		97.87 %
  top 2 accuracy:		99.56 %
0.13842861354351044
0.04374045878648758
0.03250720351934433
Batch of classes 8 out of 12 batches
Epoch 2 of 30 took 803.426s
  training loss:		0.059114
  validation loss:		0.006628
  top 1 accuracy:		98.58 %
  top 2 accuracy:		99.54 %
0.07986685633659363
0.11414629220962524
0.06600474566221237
Batch of classes 8 out of 12 batches
Epoch 3 of 30 took 1027.084s
  training loss:		0.046380
  validation loss:		0.016205
  top 1 accuracy:		93.90 %
  top 2 accuracy:		99.52 %
0.03329368308186531
0.05638332664966583
0.024574147537350655
Batch of classes 8 out of 12 batches
Epoch 4 of 30 took 938.407s
  training loss:		0.045060
  validation loss:		0.005180
  top 1 accuracy:		98.65 %
  top 2 accuracy:		99.73 %
0.03752123937010765
0.02865111082792282
0.04742089658975601
Batch of classes 8 out of 12 batches
Epoch 5 of 30 took 1515.034s
  training loss:		0.037952
  validation loss:		0.009343
  top 1 accuracy:		97.75 %
  top 2 accuracy:		99.54 %
0.020573750138282776
0.0370921716094017
0.028360877186059952
Batch of classes 8 out of 12 batches
Epoch 6 of 30 took 1100.319s
  training loss:		0.037307
  validation loss:		0.014507
  top 1 accuracy:		95.92 %
  top 2 accuracy:		98.02 %
0.029612800106406212
0.02921273373067379
0.014540981501340866
Batch of classes 8 out of 12 batches
Epoch 7 of 30 took 1000.880s
  training loss:		0.036483
  validation loss:		0.006482
  top 1 accuracy:		98.33 %
  top 2 accuracy:		99.69 %
0.02585170604288578
0.012309187091886997
0.07994873076677322
Batch of classes 8 out of 12 batches
Epoch 8 of 30 took 1732.843s
  training loss:		0.029862
  validation loss:		0.006098
  top 1 accuracy:		98.35 %
  top 2 accuracy:		99.60 %
0.014266994781792164
0.014414096251130104
0.030201468616724014
Batch of classes 8 out of 12 batches
Epoch 9 of 30 took 1573.868s
  training loss:		0.026334
  validation loss:		0.003793
  top 1 accuracy:		99.40 %
  top 2 accuracy:		99.85 %
0.01477808691561222
0.017663003876805305
0.012615475803613663
Batch of classes 8 out of 12 batches
Epoch 10 of 30 took 188.863s
  training loss:		0.029246
  validation loss:		0.006568
  top 1 accuracy:		98.06 %
  top 2 accuracy:		99.56 %
0.03899930417537689
0.016273144632577896
0.03148616850376129
Batch of classes 8 out of 12 batches
Epoch 11 of 30 took 95.399s
  training loss:		0.019503
  validation loss:		0.002336
  top 1 accuracy:		99.54 %
  top 2 accuracy:		99.96 %
0.00631696218624711
0.007852049544453621
0.008793198503553867
Batch of classes 8 out of 12 batches
Epoch 12 of 30 took 94.906s
  training loss:		0.015716
  validation loss:		0.004382
  top 1 accuracy:		99.15 %
  top 2 accuracy:		99.85 %
0.014033569023013115
0.006168811582028866
0.010130046866834164
Batch of classes 8 out of 12 batches
Epoch 13 of 30 took 94.446s
  training loss:		0.013561
  validation loss:		0.003935
  top 1 accuracy:		99.21 %
  top 2 accuracy:		99.83 %
0.006443592719733715
0.010690098628401756
0.006202300079166889
Batch of classes 8 out of 12 batches
Epoch 14 of 30 took 94.917s
  training loss:		0.012584
  validation loss:		0.006837
  top 1 accuracy:		98.83 %
  top 2 accuracy:		99.75 %
0.004060632549226284
0.015997271984815598
0.006529550533741713
Batch of classes 8 out of 12 batches
Epoch 15 of 30 took 94.736s
  training loss:		0.012314
  validation loss:		0.004717
  top 1 accuracy:		99.12 %
  top 2 accuracy:		99.79 %
0.007414803374558687
0.010013741441071033
0.007639467716217041
Batch of classes 8 out of 12 batches
Epoch 16 of 30 took 94.551s
  training loss:		0.012519
  validation loss:		0.003928
  top 1 accuracy:		99.04 %
  top 2 accuracy:		99.83 %
0.006136460229754448
0.007838604040443897
0.0034489587415009737
Batch of classes 8 out of 12 batches
Epoch 17 of 30 took 93.830s
  training loss:		0.011236
  validation loss:		0.003308
  top 1 accuracy:		99.33 %
  top 2 accuracy:		99.79 %
0.00627652695402503
0.0055917189456522465
0.00847839005291462
Batch of classes 8 out of 12 batches
Epoch 18 of 30 took 94.303s
  training loss:		0.012922
  validation loss:		0.003524
  top 1 accuracy:		99.40 %
  top 2 accuracy:		99.85 %
0.008421181701123714
0.018457194790244102
0.004687801469117403
Batch of classes 8 out of 12 batches
Epoch 19 of 30 took 98.402s
  training loss:		0.014358
  validation loss:		0.003273
  top 1 accuracy:		99.40 %
  top 2 accuracy:		99.92 %
0.004852071404457092
0.006007158197462559
0.009123989380896091
Batch of classes 8 out of 12 batches
Epoch 20 of 30 took 294.725s
  training loss:		0.016184
  validation loss:		0.002051
  top 1 accuracy:		99.58 %
  top 2 accuracy:		99.98 %
0.00545703899115324
0.007078022230416536
0.0033313033636659384
Batch of classes 8 out of 12 batches
Epoch 21 of 30 took 223.879s
  training loss:		0.011481
  validation loss:		0.003850
  top 1 accuracy:		99.02 %
  top 2 accuracy:		99.81 %
0.005335169844329357
0.00875204335898161
0.006035221740603447
Batch of classes 8 out of 12 batches
Epoch 22 of 30 took 96.762s
  training loss:		0.009413
  validation loss:		0.001882
  top 1 accuracy:		99.65 %
  top 2 accuracy:		99.98 %
0.0007688853656873107
0.03318963199853897
0.0026840870268642902
Batch of classes 8 out of 12 batches
Epoch 23 of 30 took 94.210s
  training loss:		0.008050
  validation loss:		0.002044
  top 1 accuracy:		99.62 %
  top 2 accuracy:		99.96 %
0.002705889753997326
0.0015308453002944589
0.002436211099848151
Batch of classes 8 out of 12 batches
Epoch 24 of 30 took 94.506s
  training loss:		0.008901
  validation loss:		0.002409
  top 1 accuracy:		99.35 %
  top 2 accuracy:		99.92 %
0.004507239907979965
0.017042003571987152
0.0841369479894638
Batch of classes 8 out of 12 batches
Epoch 25 of 30 took 94.193s
  training loss:		0.008464
  validation loss:		0.004659
  top 1 accuracy:		99.04 %
  top 2 accuracy:		99.83 %
0.004868090618401766
0.004400425124913454
0.003926802426576614
Batch of classes 8 out of 12 batches
Epoch 26 of 30 took 94.721s
  training loss:		0.007578
  validation loss:		0.003830
  top 1 accuracy:		99.44 %
  top 2 accuracy:		99.87 %
0.005302952602505684
0.004214751999825239
0.0020085179712623358
Batch of classes 8 out of 12 batches
Epoch 27 of 30 took 93.989s
  training loss:		0.007724
  validation loss:		0.001678
  top 1 accuracy:		99.65 %
  top 2 accuracy:		99.94 %
0.001449462492018938
0.006847848650068045
0.0071752057410776615
Batch of classes 8 out of 12 batches
Epoch 28 of 30 took 93.383s
  training loss:		0.007090
  validation loss:		0.002062
  top 1 accuracy:		99.62 %
  top 2 accuracy:		99.94 %
0.004639709834009409
0.005279346369206905
0.004233814310282469
Batch of classes 8 out of 12 batches
Epoch 29 of 30 took 94.252s
  training loss:		0.005776
  validation loss:		0.001632
  top 1 accuracy:		99.65 %
  top 2 accuracy:		99.92 %
0.007181686814874411
0.0034979816991835833
0.0024020655546337366
Batch of classes 8 out of 12 batches
Epoch 30 of 30 took 93.778s
  training loss:		0.007563
  validation loss:		0.003684
  top 1 accuracy:		99.31 %
  top 2 accuracy:		99.85 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
tensor(96)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		53.50 %
  top 1 accuracy Hybrid 1       :		56.10 %
  top 1 accuracy NCM            :		51.40 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		73.95 %
  top 1 accuracy Hybrid 1       :		75.20 %
  top 1 accuracy NCM            :		73.85 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		45.88 %
  top 1 accuracy Hybrid 1       :		38.12 %
  top 1 accuracy NCM            :		48.62 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		79.25 %
  top 1 accuracy Hybrid 1       :		77.88 %
  top 1 accuracy NCM            :		79.12 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		76.15 %
  top 1 accuracy Hybrid 1       :		81.30 %
  top 1 accuracy NCM            :		78.63 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		90.84 %
  top 1 accuracy Hybrid 1       :		90.84 %
  top 1 accuracy NCM            :		90.27 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		76.84 %
  top 1 accuracy Hybrid 1       :		81.03 %
  top 1 accuracy NCM            :		74.02 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.49 %
  top 1 accuracy Hybrid 1       :		99.14 %
  top 1 accuracy NCM            :		99.45 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		86.97 %
  top 1 accuracy Hybrid 1       :		88.17 %
  top 1 accuracy NCM            :		87.43 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		92.51 %
  top 1 accuracy Hybrid 1       :		92.98 %
  top 1 accuracy NCM            :		92.51 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		71.24 %
  top 1 accuracy Hybrid 1       :		67.05 %
  top 1 accuracy NCM            :		74.02 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.45 %
  top 1 accuracy Hybrid 1       :		99.14 %
  top 1 accuracy NCM            :		99.41 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		62.68 %
  top 1 accuracy Hybrid 1       :		61.75 %
  top 1 accuracy NCM            :		61.80 %
Binary accuracy:
Final results on wild classes:
  top 1 accuracy iCaRL          :		72.76 %
  top 1 accuracy Hybrid 1       :		72.52 %
  top 1 accuracy NCM            :		73.19 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		99.06 %
  top 1 accuracy Hybrid 1       :		99.31 %
  top 1 accuracy NCM            :		99.12 %
Binary accuracy:
Final results on glow classes:
  top 1 accuracy iCaRL          :		99.60 %
  top 1 accuracy Hybrid 1       :		99.38 %
  top 1 accuracy NCM            :		99.60 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		76.98 %
  top 1 accuracy Hybrid 1       :		77.12 %
  top 1 accuracy NCM            :		76.87 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		91.30 %
  top 1 accuracy Hybrid 1       :		91.22 %
  top 1 accuracy NCM            :		91.31 %
Classes in this batch: tensor([16, 17])
Data Size: 7200


Before first epoch
  validation loss:		0.667782
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 9 arrives ...
0.5712635517120361
0.03248322382569313
0.05916960537433624
Batch of classes 9 out of 12 batches
Epoch 1 of 30 took 199.437s
  training loss:		0.086159
  validation loss:		0.003294
  top 1 accuracy:		99.75 %
  top 2 accuracy:		99.90 %
0.010370785370469093
0.04710852727293968
0.0170158501714468
Batch of classes 9 out of 12 batches
Epoch 2 of 30 took 96.926s
  training loss:		0.030215
  validation loss:		0.003178
  top 1 accuracy:		99.69 %
  top 2 accuracy:		99.94 %
0.029427673667669296
0.0157878790050745
0.037994492799043655
Batch of classes 9 out of 12 batches
Epoch 3 of 30 took 96.491s
  training loss:		0.028659
  validation loss:		0.003145
  top 1 accuracy:		99.62 %
  top 2 accuracy:		99.96 %
0.03125765919685364
0.01725899614393711
0.024887653067708015
Batch of classes 9 out of 12 batches
Epoch 4 of 30 took 96.281s
  training loss:		0.025858
  validation loss:		0.002462
  top 1 accuracy:		99.50 %
  top 2 accuracy:		99.92 %
0.02946789748966694
0.008293193764984608
0.04311620444059372
Batch of classes 9 out of 12 batches
Epoch 5 of 30 took 96.208s
  training loss:		0.024542
  validation loss:		0.003538
  top 1 accuracy:		99.27 %
  top 2 accuracy:		99.98 %
0.03241214156150818
0.02542610466480255
0.011972426436841488
Batch of classes 9 out of 12 batches
Epoch 6 of 30 took 95.976s
  training loss:		0.023200
  validation loss:		0.003424
  top 1 accuracy:		99.67 %
  top 2 accuracy:		99.94 %
0.007812376134097576
0.0041154297068715096
0.05029546841979027
Batch of classes 9 out of 12 batches
Epoch 7 of 30 took 96.662s
  training loss:		0.021512
  validation loss:		0.004129
  top 1 accuracy:		99.25 %
  top 2 accuracy:		99.77 %
0.009682185016572475
0.01074462290853262
0.029604587703943253
Batch of classes 9 out of 12 batches
Epoch 8 of 30 took 96.290s
  training loss:		0.025870
  validation loss:		0.005659
  top 1 accuracy:		99.02 %
  top 2 accuracy:		99.81 %
0.016323618590831757
0.007213860750198364
0.007867895998060703
Batch of classes 9 out of 12 batches
Epoch 9 of 30 took 95.215s
  training loss:		0.024181
  validation loss:		0.005697
  top 1 accuracy:		98.58 %
  top 2 accuracy:		99.98 %
0.020801793783903122
0.004643426742404699
0.012445882894098759
Batch of classes 9 out of 12 batches
Epoch 10 of 30 took 96.479s
  training loss:		0.018486
  validation loss:		0.003176
  top 1 accuracy:		99.46 %
  top 2 accuracy:		99.90 %
0.014111548662185669
0.010190430097281933
0.009210491552948952
Batch of classes 9 out of 12 batches
Epoch 11 of 30 took 96.259s
  training loss:		0.011285
  validation loss:		0.001679
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
0.009602043777704239
0.0034963185898959637
0.008935394696891308
Batch of classes 9 out of 12 batches
Epoch 12 of 30 took 96.361s
  training loss:		0.009582
  validation loss:		0.001766
  top 1 accuracy:		99.87 %
  top 2 accuracy:		100.00 %
0.004155673552304506
0.021197030320763588
0.006215877830982208
Batch of classes 9 out of 12 batches
Epoch 13 of 30 took 96.065s
  training loss:		0.009137
  validation loss:		0.002149
  top 1 accuracy:		99.79 %
  top 2 accuracy:		100.00 %
0.008792485110461712
0.00540551682934165
0.0047590285539627075
Batch of classes 9 out of 12 batches
Epoch 14 of 30 took 96.827s
  training loss:		0.008458
  validation loss:		0.001961
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
0.004267708398401737
0.0030285052489489317
0.0037951681297272444
Batch of classes 9 out of 12 batches
Epoch 15 of 30 took 96.395s
  training loss:		0.007940
  validation loss:		0.001865
  top 1 accuracy:		99.71 %
  top 2 accuracy:		100.00 %
0.0061528971418738365
0.0035885553807020187
0.007545591797679663
Batch of classes 9 out of 12 batches
Epoch 16 of 30 took 96.604s
  training loss:		0.007535
  validation loss:		0.002377
  top 1 accuracy:		99.79 %
  top 2 accuracy:		99.94 %
0.00881227571517229
0.0025346383918076754
0.005469036288559437
Batch of classes 9 out of 12 batches
Epoch 17 of 30 took 94.988s
  training loss:		0.007472
  validation loss:		0.001714
  top 1 accuracy:		99.94 %
  top 2 accuracy:		100.00 %
0.005655501037836075
0.009613612666726112
0.0075353095307946205
Batch of classes 9 out of 12 batches
Epoch 18 of 30 took 96.334s
  training loss:		0.009690
  validation loss:		0.001150
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.0035519972443580627
0.004942002240568399
0.0074747176840901375
Batch of classes 9 out of 12 batches
Epoch 19 of 30 took 96.325s
  training loss:		0.007626
  validation loss:		0.001653
  top 1 accuracy:		99.90 %
  top 2 accuracy:		99.98 %
0.007337851449847221
0.013391688466072083
0.0037710927426815033
Batch of classes 9 out of 12 batches
Epoch 20 of 30 took 96.281s
  training loss:		0.008020
  validation loss:		0.002979
  top 1 accuracy:		99.67 %
  top 2 accuracy:		99.98 %
0.00281848874874413
0.0038852416910231113
0.0027459412813186646
Batch of classes 9 out of 12 batches
Epoch 21 of 30 took 96.234s
  training loss:		0.007038
  validation loss:		0.001242
  top 1 accuracy:		99.98 %
  top 2 accuracy:		100.00 %
0.00804289523512125
0.033454641699790955
0.0022539650090038776
Batch of classes 9 out of 12 batches
Epoch 22 of 30 took 96.088s
  training loss:		0.008374
  validation loss:		0.001742
  top 1 accuracy:		99.87 %
  top 2 accuracy:		100.00 %
0.002948598936200142
0.024248912930488586
0.025422247126698494
Batch of classes 9 out of 12 batches
Epoch 23 of 30 took 96.282s
  training loss:		0.006513
  validation loss:		0.001582
  top 1 accuracy:		99.94 %
  top 2 accuracy:		100.00 %
0.0007851996924728155
0.006571173667907715
0.0007939886418171227
Batch of classes 9 out of 12 batches
Epoch 24 of 30 took 96.012s
  training loss:		0.005385
  validation loss:		0.001375
  top 1 accuracy:		99.94 %
  top 2 accuracy:		100.00 %
0.0046248892322182655
0.0019524154486134648
0.002697594463825226
Batch of classes 9 out of 12 batches
Epoch 25 of 30 took 95.593s
  training loss:		0.005147
  validation loss:		0.001281
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
0.007462366949766874
0.00875361729413271
0.003971721511334181
Batch of classes 9 out of 12 batches
Epoch 26 of 30 took 95.723s
  training loss:		0.004864
  validation loss:		0.000960
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.001608262537047267
0.002157311188057065
0.0037903031334280968
Batch of classes 9 out of 12 batches
Epoch 27 of 30 took 95.810s
  training loss:		0.004694
  validation loss:		0.000936
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.0011750566773116589
0.003010192420333624
0.003477402264252305
Batch of classes 9 out of 12 batches
Epoch 28 of 30 took 96.442s
  training loss:		0.005185
  validation loss:		0.001089
  top 1 accuracy:		99.94 %
  top 2 accuracy:		100.00 %
0.0024073179811239243
0.017932873219251633
0.0012304718839004636
Batch of classes 9 out of 12 batches
Epoch 29 of 30 took 95.936s
  training loss:		0.004239
  validation loss:		0.001036
  top 1 accuracy:		99.96 %
  top 2 accuracy:		100.00 %
0.003067554673179984
0.0033909534104168415
0.0015449998900294304
Batch of classes 9 out of 12 batches
Epoch 30 of 30 took 95.987s
  training loss:		0.003683
  validation loss:		0.000868
  top 1 accuracy:		99.92 %
  top 2 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
tensor(86)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		58.85 %
  top 1 accuracy Hybrid 1       :		57.85 %
  top 1 accuracy NCM            :		59.10 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		79.20 %
  top 1 accuracy Hybrid 1       :		78.30 %
  top 1 accuracy NCM            :		79.50 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		49.38 %
  top 1 accuracy Hybrid 1       :		48.00 %
  top 1 accuracy NCM            :		49.12 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		79.62 %
  top 1 accuracy Hybrid 1       :		78.88 %
  top 1 accuracy NCM            :		79.75 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		68.89 %
  top 1 accuracy Hybrid 1       :		71.18 %
  top 1 accuracy NCM            :		72.90 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		90.27 %
  top 1 accuracy Hybrid 1       :		90.46 %
  top 1 accuracy NCM            :		90.84 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		76.57 %
  top 1 accuracy Hybrid 1       :		77.59 %
  top 1 accuracy NCM            :		72.61 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.45 %
  top 1 accuracy Hybrid 1       :		99.73 %
  top 1 accuracy NCM            :		99.18 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		85.21 %
  top 1 accuracy Hybrid 1       :		85.67 %
  top 1 accuracy NCM            :		85.77 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		92.42 %
  top 1 accuracy Hybrid 1       :		92.51 %
  top 1 accuracy NCM            :		92.70 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		71.24 %
  top 1 accuracy Hybrid 1       :		71.75 %
  top 1 accuracy NCM            :		74.53 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.45 %
  top 1 accuracy Hybrid 1       :		99.76 %
  top 1 accuracy NCM            :		99.14 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		60.01 %
  top 1 accuracy Hybrid 1       :		59.52 %
  top 1 accuracy NCM            :		58.75 %
Binary accuracy:
Final results on wild classes:
  top 1 accuracy iCaRL          :		67.96 %
  top 1 accuracy Hybrid 1       :		67.23 %
  top 1 accuracy NCM            :		67.96 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		66.54 %
  top 1 accuracy Hybrid 1       :		44.50 %
  top 1 accuracy NCM            :		69.81 %
Binary accuracy:
Final results on glow classes:
  top 1 accuracy iCaRL          :		98.29 %
  top 1 accuracy Hybrid 1       :		94.35 %
  top 1 accuracy NCM            :		98.46 %
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		80.21 %
  top 1 accuracy Hybrid 1       :		99.92 %
  top 1 accuracy NCM            :		76.81 %
Binary accuracy:
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		99.75 %
  top 1 accuracy Hybrid 1       :		99.94 %
  top 1 accuracy NCM            :		99.71 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		70.42 %
  top 1 accuracy Hybrid 1       :		69.96 %
  top 1 accuracy NCM            :		70.33 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		92.94 %
  top 1 accuracy Hybrid 1       :		91.99 %
  top 1 accuracy NCM            :		92.96 %
Classes in this batch: tensor([18, 19])
Data Size: 7188


Before first epoch
  validation loss:		0.515627
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 10 arrives ...
0.7435944080352783
0.16077764332294464
0.1115042120218277
Batch of classes 10 out of 12 batches
Epoch 1 of 30 took 185.712s
  training loss:		0.207217
  validation loss:		0.028669
  top 1 accuracy:		90.39 %
  top 2 accuracy:		98.25 %
0.14607372879981995
0.05931849777698517
0.17329025268554688
Batch of classes 10 out of 12 batches
Epoch 2 of 30 took 85.825s
  training loss:		0.097395
  validation loss:		0.020713
  top 1 accuracy:		90.48 %
  top 2 accuracy:		99.16 %
0.07207215577363968
0.0652940422296524
0.087528295814991
Batch of classes 10 out of 12 batches
Epoch 3 of 30 took 85.518s
  training loss:		0.071679
  validation loss:		0.044981
  top 1 accuracy:		81.79 %
  top 2 accuracy:		96.20 %
0.16099196672439575
0.0554245263338089
0.017343370243906975
Batch of classes 10 out of 12 batches
Epoch 4 of 30 took 85.221s
  training loss:		0.061326
  validation loss:		0.012004
  top 1 accuracy:		96.53 %
  top 2 accuracy:		99.42 %
0.04796021431684494
0.04130370914936066
0.1666807383298874
Batch of classes 10 out of 12 batches
Epoch 5 of 30 took 85.797s
  training loss:		0.052028
  validation loss:		0.016572
  top 1 accuracy:		95.07 %
  top 2 accuracy:		98.62 %
0.041917622089385986
0.07056444138288498
0.029569994658231735
Batch of classes 10 out of 12 batches
Epoch 6 of 30 took 84.474s
  training loss:		0.048055
  validation loss:		0.013293
  top 1 accuracy:		95.41 %
  top 2 accuracy:		99.33 %
0.025889458134770393
0.03838755190372467
0.031319424510002136
Batch of classes 10 out of 12 batches
Epoch 7 of 30 took 85.709s
  training loss:		0.045959
  validation loss:		0.012485
  top 1 accuracy:		96.32 %
  top 2 accuracy:		98.75 %
0.024798374623060226
0.022108083590865135
0.09661874920129776
Batch of classes 10 out of 12 batches
Epoch 8 of 30 took 85.026s
  training loss:		0.038762
  validation loss:		0.005881
  top 1 accuracy:		98.66 %
  top 2 accuracy:		99.87 %
0.015468013472855091
0.038828045129776
0.05840478464961052
Batch of classes 10 out of 12 batches
Epoch 9 of 30 took 86.061s
  training loss:		0.039097
  validation loss:		0.009879
  top 1 accuracy:		97.12 %
  top 2 accuracy:		99.08 %
0.02608693391084671
0.012297752313315868
0.05303456634283066
Batch of classes 10 out of 12 batches
Epoch 10 of 30 took 86.052s
  training loss:		0.038689
  validation loss:		0.027190
  top 1 accuracy:		89.18 %
  top 2 accuracy:		98.16 %
0.03974257409572601
0.0435531809926033
0.010667761787772179
Batch of classes 10 out of 12 batches
Epoch 11 of 30 took 86.212s
  training loss:		0.024465
  validation loss:		0.005127
  top 1 accuracy:		99.16 %
  top 2 accuracy:		99.83 %
0.024507079273462296
0.02670179307460785
0.010567933320999146
Batch of classes 10 out of 12 batches
Epoch 12 of 30 took 85.912s
  training loss:		0.016571
  validation loss:		0.004412
  top 1 accuracy:		98.87 %
  top 2 accuracy:		99.87 %
0.007263803388923407
0.005977476481348276
0.011981192976236343
Batch of classes 10 out of 12 batches
Epoch 13 of 30 took 85.643s
  training loss:		0.014190
  validation loss:		0.004200
  top 1 accuracy:		99.08 %
  top 2 accuracy:		99.87 %
0.018706681206822395
0.006061426363885403
0.01010623574256897
Batch of classes 10 out of 12 batches
Epoch 14 of 30 took 86.220s
  training loss:		0.013150
  validation loss:		0.004781
  top 1 accuracy:		98.91 %
  top 2 accuracy:		99.75 %
0.013903721235692501
0.014700080268085003
0.007857182994484901
Batch of classes 10 out of 12 batches
Epoch 15 of 30 took 85.910s
  training loss:		0.011886
  validation loss:		0.003321
  top 1 accuracy:		99.37 %
  top 2 accuracy:		99.96 %
0.01501774787902832
0.003377854824066162
0.006948900409042835
Batch of classes 10 out of 12 batches
Epoch 16 of 30 took 85.739s
  training loss:		0.011811
  validation loss:		0.003373
  top 1 accuracy:		99.25 %
  top 2 accuracy:		100.00 %
0.023144235834479332
0.009457370266318321
0.006553461775183678
Batch of classes 10 out of 12 batches
Epoch 17 of 30 took 85.504s
  training loss:		0.011155
  validation loss:		0.003911
  top 1 accuracy:		99.08 %
  top 2 accuracy:		99.83 %
0.018666859716176987
0.015544045716524124
0.006960178725421429
Batch of classes 10 out of 12 batches
Epoch 18 of 30 took 85.689s
  training loss:		0.010822
  validation loss:		0.003240
  top 1 accuracy:		99.33 %
  top 2 accuracy:		99.79 %
0.006460113450884819
0.008301090449094772
0.016249779611825943
Batch of classes 10 out of 12 batches
Epoch 19 of 30 took 85.935s
  training loss:		0.012559
  validation loss:		0.006227
  top 1 accuracy:		98.33 %
  top 2 accuracy:		99.46 %
0.02903003618121147
0.023077119141817093
0.005621545948088169
Batch of classes 10 out of 12 batches
Epoch 20 of 30 took 85.811s
  training loss:		0.012790
  validation loss:		0.005847
  top 1 accuracy:		98.58 %
  top 2 accuracy:		99.50 %
0.006830975878983736
0.003847964107990265
0.007474393583834171
Batch of classes 10 out of 12 batches
Epoch 21 of 30 took 86.047s
  training loss:		0.008680
  validation loss:		0.003374
  top 1 accuracy:		99.29 %
  top 2 accuracy:		99.83 %
0.006554990075528622
0.009938538074493408
0.005528511945158243
Batch of classes 10 out of 12 batches
Epoch 22 of 30 took 86.035s
  training loss:		0.007263
  validation loss:		0.002848
  top 1 accuracy:		99.37 %
  top 2 accuracy:		99.92 %
0.015233233571052551
0.004316158592700958
0.007258137222379446
Batch of classes 10 out of 12 batches
Epoch 23 of 30 took 86.205s
  training loss:		0.006887
  validation loss:		0.002522
  top 1 accuracy:		99.46 %
  top 2 accuracy:		99.87 %
0.012721431441605091
0.0077443355694413185
0.005244371481239796
Batch of classes 10 out of 12 batches
Epoch 24 of 30 took 86.114s
  training loss:		0.008489
  validation loss:		0.002569
  top 1 accuracy:		99.46 %
  top 2 accuracy:		99.83 %
0.008235294371843338
0.013070781715214252
0.006008622702211142
Batch of classes 10 out of 12 batches
Epoch 25 of 30 took 86.066s
  training loss:		0.006463
  validation loss:		0.003130
  top 1 accuracy:		99.25 %
  top 2 accuracy:		99.79 %
0.00859878771007061
0.005265377461910248
0.004949823021888733
Batch of classes 10 out of 12 batches
Epoch 26 of 30 took 85.649s
  training loss:		0.006298
  validation loss:		0.002447
  top 1 accuracy:		99.33 %
  top 2 accuracy:		99.79 %
0.003217973280698061
0.004132842645049095
0.0028185814153403044
Batch of classes 10 out of 12 batches
Epoch 27 of 30 took 86.113s
  training loss:		0.006651
  validation loss:		0.002387
  top 1 accuracy:		99.46 %
  top 2 accuracy:		99.92 %
0.008701388724148273
0.001647246885113418
0.0032813844736665487
Batch of classes 10 out of 12 batches
Epoch 28 of 30 took 85.233s
  training loss:		0.007072
  validation loss:		0.003012
  top 1 accuracy:		99.33 %
  top 2 accuracy:		99.87 %
0.005105831194669008
0.007176038809120655
0.0018864674493670464
Batch of classes 10 out of 12 batches
Epoch 29 of 30 took 85.062s
  training loss:		0.005535
  validation loss:		0.002444
  top 1 accuracy:		99.25 %
  top 2 accuracy:		99.87 %
0.005671706050634384
0.010918446816504002
0.008282046765089035
Batch of classes 10 out of 12 batches
Epoch 30 of 30 took 85.846s
  training loss:		0.007756
  validation loss:		0.002439
  top 1 accuracy:		99.29 %
  top 2 accuracy:		99.79 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
tensor(77)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		59.10 %
  top 1 accuracy Hybrid 1       :		53.50 %
  top 1 accuracy NCM            :		59.90 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		79.20 %
  top 1 accuracy Hybrid 1       :		78.80 %
  top 1 accuracy NCM            :		79.70 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		42.75 %
  top 1 accuracy Hybrid 1       :		28.12 %
  top 1 accuracy NCM            :		40.75 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		86.25 %
  top 1 accuracy Hybrid 1       :		82.25 %
  top 1 accuracy NCM            :		85.62 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		75.19 %
  top 1 accuracy Hybrid 1       :		79.58 %
  top 1 accuracy NCM            :		77.86 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		93.89 %
  top 1 accuracy Hybrid 1       :		94.08 %
  top 1 accuracy NCM            :		94.08 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		78.17 %
  top 1 accuracy Hybrid 1       :		78.21 %
  top 1 accuracy NCM            :		75.51 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.80 %
  top 1 accuracy Hybrid 1       :		98.51 %
  top 1 accuracy NCM            :		99.80 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		87.99 %
  top 1 accuracy Hybrid 1       :		88.26 %
  top 1 accuracy NCM            :		87.52 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		94.36 %
  top 1 accuracy Hybrid 1       :		94.55 %
  top 1 accuracy NCM            :		94.27 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		71.51 %
  top 1 accuracy Hybrid 1       :		70.06 %
  top 1 accuracy NCM            :		74.14 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.80 %
  top 1 accuracy Hybrid 1       :		98.51 %
  top 1 accuracy NCM            :		99.80 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		62.19 %
  top 1 accuracy Hybrid 1       :		60.20 %
  top 1 accuracy NCM            :		62.34 %
Binary accuracy:
Final results on wild classes:
  top 1 accuracy iCaRL          :		66.84 %
  top 1 accuracy Hybrid 1       :		67.23 %
  top 1 accuracy NCM            :		66.99 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		81.21 %
  top 1 accuracy Hybrid 1       :		87.35 %
  top 1 accuracy NCM            :		68.96 %
Binary accuracy:
Final results on glow classes:
  top 1 accuracy iCaRL          :		98.08 %
  top 1 accuracy Hybrid 1       :		97.96 %
  top 1 accuracy NCM            :		98.12 %
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		64.92 %
  top 1 accuracy Hybrid 1       :		56.88 %
  top 1 accuracy NCM            :		78.10 %
Binary accuracy:
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		98.44 %
  top 1 accuracy Hybrid 1       :		98.27 %
  top 1 accuracy NCM            :		98.40 %
Final results on stylegan classes:
  top 1 accuracy iCaRL          :		96.78 %
  top 1 accuracy Hybrid 1       :		99.29 %
  top 1 accuracy NCM            :		96.83 %
Binary accuracy:
Final results on stylegan classes:
  top 1 accuracy iCaRL          :		99.62 %
  top 1 accuracy Hybrid 1       :		99.79 %
  top 1 accuracy NCM            :		99.58 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		73.42 %
  top 1 accuracy Hybrid 1       :		72.11 %
  top 1 accuracy NCM            :		73.67 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		93.68 %
  top 1 accuracy Hybrid 1       :		93.24 %
  top 1 accuracy NCM            :		93.71 %
Classes in this batch: tensor([20, 21])
Data Size: 1200


Before first epoch
  validation loss:		0.462408
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 11 arrives ...
0.49517136812210083
Batch of classes 11 out of 12 batches
Epoch 1 of 30 took 77.621s
  training loss:		0.236130
  validation loss:		0.088280
  top 1 accuracy:		48.50 %
  top 2 accuracy:		85.00 %
0.15846960246562958
Batch of classes 11 out of 12 batches
Epoch 2 of 30 took 49.574s
  training loss:		0.129340
  validation loss:		0.055433
  top 1 accuracy:		78.25 %
  top 2 accuracy:		96.25 %
0.1305863857269287
Batch of classes 11 out of 12 batches
Epoch 3 of 30 took 50.502s
  training loss:		0.117829
  validation loss:		0.060673
  top 1 accuracy:		73.00 %
  top 2 accuracy:		95.50 %
0.1404670625925064
Batch of classes 11 out of 12 batches
Epoch 4 of 30 took 49.709s
  training loss:		0.098863
  validation loss:		0.037485
  top 1 accuracy:		87.50 %
  top 2 accuracy:		98.50 %
0.07435251772403717
Batch of classes 11 out of 12 batches
Epoch 5 of 30 took 48.704s
  training loss:		0.088927
  validation loss:		0.035983
  top 1 accuracy:		87.00 %
  top 2 accuracy:		99.00 %
0.047695375978946686
Batch of classes 11 out of 12 batches
Epoch 6 of 30 took 48.851s
  training loss:		0.083017
  validation loss:		0.034027
  top 1 accuracy:		85.75 %
  top 2 accuracy:		98.25 %
0.05301676690578461
Batch of classes 11 out of 12 batches
Epoch 7 of 30 took 49.543s
  training loss:		0.079757
  validation loss:		0.051555
  top 1 accuracy:		75.50 %
  top 2 accuracy:		94.25 %
0.05263712257146835
Batch of classes 11 out of 12 batches
Epoch 8 of 30 took 49.788s
  training loss:		0.076367
  validation loss:		0.026236
  top 1 accuracy:		90.75 %
  top 2 accuracy:		99.00 %
0.13488832116127014
Batch of classes 11 out of 12 batches
Epoch 9 of 30 took 49.768s
  training loss:		0.068294
  validation loss:		0.028609
  top 1 accuracy:		88.00 %
  top 2 accuracy:		99.00 %
0.06216251850128174
Batch of classes 11 out of 12 batches
Epoch 10 of 30 took 49.025s
  training loss:		0.063496
  validation loss:		0.030053
  top 1 accuracy:		87.75 %
  top 2 accuracy:		99.00 %
0.061036303639411926
Batch of classes 11 out of 12 batches
Epoch 11 of 30 took 49.574s
  training loss:		0.049150
  validation loss:		0.021434
  top 1 accuracy:		91.00 %
  top 2 accuracy:		99.75 %
0.025282692164182663
Batch of classes 11 out of 12 batches
Epoch 12 of 30 took 49.428s
  training loss:		0.042282
  validation loss:		0.015952
  top 1 accuracy:		94.75 %
  top 2 accuracy:		99.75 %
0.024382183328270912
Batch of classes 11 out of 12 batches
Epoch 13 of 30 took 49.776s
  training loss:		0.036097
  validation loss:		0.019319
  top 1 accuracy:		92.50 %
  top 2 accuracy:		99.50 %
0.015791412442922592
Batch of classes 11 out of 12 batches
Epoch 14 of 30 took 49.830s
  training loss:		0.038689
  validation loss:		0.025821
  top 1 accuracy:		89.00 %
  top 2 accuracy:		99.50 %
0.026746142655611038
Batch of classes 11 out of 12 batches
Epoch 15 of 30 took 50.014s
  training loss:		0.036747
  validation loss:		0.017109
  top 1 accuracy:		95.75 %
  top 2 accuracy:		100.00 %
0.018465865403413773
Batch of classes 11 out of 12 batches
Epoch 16 of 30 took 50.498s
  training loss:		0.034669
  validation loss:		0.017595
  top 1 accuracy:		94.25 %
  top 2 accuracy:		99.25 %
0.05621626228094101
Batch of classes 11 out of 12 batches
Epoch 17 of 30 took 49.505s
  training loss:		0.031745
  validation loss:		0.015967
  top 1 accuracy:		94.50 %
  top 2 accuracy:		99.75 %
0.02993478998541832
Batch of classes 11 out of 12 batches
Epoch 18 of 30 took 50.277s
  training loss:		0.028776
  validation loss:		0.017257
  top 1 accuracy:		94.75 %
  top 2 accuracy:		100.00 %
0.03555876016616821
Batch of classes 11 out of 12 batches
Epoch 19 of 30 took 50.151s
  training loss:		0.032298
  validation loss:		0.012189
  top 1 accuracy:		94.75 %
  top 2 accuracy:		100.00 %
0.01367170363664627
Batch of classes 11 out of 12 batches
Epoch 20 of 30 took 50.140s
  training loss:		0.025458
  validation loss:		0.016136
  top 1 accuracy:		94.75 %
  top 2 accuracy:		100.00 %
0.024314336478710175
Batch of classes 11 out of 12 batches
Epoch 21 of 30 took 50.825s
  training loss:		0.023554
  validation loss:		0.014320
  top 1 accuracy:		94.75 %
  top 2 accuracy:		100.00 %
0.0195171982049942
Batch of classes 11 out of 12 batches
Epoch 22 of 30 took 50.142s
  training loss:		0.021824
  validation loss:		0.013197
  top 1 accuracy:		95.25 %
  top 2 accuracy:		99.50 %
0.023567557334899902
Batch of classes 11 out of 12 batches
Epoch 23 of 30 took 49.255s
  training loss:		0.022661
  validation loss:		0.011785
  top 1 accuracy:		95.25 %
  top 2 accuracy:		100.00 %
0.023074068129062653
Batch of classes 11 out of 12 batches
Epoch 24 of 30 took 49.748s
  training loss:		0.020851
  validation loss:		0.013711
  top 1 accuracy:		95.25 %
  top 2 accuracy:		99.50 %
0.019142065197229385
Batch of classes 11 out of 12 batches
Epoch 25 of 30 took 49.824s
  training loss:		0.021378
  validation loss:		0.012510
  top 1 accuracy:		94.75 %
  top 2 accuracy:		99.75 %
0.038597624748945236
Batch of classes 11 out of 12 batches
Epoch 26 of 30 took 49.160s
  training loss:		0.022932
  validation loss:		0.014540
  top 1 accuracy:		95.00 %
  top 2 accuracy:		99.75 %
0.028156913816928864
Batch of classes 11 out of 12 batches
Epoch 27 of 30 took 49.699s
  training loss:		0.020709
  validation loss:		0.013668
  top 1 accuracy:		95.50 %
  top 2 accuracy:		99.75 %
0.04054277390241623
Batch of classes 11 out of 12 batches
Epoch 28 of 30 took 50.183s
  training loss:		0.022754
  validation loss:		0.013825
  top 1 accuracy:		95.75 %
  top 2 accuracy:		99.75 %
0.013262128457427025
Batch of classes 11 out of 12 batches
Epoch 29 of 30 took 49.790s
  training loss:		0.023173
  validation loss:		0.012391
  top 1 accuracy:		96.25 %
  top 2 accuracy:		100.00 %
0.06825223565101624
Batch of classes 11 out of 12 batches
Epoch 30 of 30 took 50.268s
  training loss:		0.020238
  validation loss:		0.011747
  top 1 accuracy:		95.25 %
  top 2 accuracy:		100.00 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
tensor(70)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		63.40 %
  top 1 accuracy Hybrid 1       :		60.30 %
  top 1 accuracy NCM            :		63.20 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		84.55 %
  top 1 accuracy Hybrid 1       :		84.35 %
  top 1 accuracy NCM            :		84.60 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		45.12 %
  top 1 accuracy Hybrid 1       :		45.12 %
  top 1 accuracy NCM            :		44.62 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		86.38 %
  top 1 accuracy Hybrid 1       :		87.50 %
  top 1 accuracy NCM            :		86.62 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		77.86 %
  top 1 accuracy Hybrid 1       :		84.35 %
  top 1 accuracy NCM            :		80.15 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		94.27 %
  top 1 accuracy Hybrid 1       :		94.66 %
  top 1 accuracy NCM            :		94.27 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		77.86 %
  top 1 accuracy Hybrid 1       :		88.87 %
  top 1 accuracy NCM            :		73.67 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.69 %
  top 1 accuracy Hybrid 1       :		99.80 %
  top 1 accuracy NCM            :		99.69 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		89.09 %
  top 1 accuracy Hybrid 1       :		91.40 %
  top 1 accuracy NCM            :		89.19 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		94.64 %
  top 1 accuracy Hybrid 1       :		95.38 %
  top 1 accuracy NCM            :		94.55 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		71.32 %
  top 1 accuracy Hybrid 1       :		60.82 %
  top 1 accuracy NCM            :		75.59 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.76 %
  top 1 accuracy Hybrid 1       :		99.84 %
  top 1 accuracy NCM            :		99.76 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		63.31 %
  top 1 accuracy Hybrid 1       :		60.49 %
  top 1 accuracy NCM            :		63.69 %
Binary accuracy:
Final results on wild classes:
  top 1 accuracy iCaRL          :		66.80 %
  top 1 accuracy Hybrid 1       :		65.97 %
  top 1 accuracy NCM            :		67.38 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		75.29 %
  top 1 accuracy Hybrid 1       :		70.44 %
  top 1 accuracy NCM            :		72.81 %
Binary accuracy:
Final results on glow classes:
  top 1 accuracy iCaRL          :		98.23 %
  top 1 accuracy Hybrid 1       :		97.21 %
  top 1 accuracy NCM            :		98.31 %
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		71.35 %
  top 1 accuracy Hybrid 1       :		73.48 %
  top 1 accuracy NCM            :		73.83 %
Binary accuracy:
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		98.08 %
  top 1 accuracy Hybrid 1       :		97.10 %
  top 1 accuracy NCM            :		98.15 %
Final results on stylegan classes:
  top 1 accuracy iCaRL          :		89.35 %
  top 1 accuracy Hybrid 1       :		87.18 %
  top 1 accuracy NCM            :		90.14 %
Binary accuracy:
Final results on stylegan classes:
  top 1 accuracy iCaRL          :		94.78 %
  top 1 accuracy Hybrid 1       :		94.28 %
  top 1 accuracy NCM            :		94.95 %
Final results on whichfaceisreal classes:
  top 1 accuracy iCaRL          :		95.00 %
  top 1 accuracy Hybrid 1       :		95.25 %
  top 1 accuracy NCM            :		95.00 %
Binary accuracy:
Final results on whichfaceisreal classes:
  top 1 accuracy iCaRL          :		95.25 %
  top 1 accuracy Hybrid 1       :		95.25 %
  top 1 accuracy NCM            :		95.25 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		73.73 %
  top 1 accuracy Hybrid 1       :		72.78 %
  top 1 accuracy NCM            :		73.88 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		93.63 %
  top 1 accuracy Hybrid 1       :		93.19 %
  top 1 accuracy NCM            :		93.74 %
Classes in this batch: tensor([22, 23])
Data Size: 260


Before first epoch
  validation loss:		0.811354
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 12 arrives ...
0.2435721755027771
Batch of classes 12 out of 12 batches
Epoch 1 of 30 took 20.663s
  training loss:		0.184098
  validation loss:		0.204384
  top 1 accuracy:		1.11 %
  top 2 accuracy:		14.44 %
0.08221504837274551
Batch of classes 12 out of 12 batches
Epoch 2 of 30 took 20.586s
  training loss:		0.101682
  validation loss:		0.212099
  top 1 accuracy:		3.33 %
  top 2 accuracy:		23.33 %
0.06246122717857361
Batch of classes 12 out of 12 batches
Epoch 3 of 30 took 20.526s
  training loss:		0.086766
  validation loss:		0.178700
  top 1 accuracy:		11.11 %
  top 2 accuracy:		37.78 %
0.058049559593200684
Batch of classes 12 out of 12 batches
Epoch 4 of 30 took 20.282s
  training loss:		0.086975
  validation loss:		0.293476
  top 1 accuracy:		21.11 %
  top 2 accuracy:		42.22 %
0.04787493124604225
Batch of classes 12 out of 12 batches
Epoch 5 of 30 took 20.168s
  training loss:		0.081206
  validation loss:		0.178653
  top 1 accuracy:		11.11 %
  top 2 accuracy:		26.67 %
0.06792560964822769
Batch of classes 12 out of 12 batches
Epoch 6 of 30 took 20.642s
  training loss:		0.070793
  validation loss:		0.182931
  top 1 accuracy:		27.78 %
  top 2 accuracy:		47.78 %
0.040827881544828415
Batch of classes 12 out of 12 batches
Epoch 7 of 30 took 20.692s
  training loss:		0.071261
  validation loss:		0.147014
  top 1 accuracy:		35.56 %
  top 2 accuracy:		54.44 %
0.04530071094632149
Batch of classes 12 out of 12 batches
Epoch 8 of 30 took 20.559s
  training loss:		0.085486
  validation loss:		0.152093
  top 1 accuracy:		32.22 %
  top 2 accuracy:		54.44 %
0.0489090196788311
Batch of classes 12 out of 12 batches
Epoch 9 of 30 took 20.124s
  training loss:		0.065093
  validation loss:		0.145791
  top 1 accuracy:		28.89 %
  top 2 accuracy:		53.33 %
0.07631958276033401
Batch of classes 12 out of 12 batches
Epoch 10 of 30 took 20.783s
  training loss:		0.059765
  validation loss:		0.133637
  top 1 accuracy:		34.44 %
  top 2 accuracy:		62.22 %
0.054857973009347916
Batch of classes 12 out of 12 batches
Epoch 11 of 30 took 20.551s
  training loss:		0.044140
  validation loss:		0.108741
  top 1 accuracy:		51.11 %
  top 2 accuracy:		73.33 %
0.02306274138391018
Batch of classes 12 out of 12 batches
Epoch 12 of 30 took 20.612s
  training loss:		0.040347
  validation loss:		0.114849
  top 1 accuracy:		46.67 %
  top 2 accuracy:		70.00 %
0.0271778367459774
Batch of classes 12 out of 12 batches
Epoch 13 of 30 took 20.622s
  training loss:		0.039066
  validation loss:		0.127476
  top 1 accuracy:		48.89 %
  top 2 accuracy:		65.56 %
0.020630981773138046
Batch of classes 12 out of 12 batches
Epoch 14 of 30 took 20.426s
  training loss:		0.031461
  validation loss:		0.132781
  top 1 accuracy:		37.78 %
  top 2 accuracy:		64.44 %
0.04050964489579201
Batch of classes 12 out of 12 batches
Epoch 15 of 30 took 20.459s
  training loss:		0.034518
  validation loss:		0.119384
  top 1 accuracy:		47.78 %
  top 2 accuracy:		73.33 %
0.027329642325639725
Batch of classes 12 out of 12 batches
Epoch 16 of 30 took 20.734s
  training loss:		0.038357
  validation loss:		0.128917
  top 1 accuracy:		44.44 %
  top 2 accuracy:		62.22 %
0.023472044616937637
Batch of classes 12 out of 12 batches
Epoch 17 of 30 took 20.330s
  training loss:		0.036511
  validation loss:		0.127225
  top 1 accuracy:		40.00 %
  top 2 accuracy:		68.89 %
0.02209518477320671
Batch of classes 12 out of 12 batches
Epoch 18 of 30 took 20.606s
  training loss:		0.031447
  validation loss:		0.132249
  top 1 accuracy:		40.00 %
  top 2 accuracy:		61.11 %
0.023202676326036453
Batch of classes 12 out of 12 batches
Epoch 19 of 30 took 20.582s
  training loss:		0.034999
  validation loss:		0.120623
  top 1 accuracy:		45.56 %
  top 2 accuracy:		67.78 %
0.028149597346782684
Batch of classes 12 out of 12 batches
Epoch 20 of 30 took 19.997s
  training loss:		0.036485
  validation loss:		0.127257
  top 1 accuracy:		44.44 %
  top 2 accuracy:		70.00 %
0.022039217874407768
Batch of classes 12 out of 12 batches
Epoch 21 of 30 took 20.298s
  training loss:		0.031461
  validation loss:		0.121374
  top 1 accuracy:		44.44 %
  top 2 accuracy:		75.56 %
0.01929725892841816
Batch of classes 12 out of 12 batches
Epoch 22 of 30 took 20.140s
  training loss:		0.029905
  validation loss:		0.116482
  top 1 accuracy:		48.89 %
  top 2 accuracy:		73.33 %
0.020743345841765404
Batch of classes 12 out of 12 batches
Epoch 23 of 30 took 20.408s
  training loss:		0.034792
  validation loss:		0.115692
  top 1 accuracy:		48.89 %
  top 2 accuracy:		76.67 %
0.03607115149497986
Batch of classes 12 out of 12 batches
Epoch 24 of 30 took 20.385s
  training loss:		0.029276
  validation loss:		0.111533
  top 1 accuracy:		46.67 %
  top 2 accuracy:		76.67 %
0.020337507128715515
Batch of classes 12 out of 12 batches
Epoch 25 of 30 took 20.141s
  training loss:		0.025953
  validation loss:		0.133047
  top 1 accuracy:		37.78 %
  top 2 accuracy:		68.89 %
0.04855290800333023
Batch of classes 12 out of 12 batches
Epoch 26 of 30 took 20.153s
  training loss:		0.027957
  validation loss:		0.122091
  top 1 accuracy:		45.56 %
  top 2 accuracy:		74.44 %
0.009421389549970627
Batch of classes 12 out of 12 batches
Epoch 27 of 30 took 20.689s
  training loss:		0.027154
  validation loss:		0.133781
  top 1 accuracy:		43.33 %
  top 2 accuracy:		72.22 %
0.029425524175167084
Batch of classes 12 out of 12 batches
Epoch 28 of 30 took 20.426s
  training loss:		0.028990
  validation loss:		0.123597
  top 1 accuracy:		46.67 %
  top 2 accuracy:		76.67 %
0.017487037926912308
Batch of classes 12 out of 12 batches
Epoch 29 of 30 took 20.247s
  training loss:		0.027526
  validation loss:		0.124205
  top 1 accuracy:		43.33 %
  top 2 accuracy:		75.56 %
0.020281028002500534
Batch of classes 12 out of 12 batches
Epoch 30 of 30 took 20.165s
  training loss:		0.028821
  validation loss:		0.118137
  top 1 accuracy:		45.56 %
  top 2 accuracy:		74.44 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
tensor(64)
Computing accuracy on the original batch of classes...
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		62.45 %
  top 1 accuracy Hybrid 1       :		58.70 %
  top 1 accuracy NCM            :		61.05 %
Binary accuracy:
Final results on gaugan classes:
  top 1 accuracy iCaRL          :		83.10 %
  top 1 accuracy Hybrid 1       :		82.45 %
  top 1 accuracy NCM            :		82.90 %
Final results on biggan classes:
  top 1 accuracy iCaRL          :		38.62 %
  top 1 accuracy Hybrid 1       :		36.88 %
  top 1 accuracy NCM            :		39.88 %
Binary accuracy:
Final results on biggan classes:
  top 1 accuracy iCaRL          :		84.38 %
  top 1 accuracy Hybrid 1       :		83.62 %
  top 1 accuracy NCM            :		83.50 %
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		79.20 %
  top 1 accuracy Hybrid 1       :		84.73 %
  top 1 accuracy NCM            :		81.87 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		94.66 %
  top 1 accuracy Hybrid 1       :		95.99 %
  top 1 accuracy NCM            :		95.04 %
Final results on imle classes:
  top 1 accuracy iCaRL          :		73.94 %
  top 1 accuracy Hybrid 1       :		73.59 %
  top 1 accuracy NCM            :		73.82 %
Binary accuracy:
Final results on imle classes:
  top 1 accuracy iCaRL          :		99.49 %
  top 1 accuracy Hybrid 1       :		99.26 %
  top 1 accuracy NCM            :		99.45 %
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		89.00 %
  top 1 accuracy Hybrid 1       :		89.46 %
  top 1 accuracy NCM            :		89.65 %
Binary accuracy:
Final results on deepfake classes:
  top 1 accuracy iCaRL          :		95.01 %
  top 1 accuracy Hybrid 1       :		93.81 %
  top 1 accuracy NCM            :		94.82 %
Final results on crn classes:
  top 1 accuracy iCaRL          :		74.53 %
  top 1 accuracy Hybrid 1       :		74.96 %
  top 1 accuracy NCM            :		74.33 %
Binary accuracy:
Final results on crn classes:
  top 1 accuracy iCaRL          :		99.53 %
  top 1 accuracy Hybrid 1       :		99.26 %
  top 1 accuracy NCM            :		99.49 %
Final results on wild classes:
  top 1 accuracy iCaRL          :		62.63 %
  top 1 accuracy Hybrid 1       :		60.40 %
  top 1 accuracy NCM            :		63.11 %
Binary accuracy:
Final results on wild classes:
  top 1 accuracy iCaRL          :		66.26 %
  top 1 accuracy Hybrid 1       :		66.26 %
  top 1 accuracy NCM            :		67.62 %
Final results on glow classes:
  top 1 accuracy iCaRL          :		74.65 %
  top 1 accuracy Hybrid 1       :		71.69 %
  top 1 accuracy NCM            :		76.73 %
Binary accuracy:
Final results on glow classes:
  top 1 accuracy iCaRL          :		98.65 %
  top 1 accuracy Hybrid 1       :		98.15 %
  top 1 accuracy NCM            :		98.58 %
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		71.06 %
  top 1 accuracy Hybrid 1       :		74.23 %
  top 1 accuracy NCM            :		70.88 %
Binary accuracy:
Final results on stargan_gf classes:
  top 1 accuracy iCaRL          :		98.73 %
  top 1 accuracy Hybrid 1       :		98.29 %
  top 1 accuracy NCM            :		98.58 %
Final results on stylegan classes:
  top 1 accuracy iCaRL          :		88.81 %
  top 1 accuracy Hybrid 1       :		86.68 %
  top 1 accuracy NCM            :		89.77 %
Binary accuracy:
Final results on stylegan classes:
  top 1 accuracy iCaRL          :		94.15 %
  top 1 accuracy Hybrid 1       :		93.69 %
  top 1 accuracy NCM            :		94.78 %
Final results on whichfaceisreal classes:
  top 1 accuracy iCaRL          :		89.00 %
  top 1 accuracy Hybrid 1       :		89.25 %
  top 1 accuracy NCM            :		89.00 %
Binary accuracy:
Final results on whichfaceisreal classes:
  top 1 accuracy iCaRL          :		90.00 %
  top 1 accuracy Hybrid 1       :		90.00 %
  top 1 accuracy NCM            :		90.00 %
Final results on san classes:
  top 1 accuracy iCaRL          :		38.89 %
  top 1 accuracy Hybrid 1       :		45.56 %
  top 1 accuracy NCM            :		40.00 %
Binary accuracy:
Final results on san classes:
  top 1 accuracy iCaRL          :		63.33 %
  top 1 accuracy Hybrid 1       :		63.33 %
  top 1 accuracy NCM            :		63.33 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		72.86 %
  top 1 accuracy Hybrid 1       :		72.31 %
  top 1 accuracy NCM            :		73.36 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		93.33 %
  top 1 accuracy Hybrid 1       :		92.94 %
  top 1 accuracy NCM            :		93.41 %
tensor([[[ 99.7000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 99.1000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 99.7000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 96.9000,  99.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 95.5500,  99.1250,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 97.1500,  98.8750,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 96.1500,  95.2500,  97.1374,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 95.9000,  94.1250,  97.1374,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 96.2500,  95.6250,  97.1374,   0.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 91.4000,  94.1250,  94.0840, 100.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 91.0000,  94.3750,  95.2290, 100.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 91.7000,  94.1250,  94.2748, 100.0000,   0.0000,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 66.0000,  69.3750,  78.2443,  97.1003,  89.5564,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 64.6000,  71.8750,  77.8626,  98.0016,  90.1109,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 66.3500,  70.2500,  79.5802,  97.2962,  89.4640,   0.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 70.5500,  76.5000,  84.5420,  99.8041,  76.1553,  99.8824,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 65.5000,  75.2500,  87.2137,  99.7257,  75.4159, 100.0000,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 71.1000,  76.8750,  84.9237,  99.8041,  76.1553,  99.8824,   0.0000,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 74.1000,  78.2500,  86.4504,  99.5690,  88.0776,  99.4122,  77.4600,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 73.8500,  78.5000,  86.6412,  99.7649,  85.6747,  99.7257,  77.2176,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 74.3500,  79.2500,  86.4504,  99.5690,  88.3549,  99.3730,  77.5085,
            0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 73.9500,  79.2500,  90.8397,  99.4906,  92.5139,  99.4514,  72.7581,
           99.6042,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 75.2000,  77.8750,  90.8397,  99.1379,  92.9760,  99.1379,  72.5158,
           99.3750,   0.0000,   0.0000,   0.0000,   0.0000],
         [ 73.8500,  79.1250,  90.2672,  99.4514,  92.5139,  99.4122,  73.1944,
           99.6042,   0.0000,   0.0000,   0.0000,   0.0000]],

        [[ 79.2000,  79.6250,  90.2672,  99.4514,  92.4214,  99.4514,  67.9593,
           98.2917,  99.7500,   0.0000,   0.0000,   0.0000],
         [ 78.3000,  78.8750,  90.4580,  99.7257,  92.5139,  99.7649,  67.2322,
           94.3542,  99.9375,   0.0000,   0.0000,   0.0000],
         [ 79.5000,  79.7500,  90.8397,  99.1771,  92.6987,  99.1379,  67.9593,
           98.4583,  99.7083,   0.0000,   0.0000,   0.0000]],

        [[ 79.2000,  86.2500,  93.8931,  99.8041,  94.3623,  99.8041,  66.8444,
           98.0833,  98.4375,  99.6241,   0.0000,   0.0000],
         [ 78.8000,  82.2500,  94.0840,  98.5110,  94.5471,  98.5110,  67.2322,
           97.9583,  98.2708,  99.7911,   0.0000,   0.0000],
         [ 79.7000,  85.6250,  94.0840,  99.8041,  94.2699,  99.8041,  66.9898,
           98.1250,  98.3958,  99.5823,   0.0000,   0.0000]],

        [[ 84.5500,  86.3750,  94.2748,  99.6865,  94.6396,  99.7649,  66.7959,
           98.2292,  98.0833,  94.7786,  95.2500,   0.0000],
         [ 84.3500,  87.5000,  94.6565,  99.8041,  95.3789,  99.8433,  65.9719,
           97.2083,  97.1042,  94.2774,  95.2500,   0.0000],
         [ 84.6000,  86.6250,  94.2748,  99.6865,  94.5471,  99.7649,  67.3776,
           98.3125,  98.1458,  94.9457,  95.2500,   0.0000]],

        [[ 83.1000,  84.3750,  94.6565,  99.4906,  95.0092,  99.5298,  66.2627,
           98.6458,  98.7292,  94.1520,  90.0000,  63.3333],
         [ 82.4500,  83.6250,  95.9924,  99.2555,  93.8078,  99.2555,  66.2627,
           98.1458,  98.2917,  93.6926,  90.0000,  63.3333],
         [ 82.9000,  83.5000,  95.0382,  99.4514,  94.8244,  99.4906,  67.6200,
           98.5833,  98.5833,  94.7786,  90.0000,  63.3333]]])
tensor([88.9404, 88.6760, 89.0086])
