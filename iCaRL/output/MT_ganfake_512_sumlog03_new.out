----------------- Options ---------------
               add_binary: True                          	[default: False]
               batch_size: 32                            	[default: 64]
                   binary: False                         
              binary_loss: sum_b_log                     	[default: sum_b_sig]
            binary_weight: 0.3                           	[default: 0.5]
                blur_prob: 0                             
                 blur_sig: 0.5                           
          checkpoints_dir: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL/checkpoints	[default: ./checkpoints]
                class_bal: False                         
           continue_train: False                         
                 cropSize: 224                           
                 data_aug: False                         
                 dataroot: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/DoGAN_data/new/GanFake	[default: /srv/beegfs02/scratch/generative_modeling/data/Deepfake/Adam-NSCL]
          earlystop_epoch: 5                             
                    epoch: latest                        
                 fine_tun: False                         
                    gpuid: [1]                           
                init_gain: 0.02                          
                  init_lr: 0.001                         	[default: 0.0005]
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2                           
                 jpg_prob: 0                             
                 jpg_qual: 75                            
          label_smoothing: False                         
                 loadSize: 256                           
                    mixup: False                         
              mixup_alpha: 0.1                           
                     mode: binary                        
               model_name: resnet18                      
               model_type: resnet                        
            model_weights: None                          
               multiclass: [1, 1, 0, 1, 1]               	[default: [1]]
                     name: icarl_ganfake_512_sum_log03   	[default: experiment_name]
                nb_protos: 512                           	[default: 1536]
                  no_flip: False                         
              num_classes: 2                             
               num_epochs: 60                            	[default: 12]
              num_threads: 4                             
                  outfile: temp_0.1.csv                  
            pretrain_name:                               
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 20                            
         save_latest_freq: 2000                          
                 schedule: [20, 40, 60]                  	[default: [10]]
           serial_batches: False                         
          smoothing_alpha: 0.1                           
                   suffix:                               
                task_name: cyclegan,progan256,progan1024,glow,stargan	[default: ]
              train_split: train                         
                val_split: val                           
----------------- End -------------------
{'All': 10}
Task order: ['cyclegan', 'progan256', 'progan1024', 'glow', 'stargan']
Classes in this batch: tensor([0, 1])
Data Size: 7196


Before first epoch
  validation loss:		0.651198
  top 1 accuracy:		41.60 %
  top 2 accuracy:		55.37 %
Batch of classes number 1 arrives ...
0.4120612144470215
0.20237818360328674
0.19505846500396729
Batch of classes 1 out of 5 batches
Epoch 1 of 60 took 240.210s
  training loss:		0.207493
  validation loss:		0.164112
  top 1 accuracy:		71.48 %
  top 2 accuracy:		100.00 %
0.1960219293832779
0.22203052043914795
0.22858789563179016
Batch of classes 1 out of 5 batches
Epoch 2 of 60 took 214.640s
  training loss:		0.191767
  validation loss:		0.154269
  top 1 accuracy:		74.79 %
  top 2 accuracy:		100.00 %
0.19265520572662354
0.19792453944683075
0.18389835953712463
Batch of classes 1 out of 5 batches
Epoch 3 of 60 took 222.535s
  training loss:		0.184879
  validation loss:		0.103248
  top 1 accuracy:		76.23 %
  top 2 accuracy:		100.00 %
0.18886250257492065
0.17119568586349487
0.16437336802482605
Batch of classes 1 out of 5 batches
Epoch 4 of 60 took 238.321s
  training loss:		0.180864
  validation loss:		0.113151
  top 1 accuracy:		75.48 %
  top 2 accuracy:		100.00 %
0.16561473906040192
0.17619411647319794
0.18284441530704498
Batch of classes 1 out of 5 batches
Epoch 5 of 60 took 242.656s
  training loss:		0.175067
  validation loss:		0.173681
  top 1 accuracy:		76.94 %
  top 2 accuracy:		100.00 %
0.17147931456565857
0.17725840210914612
0.1694948673248291
Batch of classes 1 out of 5 batches
Epoch 6 of 60 took 236.553s
  training loss:		0.168637
  validation loss:		0.298490
  top 1 accuracy:		72.87 %
  top 2 accuracy:		100.00 %
0.16128741204738617
0.15928274393081665
0.14814865589141846
Batch of classes 1 out of 5 batches
Epoch 7 of 60 took 244.671s
  training loss:		0.166631
  validation loss:		0.113743
  top 1 accuracy:		77.94 %
  top 2 accuracy:		100.00 %
0.15494778752326965
0.15704961121082306
0.14597786962985992
Batch of classes 1 out of 5 batches
Epoch 8 of 60 took 250.797s
  training loss:		0.159866
  validation loss:		0.468497
  top 1 accuracy:		74.33 %
  top 2 accuracy:		97.00 %
0.15863588452339172
0.14652924239635468
0.1483840048313141
Batch of classes 1 out of 5 batches
Epoch 9 of 60 took 250.010s
  training loss:		0.159936
  validation loss:		0.099005
  top 1 accuracy:		82.08 %
  top 2 accuracy:		100.00 %
0.15141473710536957
0.15285274386405945
0.14249108731746674
Batch of classes 1 out of 5 batches
Epoch 10 of 60 took 248.860s
  training loss:		0.156348
  validation loss:		0.245039
  top 1 accuracy:		74.94 %
  top 2 accuracy:		99.94 %
0.16897760331630707
0.14583466947078705
0.1775120198726654
Batch of classes 1 out of 5 batches
Epoch 11 of 60 took 235.439s
  training loss:		0.156406
  validation loss:		0.334459
  top 1 accuracy:		75.35 %
  top 2 accuracy:		98.21 %
0.197259783744812
0.14960788190364838
0.14927612245082855
Batch of classes 1 out of 5 batches
Epoch 12 of 60 took 235.753s
  training loss:		0.154810
  validation loss:		0.093058
  top 1 accuracy:		78.23 %
  top 2 accuracy:		100.00 %
0.1562615931034088
0.14788396656513214
0.14513708651065826
Batch of classes 1 out of 5 batches
Epoch 13 of 60 took 199.539s
  training loss:		0.154208
  validation loss:		0.044507
  top 1 accuracy:		91.60 %
  top 2 accuracy:		100.00 %
0.14187337458133698
0.1403525024652481
0.18181926012039185
Batch of classes 1 out of 5 batches
Epoch 14 of 60 took 183.138s
  training loss:		0.154915
  validation loss:		0.155901
  top 1 accuracy:		75.98 %
  top 2 accuracy:		100.00 %
0.14271686971187592
0.1487974226474762
0.14731955528259277
Batch of classes 1 out of 5 batches
Epoch 15 of 60 took 179.362s
  training loss:		0.153468
  validation loss:		0.429556
  top 1 accuracy:		74.65 %
  top 2 accuracy:		98.79 %
0.15008701384067535
0.14232659339904785
0.16154845058918
Batch of classes 1 out of 5 batches
Epoch 16 of 60 took 161.853s
  training loss:		0.150848
  validation loss:		0.403727
  top 1 accuracy:		74.96 %
  top 2 accuracy:		99.58 %
0.15375128388404846
0.14444907009601593
0.14195266366004944
Batch of classes 1 out of 5 batches
Epoch 17 of 60 took 171.627s
  training loss:		0.149638
  validation loss:		0.202168
  top 1 accuracy:		74.44 %
  top 2 accuracy:		100.00 %
0.16722415387630463
0.14844341576099396
0.1562718003988266
Batch of classes 1 out of 5 batches
Epoch 18 of 60 took 159.209s
  training loss:		0.154395
  validation loss:		0.272094
  top 1 accuracy:		75.15 %
  top 2 accuracy:		99.98 %
0.15552186965942383
0.1496221125125885
0.14166173338890076
Batch of classes 1 out of 5 batches
Epoch 19 of 60 took 159.620s
  training loss:		0.150036
  validation loss:		0.312898
  top 1 accuracy:		74.75 %
  top 2 accuracy:		100.00 %
0.17355909943580627
0.14561665058135986
0.14038987457752228
Batch of classes 1 out of 5 batches
Epoch 20 of 60 took 146.113s
  training loss:		0.149968
  validation loss:		0.277548
  top 1 accuracy:		75.90 %
  top 2 accuracy:		99.90 %
0.1536550670862198
0.14236463606357574
0.1427536904811859
Batch of classes 1 out of 5 batches
Epoch 21 of 60 took 126.368s
  training loss:		0.142648
  validation loss:		0.302371
  top 1 accuracy:		75.00 %
  top 2 accuracy:		100.00 %
0.15105201303958893
0.1383380889892578
0.13669393956661224
Batch of classes 1 out of 5 batches
Epoch 22 of 60 took 103.825s
  training loss:		0.140295
  validation loss:		0.398601
  top 1 accuracy:		75.04 %
  top 2 accuracy:		99.48 %
0.13955305516719818
0.14452658593654633
0.13844820857048035
Batch of classes 1 out of 5 batches
Epoch 23 of 60 took 92.248s
  training loss:		0.139860
  validation loss:		0.417579
  top 1 accuracy:		75.19 %
  top 2 accuracy:		97.48 %
0.1376173347234726
0.15180104970932007
0.1415143609046936
Batch of classes 1 out of 5 batches
Epoch 24 of 60 took 107.149s
  training loss:		0.140317
  validation loss:		0.410935
  top 1 accuracy:		75.02 %
  top 2 accuracy:		99.48 %
0.13908633589744568
0.1375938206911087
0.14158228039741516
Batch of classes 1 out of 5 batches
Epoch 25 of 60 took 96.810s
  training loss:		0.140489
  validation loss:		0.457082
  top 1 accuracy:		75.02 %
  top 2 accuracy:		98.60 %
0.13767029345035553
0.1413859874010086
0.13693994283676147
Batch of classes 1 out of 5 batches
Epoch 26 of 60 took 94.320s
  training loss:		0.140927
  validation loss:		0.415343
  top 1 accuracy:		75.00 %
  top 2 accuracy:		98.65 %
0.13565608859062195
0.137450709939003
0.13608913123607635
Batch of classes 1 out of 5 batches
Epoch 27 of 60 took 110.725s
  training loss:		0.138851
  validation loss:		0.315480
  top 1 accuracy:		75.08 %
  top 2 accuracy:		99.77 %
0.13981656730175018
0.15400676429271698
0.13578210771083832
Batch of classes 1 out of 5 batches
Epoch 28 of 60 took 177.670s
  training loss:		0.139755
  validation loss:		0.265814
  top 1 accuracy:		76.02 %
  top 2 accuracy:		99.94 %
0.13680866360664368
0.13856616616249084
0.14242205023765564
Batch of classes 1 out of 5 batches
Epoch 29 of 60 took 202.246s
  training loss:		0.139561
  validation loss:		0.190746
  top 1 accuracy:		77.23 %
  top 2 accuracy:		100.00 %
0.1358094960451126
0.13778740167617798
0.14602449536323547
Batch of classes 1 out of 5 batches
Epoch 30 of 60 took 184.575s
  training loss:		0.139605
  validation loss:		0.191079
  top 1 accuracy:		76.42 %
  top 2 accuracy:		99.94 %
0.1371760219335556
0.13830290734767914
0.13467244803905487
Batch of classes 1 out of 5 batches
Epoch 31 of 60 took 183.671s
  training loss:		0.137713
  validation loss:		0.274986
  top 1 accuracy:		75.29 %
  top 2 accuracy:		99.81 %
0.138144850730896
0.13593371212482452
0.13834530115127563
Batch of classes 1 out of 5 batches
Epoch 32 of 60 took 192.096s
  training loss:		0.138598
  validation loss:		0.485354
  top 1 accuracy:		70.35 %
  top 2 accuracy:		99.12 %
0.13750334084033966
0.13509410619735718
0.13339123129844666
Batch of classes 1 out of 5 batches
Epoch 33 of 60 took 168.549s
  training loss:		0.138851
  validation loss:		0.290856
  top 1 accuracy:		75.85 %
  top 2 accuracy:		99.75 %
0.13654306530952454
0.1350947767496109
0.13720926642417908
Batch of classes 1 out of 5 batches
Epoch 34 of 60 took 179.802s
  training loss:		0.137524
  validation loss:		0.332320
  top 1 accuracy:		75.15 %
  top 2 accuracy:		99.81 %
0.13430674374103546
0.13420380651950836
0.1361238956451416
Batch of classes 1 out of 5 batches
Epoch 35 of 60 took 182.153s
  training loss:		0.138161
  validation loss:		0.241530
  top 1 accuracy:		75.63 %
  top 2 accuracy:		100.00 %
0.14214083552360535
0.1340617686510086
0.13727536797523499
Batch of classes 1 out of 5 batches
Epoch 36 of 60 took 160.318s
  training loss:		0.138229
  validation loss:		0.451261
  top 1 accuracy:		75.02 %
  top 2 accuracy:		97.21 %
0.13670963048934937
0.13368035852909088
0.13696758449077606
Batch of classes 1 out of 5 batches
Epoch 37 of 60 took 151.521s
  training loss:		0.137145
  validation loss:		0.240715
  top 1 accuracy:		76.44 %
  top 2 accuracy:		99.87 %
0.13564401865005493
0.13635288178920746
0.13567011058330536
Batch of classes 1 out of 5 batches
Epoch 38 of 60 took 185.019s
  training loss:		0.137171
  validation loss:		0.346627
  top 1 accuracy:		75.23 %
  top 2 accuracy:		98.33 %
0.14939159154891968
0.13778802752494812
0.13476069271564484
Batch of classes 1 out of 5 batches
Epoch 39 of 60 took 186.312s
  training loss:		0.137580
  validation loss:		0.400453
  top 1 accuracy:		75.02 %
  top 2 accuracy:		96.92 %
0.14405691623687744
0.13598011434078217
0.13428300619125366
Batch of classes 1 out of 5 batches
Epoch 40 of 60 took 184.804s
  training loss:		0.136453
  validation loss:		0.258918
  top 1 accuracy:		75.44 %
  top 2 accuracy:		100.00 %
0.13376039266586304
0.14922967553138733
0.13389074802398682
Batch of classes 1 out of 5 batches
Epoch 41 of 60 took 186.961s
  training loss:		0.135750
  validation loss:		0.194824
  top 1 accuracy:		77.54 %
  top 2 accuracy:		99.98 %
0.1339711993932724
0.1336386650800705
0.13406838476657867
Batch of classes 1 out of 5 batches
Epoch 42 of 60 took 187.859s
  training loss:		0.134900
  validation loss:		0.331098
  top 1 accuracy:		75.17 %
  top 2 accuracy:		99.90 %
0.1336410492658615
0.13311882317066193
0.1334477812051773
Batch of classes 1 out of 5 batches
Epoch 43 of 60 took 191.156s
  training loss:		0.134674
  validation loss:		0.184962
  top 1 accuracy:		77.25 %
  top 2 accuracy:		100.00 %
0.1344628483057022
0.13225704431533813
0.13344243168830872
Batch of classes 1 out of 5 batches
Epoch 44 of 60 took 177.953s
  training loss:		0.134593
  validation loss:		0.352890
  top 1 accuracy:		75.27 %
  top 2 accuracy:		99.08 %
0.13203860819339752
0.13281360268592834
0.1316484808921814
Batch of classes 1 out of 5 batches
Epoch 45 of 60 took 196.022s
  training loss:		0.133742
  validation loss:		0.310430
  top 1 accuracy:		75.63 %
  top 2 accuracy:		99.21 %
0.1338895559310913
0.13442327082157135
0.13332775235176086
Batch of classes 1 out of 5 batches
Epoch 46 of 60 took 214.202s
  training loss:		0.134215
  validation loss:		0.436305
  top 1 accuracy:		75.02 %
  top 2 accuracy:		94.79 %
0.13220466673374176
0.13288722932338715
0.13239584863185883
Batch of classes 1 out of 5 batches
Epoch 47 of 60 took 222.623s
  training loss:		0.133554
  validation loss:		0.484521
  top 1 accuracy:		75.02 %
  top 2 accuracy:		90.77 %
0.1327284723520279
0.13223691284656525
0.13207848370075226
Batch of classes 1 out of 5 batches
Epoch 48 of 60 took 232.382s
  training loss:		0.132908
  validation loss:		0.392911
  top 1 accuracy:		75.00 %
  top 2 accuracy:		98.73 %
0.1322927623987198
0.13310879468917847
0.13367198407649994
Batch of classes 1 out of 5 batches
Epoch 49 of 60 took 234.576s
  training loss:		0.133896
  validation loss:		0.442570
  top 1 accuracy:		75.02 %
  top 2 accuracy:		96.04 %
0.13320009410381317
0.13448771834373474
0.1362660676240921
Batch of classes 1 out of 5 batches
Epoch 50 of 60 took 191.619s
  training loss:		0.133816
  validation loss:		0.375551
  top 1 accuracy:		75.17 %
  top 2 accuracy:		98.21 %
0.13584136962890625
0.1309245228767395
0.13358519971370697
Batch of classes 1 out of 5 batches
Epoch 51 of 60 took 84.651s
  training loss:		0.134167
  validation loss:		0.206664
  top 1 accuracy:		77.50 %
  top 2 accuracy:		99.92 %
0.13409681618213654
0.13222815096378326
0.1329001635313034
Batch of classes 1 out of 5 batches
Epoch 52 of 60 took 80.131s
  training loss:		0.133209
  validation loss:		0.316025
  top 1 accuracy:		75.44 %
  top 2 accuracy:		98.77 %
0.1343807429075241
0.13380730152130127
0.13378868997097015
Batch of classes 1 out of 5 batches
Epoch 53 of 60 took 82.037s
  training loss:		0.132754
  validation loss:		0.320916
  top 1 accuracy:		75.50 %
  top 2 accuracy:		99.31 %
0.1350616067647934
0.13259676098823547
0.14108450710773468
Batch of classes 1 out of 5 batches
Epoch 54 of 60 took 82.592s
  training loss:		0.133412
  validation loss:		0.324170
  top 1 accuracy:		75.81 %
  top 2 accuracy:		98.62 %
0.13625991344451904
0.13218751549720764
0.13186736404895782
Batch of classes 1 out of 5 batches
Epoch 55 of 60 took 82.286s
  training loss:		0.133196
  validation loss:		0.267010
  top 1 accuracy:		75.98 %
  top 2 accuracy:		99.65 %
0.1321907490491867
0.13060292601585388
0.13240349292755127
Batch of classes 1 out of 5 batches
Epoch 56 of 60 took 103.370s
  training loss:		0.132231
  validation loss:		0.487764
  top 1 accuracy:		75.15 %
  top 2 accuracy:		93.25 %
0.13187634944915771
0.13120640814304352
0.13503944873809814
Batch of classes 1 out of 5 batches
Epoch 57 of 60 took 201.919s
  training loss:		0.132068
  validation loss:		0.315755
  top 1 accuracy:		75.06 %
  top 2 accuracy:		99.29 %
0.13154691457748413
0.1316126137971878
0.13079993426799774
Batch of classes 1 out of 5 batches
Epoch 58 of 60 took 167.630s
  training loss:		0.132044
  validation loss:		0.349273
  top 1 accuracy:		75.10 %
  top 2 accuracy:		99.12 %
0.13378436863422394
0.13309425115585327
0.1315128654241562
Batch of classes 1 out of 5 batches
Epoch 59 of 60 took 84.243s
  training loss:		0.132657
  validation loss:		0.397288
  top 1 accuracy:		75.33 %
  top 2 accuracy:		95.52 %
0.1312558799982071
0.13192950189113617
0.13312150537967682
Batch of classes 1 out of 5 batches
Epoch 60 of 60 took 82.174s
  training loss:		0.132403
  validation loss:		0.381339
  top 1 accuracy:		75.52 %
  top 2 accuracy:		96.88 %
Updating exemplar set...
Computing mean-of_exemplars and theoretical mean...
tensor(256)
tensor(256)
Computing accuracy on the original batch of classes...
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		75.54 %
  top 1 accuracy Hybrid 1       :		75.52 %
  top 1 accuracy NCM            :		75.56 %
Binary accuracy:
Final results on cyclegan classes:
  top 1 accuracy iCaRL          :		75.54 %
  top 1 accuracy Hybrid 1       :		75.52 %
  top 1 accuracy NCM            :		75.56 %
Final results on cumul of classes:
  top 1 accuracy iCaRL          :		75.54 %
  top 1 accuracy Hybrid 1       :		75.52 %
  top 1 accuracy NCM            :		75.56 %
Binary accuracy:
Final results on binary cumul of classes:
  top 1 accuracy iCaRL          :		75.54 %
  top 1 accuracy Hybrid 1       :		75.52 %
  top 1 accuracy NCM            :		75.56 %
Classes in this batch: tensor([2, 3])
Data Size: 7200


Before first epoch
  validation loss:		6.377837
  top 1 accuracy:		0.00 %
  top 2 accuracy:		0.00 %
Batch of classes number 2 arrives ...
0.9975544214248657
0.2562243938446045
0.2488342523574829
Batch of classes 2 out of 5 batches
Epoch 1 of 60 took 182.661s
  training loss:		0.287848
  validation loss:		0.167490
  top 1 accuracy:		45.19 %
  top 2 accuracy:		92.56 %
0.2560010552406311
0.2572484016418457
0.24194693565368652
Batch of classes 2 out of 5 batches
Epoch 2 of 60 took 101.751s
  training loss:		0.246180
  validation loss:		0.153917
  top 1 accuracy:		49.58 %
  top 2 accuracy:		98.44 %
0.24995440244674683
0.23845955729484558
0.24099907279014587
Batch of classes 2 out of 5 batches
Epoch 3 of 60 took 98.119s
  training loss:		0.225790
  validation loss:		0.056439
  top 1 accuracy:		90.85 %
  top 2 accuracy:		99.52 %
0.1927037090063095
0.20256641507148743
0.19659166038036346
Batch of classes 2 out of 5 batches
Epoch 4 of 60 took 98.144s
  training loss:		0.201823
  validation loss:		0.039949
  top 1 accuracy:		95.38 %
  top 2 accuracy:		99.79 %
0.16220638155937195
0.1994415819644928
0.20425552129745483
Batch of classes 2 out of 5 batches
Epoch 5 of 60 took 97.736s
  training loss:		0.174589
  validation loss:		0.020644
  top 1 accuracy:		97.83 %
  top 2 accuracy:		99.94 %
0.1480286717414856
0.17573074996471405
0.15361715853214264
Batch of classes 2 out of 5 batches
Epoch 6 of 60 took 98.746s
  training loss:		0.159601
  validation loss:		0.038719
  top 1 accuracy:		93.50 %
  top 2 accuracy:		99.81 %
0.14994263648986816
0.1548539400100708
0.15215374529361725
Batch of classes 2 out of 5 batches
Epoch 7 of 60 took 97.980s
  training loss:		0.155866
  validation loss:		0.066988
  top 1 accuracy:		85.69 %
  top 2 accuracy:		99.58 %
0.1617579609155655
0.14711090922355652
0.1379740685224533
Batch of classes 2 out of 5 batches
Epoch 8 of 60 took 95.075s
  training loss:		0.152919
  validation loss:		0.024978
  top 1 accuracy:		95.85 %
  top 2 accuracy:		99.85 %
0.14652837812900543
0.15417395532131195
0.14727216958999634
Batch of classes 2 out of 5 batches
Epoch 9 of 60 took 98.063s
  training loss:		0.152745
  validation loss:		0.007453
  top 1 accuracy:		99.21 %
  top 2 accuracy:		99.98 %
0.1425085812807083
0.16658039391040802
0.15085814893245697
Batch of classes 2 out of 5 batches
Epoch 10 of 60 took 98.531s
  training loss:		0.147908
  validation loss:		0.017759
  top 1 accuracy:		97.87 %
  top 2 accuracy:		99.79 %
0.15014544129371643
0.14053405821323395
0.15542413294315338
slurmstepd: error: *** JOB 541122 ON biwirender14 CANCELLED AT 2022-03-14T15:39:01 ***
